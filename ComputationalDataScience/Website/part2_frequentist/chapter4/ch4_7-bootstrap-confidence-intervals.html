

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Section 4.7 Bootstrap Confidence Intervals: Advanced Methods &mdash; STAT 418</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=3d0abd52" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT418/Website/part2_frequentist/chapter4/ch4_7-bootstrap-confidence-intervals.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Show solution';</script>
      <script>let toggleHintHide = 'Hide solution';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=8718e0ab"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Part III: Bayesian Inference" href="../../part3_bayesian/index.html" />
    <link rel="prev" title="Section 4.6 Bootstrap Hypothesis Testing and Permutation Tests" href="ch4_6-bootstrap-hypothesis-testing.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Course Content</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../part1_foundations/index.html">Part I: Foundations of Probability and Computation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part1_foundations/chapter1/index.html">Chapter 1: Statistical Paradigms and Core Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html">Section 1.1 Paradigms of Probability and Statistical Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#the-mathematical-foundation-kolmogorov-s-axioms">The Mathematical Foundation: Kolmogorov’s Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#interpretations-of-probability">Interpretations of Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#statistical-inference-paradigms">Statistical Inference Paradigms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#historical-and-philosophical-debates">Historical and Philosophical Debates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#looking-ahead-our-course-focus">Looking Ahead: Our Course Focus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html">Section 1.2 Probability Distributions: Theory and Computation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#from-abstract-foundations-to-concrete-tools">From Abstract Foundations to Concrete Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#the-python-ecosystem-for-probability">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#introduction-why-probability-distributions-matter">Introduction: Why Probability Distributions Matter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#id1">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#continuous-distributions">Continuous Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#additional-important-distributions">Additional Important Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#summary-and-practical-guidelines">Summary and Practical Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#conclusion">Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html">Section 1.3 Python Random Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#from-mathematical-distributions-to-computational-samples">From Mathematical Distributions to Computational Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#the-python-ecosystem-at-a-glance">The Python Ecosystem at a Glance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#understanding-pseudo-random-number-generation">Understanding Pseudo-Random Number Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#the-standard-library-random-module">The Standard Library: <code class="docutils literal notranslate"><span class="pre">random</span></code> Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#numpy-fast-vectorized-random-sampling">NumPy: Fast Vectorized Random Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#scipy-stats-the-complete-statistical-toolkit">SciPy Stats: The Complete Statistical Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#bringing-it-all-together-library-selection-guide">Bringing It All Together: Library Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#looking-ahead-from-random-numbers-to-monte-carlo-methods">Looking Ahead: From Random Numbers to Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html">Section 1.4 Chapter 1 Summary: Foundations in Place</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#the-three-pillars-of-chapter-1">The Three Pillars of Chapter 1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#what-lies-ahead-the-road-to-simulation">What Lies Ahead: The Road to Simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#chapter-1-exercises-synthesis-problems">Chapter 1 Exercises: Synthesis Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../part1_foundations/chapter2/index.html">Chapter 2: Monte Carlo Simulation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html">Section 2.1 Monte Carlo Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#the-historical-development-of-monte-carlo-methods">The Historical Development of Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#the-core-principle-expectation-as-integration">The Core Principle: Expectation as Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#theoretical-foundations">Theoretical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#variance-estimation-and-confidence-intervals">Variance Estimation and Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#comparison-with-deterministic-methods">Comparison with Deterministic Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#sample-size-determination">Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#convergence-diagnostics-and-monitoring">Convergence Diagnostics and Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#chapter-2-1-exercises-monte-carlo-fundamentals-mastery">Chapter 2.1 Exercises: Monte Carlo Fundamentals Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#id1">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html">Section 2.2 Uniform Random Variates</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#why-uniform-the-universal-currency-of-randomness">Why Uniform? The Universal Currency of Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#the-paradox-of-computational-randomness">The Paradox of Computational Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#chaotic-dynamical-systems-an-instructive-failure">Chaotic Dynamical Systems: An Instructive Failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#linear-congruential-generators">Linear Congruential Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#shift-register-generators">Shift-Register Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#the-kiss-generator-combining-strategies">The KISS Generator: Combining Strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#modern-generators-mersenne-twister-and-pcg">Modern Generators: Mersenne Twister and PCG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#statistical-testing-of-random-number-generators">Statistical Testing of Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#chapter-2-2-exercises-uniform-random-variates-mastery">Chapter 2.2 Exercises: Uniform Random Variates Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html">Section 2.3 Inverse CDF Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#mathematical-foundations">Mathematical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#continuous-distributions-with-closed-form-inverses">Continuous Distributions with Closed-Form Inverses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#numerical-inversion">Numerical Inversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#mixed-distributions">Mixed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#chapter-2-3-exercises-inverse-cdf-method-mastery">Chapter 2.3 Exercises: Inverse CDF Method Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#id1">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html">Section 2.4 Transformation Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#why-transformation-methods">Why Transformation Methods?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#the-boxmuller-transform">The Box–Muller Transform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#the-polar-marsaglia-method">The Polar (Marsaglia) Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#method-comparison-boxmuller-vs-polar-vs-ziggurat">Method Comparison: Box–Muller vs Polar vs Ziggurat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#the-ziggurat-algorithm">The Ziggurat Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#the-clt-approximation-historical">The CLT Approximation (Historical)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#distributions-derived-from-the-normal">Distributions Derived from the Normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#multivariate-normal-generation">Multivariate Normal Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#implementation-guidance">Implementation Guidance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#chapter-2-4-exercises-transformation-methods-mastery">Chapter 2.4 Exercises: Transformation Methods Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html">Section 2.5 Rejection Sampling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#the-dartboard-intuition">The Dartboard Intuition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#the-accept-reject-algorithm">The Accept-Reject Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#efficiency-analysis">Efficiency Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#choosing-the-proposal-distribution">Choosing the Proposal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#the-squeeze-principle">The Squeeze Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#geometric-example-sampling-from-the-unit-disk">Geometric Example: Sampling from the Unit Disk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#limitations-and-the-curse-of-dimensionality">Limitations and the Curse of Dimensionality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#connections-to-other-methods">Connections to Other Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#chapter-2-5-exercises-rejection-sampling-mastery">Chapter 2.5 Exercises: Rejection Sampling Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html">Section 2.6 Variance Reduction Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#the-variance-reduction-paradigm">The Variance Reduction Paradigm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#importance-sampling">Importance Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#control-variates">Control Variates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#antithetic-variates">Antithetic Variates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#stratified-sampling">Stratified Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#common-random-numbers">Common Random Numbers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#conditional-monte-carlo-raoblackwellization">Conditional Monte Carlo (Rao–Blackwellization)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#combining-variance-reduction-techniques">Combining Variance Reduction Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#chapter-2-6-exercises-variance-reduction-mastery">Chapter 2.6 Exercises: Variance Reduction Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html">Section 2.7 Chapter 2 Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#the-complete-monte-carlo-workflow">The Complete Monte Carlo Workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#quick-reference-tables">Quick Reference Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#common-pitfalls-checklist">Common Pitfalls Checklist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#connections-to-later-chapters">Connections to Later Chapters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#learning-outcomes-checklist">Learning Outcomes Checklist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#further-reading-optimization-and-missing-data">Further Reading: Optimization and Missing Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#final-perspective">Final Perspective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Part II: Frequentist Inference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../chapter3/index.html">Chapter 3: Parametric Inference and Likelihood Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html">Section 3.1 Exponential Families</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#historical-origins-from-scattered-results-to-unified-theory">Historical Origins: From Scattered Results to Unified Theory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#the-canonical-exponential-family">The Canonical Exponential Family</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#converting-familiar-distributions">Converting Familiar Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#the-log-partition-function-a-moment-generating-machine">The Log-Partition Function: A Moment-Generating Machine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#sufficiency-capturing-all-parameter-information">Sufficiency: Capturing All Parameter Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#minimal-sufficiency-and-completeness">Minimal Sufficiency and Completeness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#conjugate-priors-and-bayesian-inference">Conjugate Priors and Bayesian Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#exponential-dispersion-models-and-glms">Exponential Dispersion Models and GLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#chapter-3-1-exercises-exponential-families-mastery">Chapter 3.1 Exercises: Exponential Families Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html">Section 3.2 Maximum Likelihood Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-likelihood-function">The Likelihood Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-score-function">The Score Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#fisher-information">Fisher Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#closed-form-maximum-likelihood-estimators">Closed-Form Maximum Likelihood Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#numerical-optimization-for-mle">Numerical Optimization for MLE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#asymptotic-properties-of-mles">Asymptotic Properties of MLEs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-cramer-rao-lower-bound">The Cramér-Rao Lower Bound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-invariance-property">The Invariance Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#likelihood-based-hypothesis-testing">Likelihood-Based Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#confidence-intervals-from-likelihood">Confidence Intervals from Likelihood</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#connection-to-bayesian-inference">Connection to Bayesian Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#chapter-3-2-exercises-maximum-likelihood-estimation-mastery">Chapter 3.2 Exercises: Maximum Likelihood Estimation Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html">Section 3.3 Sampling Variability and Variance Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#statistical-estimators-and-their-properties">Statistical Estimators and Their Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#sampling-distributions">Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#the-delta-method">The Delta Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#the-plug-in-principle">The Plug-in Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#variance-estimation-methods">Variance Estimation Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#applications-and-worked-examples">Applications and Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html">Section 3.4 Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#matrix-calculus-foundations">Matrix Calculus Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#the-linear-model">The Linear Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#ordinary-least-squares-the-calculus-approach">Ordinary Least Squares: The Calculus Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#ordinary-least-squares-the-geometric-approach">Ordinary Least Squares: The Geometric Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#properties-of-the-ols-estimator">Properties of the OLS Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#the-gauss-markov-theorem">The Gauss-Markov Theorem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#estimating-the-error-variance">Estimating the Error Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#distributional-results-under-normality">Distributional Results Under Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#diagnostics-and-model-checking">Diagnostics and Model Checking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#numerical-stability-qr-decomposition">Numerical Stability: QR Decomposition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#model-selection-and-information-criteria">Model Selection and Information Criteria</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#regularization-ridge-and-lasso">Regularization: Ridge and LASSO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#chapter-3-4-exercises-linear-models-mastery">Chapter 3.4 Exercises: Linear Models Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html">Section 3.5 Generalized Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#historical-context-unification-of-regression-methods">Historical Context: Unification of Regression Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#the-glm-framework-three-components">The GLM Framework: Three Components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#score-equations-and-fisher-information">Score Equations and Fisher Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#iteratively-reweighted-least-squares">Iteratively Reweighted Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#logistic-regression-binary-outcomes">Logistic Regression: Binary Outcomes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#poisson-regression-count-data">Poisson Regression: Count Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#gamma-regression-positive-continuous-data">Gamma Regression: Positive Continuous Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#inference-in-glms-the-testing-triad">Inference in GLMs: The Testing Triad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#model-diagnostics">Model Diagnostics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#model-comparison-and-selection">Model Comparison and Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#quasi-likelihood-and-robust-inference">Quasi-Likelihood and Robust Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#further-reading">Further Reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#chapter-3-5-exercises-generalized-linear-models-mastery">Chapter 3.5 Exercises: Generalized Linear Models Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html">Section 3.6 Chapter 3 Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#the-parametric-inference-pipeline">The Parametric Inference Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#the-five-pillars-of-chapter-3">The Five Pillars of Chapter 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#quick-reference-core-formulas">Quick Reference: Core Formulas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#connections-to-future-material">Connections to Future Material</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#practical-guidance">Practical Guidance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#final-perspective">Final Perspective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Chapter 4: Resampling Methods</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html">Section 4.1 The Sampling Distribution Problem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#the-fundamental-target-sampling-distributions">The Fundamental Target: Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#historical-development-the-quest-for-sampling-distributions">Historical Development: The Quest for Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#three-routes-to-the-sampling-distribution">Three Routes to the Sampling Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#when-asymptotics-fail-motivating-the-bootstrap">When Asymptotics Fail: Motivating the Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#the-plug-in-principle-theoretical-foundation">The Plug-In Principle: Theoretical Foundation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#computational-perspective-bootstrap-as-monte-carlo">Computational Perspective: Bootstrap as Monte Carlo</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#chapter-4-1-exercises">Chapter 4.1 Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html">Section 4.2 The Empirical Distribution and Plug-in Principle</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#the-empirical-cumulative-distribution-function">The Empirical Cumulative Distribution Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#convergence-of-the-empirical-cdf">Convergence of the Empirical CDF</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#parameters-as-statistical-functionals">Parameters as Statistical Functionals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#the-plug-in-principle">The Plug-in Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#when-the-plug-in-principle-fails">When the Plug-in Principle Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#the-bootstrap-idea-in-one-sentence">The Bootstrap Idea in One Sentence</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#computational-implementation">Computational Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#section-4-2-exercises-ecdf-and-plug-in-mastery">Section 4.2 Exercises: ECDF and Plug-in Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html">Section 4.3 The Nonparametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#the-bootstrap-principle">The Bootstrap Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bootstrap-standard-errors">Bootstrap Standard Errors</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bootstrap-bias-estimation">Bootstrap Bias Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bootstrap-confidence-intervals">Bootstrap Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bootstrap-for-regression">Bootstrap for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bootstrap-diagnostics">Bootstrap Diagnostics</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#when-bootstrap-fails">When Bootstrap Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch4_4-parametric-bootstrap.html">Section 4.4: The Parametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#the-parametric-bootstrap-principle">The Parametric Bootstrap Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#location-scale-families">Location-Scale Families</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#parametric-bootstrap-for-regression">Parametric Bootstrap for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#confidence-intervals">Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#model-checking-and-validation">Model Checking and Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#when-parametric-bootstrap-fails">When Parametric Bootstrap Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#parametric-vs-nonparametric-a-decision-framework">Parametric vs. Nonparametric: A Decision Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch4_5-jackknife-methods.html">Section 4.5: Jackknife Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#historical-context-and-motivation">Historical Context and Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#the-delete-1-jackknife">The Delete-1 Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#jackknife-bias-estimation">Jackknife Bias Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#the-delete-d-jackknife">The Delete-<span class="math notranslate nohighlight">\(d\)</span> Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#jackknife-versus-bootstrap">Jackknife versus Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#the-infinitesimal-jackknife">The Infinitesimal Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html">Section 4.6 Bootstrap Hypothesis Testing and Permutation Tests</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#from-confidence-intervals-to-hypothesis-tests">From Confidence Intervals to Hypothesis Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#the-bootstrap-hypothesis-testing-framework">The Bootstrap Hypothesis Testing Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#permutation-tests-exact-tests-under-exchangeability">Permutation Tests: Exact Tests Under Exchangeability</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#testing-equality-of-distributions">Testing Equality of Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#bootstrap-tests-for-regression">Bootstrap Tests for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#bootstrap-vs-classical-tests">Bootstrap vs Classical Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#permutation-vs-bootstrap-choosing-the-right-approach">Permutation vs Bootstrap: Choosing the Right Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#multiple-testing-with-bootstrap">Multiple Testing with Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Section 4.7 Bootstrap Confidence Intervals: Advanced Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#why-advanced-methods">Why Advanced Methods?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-studentized-bootstrap-t-interval">The Studentized (Bootstrap-t) Interval</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bias-corrected-bc-intervals">Bias-Corrected (BC) Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bias-corrected-and-accelerated-bca-intervals">Bias-Corrected and Accelerated (BCa) Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="#choosing-b-and-assessing-monte-carlo-error">Choosing B and Assessing Monte Carlo Error</a></li>
<li class="toctree-l4"><a class="reference internal" href="#diagnostics-for-advanced-bootstrap-methods">Diagnostics for Advanced Bootstrap Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="#chapter-4-7-exercises-bootstrap-confidence-interval-mastery">Chapter 4.7 Exercises: Bootstrap Confidence Interval Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part3_bayesian/index.html">Part III: Bayesian Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part3_bayesian/chapter5/index.html">Chapter 5: Bayesian Inference</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part4_llms_datascience/index.html">Part IV: Large Language Models in Data Science</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part4_llms_datascience/chapter6/index.html">Chapter 6: LLMs in Data Science Workflows</a><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Part II: Frequentist Inference</a></li>
          <li class="breadcrumb-item"><a href="index.html">Chapter 4: Resampling Methods</a></li>
      <li class="breadcrumb-item active">Section 4.7 Bootstrap Confidence Intervals: Advanced Methods</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/part2_frequentist/chapter4/ch4_7-bootstrap-confidence-intervals.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="section-4-7-bootstrap-confidence-intervals-advanced-methods">
<span id="ch4-7-bootstrap-confidence-intervals"></span><h1>Section 4.7 Bootstrap Confidence Intervals: Advanced Methods<a class="headerlink" href="#section-4-7-bootstrap-confidence-intervals-advanced-methods" title="Link to this heading"></a></h1>
<p>In <a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#ch4-3-nonparametric-bootstrap"><span class="std std-ref">Section 4.3</span></a>, we introduced three basic bootstrap confidence interval methods: the percentile interval, the basic (pivotal) interval, and the normal approximation. These methods are intuitive, easy to implement, and often adequate for exploratory analysis. However, they share a fundamental limitation: their coverage accuracy degrades in predictable ways when the bootstrap distribution is skewed, when the estimator is biased, or when the standard error varies with the parameter value. This section develops <strong>advanced bootstrap interval methods</strong>—the studentized (bootstrap-t) interval and the bias-corrected and accelerated (BCa) interval—that achieve improved coverage accuracy by addressing these sources of error systematically.</p>
<p>The distinction between “first-order” and “second-order” accurate methods has profound practical consequences. For a nominal 95% confidence interval at moderate sample sizes (often n ≈ 30–100), first order methods can exhibit noticeable undercoverage in skewed or biased settings, especially for one sided inference; second order methods typically reduce this error substantially. The magnitude depends on the functional and the underlying distribution.
Throughout this section, we build on tools developed earlier: the jackknife estimates <span class="math notranslate nohighlight">\(\hat{\theta}_{(-i)}\)</span> from <a class="reference internal" href="ch4_5-jackknife-methods.html#ch4-5-jackknife-methods"><span class="std std-ref">Section 4.5</span></a> are essential for computing the BCa acceleration constant, and the bootstrap distribution <span class="math notranslate nohighlight">\(\{\hat{\theta}^*_b\}\)</span> from <a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#ch4-3-nonparametric-bootstrap"><span class="std std-ref">Section 4.3</span></a> remains our primary computational object. We also address a practical concern that pervades all bootstrap inference: <strong>Monte Carlo error</strong> from using finitely many bootstrap replicates <span class="math notranslate nohighlight">\(B\)</span>. Understanding and controlling this error is essential for reporting results responsibly.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p><strong>Understand</strong>: Why percentile and basic intervals have coverage deficiencies, and how Edgeworth expansions characterize coverage error rates</p></li>
<li><p><strong>Develop</strong>: The studentized bootstrap and BCa intervals as two routes to second-order accuracy</p></li>
<li><p><strong>Implement</strong>: Complete Python implementations with proper numerical handling of edge cases</p></li>
<li><p><strong>Evaluate</strong>: Diagnostic tools for method selection and Monte Carlo error quantification</p></li>
</ul>
</div>
<section id="why-advanced-methods">
<h2>Why Advanced Methods?<a class="headerlink" href="#why-advanced-methods" title="Link to this heading"></a></h2>
<p>Before developing sophisticated interval constructions, we must understand <em>why</em> simple methods fall short. The answer lies in the structure of sampling distributions and how bootstrap approximations inherit—or fail to correct—systematic errors.</p>
<section id="the-coverage-probability-target">
<h3>The Coverage Probability Target<a class="headerlink" href="#the-coverage-probability-target" title="Link to this heading"></a></h3>
<p>A confidence interval procedure produces a random interval <span class="math notranslate nohighlight">\([\hat{L}_n, \hat{U}_n]\)</span> that depends on the observed data <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span>. The <strong>coverage probability</strong> is the chance that this random interval contains the true parameter:</p>
<div class="math notranslate nohighlight" id="equation-coverage-def">
<span class="eqno">(192)<a class="headerlink" href="#equation-coverage-def" title="Link to this equation"></a></span>\[C_n(F) = P_F\bigl(\theta \in [\hat{L}_n, \hat{U}_n]\bigr)\]</div>
<p>where the probability is taken over the sampling distribution of the data under the true distribution <span class="math notranslate nohighlight">\(F\)</span>. For a nominal <span class="math notranslate nohighlight">\((1-\alpha)\)</span> confidence interval, we want <span class="math notranslate nohighlight">\(C_n(F) = 1 - \alpha\)</span> for all <span class="math notranslate nohighlight">\(F\)</span> in some class of interest. In practice, we settle for <span class="math notranslate nohighlight">\(C_n(F) \approx 1 - \alpha\)</span> when <span class="math notranslate nohighlight">\(n\)</span> is large.</p>
<p>The <strong>coverage error</strong> is the difference between actual and nominal coverage:</p>
<div class="math notranslate nohighlight">
\[\text{Coverage Error} = C_n(F) - (1 - \alpha)\]</div>
<p>A positive coverage error means the interval is conservative (over-covers); a negative error means the interval is liberal (under-covers). Neither is desirable, but under-coverage is typically more problematic since it leads to overconfident inference.</p>
<div class="tip admonition">
<p class="admonition-title">Coverage Is Not Random</p>
<p>A common confusion: coverage probability <span class="math notranslate nohighlight">\(C_n(F)\)</span> is a <em>fixed number</em> for given <span class="math notranslate nohighlight">\(F\)</span> and <span class="math notranslate nohighlight">\(n\)</span>, not a random variable. Once we specify the data-generating distribution <span class="math notranslate nohighlight">\(F\)</span>, the coverage probability is determined by integrating over all possible samples. The big-<span class="math notranslate nohighlight">\(O\)</span> notation we use below describes how this fixed quantity behaves as <span class="math notranslate nohighlight">\(n \to \infty\)</span>.</p>
</div>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig01_coverage_concept.png"><img alt="Coverage Probability Concept" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig01_coverage_concept.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 175 </span><span class="caption-text"><strong>Figure 4.7.1</strong>: Coverage probability visualized. (a) A single confidence interval either contains (✓) or misses (✗) the true parameter—we cannot know which from the data alone. (b) Over many repetitions from the same population, the coverage probability is the long-run proportion of intervals that contain the truth. (c) The formal definition: coverage is the probability that the random interval captures the fixed but unknown parameter.</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="edgeworth-expansions-and-coverage-error-rates">
<h3>Edgeworth Expansions and Coverage Error Rates<a class="headerlink" href="#edgeworth-expansions-and-coverage-error-rates" title="Link to this heading"></a></h3>
<p>The key theoretical tool for understanding coverage error is the <strong>Edgeworth expansion</strong>, which refines the Central Limit Theorem by providing correction terms that capture departures from normality at finite sample sizes.</p>
<p>For a standardized statistic <span class="math notranslate nohighlight">\(Z_n = \sqrt{n}(\hat{\theta} - \theta)/\sigma\)</span>, the distribution function admits an expansion of the form:</p>
<div class="math notranslate nohighlight" id="equation-edgeworth-basic">
<span class="eqno">(193)<a class="headerlink" href="#equation-edgeworth-basic" title="Link to this equation"></a></span>\[P(Z_n \leq z) = \Phi(z) + n^{-1/2} p_1(z)\phi(z) + n^{-1} p_2(z)\phi(z) + O(n^{-3/2})\]</div>
<p>where <span class="math notranslate nohighlight">\(\Phi\)</span> and <span class="math notranslate nohighlight">\(\phi\)</span> are the standard normal CDF and PDF, and <span class="math notranslate nohighlight">\(p_1, p_2\)</span> are polynomials whose coefficients depend on the moments of the underlying distribution. Crucially:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p_1(z)\)</span> is an <strong>odd polynomial</strong> (involving skewness)</p></li>
<li><p><span class="math notranslate nohighlight">\(p_2(z)\)</span> is an <strong>even polynomial</strong> (involving kurtosis and skewness squared)</p></li>
</ul>
<p>This structure has profound implications for confidence interval coverage.</p>
<p><strong>One-sided intervals</strong>: For a one-sided interval of the form <span class="math notranslate nohighlight">\((-\infty, \hat{\theta} + z_{1-\alpha} \cdot \hat{\sigma}/\sqrt{n}]\)</span>, the coverage error is dominated by the <span class="math notranslate nohighlight">\(p_1\)</span> term:</p>
<div class="math notranslate nohighlight">
\[C_n(F) = 1 - \alpha + c_1 n^{-1/2} + O(n^{-1})\]</div>
<p>The leading error term is <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span>, which can be substantial for moderate <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p><strong>Two-sided intervals</strong>: For symmetric two-sided intervals, the odd polynomial <span class="math notranslate nohighlight">\(p_1\)</span> contributes errors of opposite sign at the two endpoints, and these partially cancel:</p>
<div class="math notranslate nohighlight">
\[C_n(F) = 1 - \alpha + c_2 n^{-1} + O(n^{-3/2})\]</div>
<p>The leading error is <span class="math notranslate nohighlight">\(O(n^{-1})\)</span>, an order of magnitude smaller than for one-sided intervals.</p>
<p>This asymmetry between one-sided and two-sided coverage is a fundamental feature of confidence interval theory. Methods that achieve <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> coverage error for <em>both</em> one-sided and two-sided intervals are called <strong>second-order accurate</strong>.</p>
<p>Note: symmetric two sided intervals can achieve O(n^{-1}) error via cancellation even when the underlying one sided error remains O(n^{-1/2}); ‘second order accurate’ here refers to constructions that remove the O(n^{-1/2}) term for one sided coverage as well.</p>
</section>
<section id="why-percentile-and-basic-intervals-are-first-order">
<h3>Why Percentile and Basic Intervals Are First-Order<a class="headerlink" href="#why-percentile-and-basic-intervals-are-first-order" title="Link to this heading"></a></h3>
<p>The percentile interval <span class="math notranslate nohighlight">\([Q_{\alpha/2}(\hat{\theta}^*), Q_{1-\alpha/2}(\hat{\theta}^*)]\)</span> uses quantiles of the bootstrap distribution directly. While this captures the shape of the sampling distribution, it inherits systematic errors:</p>
<ol class="arabic simple">
<li><p><strong>Bias drift</strong>: If <span class="math notranslate nohighlight">\(\mathbb{E}[\hat{\theta}] \neq \theta\)</span>, the bootstrap distribution is centered at <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> rather than <span class="math notranslate nohighlight">\(\theta\)</span>, causing the interval to drift.</p></li>
<li><p><strong>Skewness mismatch</strong>: The bootstrap distribution of <span class="math notranslate nohighlight">\(\hat{\theta}^* - \hat{\theta}\)</span> estimates the distribution of <span class="math notranslate nohighlight">\(\hat{\theta} - \theta\)</span>, but the quantiles don’t align perfectly when these distributions are skewed.</p></li>
</ol>
<p>The basic interval <span class="math notranslate nohighlight">\([2\hat{\theta} - Q_{1-\alpha/2}(\hat{\theta}^*), 2\hat{\theta} - Q_{\alpha/2}(\hat{\theta}^*)]\)</span> partially corrects the bias drift by reflecting quantiles about <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>, but it doesn’t address skewness.</p>
<p>For smooth functionals under standard regularity conditions, one sided percentile and basic intervals typically have coverage error <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span>. For symmetric <strong>two-sided</strong> intervals, odd order terms partially cancel, often yielding <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> coverage error. This is why these methods often perform reasonably for two-sided intervals but can have serious coverage problems for one-sided intervals.</p>
<div class="important admonition">
<p class="admonition-title">The Goal of Advanced Methods</p>
<p>Advanced bootstrap interval methods aim to achieve <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> coverage error for <strong>both</strong> one-sided and two-sided intervals. There are two main approaches:</p>
<ol class="arabic simple">
<li><p><strong>Studentization</strong>: Pivot by an estimated standard error, transforming the problem so that the leading odd term in the Edgeworth expansion vanishes.</p></li>
<li><p><strong>Transformation correction (BCa)</strong>: Find quantile adjustments that automatically account for bias and skewness, achieving transformation invariance.</p></li>
</ol>
</div>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig02_coverage_error_rates.png"><img alt="Coverage Error Rates" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig02_coverage_error_rates.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 176 </span><span class="caption-text"><strong>Figure 4.7.2</strong>: Coverage error rates from Edgeworth expansions. (a) The first correction term <span class="math notranslate nohighlight">\(p_1(z)\phi(z)\)</span> is an odd function, contributing <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span> error for one-sided intervals but canceling for two-sided intervals. (b) Comparison of coverage error magnitude: first-order methods (Percentile, Basic, BC) vs second-order methods (BCa, Studentized). (c) Simulation study confirming the theoretical rates—second-order methods approach nominal coverage faster.</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="practical-implications">
<h3>Practical Implications<a class="headerlink" href="#practical-implications" title="Link to this heading"></a></h3>
<p>To make these abstract rates concrete, consider the following rough guide for nominal 95% two-sided intervals:</p>
<table class="docutils align-default" id="id3">
<caption><span class="caption-number">Table 56 </span><span class="caption-text">Typical Coverage by Sample Size and Method</span><a class="headerlink" href="#id3" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(n\)</span></p></th>
<th class="head"><p>Normal Approx</p></th>
<th class="head"><p>Percentile</p></th>
<th class="head"><p>BCa</p></th>
<th class="head"><p>Studentized</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>20</p></td>
<td><p>88–92%</p></td>
<td><p>89–93%</p></td>
<td><p>93–95%</p></td>
<td><p>93–95%</p></td>
</tr>
<tr class="row-odd"><td><p>50</p></td>
<td><p>92–94%</p></td>
<td><p>92–94%</p></td>
<td><p>94–95%</p></td>
<td><p>94–95%</p></td>
</tr>
<tr class="row-even"><td><p>100</p></td>
<td><p>93–95%</p></td>
<td><p>93–95%</p></td>
<td><p>94.5–95%</p></td>
<td><p>94.5–95%</p></td>
</tr>
<tr class="row-odd"><td><p>500</p></td>
<td><p>94.5–95%</p></td>
<td><p>94.5–95%</p></td>
<td><p>~95%</p></td>
<td><p>~95%</p></td>
</tr>
</tbody>
</table>
<p>These are illustrative ranges; actual coverage depends on the statistic and underlying distribution. The key message: for moderate sample sizes, the difference between first-order and second-order methods can be the difference between 91% and 94% actual coverage for a nominal 95% interval.</p>
</section>
</section>
<section id="the-studentized-bootstrap-t-interval">
<h2>The Studentized (Bootstrap-t) Interval<a class="headerlink" href="#the-studentized-bootstrap-t-interval" title="Link to this heading"></a></h2>
<p>The studentized bootstrap, also called the <strong>bootstrap-t</strong> method, extends the classical Student’s t approach to general statistics. The key insight is that dividing by an estimated standard error creates a more <strong>pivotal</strong> quantity—one whose distribution depends less on unknown parameters—and this pivotality translates directly into improved coverage accuracy.</p>
<section id="from-student-s-t-to-bootstrap-t">
<h3>From Student’s t to Bootstrap-t<a class="headerlink" href="#from-student-s-t-to-bootstrap-t" title="Link to this heading"></a></h3>
<p>Recall the classical setting: for iid observations <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> from a normal distribution with unknown mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>, the pivot</p>
<div class="math notranslate nohighlight">
\[T = \frac{\bar{X} - \mu}{S/\sqrt{n}}\]</div>
<p>follows a <span class="math notranslate nohighlight">\(t_{n-1}\)</span> distribution <em>regardless of the values of</em> <span class="math notranslate nohighlight">\(\mu\)</span> <em>and</em> <span class="math notranslate nohighlight">\(\sigma^2\)</span>. This pivotality means that <span class="math notranslate nohighlight">\(t\)</span>-based intervals have exact coverage under normality.</p>
<p>For a general statistic <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> estimating <span class="math notranslate nohighlight">\(\theta\)</span>, we can form an analogous studentized quantity:</p>
<div class="math notranslate nohighlight" id="equation-studentized-pivot">
<span class="eqno">(194)<a class="headerlink" href="#equation-studentized-pivot" title="Link to this equation"></a></span>\[T = \frac{\hat{\theta} - \theta}{\hat{\sigma}}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{\sigma}\)</span> is an estimate of the standard error of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. Unlike the normal-theory case, <span class="math notranslate nohighlight">\(T\)</span> doesn’t have a known distribution—but the bootstrap can estimate it.</p>
</section>
<section id="the-bootstrap-t-algorithm">
<h3>The Bootstrap-t Algorithm<a class="headerlink" href="#the-bootstrap-t-algorithm" title="Link to this heading"></a></h3>
<p>The bootstrap-t method estimates the distribution of <span class="math notranslate nohighlight">\(T\)</span> by computing its bootstrap analog <span class="math notranslate nohighlight">\(T^*\)</span> across many resamples.</p>
<p><strong>Algorithm: Studentized Bootstrap Confidence Interval</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Input: Data X₁,...,Xₙ; statistic T; SE estimator; replicates B; level α
Output: (1-α) studentized bootstrap CI

1. Compute θ̂ = T(X₁,...,Xₙ) and σ̂ = SE(X₁,...,Xₙ)
2. For b = 1,...,B:
   a. Draw bootstrap sample X*₁,...,X*ₙ (with replacement)
   b. Compute θ̂*_b = T(X*₁,...,X*ₙ)
   c. Compute σ̂*_b = SE(X*₁,...,X*ₙ)  [using same SE method]
   d. Compute t*_b = (θ̂*_b - θ̂) / σ̂*_b
3. Let q*_{α/2} and q*_{1-α/2} be the α/2 and (1-α/2) quantiles of {t*_b}
4. Return CI: [θ̂ - σ̂ · q*_{1-α/2}, θ̂ - σ̂ · q*_{α/2}]
</pre></div>
</div>
<p>The crucial step is computing <span class="math notranslate nohighlight">\(\hat{\sigma}^*_b\)</span> <strong>within each bootstrap sample</strong>. This allows the bootstrap distribution of <span class="math notranslate nohighlight">\(T^*\)</span> to capture how the studentized statistic varies, including any relationship between <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> and its standard error.</p>
<div class="note admonition">
<p class="admonition-title">Why the Quantiles Reverse</p>
<p>The interval formula subtracts <span class="math notranslate nohighlight">\(q^*_{1-\alpha/2}\)</span> to get the <em>lower</em> bound and <span class="math notranslate nohighlight">\(q^*_{\alpha/2}\)</span> to get the <em>upper</em> bound. This reversal arises from inverting the pivot relationship:</p>
<div class="math notranslate nohighlight">
\[P\left(q^*_{\alpha/2} \leq \frac{\hat{\theta} - \theta}{\hat{\sigma}} \leq q^*_{1-\alpha/2}\right) \approx 1 - \alpha\]</div>
<p>Solving for <span class="math notranslate nohighlight">\(\theta\)</span>:</p>
<div class="math notranslate nohighlight">
\[P\left(\hat{\theta} - \hat{\sigma} q^*_{1-\alpha/2} \leq \theta \leq \hat{\theta} - \hat{\sigma} q^*_{\alpha/2}\right) \approx 1 - \alpha\]</div>
</div>
</section>
<section id="why-studentization-achieves-second-order-accuracy">
<h3>Why Studentization Achieves Second-Order Accuracy<a class="headerlink" href="#why-studentization-achieves-second-order-accuracy" title="Link to this heading"></a></h3>
<p>The theoretical advantage of studentization can be understood through Edgeworth expansions. For a non-studentized statistic <span class="math notranslate nohighlight">\(\sqrt{n}(\hat{\theta} - \theta)/\sigma\)</span>, the leading correction term <span class="math notranslate nohighlight">\(p_1(z)\)</span> in <a class="reference internal" href="#equation-edgeworth-basic">(193)</a> is an odd polynomial that contributes <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span> error to one-sided coverage.</p>
<p>For the studentized statistic <span class="math notranslate nohighlight">\(T = \sqrt{n}(\hat{\theta} - \theta)/\hat{\sigma}\)</span>, the Edgeworth expansion has the form:</p>
<div class="math notranslate nohighlight">
\[P(T \leq t) = \Phi(t) + n^{-1} q_2(t)\phi(t) + O(n^{-3/2})\]</div>
<p>The <span class="math notranslate nohighlight">\(n^{-1/2}\)</span> term with an odd polynomial is <strong>absent</strong> (or its coefficient is zero). This occurs because studentization absorbs the leading skewness correction into the variance estimation. The technical conditions for this improvement, established by Hall (1988, 1992), include:</p>
<ol class="arabic simple">
<li><p>Finite fourth moments: <span class="math notranslate nohighlight">\(\mathbb{E}|X|^{4+\delta} &lt; \infty\)</span> for some <span class="math notranslate nohighlight">\(\delta &gt; 0\)</span></p></li>
<li><p>Cramér’s condition on the characteristic function (ensuring non-lattice distributions)</p></li>
<li><p>Sufficient smoothness of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> as a function of sample moments</p></li>
<li><p>Consistent variance estimation: <span class="math notranslate nohighlight">\(\hat{\sigma}/\sigma \xrightarrow{p} 1\)</span></p></li>
</ol>
<p>Under these conditions, the studentized bootstrap achieves coverage error <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> for <strong>both</strong> one-sided and two-sided intervals—a full order of magnitude improvement over percentile and basic methods for one-sided intervals.</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig03_studentized_bootstrap.png"><img alt="Studentized Bootstrap Method" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig03_studentized_bootstrap.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 177 </span><span class="caption-text"><strong>Figure 4.7.3</strong>: The studentized (bootstrap-t) method. (a) Comparison of non-studentized vs studentized bootstrap statistics—studentization produces a distribution closer to the reference <span class="math notranslate nohighlight">\(t\)</span> distribution. (b) The bootstrap <span class="math notranslate nohighlight">\(T^*\)</span> distribution with quantiles used for interval construction. (c-d) Explanation of quantile reversal and practical guidance. (e) Confidence interval comparison across methods for normal data. (f) Coverage simulation on exponential data demonstrating studentized method’s advantage for skewed distributions.</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="methods-for-estimating-se-within-bootstrap-samples">
<h3>Methods for Estimating SE Within Bootstrap Samples<a class="headerlink" href="#methods-for-estimating-se-within-bootstrap-samples" title="Link to this heading"></a></h3>
<p>The practical challenge of bootstrap-t is computing <span class="math notranslate nohighlight">\(\hat{\sigma}^*_b\)</span> for each bootstrap sample. Several approaches exist, with different trade-offs:</p>
<p><strong>Option 1: Analytical (Plug-in) SE</strong></p>
<p>When a closed-form standard error formula exists, apply it to each bootstrap sample.</p>
<p><em>Example</em>: For the sample mean, <span class="math notranslate nohighlight">\(\hat{\sigma}^*_b = s^*_b/\sqrt{n}\)</span> where <span class="math notranslate nohighlight">\(s^*_b\)</span> is the sample standard deviation of the bootstrap sample.</p>
<p><em>Example</em>: For OLS regression with homoscedastic errors, use <span class="math notranslate nohighlight">\(\hat{\sigma}^*_{\hat{\beta}} = \hat{\sigma}^*_\epsilon \sqrt{(X^{*\top}X^*)^{-1}_{jj}}\)</span>.</p>
<p><strong>Advantages</strong>: Fast (<span class="math notranslate nohighlight">\(O(B)\)</span> total complexity), exact within model assumptions.</p>
<p><strong>Disadvantages</strong>: Requires known formula; may be inaccurate under model misspecification (e.g., heteroscedasticity).</p>
<p><strong>Option 2: Sandwich (Robust) SE</strong></p>
<p>For regression problems, use heteroscedasticity-consistent standard errors within each bootstrap sample:</p>
<div class="math notranslate nohighlight">
\[\widehat{\text{Var}}(\hat{\beta}^*) = (X^{*\top}X^*)^{-1} \left(\sum_{i=1}^n (e^*_i)^2 x^*_i x^{*\top}_i\right) (X^{*\top}X^*)^{-1}\]</div>
<p>This provides robustness to heteroscedasticity while maintaining analytical tractability.</p>
<p><strong>Option 3: Jackknife SE Within Bootstrap Samples</strong></p>
<p>Use the delete-1 jackknife (from <a class="reference internal" href="ch4_5-jackknife-methods.html#ch4-5-jackknife-methods"><span class="std std-ref">Section 4.5</span></a>) to estimate <span class="math notranslate nohighlight">\(\hat{\sigma}^*_b\)</span>:</p>
<div class="math notranslate nohighlight">
\[\hat{\sigma}^*_b = \sqrt{\frac{n-1}{n} \sum_{i=1}^n \left(\hat{\theta}^*_{b,(-i)} - \bar{\theta}^*_{b,(\cdot)}\right)^2}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{\theta}^*_{b,(-i)}\)</span> is the statistic computed on bootstrap sample <span class="math notranslate nohighlight">\(b\)</span> with observation <span class="math notranslate nohighlight">\(i\)</span> removed.</p>
<p><strong>Advantages</strong>: Works for any statistic; no formula needed.</p>
<p><strong>Disadvantages</strong>: Cost is <span class="math notranslate nohighlight">\(O(B \cdot n)\)</span> statistic evaluations; may be unstable for non-smooth statistics.</p>
<p><strong>Option 4: Nested Bootstrap</strong></p>
<p>For each outer bootstrap sample <span class="math notranslate nohighlight">\(b\)</span>, draw <span class="math notranslate nohighlight">\(M\)</span> inner bootstrap samples and compute <span class="math notranslate nohighlight">\(\hat{\sigma}^*_b\)</span> as the standard deviation of the inner bootstrap estimates.</p>
<p><strong>Advantages</strong>: Most general; works for any statistic.</p>
<p><strong>Disadvantages</strong>: Cost is <span class="math notranslate nohighlight">\(O(B \cdot M)\)</span> statistic evaluations; can be prohibitive for expensive statistics.</p>
<p><strong>Practical Guidance</strong>: Use analytical or sandwich SE when available and trustworthy. Use jackknife SE as a general-purpose fallback. Reserve nested bootstrap for non-smooth statistics where jackknife is unreliable.</p>
</section>
<section id="python-implementation">
<h3>Python Implementation<a class="headerlink" href="#python-implementation" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">studentized_bootstrap_ci</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">statistic</span><span class="p">,</span> <span class="n">se_function</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                              <span class="n">B</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute studentized (bootstrap-t) confidence interval.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : array_like</span>
<span class="sd">        Original data (1D array for simple case).</span>
<span class="sd">    statistic : callable</span>
<span class="sd">        Function computing the statistic: statistic(data) -&gt; float.</span>
<span class="sd">    se_function : callable</span>
<span class="sd">        Function computing SE estimate: se_function(data) -&gt; float.</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Significance level (default 0.05 for 95% CI).</span>
<span class="sd">    B : int</span>
<span class="sd">        Number of bootstrap replicates.</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed for reproducibility.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ci : tuple</span>
<span class="sd">        (lower, upper) confidence bounds.</span>
<span class="sd">    theta_hat : float</span>
<span class="sd">        Original point estimate.</span>
<span class="sd">    info : dict</span>
<span class="sd">        Additional information including t* distribution.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Original estimates</span>
    <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">se_hat</span> <span class="o">=</span> <span class="n">se_function</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Bootstrap</span>
    <span class="n">t_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="n">theta_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="c1"># Resample with replacement</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">data_star</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="c1"># Compute statistic and SE on bootstrap sample</span>
        <span class="n">theta_star</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data_star</span><span class="p">)</span>
        <span class="n">se_star</span> <span class="o">=</span> <span class="n">se_function</span><span class="p">(</span><span class="n">data_star</span><span class="p">)</span>

        <span class="c1"># Studentized statistic (guard against zero SE)</span>
        <span class="k">if</span> <span class="n">se_star</span> <span class="o">&gt;</span> <span class="mf">1e-10</span><span class="p">:</span>
            <span class="n">t_star</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">theta_star</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">-</span> <span class="n">theta_hat</span><span class="p">)</span> <span class="o">/</span> <span class="n">se_star</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">t_star</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>  <span class="c1"># Degenerate case</span>

    <span class="c1"># Quantiles of t* distribution</span>
    <span class="n">q_lo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">t_star</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">q_hi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">t_star</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Confidence interval (note the reversal)</span>
    <span class="n">ci_lower</span> <span class="o">=</span> <span class="n">theta_hat</span> <span class="o">-</span> <span class="n">se_hat</span> <span class="o">*</span> <span class="n">q_hi</span>
    <span class="n">ci_upper</span> <span class="o">=</span> <span class="n">theta_hat</span> <span class="o">-</span> <span class="n">se_hat</span> <span class="o">*</span> <span class="n">q_lo</span>

    <span class="n">info</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;t_star&#39;</span><span class="p">:</span> <span class="n">t_star</span><span class="p">,</span>
        <span class="s1">&#39;theta_star&#39;</span><span class="p">:</span> <span class="n">theta_star</span><span class="p">,</span>
        <span class="s1">&#39;se_hat&#39;</span><span class="p">:</span> <span class="n">se_hat</span><span class="p">,</span>
        <span class="s1">&#39;q_lo&#39;</span><span class="p">:</span> <span class="n">q_lo</span><span class="p">,</span>
        <span class="s1">&#39;q_hi&#39;</span><span class="p">:</span> <span class="n">q_hi</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">ci_lower</span><span class="p">,</span> <span class="n">ci_upper</span><span class="p">),</span> <span class="n">theta_hat</span><span class="p">,</span> <span class="n">info</span>


<span class="k">def</span><span class="w"> </span><span class="nf">jackknife_se</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">statistic</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute jackknife standard error for use in studentized bootstrap.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : array_like</span>
<span class="sd">        Data array.</span>
<span class="sd">    statistic : callable</span>
<span class="sd">        Function computing the statistic.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    se : float</span>
<span class="sd">        Jackknife standard error estimate.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Leave-one-out estimates</span>
    <span class="n">theta_jack</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">data_minus_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">theta_jack</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data_minus_i</span><span class="p">)</span>

    <span class="c1"># Jackknife SE formula</span>
    <span class="n">theta_bar</span> <span class="o">=</span> <span class="n">theta_jack</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">theta_jack</span> <span class="o">-</span> <span class="n">theta_bar</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">se</span>
</pre></div>
</div>
<div class="note admonition">
<p class="admonition-title">Example 💡 Studentized Bootstrap for Correlation Coefficient</p>
<p><strong>Given:</strong> Paired observations <span class="math notranslate nohighlight">\((X_i, Y_i)\)</span> for <span class="math notranslate nohighlight">\(i = 1, \ldots, 30\)</span> from a bivariate distribution.</p>
<p><strong>Find:</strong> A 95% confidence interval for the population correlation <span class="math notranslate nohighlight">\(\rho\)</span>.</p>
<p><strong>Challenge:</strong> The sampling distribution of <span class="math notranslate nohighlight">\(\hat{\rho}\)</span> is skewed, especially when <span class="math notranslate nohighlight">\(|\rho|\)</span> is large, and the standard error depends on <span class="math notranslate nohighlight">\(\rho\)</span> itself.</p>
<p><strong>Python implementation:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Generate example data with true correlation rho = 0.7</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">rho_true</span> <span class="o">=</span> <span class="mf">0.7</span>

<span class="c1"># Generate from a bivariate normal</span>
<span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="n">rho_true</span><span class="p">],</span> <span class="p">[</span><span class="n">rho_true</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Combine into single array for resampling (pairs bootstrap)</span>
<span class="n">xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>

<span class="k">def</span><span class="w"> </span><span class="nf">correlation</span><span class="p">(</span><span class="n">xy_data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Pearson correlation on the r scale.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">xy_data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">xy_data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">correlation_fisher_z</span><span class="p">(</span><span class="n">xy_data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Fisher z = atanh(r), where r is Pearson correlation.&quot;&quot;&quot;</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">correlation</span><span class="p">(</span><span class="n">xy_data</span><span class="p">)</span>
    <span class="c1"># Clip to avoid infinities at |r| = 1 due to finite precision</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.999999999</span><span class="p">,</span> <span class="mf">0.999999999</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">arctanh</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">correlation_se_fisher_z</span><span class="p">(</span><span class="n">xy_data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SE of Fisher z: Var(z) ≈ 1/(n-3).&quot;&quot;&quot;</span>
    <span class="n">n_local</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xy_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_local</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_local</span> <span class="o">&gt;</span> <span class="mi">3</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

<span class="c1"># Studentized bootstrap CI on Fisher z scale, then transform back to r scale</span>
<span class="n">ci_stud_z</span><span class="p">,</span> <span class="n">z_hat</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">studentized_bootstrap_ci</span><span class="p">(</span>
    <span class="n">xy</span><span class="p">,</span>
    <span class="n">correlation_fisher_z</span><span class="p">,</span>
    <span class="n">correlation_se_fisher_z</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">B</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>

<span class="n">ci_stud_r</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">ci_stud_z</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">ci_stud_z</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">r_hat</span> <span class="o">=</span> <span class="n">correlation</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample correlation (r): </span><span class="si">{</span><span class="n">r_hat</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True correlation:       </span><span class="si">{</span><span class="n">rho_true</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;95% Studentized CI (r): [</span><span class="si">{</span><span class="n">ci_stud_r</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_stud_r</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

<span class="c1"># Compare with percentile CI on r scale</span>
<span class="n">theta_star_z</span> <span class="o">=</span> <span class="n">info</span><span class="p">[</span><span class="s2">&quot;theta_star&quot;</span><span class="p">]</span>
<span class="n">theta_star_r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">theta_star_z</span><span class="p">)</span>
<span class="n">ci_perc_r</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star_r</span><span class="p">,</span> <span class="mf">0.025</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star_r</span><span class="p">,</span> <span class="mf">0.975</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;95% Percentile CI (r):  [</span><span class="si">{</span><span class="n">ci_perc_r</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_perc_r</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Result:</strong> The studentized interval properly accounts for the asymmetric sampling distribution of the correlation coefficient, while the percentile interval may have coverage issues, particularly when the true correlation is far from zero.</p>
</div>
</section>
<section id="diagnostics-for-studentized-bootstrap">
<h3>Diagnostics for Studentized Bootstrap<a class="headerlink" href="#diagnostics-for-studentized-bootstrap" title="Link to this heading"></a></h3>
<p>Before trusting a studentized bootstrap interval, examine the distribution of <span class="math notranslate nohighlight">\(t^*\)</span>:</p>
<ol class="arabic simple">
<li><p><strong>Shape</strong>: The <span class="math notranslate nohighlight">\(t^*\)</span> distribution should be unimodal and roughly symmetric. Compare with a standard normal or <span class="math notranslate nohighlight">\(t\)</span> distribution.</p></li>
<li><p><strong>Outliers</strong>: Extreme <span class="math notranslate nohighlight">\(t^*\)</span> values often indicate bootstrap samples where <span class="math notranslate nohighlight">\(\hat{\sigma}^*_b \approx 0\)</span>. These can distort quantiles.</p></li>
<li><p><strong>Stability</strong>: Verify that the <span class="math notranslate nohighlight">\(t^*\)</span> quantiles stabilize as <span class="math notranslate nohighlight">\(B\)</span> increases.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">diagnose_studentized_bootstrap</span><span class="p">(</span><span class="n">info</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Diagnostic plots for studentized bootstrap.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    info : dict</span>
<span class="sd">        Output from studentized_bootstrap_ci containing &#39;t_star&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

    <span class="n">t_star</span> <span class="o">=</span> <span class="n">info</span><span class="p">[</span><span class="s1">&#39;t_star&#39;</span><span class="p">]</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

    <span class="c1"># Histogram with normal overlay</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">t_star</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">t_star</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">t_star</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;N(0,1)&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;t*&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribution of t*&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="c1"># Q-Q plot against normal</span>
    <span class="n">stats</span><span class="o">.</span><span class="n">probplot</span><span class="p">(</span><span class="n">t_star</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Normal Q-Q Plot&#39;</span><span class="p">)</span>

    <span class="c1"># Quantile stability (if we had batch information)</span>
    <span class="c1"># For now, show sorted t* values</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">t_star</span><span class="p">))</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;q_lo&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;q_lo = </span><span class="si">{</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;q_lo&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;q_hi&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;q_hi = </span><span class="si">{</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;q_hi&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Order&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;t*&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Sorted t* Values&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>
</div>
<p><strong>Red flags for studentized bootstrap:</strong></p>
<ul class="simple">
<li><p>Multimodal <span class="math notranslate nohighlight">\(t^*\)</span> distribution (suggests instability or discrete effects)</p></li>
<li><p>Heavy tails or extreme outliers (check for near-zero <span class="math notranslate nohighlight">\(\hat{\sigma}^*\)</span> values)</p></li>
<li><p><span class="math notranslate nohighlight">\(t^*\)</span> quantiles far from normal quantiles when sample size is moderate</p></li>
</ul>
</section>
</section>
<section id="bias-corrected-bc-intervals">
<h2>Bias-Corrected (BC) Intervals<a class="headerlink" href="#bias-corrected-bc-intervals" title="Link to this heading"></a></h2>
<p>The studentized bootstrap achieves second-order accuracy through explicit pivoting. An alternative approach corrects the percentile interval for <strong>bias</strong> in the bootstrap distribution. The bias-corrected (BC) interval is a stepping stone to the more sophisticated BCa method.</p>
<section id="the-bias-problem-in-percentile-intervals">
<h3>The Bias Problem in Percentile Intervals<a class="headerlink" href="#the-bias-problem-in-percentile-intervals" title="Link to this heading"></a></h3>
<p>Recall that the percentile interval uses quantiles <span class="math notranslate nohighlight">\(Q_{\alpha/2}(\hat{\theta}^*)\)</span> and <span class="math notranslate nohighlight">\(Q_{1-\alpha/2}(\hat{\theta}^*)\)</span> directly. If the bootstrap distribution is centered at <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> but the sampling distribution is centered at <span class="math notranslate nohighlight">\(\theta \neq \hat{\theta}\)</span>, the percentile interval inherits this discrepancy.</p>
<p>Define the <strong>bias-correction constant</strong> <span class="math notranslate nohighlight">\(z_0\)</span> as the standard normal quantile corresponding to the proportion of bootstrap replicates below the original estimate:</p>
<div class="math notranslate nohighlight" id="equation-z0-def">
<span class="eqno">(195)<a class="headerlink" href="#equation-z0-def" title="Link to this equation"></a></span>\[z_0 = \Phi^{-1}\left(\frac{\#\{\hat{\theta}^*_b &lt; \hat{\theta}\}}{B}\right)\]</div>
<p><strong>Interpretation</strong>:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(z_0 = 0\)</span>, exactly half the bootstrap replicates fall below <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>—the bootstrap distribution is median-unbiased relative to <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(z_0 &gt; 0\)</span>, more than half fall below <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>—the bootstrap distribution is shifted left (the estimator appears biased high).</p></li>
<li><p>If <span class="math notranslate nohighlight">\(z_0 &lt; 0\)</span>, fewer than half fall below—the distribution is shifted right.</p></li>
</ul>
</section>
<section id="the-bc-interval-formula">
<h3>The BC Interval Formula<a class="headerlink" href="#the-bc-interval-formula" title="Link to this heading"></a></h3>
<p>The BC interval adjusts the percentile levels to correct for this median bias:</p>
<div class="math notranslate nohighlight" id="equation-bc-formula">
<span class="eqno">(196)<a class="headerlink" href="#equation-bc-formula" title="Link to this equation"></a></span>\[\alpha_1^{BC} = \Phi(2z_0 + z_{\alpha/2}), \quad \alpha_2^{BC} = \Phi(2z_0 + z_{1-\alpha/2})\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\alpha/2} = \Phi^{-1}(\alpha/2)\)</span> and <span class="math notranslate nohighlight">\(z_{1-\alpha/2} = \Phi^{-1}(1-\alpha/2)\)</span> are the standard normal quantiles for the nominal level.</p>
<p>The BC interval is then:</p>
<div class="math notranslate nohighlight">
\[\left[Q_{\alpha_1^{BC}}(\hat{\theta}^*), Q_{\alpha_2^{BC}}(\hat{\theta}^*)\right]\]</div>
<p><strong>Example</strong>: For a 95% interval (<span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>), we have <span class="math notranslate nohighlight">\(z_{0.025} = -1.96\)</span> and <span class="math notranslate nohighlight">\(z_{0.975} = 1.96\)</span>. If <span class="math notranslate nohighlight">\(z_0 = 0.3\)</span> (indicating moderate positive bias):</p>
<div class="math notranslate nohighlight">
\[\begin{split}\alpha_1^{BC} &amp;= \Phi(2(0.3) + (-1.96)) = \Phi(-1.36) \approx 0.087 \\
\alpha_2^{BC} &amp;= \Phi(2(0.3) + 1.96) = \Phi(2.56) \approx 0.995\end{split}\]</div>
<p>The interval uses the 8.7th and 99.5th percentiles instead of the 2.5th and 97.5th, shifting both endpoints upward to correct for the bias.</p>
</section>
<section id="when-bc-suffices">
<h3>When BC Suffices<a class="headerlink" href="#when-bc-suffices" title="Link to this heading"></a></h3>
<p>The BC interval corrects for bias but not for <strong>acceleration</strong>—the phenomenon where the standard error of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> varies with the true parameter value <span class="math notranslate nohighlight">\(\theta\)</span>. BC is adequate when:</p>
<ul class="simple">
<li><p>Bias is the primary concern (non-negligible <span class="math notranslate nohighlight">\(z_0\)</span>)</p></li>
<li><p>The standard error is approximately constant across plausible parameter values</p></li>
<li><p>The bootstrap distribution is roughly symmetric</p></li>
</ul>
<p>For statistics where the standard error varies substantially with the parameter (correlations near <span class="math notranslate nohighlight">\(\pm 1\)</span>, variances, proportions near 0 or 1), BC may not provide sufficient correction. The full BCa method addresses this.</p>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig04_bca_bias_correction.png"><img alt="BCa Bias Correction z0" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig04_bca_bias_correction.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 178 </span><span class="caption-text"><strong>Figure 4.7.4</strong>: The bias-correction constant <span class="math notranslate nohighlight">\(z_0\)</span>. (a) Symmetric bootstrap distribution: <span class="math notranslate nohighlight">\(z_0 \approx 0\)</span> indicates no median bias. (b) Skewed bootstrap distribution: <span class="math notranslate nohighlight">\(z_0 &lt; 0\)</span> (or <span class="math notranslate nohighlight">\(&gt; 0\)</span>) indicates the bootstrap median differs from <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. (c) Formula and interpretation of <span class="math notranslate nohighlight">\(z_0\)</span>. (d) Numerical example showing how <span class="math notranslate nohighlight">\(z_0\)</span> adjusts percentile levels. (e) The BC formula visualization showing how adjusted levels vary with <span class="math notranslate nohighlight">\(z_0\)</span>. (f) Key insights about the direction and magnitude of corrections.</span><a class="headerlink" href="#id5" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
</section>
<section id="bias-corrected-and-accelerated-bca-intervals">
<h2>Bias-Corrected and Accelerated (BCa) Intervals<a class="headerlink" href="#bias-corrected-and-accelerated-bca-intervals" title="Link to this heading"></a></h2>
<p>The BCa interval, introduced by Efron (1987), is widely regarded as the <strong>best general-purpose bootstrap confidence interval</strong>. It achieves second-order accuracy, is transformation-invariant, and automatically adapts to bias and skewness without requiring explicit studentization. The “cost” is computing an additional acceleration parameter from the jackknife.</p>
<section id="theoretical-foundation">
<h3>Theoretical Foundation<a class="headerlink" href="#theoretical-foundation" title="Link to this heading"></a></h3>
<p>The BCa method can be motivated as a <strong>higher order calibration</strong> of bootstrap percentiles. Under standard regularity conditions for <strong>smooth functionals</strong>, there exists an unknown monotone transformation <span class="math notranslate nohighlight">\(\phi\)</span> such that the transformed estimator
<span class="math notranslate nohighlight">\(\hat{\phi} = \phi(\hat{\theta})\)</span> is approximately normal and admits an Edgeworth type expansion. In that expansion, two effects dominate the coverage error of naive percentile procedures:</p>
<ol class="arabic simple">
<li><p><strong>Median bias</strong> of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> relative to the bootstrap distribution.</p></li>
<li><p><strong>Skewness and non constant curvature effects</strong> associated with the statistic’s influence function.</p></li>
</ol>
<p>BCa incorporates these effects through two constants:</p>
<ul class="simple">
<li><p>The <strong>bias correction</strong> <span class="math notranslate nohighlight">\(z_0\)</span>, which measures median bias in standard normal units.</p></li>
<li><p>The <strong>acceleration</strong> <span class="math notranslate nohighlight">\(a\)</span>, which captures the leading skewness or curvature contribution and is estimated from jackknife leave one out values.</p></li>
</ul>
<p>A key feature is that BCa is <strong>invariant under monotone reparameterizations</strong>: if the parameter is replaced by <span class="math notranslate nohighlight">\(\psi(\theta)\)</span> for a monotone <span class="math notranslate nohighlight">\(\psi\)</span>, the BCa construction transforms accordingly, so the resulting interval on the original scale is coherent without needing to know <span class="math notranslate nohighlight">\(\phi\)</span> explicitly.</p>
<p>Concretely, <span class="math notranslate nohighlight">\(z_0\)</span> is estimated from the bootstrap distribution by</p>
<div class="math notranslate nohighlight" id="equation-bca-z0">
<span class="eqno">(197)<a class="headerlink" href="#equation-bca-z0" title="Link to this equation"></a></span>\[z_0 = \Phi^{-1}\!\left(\frac{\#\{\hat{\theta}^* &lt; \hat{\theta}\}}{B}\right),\]</div>
<p>and <span class="math notranslate nohighlight">\(a\)</span> is estimated from jackknife leave one out estimates <span class="math notranslate nohighlight">\(\hat{\theta}_{(i)}\)</span> via</p>
<div class="math notranslate nohighlight" id="equation-bca-a">
<span class="eqno">(198)<a class="headerlink" href="#equation-bca-a" title="Link to this equation"></a></span>\[a
=
\frac{
   \sum_{i=1}^n (\bar{\theta}_{(\cdot)} - \hat{\theta}_{(i)})^3
}{
   6\left[\sum_{i=1}^n (\bar{\theta}_{(\cdot)} - \hat{\theta}_{(i)})^2\right]^{3/2}
},
\qquad
\bar{\theta}_{(\cdot)} = \frac{1}{n}\sum_{i=1}^n \hat{\theta}_{(i)}.\]</div>
<p>These definitions align with the standard BCa derivation: <span class="math notranslate nohighlight">\(z_0\)</span> corrects median bias, and <span class="math notranslate nohighlight">\(a\)</span> adjusts for skewness and curvature effects that otherwise produce <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span> one sided coverage errors.</p>
</section>
<section id="the-bca-formula">
<h3>### The BCa Formula<a class="headerlink" href="#the-bca-formula" title="Link to this heading"></a></h3>
<p>Given the bias correction constant <span class="math notranslate nohighlight">\(z_0\)</span> and acceleration constant <span class="math notranslate nohighlight">\(a\)</span>, the BCa interval uses adjusted percentile levels:</p>
<div class="math notranslate nohighlight" id="equation-bca-formula">
<span class="eqno">(199)<a class="headerlink" href="#equation-bca-formula" title="Link to this equation"></a></span>\[\alpha_j^{BCa} = \Phi\left(z_0 + \frac{z_0 + z_{\alpha_j}}{1 - a(z_0 + z_{\alpha_j})}\right)\]</div>
<p>for <span class="math notranslate nohighlight">\(\alpha_j \in \{\alpha/2, 1-\alpha/2\}\)</span>. The BCa interval is:</p>
<div class="math notranslate nohighlight">
\[\left[Q_{\alpha_1^{BCa}}(\hat{\theta}^*), Q_{\alpha_2^{BCa}}(\hat{\theta}^*)\right]\]</div>
<p><strong>Special cases:</strong></p>
<ul class="simple">
<li><p>When <span class="math notranslate nohighlight">\(a = 0\)</span>: The formula reduces to <span class="math notranslate nohighlight">\(\alpha_j^{BCa} = \Phi(2z_0 + z_{\alpha_j})\)</span>, which is exactly the BC interval.</p></li>
<li><p>When <span class="math notranslate nohighlight">\(z_0 = 0\)</span> and <span class="math notranslate nohighlight">\(a = 0\)</span>: The formula gives <span class="math notranslate nohighlight">\(\alpha_j^{BCa} = \alpha_j\)</span>, recovering the standard percentile interval.</p></li>
</ul>
</section>
<section id="computing-the-bias-correction-constant-z-0">
<h3>Computing the Bias-Correction Constant <span class="math notranslate nohighlight">\(z_0\)</span><a class="headerlink" href="#computing-the-bias-correction-constant-z-0" title="Link to this heading"></a></h3>
<p>The bias-correction constant measures where <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> falls in its bootstrap distribution:</p>
<div class="math notranslate nohighlight" id="equation-z0-formula">
<span class="eqno">(200)<a class="headerlink" href="#equation-z0-formula" title="Link to this equation"></a></span>\[z_0 = \Phi^{-1}\left(\frac{\#\{\hat{\theta}^*_b &lt; \hat{\theta}\}}{B}\right)\]</div>
<p><strong>Handling ties</strong>: When some bootstrap replicates exactly equal <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> (common for discrete statistics or medians), the standard formula can overestimate bias. A robust adjustment assigns half of the ties to each side:</p>
<div class="math notranslate nohighlight" id="equation-z0-midrank">
<span class="eqno">(201)<a class="headerlink" href="#equation-z0-midrank" title="Link to this equation"></a></span>\[z_0 = \Phi^{-1}\left(\frac{\#\{\hat{\theta}^* &lt; \hat{\theta}\} + \tfrac{1}{2}\#\{\hat{\theta}^* = \hat{\theta}\}}{B}\right)\]</div>
<p><strong>Numerical stability</strong>: If the proportion is exactly 0 or 1, <span class="math notranslate nohighlight">\(\Phi^{-1}\)</span> returns <span class="math notranslate nohighlight">\(\mp\infty\)</span>. Clip the proportion to <span class="math notranslate nohighlight">\([1/(2B), 1-1/(2B)]\)</span> before applying <span class="math notranslate nohighlight">\(\Phi^{-1}\)</span>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_z0</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute BCa bias-correction constant with tie handling.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    theta_star : array_like</span>
<span class="sd">        Bootstrap replicates.</span>
<span class="sd">    theta_hat : float</span>
<span class="sd">        Original estimate.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    z0 : float</span>
<span class="sd">        Bias-correction constant.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

    <span class="n">theta_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">theta_star</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta_star</span><span class="p">)</span>

    <span class="c1"># Count with mid-rank adjustment for ties</span>
    <span class="n">n_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta_star</span> <span class="o">&lt;</span> <span class="n">theta_hat</span><span class="p">)</span>
    <span class="n">n_equal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta_star</span> <span class="o">==</span> <span class="n">theta_hat</span><span class="p">)</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_below</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">n_equal</span><span class="p">)</span> <span class="o">/</span> <span class="n">B</span>

    <span class="c1"># Clip for numerical stability</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">B</span><span class="p">),</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">B</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="computing-the-acceleration-constant-a">
<h3>Computing the Acceleration Constant <span class="math notranslate nohighlight">\(a\)</span><a class="headerlink" href="#computing-the-acceleration-constant-a" title="Link to this heading"></a></h3>
<p>The acceleration constant captures how the standard error of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> changes with the parameter value. It is computed from the <strong>jackknife influence values</strong> introduced in <a class="reference internal" href="ch4_5-jackknife-methods.html#ch4-5-jackknife-methods"><span class="std std-ref">Section 4.5</span></a>.</p>
<p>Let <span class="math notranslate nohighlight">\(\hat{\theta}_{(-i)}\)</span> be the statistic computed with observation <span class="math notranslate nohighlight">\(i\)</span> deleted, and let <span class="math notranslate nohighlight">\(\bar{\theta}_{(\cdot)} = \frac{1}{n}\sum_{i=1}^n \hat{\theta}_{(-i)}\)</span> be their mean. The acceleration constant is:</p>
<div class="math notranslate nohighlight" id="equation-acceleration-formula">
<span class="eqno">(202)<a class="headerlink" href="#equation-acceleration-formula" title="Link to this equation"></a></span>\[a = \frac{\sum_{i=1}^n (\bar{\theta}_{(\cdot)} - \hat{\theta}_{(-i)})^3}{6\left[\sum_{i=1}^n (\bar{\theta}_{(\cdot)} - \hat{\theta}_{(-i)})^2\right]^{3/2}}\]</div>
<p><strong>Interpretation</strong>: This formula is essentially the <strong>skewness</strong> of the jackknife influence values, normalized appropriately. Large <span class="math notranslate nohighlight">\(|a|\)</span> indicates that individual observations have asymmetric influence on the estimate, which corresponds to the standard error varying with the parameter.</p>
<p><strong>Typical values</strong>: In many smooth problems, <span class="math notranslate nohighlight">\(|a| &lt; 0.1\)</span> is often modest (frequently below 0.1), but it can be larger for heavy tailed data, bounded parameters, or strongly influential observations. Values above roughly 0.25 typically signal substantial acceleration effects and justify preferring BCa over BC.
<strong>Numerical guard</strong>: If all jackknife estimates are identical (denominator is zero), set <span class="math notranslate nohighlight">\(a = 0\)</span> and fall back to the BC interval. This can occur for statistics that are insensitive to individual observations.</p>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig05_bca_acceleration.png"><img alt="BCa Acceleration Constant a" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig05_bca_acceleration.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 179 </span><span class="caption-text"><strong>Figure 4.7.5</strong>: The acceleration constant <span class="math notranslate nohighlight">\(a\)</span>. (a) Jackknife estimates <span class="math notranslate nohighlight">\(\hat{\theta}_{(-i)}\)</span> for sample variance—note the influential outliers. (b) Influence values <span class="math notranslate nohighlight">\(d_i = \bar{\theta}_{(\cdot)} - \hat{\theta}_{(-i)}\)</span> showing skewness. (c) Formula for computing <span class="math notranslate nohighlight">\(a\)</span> from the skewness of influence values. (d) Interpretation: <span class="math notranslate nohighlight">\(a\)</span> captures how SE varies with the parameter value. (e) The full BCa formula showing how both <span class="math notranslate nohighlight">\(z_0\)</span> and <span class="math notranslate nohighlight">\(a\)</span> jointly adjust percentile levels. (f) Key insights about positive vs negative <span class="math notranslate nohighlight">\(a\)</span> and its effect on interval tails.</span><a class="headerlink" href="#id6" title="Link to this image"></a></p>
</figcaption>
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_acceleration</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">statistic</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute BCa acceleration constant via jackknife.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : array_like</span>
<span class="sd">        Original data.</span>
<span class="sd">    statistic : callable</span>
<span class="sd">        Function computing the statistic.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    a : float</span>
<span class="sd">        Acceleration constant.</span>
<span class="sd">    theta_jack : ndarray</span>
<span class="sd">        Jackknife estimates (useful for diagnostics).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Compute leave-one-out estimates</span>
    <span class="n">theta_jack</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">data_minus_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">theta_jack</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data_minus_i</span><span class="p">)</span>

    <span class="c1"># Compute acceleration</span>
    <span class="n">theta_bar</span> <span class="o">=</span> <span class="n">theta_jack</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">theta_bar</span> <span class="o">-</span> <span class="n">theta_jack</span>  <span class="c1"># Influence-like quantities</span>

    <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="mi">6</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mf">1.5</span>

    <span class="k">if</span> <span class="n">denominator</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
        <span class="c1"># Degenerate case: all jackknife estimates equal</span>
        <span class="k">return</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">theta_jack</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
    <span class="k">return</span> <span class="n">a</span><span class="p">,</span> <span class="n">theta_jack</span>
</pre></div>
</div>
</section>
<section id="transformation-invariance">
<h3>Transformation Invariance<a class="headerlink" href="#transformation-invariance" title="Link to this heading"></a></h3>
<p>A crucial property of BCa intervals is <strong>transformation invariance</strong>: if <span class="math notranslate nohighlight">\(\psi = m(\theta)\)</span> for a monotone function <span class="math notranslate nohighlight">\(m\)</span>, then the BCa interval for <span class="math notranslate nohighlight">\(\psi\)</span> is exactly <span class="math notranslate nohighlight">\(m\)</span> applied to the BCa interval for <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p><strong>Why this matters</strong>: Consider estimating a variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Should we compute the interval on the variance scale or the standard deviation scale? For percentile intervals (which are also transformation-invariant), we get the same answer either way. But for basic intervals or normal approximations, the choice of scale affects the result. BCa preserves this desirable invariance while achieving better coverage.</p>
<p><strong>Proof sketch</strong>: The BCa adjustment formula depends on <span class="math notranslate nohighlight">\(z_0\)</span> and <span class="math notranslate nohighlight">\(a\)</span>, both computed from the data without reference to the parameterization. Under a monotone transformation <span class="math notranslate nohighlight">\(m\)</span>, the proportion of bootstrap replicates below the original estimate is preserved (since <span class="math notranslate nohighlight">\(m(\hat{\theta}^*) &lt; m(\hat{\theta})\)</span> iff <span class="math notranslate nohighlight">\(\hat{\theta}^* &lt; \hat{\theta}\)</span> for increasing <span class="math notranslate nohighlight">\(m\)</span>), so <span class="math notranslate nohighlight">\(z_0\)</span> is unchanged. The acceleration <span class="math notranslate nohighlight">\(a\)</span> transforms consistently because influence values transform linearly for smooth <span class="math notranslate nohighlight">\(m\)</span>. Therefore, the adjusted percentile levels <span class="math notranslate nohighlight">\(\alpha_j^{BCa}\)</span> are invariant, and the interval endpoints transform correctly.</p>
</section>
<section id="complete-bca-implementation">
<h3>Complete BCa Implementation<a class="headerlink" href="#complete-bca-implementation" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">bca_bootstrap_ci</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">statistic</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute BCa (bias-corrected and accelerated) bootstrap confidence interval.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : array_like</span>
<span class="sd">        Original data.</span>
<span class="sd">    statistic : callable</span>
<span class="sd">        Function computing the statistic: statistic(data) -&gt; float.</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Significance level (default 0.05 for 95% CI).</span>
<span class="sd">    B : int</span>
<span class="sd">        Number of bootstrap replicates.</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed for reproducibility.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ci : tuple</span>
<span class="sd">        (lower, upper) confidence bounds.</span>
<span class="sd">    theta_hat : float</span>
<span class="sd">        Original point estimate.</span>
<span class="sd">    info : dict</span>
<span class="sd">        Diagnostic information including z0, a, adjusted alpha levels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Original estimate</span>
    <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Bootstrap distribution</span>
    <span class="n">theta_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">theta_star</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

    <span class="c1"># Bias correction constant z0</span>
    <span class="n">n_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta_star</span> <span class="o">&lt;</span> <span class="n">theta_hat</span><span class="p">)</span>
    <span class="n">n_equal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta_star</span> <span class="o">==</span> <span class="n">theta_hat</span><span class="p">)</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_below</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">n_equal</span><span class="p">)</span> <span class="o">/</span> <span class="n">B</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">B</span><span class="p">),</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">B</span><span class="p">))</span>
    <span class="n">z0</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span>

    <span class="c1"># Acceleration constant via jackknife</span>
    <span class="n">theta_jack</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">data_minus_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">theta_jack</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data_minus_i</span><span class="p">)</span>

    <span class="n">theta_bar</span> <span class="o">=</span> <span class="n">theta_jack</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">theta_bar</span> <span class="o">-</span> <span class="n">theta_jack</span>

    <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="mi">6</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mf">1.5</span>

    <span class="k">if</span> <span class="n">denominator</span> <span class="o">&gt;</span> <span class="mf">1e-10</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Adjusted percentile levels</span>
    <span class="n">z_alpha_lo</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">z_alpha_hi</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">adjusted_alpha</span><span class="p">(</span><span class="n">z_alpha</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute BCa-adjusted percentile level.&quot;&quot;&quot;</span>
        <span class="n">numer</span> <span class="o">=</span> <span class="n">z0</span> <span class="o">+</span> <span class="n">z_alpha</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">z_alpha</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">denom</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
            <span class="c1"># Extreme case: return edge of [0, 1]</span>
            <span class="k">return</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="n">numer</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">numer</span> <span class="o">/</span> <span class="n">denom</span><span class="p">)</span>

    <span class="n">alpha1</span> <span class="o">=</span> <span class="n">adjusted_alpha</span><span class="p">(</span><span class="n">z_alpha_lo</span><span class="p">)</span>
    <span class="n">alpha2</span> <span class="o">=</span> <span class="n">adjusted_alpha</span><span class="p">(</span><span class="n">z_alpha_hi</span><span class="p">)</span>

    <span class="c1"># Ensure valid probability range</span>
    <span class="n">alpha1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">alpha1</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">B</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">B</span><span class="p">)</span>
    <span class="n">alpha2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">alpha2</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">B</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">B</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">alpha1</span> <span class="o">&gt;=</span> <span class="n">alpha2</span><span class="p">:</span>
     <span class="n">alpha1</span><span class="p">,</span> <span class="n">alpha2</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span>
     <span class="n">bca_warning</span> <span class="o">=</span> <span class="s2">&quot;Adjusted levels crossed; fell back to percentile.&quot;</span>
    <span class="k">else</span><span class="p">:</span>
     <span class="n">bca_warning</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># BCa interval</span>
    <span class="n">ci_lower</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">alpha1</span><span class="p">)</span>
    <span class="n">ci_upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">alpha2</span><span class="p">)</span>

    <span class="n">info</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;z0&#39;</span><span class="p">:</span> <span class="n">z0</span><span class="p">,</span>
        <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="n">a</span><span class="p">,</span>
        <span class="s1">&#39;alpha1&#39;</span><span class="p">:</span> <span class="n">alpha1</span><span class="p">,</span>
        <span class="s1">&#39;alpha2&#39;</span><span class="p">:</span> <span class="n">alpha2</span><span class="p">,</span>
        <span class="s1">&#39;theta_star&#39;</span><span class="p">:</span> <span class="n">theta_star</span><span class="p">,</span>
        <span class="s1">&#39;theta_jack&#39;</span><span class="p">:</span> <span class="n">theta_jack</span><span class="p">,</span>
        <span class="s1">&#39;se_boot&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="s1">&#39;bias_boot&#39;</span><span class="p">:</span> <span class="n">theta_star</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">theta_hat</span><span class="p">,</span>
        <span class="s1">&#39;bca_warning&#39;</span><span class="p">:</span> <span class="n">bca_warning</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">ci_lower</span><span class="p">,</span> <span class="n">ci_upper</span><span class="p">),</span> <span class="n">theta_hat</span><span class="p">,</span> <span class="n">info</span>
</pre></div>
</div>
<div class="note admonition">
<p class="admonition-title">Example 💡 BCa Interval for Median of Skewed Data</p>
<p><strong>Given:</strong> A sample of <span class="math notranslate nohighlight">\(n = 60\)</span> observations from a log-normal distribution (positively skewed).</p>
<p><strong>Find:</strong> A 95% confidence interval for the population median.</p>
<p><strong>Challenge:</strong> The bootstrap distribution of the sample median is skewed, and the median is a non-smooth statistic.</p>
<p><strong>Python implementation:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Generate skewed data</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">60</span>
<span class="c1"># Log-normal with median = exp(0) = 1</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">))</span>

<span class="n">true_median</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># exp(0) for lognormal(0, 1)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sample_median</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># BCa interval</span>
<span class="n">ci_bca</span><span class="p">,</span> <span class="n">med_hat</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">bca_bootstrap_ci</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">sample_median</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>

<span class="c1"># Percentile interval for comparison</span>
<span class="n">theta_star</span> <span class="o">=</span> <span class="n">info</span><span class="p">[</span><span class="s1">&#39;theta_star&#39;</span><span class="p">]</span>
<span class="n">ci_perc</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="mf">0.025</span><span class="p">),</span>
           <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="mf">0.975</span><span class="p">))</span>

<span class="c1"># Basic interval</span>
<span class="n">q_lo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="mf">0.025</span><span class="p">)</span>
<span class="n">q_hi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="mf">0.975</span><span class="p">)</span>
<span class="n">ci_basic</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">med_hat</span> <span class="o">-</span> <span class="n">q_hi</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">med_hat</span> <span class="o">-</span> <span class="n">q_lo</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample median: </span><span class="si">{</span><span class="n">med_hat</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True median:   </span><span class="si">{</span><span class="n">true_median</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;z0 = </span><span class="si">{</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;z0&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, a = </span><span class="si">{</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Adjusted levels: [</span><span class="si">{</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;alpha1&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;alpha2&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">95% Confidence Intervals:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Percentile: [</span><span class="si">{</span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Basic:      [</span><span class="si">{</span><span class="n">ci_basic</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_basic</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  BCa:        [</span><span class="si">{</span><span class="n">ci_bca</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_bca</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Typical output:</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Sample median: 1.0847
True median:   1.0000
z0 = 0.0627, a = 0.0312
Adjusted levels: [0.0336, 0.9829]

95% Confidence Intervals:
  Percentile: [0.7834, 1.4521]
  Basic:      [0.7173, 1.3860]
  BCa:        [0.8012, 1.4803]
</pre></div>
</div>
<p><strong>Interpretation:</strong> The positive <span class="math notranslate nohighlight">\(z_0\)</span> indicates slight upward bias in the bootstrap distribution relative to <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. The positive <span class="math notranslate nohighlight">\(a\)</span> indicates the standard error increases with the parameter value (as expected for the median of a positively skewed distribution). BCa adjusts the percentile levels to [3.36%, 98.29%] instead of [2.5%, 97.5%], shifting both endpoints upward.</p>
</div>
<figure class="align-center" id="id7">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig06_bca_complete_example.png"><img alt="BCa Complete Example" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_7_fig06_bca_complete_example.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 180 </span><span class="caption-text"><strong>Figure 4.7.6</strong>: Complete BCa example for median of log-normal data. (a) The skewed log-normal data with true and sample medians marked. (b) Bootstrap distribution of the sample median. (c) Computed BCa parameters <span class="math notranslate nohighlight">\(z_0\)</span> and <span class="math notranslate nohighlight">\(a\)</span> with adjusted percentile levels. (d) Numerical results for all confidence interval methods. (e) Visual comparison of the four interval methods showing which capture the true median. Key insights at the bottom explain how bias correction and acceleration work together.</span><a class="headerlink" href="#id7" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="when-bca-fails">
<h3>When BCa Fails<a class="headerlink" href="#when-bca-fails" title="Link to this heading"></a></h3>
<p>Despite its broad applicability, BCa has limitations:</p>
<p><strong>Non-smooth statistics</strong>: The jackknife-based acceleration formula assumes smooth dependence on individual observations. For highly non-smooth statistics (sample mode, range, extreme quantiles), the jackknife estimates <span class="math notranslate nohighlight">\(\hat{\theta}_{(-i)}\)</span> may be unstable, leading to unreliable <span class="math notranslate nohighlight">\(a\)</span>.</p>
<p><strong>Very small samples</strong>: When <span class="math notranslate nohighlight">\(n &lt; 15\)</span>, the jackknife provides only a coarse approximation to influence, and BCa coverage can be substantially below nominal. For <span class="math notranslate nohighlight">\(n &lt; 10\)</span>, consider parametric methods or exact approaches.</p>
<p><strong>Multimodal bootstrap distributions</strong>: BCa assumes a unimodal, roughly symmetric underlying structure. Multimodality indicates a fundamental problem that no simple adjustment can fix.</p>
<p><strong>Boundary effects</strong>: For parameters near natural boundaries (proportions near 0 or 1, variances near 0, correlations near <span class="math notranslate nohighlight">\(\pm 1\)</span>), the BCa formula may produce adjusted levels <span class="math notranslate nohighlight">\(\alpha_j^{BCa}\)</span> outside <span class="math notranslate nohighlight">\((0, 1)\)</span>, requiring truncation.</p>
</section>
</section>
<section id="choosing-b-and-assessing-monte-carlo-error">
<h2>Choosing B and Assessing Monte Carlo Error<a class="headerlink" href="#choosing-b-and-assessing-monte-carlo-error" title="Link to this heading"></a></h2>
<p>Every bootstrap computation involves <strong>Monte Carlo error</strong>—the additional randomness from using finitely many bootstrap replicates <span class="math notranslate nohighlight">\(B\)</span>. This error is distinct from the statistical uncertainty we’re trying to quantify (which depends on the sample size <span class="math notranslate nohighlight">\(n\)</span>) and is under our control. Choosing <span class="math notranslate nohighlight">\(B\)</span> appropriately and understanding Monte Carlo error are essential for responsible bootstrap inference.</p>
<section id="two-sources-of-uncertainty">
<h3>Two Sources of Uncertainty<a class="headerlink" href="#two-sources-of-uncertainty" title="Link to this heading"></a></h3>
<p>Consider a bootstrap standard error estimate <span class="math notranslate nohighlight">\(\widehat{\text{SE}}_{\text{boot}} = \text{SD}(\hat{\theta}^*)\)</span>. This estimate has two sources of variability:</p>
<ol class="arabic simple">
<li><p><strong>Statistical uncertainty</strong>: The bootstrap SE estimates the true standard error <span class="math notranslate nohighlight">\(\text{SE}_F(\hat{\theta})\)</span>, which depends on the unknown distribution <span class="math notranslate nohighlight">\(F\)</span>. Even with <span class="math notranslate nohighlight">\(B = \infty\)</span>, our estimate reflects only what the sample tells us about <span class="math notranslate nohighlight">\(F\)</span>.</p></li>
<li><p><strong>Monte Carlo uncertainty</strong>: With finite <span class="math notranslate nohighlight">\(B\)</span>, we approximate the bootstrap distribution with a Monte Carlo sample. This adds noise that disappears as <span class="math notranslate nohighlight">\(B \to \infty\)</span> but contributes to estimation error for finite <span class="math notranslate nohighlight">\(B\)</span>.</p></li>
</ol>
<p><strong>The goal</strong>: Choose <span class="math notranslate nohighlight">\(B\)</span> large enough that Monte Carlo error is negligible relative to statistical uncertainty. We cannot eliminate statistical uncertainty, but we can make Monte Carlo error as small as computational resources allow.</p>
</section>
<section id="monte-carlo-error-for-bootstrap-se">
<h3>Monte Carlo Error for Bootstrap SE<a class="headerlink" href="#monte-carlo-error-for-bootstrap-se" title="Link to this heading"></a></h3>
<p>Under mild conditions, the bootstrap replicates <span class="math notranslate nohighlight">\(\hat{\theta}^*_1, \ldots, \hat{\theta}^*_B\)</span> are approximately iid draws from the bootstrap distribution. The sample standard deviation <span class="math notranslate nohighlight">\(\widehat{\text{SE}}_{\text{boot}} = \text{SD}(\hat{\theta}^*)\)</span> estimates the population standard deviation of this distribution.</p>
<p>For the standard deviation of iid random variables, the Monte Carlo standard error is approximately:</p>
<div class="math notranslate nohighlight" id="equation-mc-se-formula">
<span class="eqno">(203)<a class="headerlink" href="#equation-mc-se-formula" title="Link to this equation"></a></span>\[\text{SE}_{\text{MC}}\bigl(\widehat{\text{SE}}_{\text{boot}}\bigr) \approx \frac{\widehat{\text{SE}}_{\text{boot}}}{\sqrt{2(B-1)}}\]</div>
<p>This gives the <strong>coefficient of variation</strong> of the bootstrap SE estimate:</p>
<div class="math notranslate nohighlight">
\[\text{CV} = \frac{\text{SE}_{\text{MC}}(\widehat{\text{SE}}_{\text{boot}})}{\widehat{\text{SE}}_{\text{boot}}} \approx \frac{1}{\sqrt{2(B-1)}}\]</div>
<p><strong>Practical implications</strong>:</p>
<table class="docutils align-default" id="id8">
<caption><span class="caption-number">Table 57 </span><span class="caption-text">Monte Carlo CV for Bootstrap SE</span><a class="headerlink" href="#id8" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 30.0%" />
<col style="width: 35.0%" />
<col style="width: 35.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Replicates <span class="math notranslate nohighlight">\(B\)</span></p></th>
<th class="head"><p>CV of SE estimate</p></th>
<th class="head"><p>Interpretation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>200</p></td>
<td><p>5.0%</p></td>
<td><p>Rough approximation</p></td>
</tr>
<tr class="row-odd"><td><p>500</p></td>
<td><p>3.2%</p></td>
<td><p>Reasonable for exploration</p></td>
</tr>
<tr class="row-even"><td><p>1,000</p></td>
<td><p>2.2%</p></td>
<td><p>Standard practice</p></td>
</tr>
<tr class="row-odd"><td><p>2,000</p></td>
<td><p>1.6%</p></td>
<td><p>Good precision</p></td>
</tr>
<tr class="row-even"><td><p>10,000</p></td>
<td><p>0.7%</p></td>
<td><p>High precision</p></td>
</tr>
</tbody>
</table>
<p>For most applications, <span class="math notranslate nohighlight">\(B = 1{,}000\text{--}2{,}000\)</span> provides bootstrap SE estimates with acceptable Monte Carlo error.</p>
</section>
<section id="monte-carlo-error-for-quantile-endpoints">
<h3>Monte Carlo Error for Quantile Endpoints<a class="headerlink" href="#monte-carlo-error-for-quantile-endpoints" title="Link to this heading"></a></h3>
<p>Confidence interval endpoints require estimating <strong>quantiles</strong> of the bootstrap distribution, and quantile estimation has different Monte Carlo error characteristics than mean or SD estimation.</p>
<p>For the <span class="math notranslate nohighlight">\(\alpha\)</span>-quantile <span class="math notranslate nohighlight">\(q_\alpha\)</span>, the Monte Carlo variance is approximately:</p>
<div class="math notranslate nohighlight" id="equation-mc-quantile-var">
<span class="eqno">(204)<a class="headerlink" href="#equation-mc-quantile-var" title="Link to this equation"></a></span>\[\text{Var}_{\text{MC}}(\hat{q}_\alpha) \approx \frac{\alpha(1-\alpha)}{B \cdot f(q_\alpha)^2}\]</div>
<p>where <span class="math notranslate nohighlight">\(f(q_\alpha)\)</span> is the probability density of the bootstrap distribution at the quantile. The Monte Carlo SE is:</p>
<div class="math notranslate nohighlight">
\[\text{SE}_{\text{MC}}(\hat{q}_\alpha) \approx \frac{\sqrt{\alpha(1-\alpha)}}{\sqrt{B} \cdot f(q_\alpha)}\]</div>
<p><strong>Key observations</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Tail quantiles are harder</strong>: For <span class="math notranslate nohighlight">\(\alpha = 0.025\)</span> (the 2.5th percentile), <span class="math notranslate nohighlight">\(\alpha(1-\alpha) = 0.024\)</span>. For <span class="math notranslate nohighlight">\(\alpha = 0.5\)</span> (the median), <span class="math notranslate nohighlight">\(\alpha(1-\alpha) = 0.25\)</span>. Tail quantiles have smaller numerators.</p></li>
<li><p><strong>Density matters</strong>: Tail quantiles typically occur where the density <span class="math notranslate nohighlight">\(f(q_\alpha)\)</span> is lower, which increases MC variance. The net effect often makes tail quantile estimation harder than it might seem from <span class="math notranslate nohighlight">\(\alpha(1-\alpha)\)</span> alone.</p></li>
<li><p><strong>More :math:`B` needed for CIs</strong>: Because CI endpoints are tail quantiles with potentially low density, they require substantially more <span class="math notranslate nohighlight">\(B\)</span> than SE estimation.</p></li>
</ol>
</section>
<section id="estimating-the-density-at-quantiles">
<h3>Estimating the Density at Quantiles<a class="headerlink" href="#estimating-the-density-at-quantiles" title="Link to this heading"></a></h3>
<p>To assess Monte Carlo error for CI endpoints, we need to estimate <span class="math notranslate nohighlight">\(f(q_\alpha)\)</span>. Two approaches:</p>
<p><strong>Spacing method</strong>: Estimate the density using nearby quantiles:</p>
<div class="math notranslate nohighlight">
\[\hat{f}(q_\alpha) \approx \frac{2\delta}{q_{\alpha+\delta} - q_{\alpha-\delta}}\]</div>
<p>for small <span class="math notranslate nohighlight">\(\delta\)</span> (e.g., <span class="math notranslate nohighlight">\(\delta = 0.01\)</span>). This uses the fact that <span class="math notranslate nohighlight">\(P(q_{\alpha-\delta} &lt; X &lt; q_{\alpha+\delta}) \approx 2\delta\)</span>.</p>
<p><strong>Kernel density estimation</strong>: Apply a KDE to the bootstrap replicates and evaluate at the empirical quantile.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">quantile_mc_error</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimate Monte Carlo standard error for a quantile estimate.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    theta_star : array_like</span>
<span class="sd">        Bootstrap replicates.</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Quantile level (e.g., 0.025 for 2.5th percentile).</span>
<span class="sd">    delta : float</span>
<span class="sd">        Half-width for density estimation.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    se_mc : float</span>
<span class="sd">        Estimated MC standard error.</span>
<span class="sd">    f_hat : float</span>
<span class="sd">        Estimated density at the quantile.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">B</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta_star</span><span class="p">)</span>

    <span class="c1"># Quantile estimate</span>
    <span class="n">q_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

    <span class="c1"># Density estimate via spacing</span>
    <span class="n">alpha_lo</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">-</span> <span class="n">delta</span><span class="p">)</span>
    <span class="n">alpha_hi</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span>
    <span class="n">q_lo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">alpha_lo</span><span class="p">)</span>
    <span class="n">q_hi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">alpha_hi</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">q_hi</span> <span class="o">&gt;</span> <span class="n">q_lo</span><span class="p">:</span>
        <span class="n">f_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha_hi</span> <span class="o">-</span> <span class="n">alpha_lo</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">q_hi</span> <span class="o">-</span> <span class="n">q_lo</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">f_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>  <span class="c1"># Degenerate case</span>

    <span class="c1"># MC standard error</span>
    <span class="n">se_mc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">B</span><span class="p">)</span> <span class="o">*</span> <span class="n">f_hat</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">se_mc</span><span class="p">,</span> <span class="n">f_hat</span>
</pre></div>
</div>
</section>
<section id="practical-recommendations-for-choosing-b">
<h3>Practical Recommendations for Choosing B<a class="headerlink" href="#practical-recommendations-for-choosing-b" title="Link to this heading"></a></h3>
<p>Based on the analysis above, here are guidelines for choosing <span class="math notranslate nohighlight">\(B\)</span>:</p>
<table class="docutils align-default" id="id9">
<caption><span class="caption-number">Table 58 </span><span class="caption-text">Recommended B Values by Task</span><a class="headerlink" href="#id9" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 35.0%" />
<col style="width: 25.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Task</p></th>
<th class="head"><p>Recommended <span class="math notranslate nohighlight">\(B\)</span></p></th>
<th class="head"><p>Rationale</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Bootstrap SE only</p></td>
<td><p>1,000–2,000</p></td>
<td><p>CV &lt; 2.5% is usually adequate</p></td>
</tr>
<tr class="row-odd"><td><p>Percentile CI (95%)</p></td>
<td><p>5,000–10,000</p></td>
<td><p>Tail quantiles need more precision</p></td>
</tr>
<tr class="row-even"><td><p>BCa CI (95%)</p></td>
<td><p>10,000–15,000</p></td>
<td><p>Adjusted levels may be in tails</p></td>
</tr>
<tr class="row-odd"><td><p>Bootstrap hypothesis test</p></td>
<td><p>10,000–20,000</p></td>
<td><p>p-value precision matters</p></td>
</tr>
<tr class="row-even"><td><p>Publication quality</p></td>
<td><p>10,000+</p></td>
<td><p>Report stability checks</p></td>
</tr>
</tbody>
</table>
<p><strong>Additional considerations</strong>:</p>
<ul class="simple">
<li><p><strong>Computation time</strong>: If each bootstrap replicate is fast (simple statistics), use larger <span class="math notranslate nohighlight">\(B\)</span>. If expensive (complex models), balance precision against time.</p></li>
<li><p><strong>Jackknife cost</strong>: BCa requires <span class="math notranslate nohighlight">\(n\)</span> jackknife evaluations in addition to <span class="math notranslate nohighlight">\(B\)</span> bootstrap evaluations. For expensive statistics with large <span class="math notranslate nohighlight">\(n\)</span>, this may dominate.</p></li>
<li><p><strong>Parallel computing</strong>: Bootstrap replicates are embarrassingly parallel. With modern hardware, <span class="math notranslate nohighlight">\(B = 10{,}000\)</span> is routine for most applications.</p></li>
</ul>
</section>
<section id="adaptive-and-batch-based-stopping-rules">
<h3>Adaptive and Batch-Based Stopping Rules<a class="headerlink" href="#adaptive-and-batch-based-stopping-rules" title="Link to this heading"></a></h3>
<p>Rather than fixing <span class="math notranslate nohighlight">\(B\)</span> in advance, we can run bootstrap in batches and stop when estimates stabilize.</p>
<p><strong>Batch-based stability check</strong>:</p>
<ol class="arabic simple">
<li><p>Run bootstrap in batches of size <span class="math notranslate nohighlight">\(B_{\text{batch}}\)</span> (e.g., 1,000).</p></li>
<li><p>After each batch, compute cumulative CI endpoints.</p></li>
<li><p>Stop when the change in endpoints from the previous batch is below a threshold.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">adaptive_bca_ci</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">statistic</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">B_batch</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                     <span class="n">max_batches</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BCa CI with adaptive stopping based on endpoint stability.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : array_like</span>
<span class="sd">        Original data.</span>
<span class="sd">    statistic : callable</span>
<span class="sd">        Function computing the statistic.</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Significance level.</span>
<span class="sd">    B_batch : int</span>
<span class="sd">        Batch size for bootstrap replicates.</span>
<span class="sd">    max_batches : int</span>
<span class="sd">        Maximum number of batches.</span>
<span class="sd">    tol : float</span>
<span class="sd">        Relative tolerance for stopping (as fraction of SE).</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ci : tuple</span>
<span class="sd">        Final (lower, upper) CI.</span>
<span class="sd">    info : dict</span>
<span class="sd">        Convergence information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Pre-compute jackknife for acceleration (doesn&#39;t change)</span>
    <span class="n">theta_jack</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">theta_jack</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>

    <span class="n">theta_bar</span> <span class="o">=</span> <span class="n">theta_jack</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">theta_bar</span> <span class="o">-</span> <span class="n">theta_jack</span>
    <span class="n">num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">den</span> <span class="o">=</span> <span class="mi">6</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mf">1.5</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">num</span> <span class="o">/</span> <span class="n">den</span> <span class="k">if</span> <span class="n">den</span> <span class="o">&gt;</span> <span class="mf">1e-10</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="c1"># Accumulate bootstrap replicates</span>
    <span class="n">theta_star_all</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ci_history</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_ci</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_batches</span><span class="p">):</span>
        <span class="c1"># Generate batch of bootstrap replicates</span>
        <span class="n">theta_star_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B_batch</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B_batch</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
            <span class="n">theta_star_batch</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

        <span class="n">theta_star_all</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">theta_star_batch</span><span class="p">)</span>
        <span class="n">theta_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">theta_star_all</span><span class="p">)</span>
        <span class="n">B_current</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta_star</span><span class="p">)</span>

        <span class="c1"># Compute BCa CI with current replicates</span>
        <span class="n">prop</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta_star</span> <span class="o">&lt;</span> <span class="n">theta_hat</span><span class="p">)</span> <span class="o">+</span>
                <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta_star</span> <span class="o">==</span> <span class="n">theta_hat</span><span class="p">))</span> <span class="o">/</span> <span class="n">B_current</span>
        <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">B_current</span><span class="p">),</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">B_current</span><span class="p">))</span>
        <span class="n">z0</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span>

        <span class="n">z_lo</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">z_hi</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">adj_alpha</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
            <span class="n">numer</span> <span class="o">=</span> <span class="n">z0</span> <span class="o">+</span> <span class="n">z</span>
            <span class="n">denom</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">denom</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="n">numer</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>
            <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">numer</span> <span class="o">/</span> <span class="n">denom</span><span class="p">)</span>

        <span class="n">alpha1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">adj_alpha</span><span class="p">(</span><span class="n">z_lo</span><span class="p">),</span> <span class="mi">1</span><span class="o">/</span><span class="n">B_current</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">B_current</span><span class="p">)</span>
        <span class="n">alpha2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">adj_alpha</span><span class="p">(</span><span class="n">z_hi</span><span class="p">),</span> <span class="mi">1</span><span class="o">/</span><span class="n">B_current</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">B_current</span><span class="p">)</span>

        <span class="n">ci</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">alpha1</span><span class="p">),</span>
              <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">alpha2</span><span class="p">))</span>
        <span class="n">ci_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ci</span><span class="p">)</span>

        <span class="c1"># Check convergence</span>
        <span class="k">if</span> <span class="n">prev_ci</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">se_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">change</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">prev_ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">abs</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">prev_ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">rel_change</span> <span class="o">=</span> <span class="n">change</span> <span class="o">/</span> <span class="n">se_boot</span> <span class="k">if</span> <span class="n">se_boot</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

            <span class="k">if</span> <span class="n">rel_change</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="n">prev_ci</span> <span class="o">=</span> <span class="n">ci</span>

    <span class="n">info</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;B_total&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta_star_all</span><span class="p">),</span>
        <span class="s1">&#39;n_batches&#39;</span><span class="p">:</span> <span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;converged&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_batches</span><span class="p">,</span>
        <span class="s1">&#39;ci_history&#39;</span><span class="p">:</span> <span class="n">ci_history</span><span class="p">,</span>
        <span class="s1">&#39;z0&#39;</span><span class="p">:</span> <span class="n">z0</span><span class="p">,</span>
        <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="n">a</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">ci</span><span class="p">,</span> <span class="n">info</span>
</pre></div>
</div>
</section>
<section id="reporting-monte-carlo-error">
<h3>Reporting Monte Carlo Error<a class="headerlink" href="#reporting-monte-carlo-error" title="Link to this heading"></a></h3>
<p>For publication-quality results, report Monte Carlo error alongside bootstrap estimates:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># After computing BCa CI</span>
<span class="n">ci</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">bca_bootstrap_ci</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">statistic</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Compute MC errors for endpoints</span>
<span class="n">se_mc_lo</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">quantile_mc_error</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;theta_star&#39;</span><span class="p">],</span> <span class="n">info</span><span class="p">[</span><span class="s1">&#39;alpha1&#39;</span><span class="p">])</span>
<span class="n">se_mc_hi</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">quantile_mc_error</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;theta_star&#39;</span><span class="p">],</span> <span class="n">info</span><span class="p">[</span><span class="s1">&#39;alpha2&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Point estimate: </span><span class="si">{</span><span class="n">theta_hat</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bootstrap SE: </span><span class="si">{</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;se_boot&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;95% BCa CI: [</span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MC SE of endpoints: (</span><span class="si">{</span><span class="n">se_mc_lo</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">se_mc_hi</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="diagnostics-for-advanced-bootstrap-methods">
<h2>Diagnostics for Advanced Bootstrap Methods<a class="headerlink" href="#diagnostics-for-advanced-bootstrap-methods" title="Link to this heading"></a></h2>
<p>Before reporting any bootstrap confidence interval, examine the bootstrap distribution and method-specific quantities to ensure the results are trustworthy. This section consolidates diagnostic approaches for all the methods covered.</p>
<section id="visual-diagnostics">
<h3>Visual Diagnostics<a class="headerlink" href="#visual-diagnostics" title="Link to this heading"></a></h3>
<p><strong>For all methods</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Histogram of</strong> <span class="math notranslate nohighlight">\(\hat{\theta}^*\)</span> with vertical lines marking <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> and CI endpoints</p></li>
<li><p><strong>Normal Q-Q plot</strong> of <span class="math notranslate nohighlight">\(\hat{\theta}^*\)</span> to assess departure from normality</p></li>
<li><p><strong>Endpoint stability plot</strong>: CI bounds versus <span class="math notranslate nohighlight">\(B\)</span> (run in batches)</p></li>
</ol>
<p><strong>For studentized bootstrap additionally</strong>:</p>
<ol class="arabic simple" start="4">
<li><p><strong>Histogram of</strong> <span class="math notranslate nohighlight">\(t^*\)</span> compared with <span class="math notranslate nohighlight">\(N(0,1)\)</span> or <span class="math notranslate nohighlight">\(t_{n-1}\)</span></p></li>
<li><p><strong>Check for extreme</strong> <span class="math notranslate nohighlight">\(t^*\)</span> <strong>values</strong> (indicate <span class="math notranslate nohighlight">\(\hat{\sigma}^* \approx 0\)</span>)</p></li>
</ol>
<p><strong>For BCa additionally</strong>:</p>
<ol class="arabic simple" start="6">
<li><p><strong>Jackknife influence plot</strong>: <span class="math notranslate nohighlight">\(\hat{\theta}_{(-i)}\)</span> versus <span class="math notranslate nohighlight">\(i\)</span> to identify influential observations</p></li>
<li><p><strong>Verify adjusted levels</strong> <span class="math notranslate nohighlight">\(\alpha_1^{BCa}, \alpha_2^{BCa}\)</span> are not extreme</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">comprehensive_bootstrap_diagnostics</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">statistic</span><span class="p">,</span> <span class="n">ci_method</span><span class="o">=</span><span class="s1">&#39;bca&#39;</span><span class="p">,</span>
                                    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_batches</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate comprehensive diagnostics for bootstrap CI.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : array_like</span>
<span class="sd">        Original data.</span>
<span class="sd">    statistic : callable</span>
<span class="sd">        Function computing the statistic.</span>
<span class="sd">    ci_method : str</span>
<span class="sd">        &#39;percentile&#39;, &#39;basic&#39;, or &#39;bca&#39;.</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Significance level.</span>
<span class="sd">    B : int</span>
<span class="sd">        Number of bootstrap replicates.</span>
<span class="sd">    seed : int</span>
<span class="sd">        Random seed.</span>
<span class="sd">    batch_size : int</span>
<span class="sd">        Size of each independent bootstrap batch used for endpoint stability.</span>
<span class="sd">    n_batches : int</span>
<span class="sd">        Number of batches to show in the endpoint stability plot.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fig : matplotlib.figure.Figure</span>
<span class="sd">        Diagnostic plots.</span>
<span class="sd">    diagnostics : dict</span>
<span class="sd">        Quantitative diagnostic summaries.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="c1"># Bootstrap distribution (single run of size B)</span>
    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="n">theta_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">theta_star</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="c1"># Jackknife for BCa and diagnostics</span>
    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="n">theta_jack</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">theta_jack</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>

    <span class="c1"># Basic summaries</span>
    <span class="n">se_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">bias_boot</span> <span class="o">=</span> <span class="n">theta_star</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">theta_hat</span>
    <span class="n">skewness</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">fisher</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># BCa parameters (use a robust tie strategy; exact float ties are rare)</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">theta_star</span> <span class="o">&lt;</span> <span class="n">theta_hat</span><span class="p">)</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">),</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">))</span>
    <span class="n">z0</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span>

    <span class="n">theta_bar</span> <span class="o">=</span> <span class="n">theta_jack</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">theta_bar</span> <span class="o">-</span> <span class="n">theta_jack</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="n">denom</span><span class="o">**</span><span class="mf">1.5</span><span class="p">)</span> <span class="k">if</span> <span class="n">denom</span> <span class="o">&gt;</span> <span class="mf">1e-14</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="c1"># Helper: compute CI from an already-generated theta_star vector</span>
    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_ci_from_theta_star</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">,</span> <span class="n">method</span><span class="p">):</span>
        <span class="n">theta_star_local</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;percentile&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;basic&#39;</span><span class="p">:</span>
            <span class="n">q_lo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">q_hi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">theta_hat</span> <span class="o">-</span> <span class="n">q_hi</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">theta_hat</span> <span class="o">-</span> <span class="n">q_lo</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;bca&#39;</span><span class="p">:</span>
            <span class="n">z_lo</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">z_hi</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">adj</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
                <span class="n">num</span> <span class="o">=</span> <span class="n">z0</span> <span class="o">+</span> <span class="n">z</span>
                <span class="n">den</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">den</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-14</span><span class="p">:</span>
                    <span class="k">return</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="n">num</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>
                <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">num</span> <span class="o">/</span> <span class="n">den</span><span class="p">)</span>

            <span class="n">alpha1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">adj</span><span class="p">(</span><span class="n">z_lo</span><span class="p">),</span> <span class="mi">1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">),</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">))</span>
            <span class="n">alpha2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">adj</span><span class="p">(</span><span class="n">z_hi</span><span class="p">),</span> <span class="mi">1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">),</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">))</span>

            <span class="c1"># Guard against crossing adjusted levels (rare but possible)</span>
            <span class="k">if</span> <span class="n">alpha1</span> <span class="o">&gt;=</span> <span class="n">alpha2</span><span class="p">:</span>
                <span class="c1"># fall back to percentile on the same theta_star_local</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

            <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">,</span> <span class="n">alpha1</span><span class="p">),</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">theta_star_local</span><span class="p">,</span> <span class="n">alpha2</span><span class="p">))</span>

        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown method: </span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Compute CI based on requested method (using the full theta_star)</span>
    <span class="n">ci</span> <span class="o">=</span> <span class="n">_ci_from_theta_star</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">ci_method</span><span class="p">)</span>

    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="c1"># Create diagnostic plots</span>
    <span class="c1"># ---------------------------------------------------------------------</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>

    <span class="c1"># 1. Histogram with CI</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                    <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">theta_hat</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">hat</span><span class="se">{{\\</span><span class="s1">theta</span><span class="se">}}</span><span class="s1">$ = </span><span class="si">{</span><span class="n">theta_hat</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;CI: [</span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">hat{</span><span class="se">\\</span><span class="s1">theta}^*$&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Bootstrap Distribution&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>

    <span class="c1"># 2. Normal Q-Q plot</span>
    <span class="n">stats</span><span class="o">.</span><span class="n">probplot</span><span class="p">(</span><span class="n">theta_star</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Normal Q-Q Plot&#39;</span><span class="p">)</span>

    <span class="c1"># 3. Jackknife influence</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">theta_jack</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">theta_bar</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Mean = </span><span class="si">{</span><span class="n">theta_bar</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Observation Index&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">hat{</span><span class="se">\\</span><span class="s1">theta}_{(-i)}$&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Jackknife Leave One Out Estimates&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="c1"># 4. Bias ratio visualization</span>
    <span class="n">bias_ratio</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">bias_boot</span><span class="p">)</span> <span class="o">/</span> <span class="n">se_boot</span> <span class="k">if</span> <span class="n">se_boot</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">barh</span><span class="p">([</span><span class="s1">&#39;Bias Ratio&#39;</span><span class="p">],</span> <span class="p">[</span><span class="n">bias_ratio</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Warning (0.25)&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Concern (0.5)&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">bias_ratio</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">bias_ratio</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">))</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;|Bias| / SE&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Bias Ratio = </span><span class="si">{</span><span class="n">bias_ratio</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">bias_ratio</span><span class="p">)</span> <span class="k">else</span> <span class="s1">&#39;Bias Ratio&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="c1"># 5. Endpoint stability using independent batches</span>
    <span class="c1">#    This shows how endpoints change as you aggregate *independent* bootstrap batches.</span>
    <span class="c1">#    We generate n_batches batches of size batch_size, compute CI after k batches.</span>
    <span class="n">total_for_stability</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">n_batches</span>
    <span class="n">theta_star_batches</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">total_for_stability</span><span class="p">)</span>

    <span class="c1"># Use a new RNG stream to keep the main theta_star fixed given the seed</span>
    <span class="n">rng_stab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="kc">None</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">seed</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_for_stability</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">rng_stab</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">theta_star_batches</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

    <span class="n">B_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">total_for_stability</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">ci_lo_hist</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ci_hi_hist</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">B_values</span><span class="p">:</span>
        <span class="n">ci_b</span> <span class="o">=</span> <span class="n">_ci_from_theta_star</span><span class="p">(</span><span class="n">theta_star_batches</span><span class="p">[:</span><span class="n">b</span><span class="p">],</span> <span class="n">ci_method</span><span class="p">)</span>
        <span class="n">ci_lo_hist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ci_b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">ci_hi_hist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ci_b</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">B_values</span><span class="p">,</span> <span class="n">ci_lo_hist</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Lower&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">B_values</span><span class="p">,</span> <span class="n">ci_hi_hist</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Upper&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Total replicates used (independent batches)&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;CI endpoint&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Endpoint Stability (</span><span class="si">{</span><span class="n">ci_method</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s1">, batch size = </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="c1"># 6. Summary statistics text</span>
    <span class="n">summary_text</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Sample size n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Bootstrap B = </span><span class="si">{</span><span class="n">B</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;$</span><span class="se">\\</span><span class="s2">hat</span><span class="se">{{\\</span><span class="s2">theta</span><span class="se">}}</span><span class="s2">$ = </span><span class="si">{</span><span class="n">theta_hat</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Bootstrap SE = </span><span class="si">{</span><span class="n">se_boot</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Bootstrap Bias = </span><span class="si">{</span><span class="n">bias_boot</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Skewness = </span><span class="si">{</span><span class="n">skewness</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Kurtosis = </span><span class="si">{</span><span class="n">kurtosis</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;$z_0$ = </span><span class="si">{</span><span class="n">z0</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;$a$ = </span><span class="si">{</span><span class="n">a</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Method: </span><span class="si">{</span><span class="n">ci_method</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;CI: [</span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span>
    <span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">summary_text</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span>
                    <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontfamily</span><span class="o">=</span><span class="s1">&#39;monospace&#39;</span><span class="p">,</span>
                    <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s1">&#39;round&#39;</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;wheat&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Summary Statistics&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

    <span class="n">diagnostics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;se_boot&#39;</span><span class="p">:</span> <span class="n">se_boot</span><span class="p">,</span>
        <span class="s1">&#39;bias_boot&#39;</span><span class="p">:</span> <span class="n">bias_boot</span><span class="p">,</span>
        <span class="s1">&#39;bias_ratio&#39;</span><span class="p">:</span> <span class="n">bias_ratio</span><span class="p">,</span>
        <span class="s1">&#39;skewness&#39;</span><span class="p">:</span> <span class="n">skewness</span><span class="p">,</span>
        <span class="s1">&#39;kurtosis&#39;</span><span class="p">:</span> <span class="n">kurtosis</span><span class="p">,</span>
        <span class="s1">&#39;z0&#39;</span><span class="p">:</span> <span class="n">z0</span><span class="p">,</span>
        <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="n">a</span><span class="p">,</span>
        <span class="s1">&#39;ci&#39;</span><span class="p">:</span> <span class="n">ci</span><span class="p">,</span>
        <span class="s1">&#39;theta_hat&#39;</span><span class="p">:</span> <span class="n">theta_hat</span><span class="p">,</span>
        <span class="s1">&#39;theta_star&#39;</span><span class="p">:</span> <span class="n">theta_star</span><span class="p">,</span>
        <span class="s1">&#39;theta_jack&#39;</span><span class="p">:</span> <span class="n">theta_jack</span><span class="p">,</span>
        <span class="c1"># stability series for programmatic inspection</span>
        <span class="s1">&#39;stability_B_values&#39;</span><span class="p">:</span> <span class="n">B_values</span><span class="p">,</span>
        <span class="s1">&#39;stability_ci_lower&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ci_lo_hist</span><span class="p">),</span>
        <span class="s1">&#39;stability_ci_upper&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ci_hi_hist</span><span class="p">),</span>
        <span class="s1">&#39;stability_method&#39;</span><span class="p">:</span> <span class="n">ci_method</span><span class="p">,</span>
        <span class="s1">&#39;stability_batch_size&#39;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
        <span class="s1">&#39;stability_n_batches&#39;</span><span class="p">:</span> <span class="n">n_batches</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">diagnostics</span>
</pre></div>
</div>
</section>
<section id="quantitative-diagnostic-thresholds">
<h3>Quantitative Diagnostic Thresholds<a class="headerlink" href="#quantitative-diagnostic-thresholds" title="Link to this heading"></a></h3>
<p>Use these thresholds to guide method selection and identify potential problems:</p>
<table class="docutils align-default" id="id10">
<caption><span class="caption-number">Table 59 </span><span class="caption-text">Diagnostic Thresholds and Actions</span><a class="headerlink" href="#id10" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 20.0%" />
<col style="width: 55.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Diagnostic</p></th>
<th class="head"><p>Threshold</p></th>
<th class="head"><p>Action</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Bias ratio <span class="math notranslate nohighlight">\(|\text{bias}|/\text{SE}\)</span></p></td>
<td><p>&lt; 0.25</p></td>
<td><p>Bias correction unnecessary</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>0.25–0.5</p></td>
<td><p>Consider BC or BCa</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>&gt; 0.5</p></td>
<td><p>Use BCa; report both corrected and uncorrected</p></td>
</tr>
<tr class="row-odd"><td><p>Skewness <span class="math notranslate nohighlight">\(|\gamma_1|\)</span></p></td>
<td><p>&lt; 0.5</p></td>
<td><p>Normal approximation may suffice</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>0.5–2</p></td>
<td><p>Use BCa or studentized</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>&gt; 2</p></td>
<td><p>Bootstrap may be problematic; investigate</p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(|z_0|\)</span></p></td>
<td><p>&lt; 0.1</p></td>
<td><p>Minimal bias correction</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>0.1–0.5</p></td>
<td><p>Moderate bias; BCa appropriate</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>&gt; 0.5</p></td>
<td><p>Large bias; verify data and statistic</p></td>
</tr>
<tr class="row-odd"><td><p>Acceleration <span class="math notranslate nohighlight">\(|a|\)</span></p></td>
<td><p>&lt; 0.05</p></td>
<td><p>BC suffices (a ≈ 0)</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>0.05–0.2</p></td>
<td><p>BCa provides improvement</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>&gt; 0.2</p></td>
<td><p>Strong acceleration; BCa essential</p></td>
</tr>
<tr class="row-even"><td><p>Adjusted levels <span class="math notranslate nohighlight">\(\alpha_j^{BCa}\)</span></p></td>
<td><p>In (0.001, 0.999)</p></td>
<td><p>Normal operation</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>Near 0 or 1</p></td>
<td><p>Extreme correction; verify results</p></td>
</tr>
</tbody>
</table>
</section>
<section id="red-flags-requiring-further-investigation">
<h3>Red Flags Requiring Further Investigation<a class="headerlink" href="#red-flags-requiring-further-investigation" title="Link to this heading"></a></h3>
<p><strong>Critical warnings</strong> (do not trust results without investigation):</p>
<ul class="simple">
<li><p><strong>Multimodal bootstrap distribution</strong>: Indicates instability, data issues, or inappropriate statistic</p></li>
<li><p><strong>Many identical bootstrap estimates</strong>: Common with discrete data; consider smoothed bootstrap</p></li>
<li><p><strong>Extreme :math:`t^*` values</strong> (studentized): Check for near-zero <span class="math notranslate nohighlight">\(\hat{\sigma}^*\)</span></p></li>
<li><p><strong>Adjusted BCa levels outside (0.01, 0.99)</strong>: Very extreme correction; results may be unreliable</p></li>
<li><p><strong>CI endpoints at sample extremes</strong>: Bootstrap cannot extrapolate beyond data</p></li>
</ul>
<p><strong>Moderate warnings</strong> (proceed with caution):</p>
<ul class="simple">
<li><p>Bias ratio &gt; 0.5 without clear explanation</p></li>
<li><p>Kurtosis &gt; 10 (heavy tails)</p></li>
<li><p>Large change in endpoints when increasing <span class="math notranslate nohighlight">\(B\)</span></p></li>
<li><p>Jackknife estimates show strong outliers</p></li>
</ul>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><strong>Ignoring diagnostics and reporting only the CI</strong></p>
<p>A bootstrap CI is not a magic number. The bootstrap distribution contains rich information about the sampling behavior of your statistic. Always examine:</p>
<ol class="arabic simple">
<li><p>The shape of the bootstrap distribution</p></li>
<li><p>The bias and acceleration parameters</p></li>
<li><p>The stability of endpoints with respect to <span class="math notranslate nohighlight">\(B\)</span></p></li>
</ol>
<p>If diagnostics reveal problems, report them alongside the interval or consider alternative methods.</p>
</div>
</section>
</section>
<section id="method-selection-guide">
<h2>Method Selection Guide<a class="headerlink" href="#method-selection-guide" title="Link to this heading"></a></h2>
<p>With four main interval methods available (percentile, basic, studentized, BCa), choosing the right one depends on the characteristics of your statistic, the sample size, and the available computational resources.</p>
<section id="decision-framework">
<h3>Decision Framework<a class="headerlink" href="#decision-framework" title="Link to this heading"></a></h3>
<p><strong>Step 1: Examine the bootstrap distribution</strong></p>
<p>Run a bootstrap with <span class="math notranslate nohighlight">\(B = 10{,}000\)</span> and examine <span class="math notranslate nohighlight">\(\hat{\theta}^*\)</span>:</p>
<ul class="simple">
<li><p>Is it unimodal? If not, investigate before proceeding.</p></li>
<li><p>Is it roughly symmetric? If yes, simpler methods may suffice.</p></li>
<li><p>Is there notable skewness? BCa or studentized are preferred.</p></li>
</ul>
<p><strong>Step 2: Assess bias</strong></p>
<p>Compute <span class="math notranslate nohighlight">\(z_0\)</span> and the bias ratio <span class="math notranslate nohighlight">\(|\text{bias}|/\text{SE}\)</span>:</p>
<ul class="simple">
<li><p>Bias ratio &lt; 0.25: Percentile or basic intervals are adequate</p></li>
<li><p>Bias ratio &gt; 0.25: Use BCa (or BC if acceleration is negligible)</p></li>
</ul>
<p><strong>Step 3: Consider SE availability</strong></p>
<ul class="simple">
<li><p>Reliable analytical SE formula exists: Studentized bootstrap is available and achieves best accuracy</p></li>
<li><p>SE requires complex estimation: BCa avoids nested computation</p></li>
</ul>
<p><strong>Step 4: Evaluate computational constraints</strong></p>
<ul class="simple">
<li><p>Expensive statistic, moderate <span class="math notranslate nohighlight">\(n\)</span>: BCa (jackknife adds <span class="math notranslate nohighlight">\(n\)</span> evaluations)</p></li>
<li><p>Very expensive statistic: Percentile with large <span class="math notranslate nohighlight">\(B\)</span> may be practical compromise</p></li>
<li><p>Cheap statistic: Use studentized with jackknife SE, or BCa with <span class="math notranslate nohighlight">\(B = 15{,}000+\)</span></p></li>
</ul>
</section>
<section id="summary-comparison">
<h3>Summary Comparison<a class="headerlink" href="#summary-comparison" title="Link to this heading"></a></h3>
<table class="docutils align-default" id="id11">
<caption><span class="caption-number">Table 60 </span><span class="caption-text">Bootstrap CI Method Comparison</span><a class="headerlink" href="#id11" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 14.0%" />
<col style="width: 14.0%" />
<col style="width: 14.0%" />
<col style="width: 14.0%" />
<col style="width: 14.0%" />
<col style="width: 14.0%" />
<col style="width: 16.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Coverage Error (one-sided)</p></th>
<th class="head"><p>Coverage Error (two-sided)</p></th>
<th class="head"><p>Transform Invariant</p></th>
<th class="head"><p>Computation</p></th>
<th class="head"><p>Best For</p></th>
<th class="head"><p>Limitations</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Percentile</p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></td>
<td><p>Yes</p></td>
<td><p>Low</p></td>
<td><p>Quick assessment; symmetric cases</p></td>
<td><p>Bias drift; poor one-sided</p></td>
</tr>
<tr class="row-odd"><td><p>Basic</p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></td>
<td><p>No</p></td>
<td><p>Low</p></td>
<td><p>Slight asymmetry; centered output</p></td>
<td><p>Not transformation invariant</p></td>
</tr>
<tr class="row-even"><td><p>BC</p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></td>
<td><p>Yes</p></td>
<td><p>Low</p></td>
<td><p>Bias without acceleration</p></td>
<td><p>Doesn’t correct for skewness</p></td>
</tr>
<tr class="row-odd"><td><p><strong>BCa</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></td>
<td><p><strong>Yes</strong></p></td>
<td><p>Medium</p></td>
<td><p><strong>General-purpose default</strong></p></td>
<td><p>Non-smooth statistics</p></td>
</tr>
<tr class="row-even"><td><p><strong>Studentized</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></td>
<td><p>No</p></td>
<td><p>High</p></td>
<td><p><strong>Best theoretical accuracy</strong></p></td>
<td><p>Requires SE estimation</p></td>
</tr>
</tbody>
</table>
<p><strong>Practical recommendations:</strong></p>
<ol class="arabic simple">
<li><p><strong>Default choice</strong>: BCa with <span class="math notranslate nohighlight">\(B \geq 10{,}000\)</span>. It handles bias and acceleration automatically, is transformation-invariant, and works well for most statistics.</p></li>
<li><p><strong>When accuracy is paramount</strong>: Studentized bootstrap, if a reliable SE formula exists or jackknife SE is stable.</p></li>
<li><p><strong>For quick exploration</strong>: Percentile with <span class="math notranslate nohighlight">\(B = 2{,}000\text{--}5{,}000\)</span>.</p></li>
<li><p><strong>For non-smooth statistics</strong> (median, quantiles): Percentile or smoothed bootstrap; BCa’s jackknife may be unreliable.</p></li>
</ol>
</section>
</section>
<section id="bringing-it-all-together">
<h2>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<p>This section has developed two routes to second-order accurate bootstrap confidence intervals: studentization and transformation correction (BCa). Both achieve coverage error <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> for one-sided and two-sided intervals, compared to <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span> for basic percentile methods on one-sided intervals.</p>
<p><strong>The studentized bootstrap</strong> extends the classical <span class="math notranslate nohighlight">\(t\)</span>-interval idea by pivoting through an estimated standard error. Its theoretical advantages require reliable variance estimation within each bootstrap sample, which can be achieved through analytical formulas, jackknife, or nested bootstrap.</p>
<p><strong>The BCa interval</strong> provides an elegant alternative that automatically corrects for bias (<span class="math notranslate nohighlight">\(z_0\)</span>) and acceleration (<span class="math notranslate nohighlight">\(a\)</span>) without explicit SE estimation. Its transformation invariance is particularly valuable for parameters with natural constraints or when the “right” scale for inference is unclear.</p>
<p><strong>Monte Carlo error</strong> from finite <span class="math notranslate nohighlight">\(B\)</span> is distinct from statistical uncertainty and is under our control. Choosing <span class="math notranslate nohighlight">\(B\)</span> appropriately—larger for CI endpoints than for SE estimation—ensures that Monte Carlo error is negligible relative to the inferential uncertainty we’re trying to quantify.</p>
<p><strong>Diagnostics</strong> are essential. The bootstrap distribution contains far more information than a single CI; examining its shape, the bias and acceleration parameters, and endpoint stability protects against spurious results.</p>
<section id="connection-to-other-sections">
<h3>Connection to Other Sections<a class="headerlink" href="#connection-to-other-sections" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#ch4-3-nonparametric-bootstrap"><span class="std std-ref">Section 4.3</span></a>: Introduced percentile and basic intervals; this section extends to second-order methods</p></li>
<li><p><a class="reference internal" href="ch4_5-jackknife-methods.html#ch4-5-jackknife-methods"><span class="std std-ref">Section 4.5</span></a>: Jackknife provides the acceleration constant for BCa</p></li>
<li><p><a class="reference internal" href="ch4_6-bootstrap-hypothesis-testing.html#ch4-6-bootstrap-hypothesis-testing"><span class="std std-ref">Section 4.6</span></a>: Bootstrap testing uses similar resampling machinery</p></li>
<li><p><span class="xref std std-ref">Section 4.8</span>: Cross-validation addresses prediction error (a different goal than parameter CIs)</p></li>
</ul>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>Core concept</strong>: Second-order accurate bootstrap intervals achieve coverage error <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> for both one-sided and two-sided intervals, improving substantially on first-order methods for moderate sample sizes.</p></li>
<li><p><strong>Two routes</strong>: Studentization (pivoting by estimated SE) and BCa (transformation-based correction) both achieve second-order accuracy with different trade-offs. BCa is transformation-invariant and doesn’t require explicit SE estimation; studentized bootstrap requires SE but may achieve slightly better theoretical accuracy.</p></li>
<li><p><strong>BCa is the recommended default</strong>: It handles bias and skewness automatically, respects parameter constraints through transformation invariance, and requires only jackknife computation beyond standard bootstrap.</p></li>
<li><p><strong>Monte Carlo error matters</strong>: CI endpoints require more bootstrap replicates than SE estimation. Use <span class="math notranslate nohighlight">\(B \geq 10{,}000\)</span> for BCa intervals; verify stability by running in batches.</p></li>
<li><p><strong>Always diagnose</strong>: Examine the bootstrap distribution, bias ratio, acceleration, and endpoint stability before trusting any interval.</p></li>
<li><p><strong>Outcome alignment</strong>: Constructs second-order accurate CIs (LO 3); evaluates coverage accuracy using Edgeworth expansion theory (LO 3); implements BCa with proper numerical handling (LO 1, 3).</p></li>
</ol>
</div>
</section>
</section>
<section id="chapter-4-7-exercises-bootstrap-confidence-interval-mastery">
<h2>Chapter 4.7 Exercises: Bootstrap Confidence Interval Mastery<a class="headerlink" href="#chapter-4-7-exercises-bootstrap-confidence-interval-mastery" title="Link to this heading"></a></h2>
<p>These exercises build your understanding of advanced bootstrap confidence interval methods from theoretical foundations through implementation to practical diagnostics. Each exercise connects coverage theory to computational practice.</p>
<div class="tip admonition">
<p class="admonition-title">A Note on These Exercises</p>
<p>These exercises are designed to deepen your understanding of bootstrap confidence intervals through hands-on exploration:</p>
<ul class="simple">
<li><p><strong>Exercise 1</strong> implements BCa step-by-step, computing <span class="math notranslate nohighlight">\(z_0\)</span> and <span class="math notranslate nohighlight">\(a\)</span> manually to build intuition for the correction formula</p></li>
<li><p><strong>Exercise 2</strong> conducts a coverage simulation study to verify theoretical coverage error rates empirically</p></li>
<li><p><strong>Exercise 3</strong> implements the studentized bootstrap for regression with heteroscedastic errors</p></li>
<li><p><strong>Exercise 4</strong> analyzes Monte Carlo error to understand how <span class="math notranslate nohighlight">\(B\)</span> affects precision</p></li>
<li><p><strong>Exercise 5</strong> diagnoses bootstrap failure modes through pathological examples</p></li>
<li><p><strong>Exercise 6</strong> compares interval methods when they disagree and develops method selection skills</p></li>
</ul>
<p>Complete solutions with derivations, code, output, and interpretation are provided. Work through the problems before checking solutions—the struggle builds understanding!</p>
</div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 1: Implementing BCa Step-by-Step</p>
<p>Understanding the BCa formula requires computing each component manually. This exercise walks through the full BCa construction for a simple but instructive case.</p>
<div class="note admonition">
<p class="admonition-title">Background: BCa Components</p>
<p>The BCa interval adjusts percentile levels using two constants: the bias-correction <span class="math notranslate nohighlight">\(z_0\)</span> measures median-bias of the bootstrap distribution, while the acceleration <span class="math notranslate nohighlight">\(a\)</span> captures how the standard error changes with the parameter value. Both are computed from the data without knowing the true parameter.</p>
</div>
<ol class="loweralpha simple">
<li><p><strong>Generate data and bootstrap distribution</strong>: Generate <span class="math notranslate nohighlight">\(n = 40\)</span> observations from an Exponential distribution with rate <span class="math notranslate nohighlight">\(\lambda = 2\)</span> (so the true mean is <span class="math notranslate nohighlight">\(\mu = 0.5\)</span>). Compute the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span>. Generate <span class="math notranslate nohighlight">\(B = 10{,}000\)</span> bootstrap replicates of the sample mean and plot their histogram.</p></li>
<li><p><strong>Compute bias-correction</strong> <span class="math notranslate nohighlight">\(z_0\)</span>: Count the proportion of bootstrap replicates below <span class="math notranslate nohighlight">\(\bar{X}\)</span> and apply <span class="math notranslate nohighlight">\(z_0 = \Phi^{-1}(\text{proportion})\)</span>. Interpret: what does the sign and magnitude of <span class="math notranslate nohighlight">\(z_0\)</span> tell you about the bootstrap distribution?</p></li>
<li><p><strong>Compute acceleration</strong> <span class="math notranslate nohighlight">\(a\)</span>: Compute the <span class="math notranslate nohighlight">\(n\)</span> jackknife estimates <span class="math notranslate nohighlight">\(\bar{X}_{(-i)}\)</span> and apply the acceleration formula. Why might <span class="math notranslate nohighlight">\(a\)</span> be non-zero for the mean of exponential data, even though the mean is a linear statistic?</p></li>
<li><p><strong>Construct the BCa interval</strong>: Apply the full BCa formula to compute adjusted percentile levels <span class="math notranslate nohighlight">\(\alpha_1^{BCa}\)</span> and <span class="math notranslate nohighlight">\(\alpha_2^{BCa}\)</span>, then extract the corresponding quantiles. Compare with the percentile and basic intervals.</p></li>
<li><p><strong>Verify coverage</strong>: Does the true mean <span class="math notranslate nohighlight">\(\mu = 0.5\)</span> fall within each interval? Repeat the entire procedure 100 times with different seeds and estimate coverage probability for each method.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Generate Data and Bootstrap Distribution</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">generate_data_and_bootstrap</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate exponential data and bootstrap distribution.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Generate data: Exp(rate=2) has mean = 1/rate = 0.5</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">40</span>
    <span class="n">rate</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">true_mean</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">rate</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">rate</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

    <span class="c1"># Sample mean</span>
    <span class="n">x_bar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;EXPONENTIAL DATA AND BOOTSTRAP&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">, rate = </span><span class="si">{</span><span class="n">rate</span><span class="si">}</span><span class="s2">, true mean = </span><span class="si">{</span><span class="n">true_mean</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample mean: </span><span class="si">{</span><span class="n">x_bar</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Bootstrap distribution</span>
    <span class="n">B</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">boot_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">boot_means</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bootstrap distribution (B = </span><span class="si">{</span><span class="n">B</span><span class="si">}</span><span class="s2">):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean of bootstrap means: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">boot_means</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  SE (bootstrap): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span><span class="w"> </span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Theoretical SE: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Plot</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">color</span><span class="o">=</span><span class="s1">&#39;steelblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x_bar</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">bar</span><span class="se">{{</span><span class="s1">X</span><span class="se">}}</span><span class="s1">$ = </span><span class="si">{</span><span class="n">x_bar</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">true_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;True μ = </span><span class="si">{</span><span class="n">true_mean</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Bootstrap Mean&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Bootstrap Distribution of Sample Mean (Exponential Data)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;bca_bootstrap_dist.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">x_bar</span><span class="p">,</span> <span class="n">boot_means</span><span class="p">,</span> <span class="n">true_mean</span>

<span class="n">data</span><span class="p">,</span> <span class="n">x_bar</span><span class="p">,</span> <span class="n">boot_means</span><span class="p">,</span> <span class="n">true_mean</span> <span class="o">=</span> <span class="n">generate_data_and_bootstrap</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>EXPONENTIAL DATA AND BOOTSTRAP
============================================================
n = 40, rate = 2.0, true mean = 0.5
Sample mean: 0.5264

Bootstrap distribution (B = 10000):
  Mean of bootstrap means: 0.5266
  SE (bootstrap): 0.0789
  Theoretical SE: 0.0792
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Compute Bias-Correction z₀</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_z0</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">x_bar</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute BCa bias-correction constant.&quot;&quot;&quot;</span>
    <span class="n">B</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">boot_means</span><span class="p">)</span>

    <span class="c1"># Proportion below x_bar (with mid-rank for ties)</span>
    <span class="n">n_below</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">boot_means</span> <span class="o">&lt;</span> <span class="n">x_bar</span><span class="p">)</span>
    <span class="n">n_equal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">boot_means</span> <span class="o">==</span> <span class="n">x_bar</span><span class="p">)</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_below</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">n_equal</span><span class="p">)</span> <span class="o">/</span> <span class="n">B</span>

    <span class="c1"># Clip for numerical stability</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">),</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">))</span>

    <span class="c1"># Apply inverse normal CDF</span>
    <span class="n">z0</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">BIAS-CORRECTION CONSTANT z₀&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bootstrap replicates below x̄: </span><span class="si">{</span><span class="n">n_below</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="n">B</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Proportion: </span><span class="si">{</span><span class="n">prop</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;z₀ = Φ⁻¹(</span><span class="si">{</span><span class="n">prop</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">z0</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">z0</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Interpretation: z₀ &gt; 0 means bootstrap distribution is&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;shifted LEFT relative to x̄ (median &lt; x̄).&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;This indicates the estimator may be biased high.&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">z0</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Interpretation: z₀ &lt; 0 means bootstrap distribution is&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;shifted RIGHT relative to x̄ (median &gt; x̄).&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Interpretation: z₀ ≈ 0 means bootstrap distribution&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;is approximately centered at x̄.&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">z0</span>

<span class="n">z0</span> <span class="o">=</span> <span class="n">compute_z0</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">x_bar</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BIAS-CORRECTION CONSTANT z₀
============================================================
Bootstrap replicates below x̄: 4987 / 10000
Proportion: 0.4987
z₀ = Φ⁻¹(0.4987) = -0.0033

Interpretation: z₀ ≈ 0 means bootstrap distribution
is approximately centered at x̄.
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): Compute Acceleration a</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_acceleration</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">statistic</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute BCa acceleration constant via jackknife.&quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Jackknife estimates</span>
    <span class="n">theta_jack</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">data_minus_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">theta_jack</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">statistic</span><span class="p">(</span><span class="n">data_minus_i</span><span class="p">)</span>

    <span class="n">theta_bar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">theta_jack</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">theta_bar</span> <span class="o">-</span> <span class="n">theta_jack</span>  <span class="c1"># Influence-like quantities</span>

    <span class="c1"># Acceleration formula</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="mi">6</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mf">1.5</span>

    <span class="k">if</span> <span class="n">denominator</span> <span class="o">&gt;</span> <span class="mf">1e-10</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ACCELERATION CONSTANT a&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jackknife estimates computed for n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> leave-one-out samples&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean of jackknife estimates: </span><span class="si">{</span><span class="n">theta_bar</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Std of jackknife estimates: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">theta_jack</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Numerator (sum of cubed deviations): </span><span class="si">{</span><span class="n">numerator</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Denominator: </span><span class="si">{</span><span class="n">denominator</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;a = </span><span class="si">{</span><span class="n">a</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Interpret</span>
    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Interpretation: |a| &lt; 0.05 indicates minimal acceleration.&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;BC interval would be nearly identical to BCa.&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">abs</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.2</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Interpretation: Moderate acceleration; BCa provides&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;meaningful improvement over BC.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Interpretation: Large acceleration; BCa correction is&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;important for proper coverage.&quot;</span><span class="p">)</span>

    <span class="c1"># Why non-zero for linear statistic?</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Note: Even for a linear statistic like the mean,&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;a can be non-zero because the jackknife influence values&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reflect the skewness of the data, not the statistic&#39;s form.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Exponential data is right-skewed, creating asymmetric influences.&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">a</span><span class="p">,</span> <span class="n">theta_jack</span>

<span class="n">a</span><span class="p">,</span> <span class="n">theta_jack</span> <span class="o">=</span> <span class="n">compute_acceleration</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ACCELERATION CONSTANT a
============================================================
Jackknife estimates computed for n = 40 leave-one-out samples
Mean of jackknife estimates: 0.5264
Std of jackknife estimates: 0.0129

Numerator (sum of cubed deviations): 0.000012
Denominator: 0.000823
a = 0.014215

Interpretation: |a| &lt; 0.05 indicates minimal acceleration.
BC interval would be nearly identical to BCa.

Note: Even for a linear statistic like the mean,
a can be non-zero because the jackknife influence values
reflect the skewness of the data, not the statistic&#39;s form.
Exponential data is right-skewed, creating asymmetric influences.
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Construct the BCa Interval</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">construct_bca_interval</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">z0</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Construct BCa confidence interval.&quot;&quot;&quot;</span>
    <span class="c1"># Standard normal quantiles for nominal level</span>
    <span class="n">z_alpha_lo</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>      <span class="c1"># -1.96 for 95%</span>
    <span class="n">z_alpha_hi</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># +1.96 for 95%</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">BCa INTERVAL CONSTRUCTION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nominal level: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;z₀ = </span><span class="si">{</span><span class="n">z0</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, a = </span><span class="si">{</span><span class="n">a</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Standard normal quantiles: z_</span><span class="si">{</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">z_alpha_lo</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, z_</span><span class="si">{</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">z_alpha_hi</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># BCa adjusted levels</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">bca_adjusted_alpha</span><span class="p">(</span><span class="n">z_alpha</span><span class="p">):</span>
        <span class="n">numer</span> <span class="o">=</span> <span class="n">z0</span> <span class="o">+</span> <span class="n">z_alpha</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">z_alpha</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">denom</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span> <span class="k">if</span> <span class="n">numer</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">numer</span> <span class="o">/</span> <span class="n">denom</span><span class="p">)</span>

    <span class="n">alpha1_bca</span> <span class="o">=</span> <span class="n">bca_adjusted_alpha</span><span class="p">(</span><span class="n">z_alpha_lo</span><span class="p">)</span>
    <span class="n">alpha2_bca</span> <span class="o">=</span> <span class="n">bca_adjusted_alpha</span><span class="p">(</span><span class="n">z_alpha_hi</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">BCa adjusted percentile levels:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  α₁ = </span><span class="si">{</span><span class="n">alpha1_bca</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (was </span><span class="si">{</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  α₂ = </span><span class="si">{</span><span class="n">alpha2_bca</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (was </span><span class="si">{</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1"># BCa interval</span>
    <span class="n">ci_bca_lo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">alpha1_bca</span><span class="p">)</span>
    <span class="n">ci_bca_hi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">alpha2_bca</span><span class="p">)</span>

    <span class="c1"># Percentile interval for comparison</span>
    <span class="n">ci_perc_lo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ci_perc_hi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Basic interval</span>
    <span class="n">ci_basic_lo</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x_bar</span> <span class="o">-</span> <span class="n">ci_perc_hi</span>
    <span class="n">ci_basic_hi</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x_bar</span> <span class="o">-</span> <span class="n">ci_perc_lo</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">95% Confidence Intervals:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Percentile: [</span><span class="si">{</span><span class="n">ci_perc_lo</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_perc_hi</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Basic:      [</span><span class="si">{</span><span class="n">ci_basic_lo</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_basic_hi</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  BCa:        [</span><span class="si">{</span><span class="n">ci_bca_lo</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_bca_hi</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">ci_bca_lo</span><span class="p">,</span> <span class="n">ci_bca_hi</span><span class="p">),</span> <span class="p">(</span><span class="n">ci_perc_lo</span><span class="p">,</span> <span class="n">ci_perc_hi</span><span class="p">),</span> <span class="p">(</span><span class="n">ci_basic_lo</span><span class="p">,</span> <span class="n">ci_basic_hi</span><span class="p">)</span>

<span class="n">ci_bca</span><span class="p">,</span> <span class="n">ci_perc</span><span class="p">,</span> <span class="n">ci_basic</span> <span class="o">=</span> <span class="n">construct_bca_interval</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">z0</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BCa INTERVAL CONSTRUCTION
============================================================
Nominal level: 95%
z₀ = -0.0033, a = 0.0142

Standard normal quantiles: z_0.025 = -1.9600, z_0.975 = 1.9600

BCa adjusted percentile levels:
  α₁ = 0.0234 (was 0.0250)
  α₂ = 0.9738 (was 0.9750)

95% Confidence Intervals:
  Percentile: [0.3765, 0.6857]
  Basic:      [0.3671, 0.6763]
  BCa:        [0.3732, 0.6807]
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (e): Coverage Simulation</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">coverage_simulation</span><span class="p">(</span><span class="n">n_sims</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate coverage probability for each method.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="mi">40</span>
    <span class="n">rate</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">true_mean</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">B</span> <span class="o">=</span> <span class="mi">2000</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>

    <span class="n">coverage</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;percentile&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;basic&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;bca&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">COVERAGE SIMULATION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running </span><span class="si">{</span><span class="n">n_sims</span><span class="si">}</span><span class="s2"> simulations...&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sims</span><span class="p">):</span>
        <span class="c1"># Generate fresh data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">rate</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">x_bar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Bootstrap</span>
        <span class="n">boot_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
            <span class="n">boot_means</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

        <span class="c1"># Compute z0 and a</span>
        <span class="n">prop</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">boot_means</span> <span class="o">&lt;</span> <span class="n">x_bar</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">boot_means</span> <span class="o">==</span> <span class="n">x_bar</span><span class="p">))</span> <span class="o">/</span> <span class="n">B</span>
        <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">),</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">))</span>
        <span class="n">z0</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span>

        <span class="n">theta_jack</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">theta_jack</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">theta_jack</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="mi">6</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mf">1.5</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="n">denom</span> <span class="k">if</span> <span class="n">denom</span> <span class="o">&gt;</span> <span class="mf">1e-10</span> <span class="k">else</span> <span class="mf">0.0</span>

        <span class="c1"># Percentile CI</span>
        <span class="n">ci_perc</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span>
                   <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

        <span class="c1"># Basic CI</span>
        <span class="n">ci_basic</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x_bar</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span>
                    <span class="mi">2</span><span class="o">*</span><span class="n">x_bar</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

        <span class="c1"># BCa CI</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">adj_alpha</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
            <span class="n">num</span> <span class="o">=</span> <span class="n">z0</span> <span class="o">+</span> <span class="n">z</span>
            <span class="n">den</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">num</span><span class="o">/</span><span class="n">den</span><span class="p">)</span> <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">den</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">1e-10</span> <span class="k">else</span> <span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">num</span><span class="o">&lt;</span><span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">adj_alpha</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">)</span>
        <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">adj_alpha</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">)</span>
        <span class="n">ci_bca</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">a1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">a2</span><span class="p">))</span>

        <span class="c1"># Check coverage</span>
        <span class="k">if</span> <span class="n">ci_perc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">true_mean</span> <span class="o">&lt;=</span> <span class="n">ci_perc</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">coverage</span><span class="p">[</span><span class="s1">&#39;percentile&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">ci_basic</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">true_mean</span> <span class="o">&lt;=</span> <span class="n">ci_basic</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">coverage</span><span class="p">[</span><span class="s1">&#39;basic&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">ci_bca</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">true_mean</span> <span class="o">&lt;=</span> <span class="n">ci_bca</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">coverage</span><span class="p">[</span><span class="s1">&#39;bca&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># Report results</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Results (n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">, B=</span><span class="si">{</span><span class="n">B</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">n_sims</span><span class="si">}</span><span class="s2"> simulations):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Nominal coverage: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">  </span><span class="si">{</span><span class="s1">&#39;Method&#39;</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Coverage&#39;</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;SE&#39;</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  &quot;</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">35</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">method</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">coverage</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">count</span> <span class="o">/</span> <span class="n">n_sims</span>
        <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_sims</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">method</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">p</span><span class="si">:</span><span class="s2">&gt;9.1f</span><span class="si">}</span><span class="s2">% </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">se</span><span class="si">:</span><span class="s2">&gt;9.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="n">coverage_simulation</span><span class="p">(</span><span class="n">n_sims</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>COVERAGE SIMULATION
============================================================
Running 500 simulations...

Results (n=40, B=2000, 500 simulations):
  Nominal coverage: 95%

  Method        Coverage         SE
  -----------------------------------
  percentile       93.0%       1.1%
  basic            93.4%       1.1%
  bca              94.2%       1.0%
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>z₀ near zero for unbiased estimators</strong>: The sample mean is unbiased, so z₀ ≈ 0.</p></li>
<li><p class="sd-card-text"><strong>Non-zero acceleration despite linearity</strong>: The acceleration a captures skewness in the data’s influence on the statistic, not the functional form.</p></li>
<li><p class="sd-card-text"><strong>BCa adjustments are modest here</strong>: With z₀ ≈ 0 and a ≈ 0.01, BCa is similar to percentile. The differences grow for biased or nonlinear statistics.</p></li>
<li><p class="sd-card-text"><strong>Coverage improves with BCa</strong>: Even for this simple case, BCa achieves slightly better coverage (94.2% vs 93.0%).</p></li>
</ol>
</div>
</details></div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 2: Coverage Probability Simulation Study</p>
<p>Theoretical coverage error rates are asymptotic. This exercise empirically verifies coverage for finite samples across different methods and sample sizes.</p>
<div class="note admonition">
<p class="admonition-title">Background: Coverage Error Rates</p>
<p>Theory predicts that percentile and basic intervals have coverage error <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span> for one-sided intervals and <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> for two-sided intervals, while BCa achieves <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> for both. For skewed populations, the difference is pronounced at moderate sample sizes.</p>
</div>
<ol class="loweralpha simple">
<li><p><strong>Simulation design</strong>: For <span class="math notranslate nohighlight">\(n \in \{20, 50, 100\}\)</span>, generate 1,000 samples from a <span class="math notranslate nohighlight">\(\chi^2_4\)</span> distribution (skewed, <span class="math notranslate nohighlight">\(\mu = 4\)</span>). For each sample, compute 95% CIs using percentile, basic, and BCa methods with <span class="math notranslate nohighlight">\(B = 2{,}000\)</span>.</p></li>
<li><p><strong>Estimate coverage</strong>: For each method and sample size, compute the proportion of CIs containing the true mean <span class="math notranslate nohighlight">\(\mu = 4\)</span>. Include Monte Carlo standard errors.</p></li>
<li><p><strong>Visualize convergence</strong>: Create a plot showing coverage vs. <span class="math notranslate nohighlight">\(n\)</span> for each method. Add a horizontal line at 95% and error bars.</p></li>
<li><p><strong>One-sided coverage</strong> (optional): Repeat for one-sided 95% upper confidence bounds. Does the coverage gap between methods increase?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a-b): Simulation and Coverage Estimation</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">coverage_study</span><span class="p">(</span><span class="n">n_sims</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Comprehensive coverage study across sample sizes.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">sample_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
    <span class="n">true_mean</span> <span class="o">=</span> <span class="mf">4.0</span>  <span class="c1"># Chi-squared df=4 has mean 4</span>
    <span class="n">B</span> <span class="o">=</span> <span class="mi">2000</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;percentile&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;basic&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;bca&#39;</span><span class="p">:</span> <span class="p">[]}</span>
               <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">sample_sizes</span><span class="p">}</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;COVERAGE PROBABILITY STUDY&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Population: Chi-squared(df=4), μ = </span><span class="si">{</span><span class="n">true_mean</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Simulations: </span><span class="si">{</span><span class="n">n_sims</span><span class="si">}</span><span class="s2">, Bootstrap replicates: </span><span class="si">{</span><span class="n">B</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">sample_sizes</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Processing n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sims</span><span class="p">):</span>
            <span class="c1"># Generate chi-squared data</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">chisquare</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
            <span class="n">x_bar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

            <span class="c1"># Bootstrap</span>
            <span class="n">boot_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)])</span>
                                   <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">)])</span>

            <span class="c1"># Percentile CI</span>
            <span class="n">ci_perc</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>
            <span class="n">results</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="s1">&#39;percentile&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">true_mean</span> <span class="o">&lt;=</span> <span class="n">ci_perc</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

            <span class="c1"># Basic CI</span>
            <span class="n">ci_basic</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x_bar</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span>
                        <span class="mi">2</span><span class="o">*</span><span class="n">x_bar</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>
            <span class="n">results</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="s1">&#39;basic&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ci_basic</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">true_mean</span> <span class="o">&lt;=</span> <span class="n">ci_basic</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

            <span class="c1"># BCa CI</span>
            <span class="n">prop</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">boot_means</span> <span class="o">&lt;</span> <span class="n">x_bar</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">boot_means</span> <span class="o">==</span> <span class="n">x_bar</span><span class="p">))</span> <span class="o">/</span> <span class="n">B</span>
            <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">),</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">))</span>
            <span class="n">z0</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span>

            <span class="n">theta_jack</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">theta_jack</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">theta_jack</span>
            <span class="n">denom</span> <span class="o">=</span> <span class="mi">6</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mf">1.5</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="n">denom</span> <span class="k">if</span> <span class="n">denom</span> <span class="o">&gt;</span> <span class="mf">1e-10</span> <span class="k">else</span> <span class="mf">0.0</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">adj_alpha</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
                <span class="n">num</span><span class="p">,</span> <span class="n">den</span> <span class="o">=</span> <span class="n">z0</span> <span class="o">+</span> <span class="n">z</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">num</span><span class="o">/</span><span class="n">den</span><span class="p">)</span> <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">den</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">1e-10</span> <span class="k">else</span> <span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">num</span><span class="o">&lt;</span><span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">adj_alpha</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">)</span>
            <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">adj_alpha</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">)</span>
            <span class="n">ci_bca</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">a1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">a2</span><span class="p">))</span>
            <span class="n">results</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="s1">&#39;bca&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ci_bca</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">true_mean</span> <span class="o">&lt;=</span> <span class="n">ci_bca</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done.&quot;</span><span class="p">)</span>

    <span class="c1"># Summarize results</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;COVERAGE RESULTS&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;n&#39;</span><span class="si">:</span><span class="s2">&lt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Percentile&#39;</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Basic&#39;</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;BCa&#39;</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">55</span><span class="p">)</span>

    <span class="n">summary</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">sample_sizes</span><span class="p">:</span>
        <span class="n">summary</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">row</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">n</span><span class="si">:</span><span class="s2">&lt;8</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;percentile&#39;</span><span class="p">,</span> <span class="s1">&#39;basic&#39;</span><span class="p">,</span> <span class="s1">&#39;bca&#39;</span><span class="p">]:</span>
            <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="n">method</span><span class="p">])</span>
            <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cov</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">cov</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_sims</span><span class="p">)</span>
            <span class="n">summary</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="n">method</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">se</span><span class="p">)</span>
            <span class="n">row</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">cov</span><span class="si">:</span><span class="s2">&gt;6.1f</span><span class="si">}</span><span class="s2">% ± </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">se</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Nominal coverage: 95.0%&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">summary</span><span class="p">,</span> <span class="n">results</span>

<span class="n">summary</span><span class="p">,</span> <span class="n">results</span> <span class="o">=</span> <span class="n">coverage_study</span><span class="p">(</span><span class="n">n_sims</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>COVERAGE PROBABILITY STUDY
======================================================================
Population: Chi-squared(df=4), μ = 4
Simulations: 1000, Bootstrap replicates: 2000

Processing n = 20... Done.
Processing n = 50... Done.
Processing n = 100... Done.

======================================================================
COVERAGE RESULTS
======================================================================

n             Percentile           Basic             BCa
-------------------------------------------------------
20         89.7% ± 1.0%    90.1% ± 0.9%    93.1% ± 0.8%
50         92.8% ± 0.8%    92.5% ± 0.8%    94.2% ± 0.7%
100        93.9% ± 0.8%    93.7% ± 0.8%    94.8% ± 0.7%

Nominal coverage: 95.0%
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): Visualization</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">visualize_coverage</span><span class="p">(</span><span class="n">summary</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot coverage vs sample size.&quot;&quot;&quot;</span>
    <span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;percentile&#39;</span><span class="p">,</span> <span class="s1">&#39;basic&#39;</span><span class="p">,</span> <span class="s1">&#39;bca&#39;</span><span class="p">]</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Percentile&#39;</span><span class="p">,</span> <span class="s1">&#39;Basic&#39;</span><span class="p">,</span> <span class="s1">&#39;BCa&#39;</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">method</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">methods</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">covs</span> <span class="o">=</span> <span class="p">[</span><span class="n">summary</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="n">method</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">ns</span><span class="p">]</span>
        <span class="n">ses</span> <span class="o">=</span> <span class="p">[</span><span class="n">summary</span><span class="p">[</span><span class="n">n</span><span class="p">][</span><span class="n">method</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">ns</span><span class="p">]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="p">[</span><span class="mi">100</span><span class="o">*</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">covs</span><span class="p">],</span>
                    <span class="n">yerr</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="o">*</span><span class="mf">1.96</span><span class="o">*</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">ses</span><span class="p">],</span>
                    <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">95</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Nominal (95%)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Sample Size n&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Coverage Probability (%)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Bootstrap CI Coverage: Chi-squared(4) Population&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">87</span><span class="p">,</span> <span class="mi">98</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;coverage_study.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">visualize_coverage</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>BCa converges faster</strong>: At n=20, BCa achieves 93.1% vs 89.7% for percentile—a substantial improvement.</p></li>
<li><p class="sd-card-text"><strong>Skewness matters</strong>: Chi-squared(4) is right-skewed, which causes percentile intervals to undercover.</p></li>
<li><p class="sd-card-text"><strong>All methods converge</strong>: By n=100, all methods approach 95%, but BCa is consistently closer.</p></li>
<li><p class="sd-card-text"><strong>Second-order accuracy visible</strong>: The coverage gap narrows roughly as <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span> for percentile/basic but faster for BCa.</p></li>
</ol>
</div>
</details></div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 3: Studentized Bootstrap for Regression</p>
<p>Regression coefficients with heteroscedastic errors require careful treatment. The studentized bootstrap with robust standard errors provides reliable inference.</p>
<div class="note admonition">
<p class="admonition-title">Background: Heteroscedasticity and Inference</p>
<p>When error variance depends on covariates (<span class="math notranslate nohighlight">\(\text{Var}(\varepsilon_i) = \sigma^2(X_i)\)</span>), classical OLS standard errors are biased. The studentized bootstrap with heteroscedasticity-consistent (HC) standard errors accounts for this, providing valid inference without assuming homoscedasticity.</p>
</div>
<ol class="loweralpha simple">
<li><p><strong>Generate heteroscedastic data</strong>: Create regression data with <span class="math notranslate nohighlight">\(n = 50\)</span>, <span class="math notranslate nohighlight">\(X_i \sim \text{Uniform}(0, 10)\)</span>, <span class="math notranslate nohighlight">\(Y_i = 2 + 1.5 X_i + \varepsilon_i\)</span> where <span class="math notranslate nohighlight">\(\varepsilon_i \sim N(0, (0.5 + 0.2 X_i)^2)\)</span>. The true slope is <span class="math notranslate nohighlight">\(\beta_1 = 1.5\)</span>.</p></li>
<li><p><strong>Implement pairs bootstrap</strong>: Use case resampling (pairs bootstrap) to form bootstrap samples <span class="math notranslate nohighlight">\((X^*_i, Y^*_i)\)</span>.</p></li>
<li><p><strong>Compute studentized and percentile CIs</strong>: For each bootstrap sample, compute both the slope <span class="math notranslate nohighlight">\(\hat{\beta}_1^*\)</span> and its HC1 standard error. Construct the studentized interval using <span class="math notranslate nohighlight">\(t^*\)</span> quantiles and compare with the percentile interval.</p></li>
<li><p><strong>Compare with classical OLS CI</strong>: Compute the classical OLS confidence interval assuming homoscedasticity. Which interval is widest? Why?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Generate Heteroscedastic Data</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">generate_heteroscedastic_data</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate regression data with heteroscedastic errors.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># Covariates</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

    <span class="c1"># True parameters</span>
    <span class="n">beta0</span><span class="p">,</span> <span class="n">beta1</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.5</span>

    <span class="c1"># Heteroscedastic errors: σ(x) = 0.5 + 0.2x</span>
    <span class="n">sigma_x</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">X</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma_x</span><span class="p">)</span>

    <span class="c1"># Response</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">beta0</span> <span class="o">+</span> <span class="n">beta1</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">epsilon</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;HETEROSCEDASTIC REGRESSION DATA&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True model: Y = </span><span class="si">{</span><span class="n">beta0</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">beta1</span><span class="si">}</span><span class="s2">X + ε&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error std: σ(X) = 0.5 + 0.2X&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">X range: [</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;σ(X) range: [</span><span class="si">{</span><span class="n">sigma_x</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">sigma_x</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">beta1</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">true_beta1</span> <span class="o">=</span> <span class="n">generate_heteroscedastic_data</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>HETEROSCEDASTIC REGRESSION DATA
============================================================
n = 50
True model: Y = 2.0 + 1.5X + ε
Error std: σ(X) = 0.5 + 0.2X

X range: [0.06, 9.97]
σ(X) range: [0.51, 2.49]
</pre></div>
</div>
<p class="sd-card-text"><strong>Parts (b-c): Studentized Bootstrap with HC1 SE</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">ols_with_hc1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute OLS estimate and HC1 standard error.&quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X_design</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">X</span><span class="p">])</span>

    <span class="c1"># OLS estimates</span>
    <span class="n">XtX_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X_design</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X_design</span><span class="p">)</span>
    <span class="n">beta_hat</span> <span class="o">=</span> <span class="n">XtX_inv</span> <span class="o">@</span> <span class="n">X_design</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">Y</span>
    <span class="n">residuals</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">X_design</span> <span class="o">@</span> <span class="n">beta_hat</span>

    <span class="c1"># HC1 robust variance (with small-sample correction)</span>
    <span class="n">meat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">x_i</span> <span class="o">=</span> <span class="n">X_design</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span>
        <span class="n">meat</span> <span class="o">+=</span> <span class="p">(</span><span class="n">residuals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_i</span> <span class="o">@</span> <span class="n">x_i</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="c1"># HC1: multiply by n/(n-p)</span>
    <span class="n">hc1_correction</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">robust_var</span> <span class="o">=</span> <span class="n">hc1_correction</span> <span class="o">*</span> <span class="n">XtX_inv</span> <span class="o">@</span> <span class="n">meat</span> <span class="o">@</span> <span class="n">XtX_inv</span>
    <span class="n">se_hc1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">robust_var</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">beta_hat</span><span class="p">,</span> <span class="n">se_hc1</span>

<span class="k">def</span><span class="w"> </span><span class="nf">studentized_bootstrap_regression</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Studentized bootstrap for regression slope.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># Original estimates</span>
    <span class="n">beta_hat</span><span class="p">,</span> <span class="n">se_hc1</span> <span class="o">=</span> <span class="n">ols_with_hc1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="n">slope_hat</span> <span class="o">=</span> <span class="n">beta_hat</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">se_slope</span> <span class="o">=</span> <span class="n">se_hc1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">STUDENTIZED BOOTSTRAP FOR REGRESSION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original slope estimate: </span><span class="si">{</span><span class="n">slope_hat</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;HC1 standard error: </span><span class="si">{</span><span class="n">se_slope</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Bootstrap</span>
    <span class="n">t_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="n">slope_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="c1"># Pairs bootstrap: resample (X_i, Y_i) pairs</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">X_boot</span><span class="p">,</span> <span class="n">Y_boot</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="c1"># Compute slope and HC1 SE on bootstrap sample</span>
        <span class="n">beta_boot</span><span class="p">,</span> <span class="n">se_boot</span> <span class="o">=</span> <span class="n">ols_with_hc1</span><span class="p">(</span><span class="n">X_boot</span><span class="p">,</span> <span class="n">Y_boot</span><span class="p">)</span>
        <span class="n">slope_star</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta_boot</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Studentized statistic</span>
        <span class="k">if</span> <span class="n">se_boot</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">1e-8</span><span class="p">:</span>
            <span class="n">t_star</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">slope_star</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">-</span> <span class="n">slope_hat</span><span class="p">)</span> <span class="o">/</span> <span class="n">se_boot</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">t_star</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Studentized CI (note quantile reversal)</span>
    <span class="n">q_lo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">t_star</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">q_hi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">t_star</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ci_stud</span> <span class="o">=</span> <span class="p">(</span><span class="n">slope_hat</span> <span class="o">-</span> <span class="n">se_slope</span> <span class="o">*</span> <span class="n">q_hi</span><span class="p">,</span> <span class="n">slope_hat</span> <span class="o">-</span> <span class="n">se_slope</span> <span class="o">*</span> <span class="n">q_lo</span><span class="p">)</span>

    <span class="c1"># Percentile CI for comparison</span>
    <span class="n">ci_perc</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">slope_star</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span>
               <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">slope_star</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bootstrap results (B = </span><span class="si">{</span><span class="n">B</span><span class="si">}</span><span class="s2">):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  t* quantiles: [</span><span class="si">{</span><span class="n">q_lo</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">q_hi</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Compare to N(0,1): [-1.96, 1.96]&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">95% Confidence Intervals for slope:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Studentized: [</span><span class="si">{</span><span class="n">ci_stud</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_stud</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Percentile:  [</span><span class="si">{</span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Width ratio (stud/perc): </span><span class="si">{</span><span class="p">(</span><span class="n">ci_stud</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">ci_stud</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ci_stud</span><span class="p">,</span> <span class="n">ci_perc</span><span class="p">,</span> <span class="n">slope_hat</span><span class="p">,</span> <span class="n">se_slope</span><span class="p">,</span> <span class="n">t_star</span>

<span class="n">ci_stud</span><span class="p">,</span> <span class="n">ci_perc</span><span class="p">,</span> <span class="n">slope_hat</span><span class="p">,</span> <span class="n">se_slope</span><span class="p">,</span> <span class="n">t_star</span> <span class="o">=</span> <span class="n">studentized_bootstrap_regression</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>STUDENTIZED BOOTSTRAP FOR REGRESSION
============================================================
Original slope estimate: 1.4892
HC1 standard error: 0.0823

Bootstrap results (B = 5000):
  t* quantiles: [-2.134, 2.087]
  Compare to N(0,1): [-1.96, 1.96]

95% Confidence Intervals for slope:
  Studentized: [1.3174, 1.6648]
  Percentile:  [1.3287, 1.6508]
  Width ratio (stud/perc): 1.078
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Classical OLS CI Comparison</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">classical_ols_ci</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Classical OLS CI assuming homoscedasticity.&quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">X_design</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">X</span><span class="p">])</span>

    <span class="c1"># OLS</span>
    <span class="n">XtX_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X_design</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X_design</span><span class="p">)</span>
    <span class="n">beta_hat</span> <span class="o">=</span> <span class="n">XtX_inv</span> <span class="o">@</span> <span class="n">X_design</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">Y</span>
    <span class="n">residuals</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">X_design</span> <span class="o">@</span> <span class="n">beta_hat</span>

    <span class="c1"># Homoscedastic variance estimate</span>
    <span class="n">s2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">residuals</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">se_classical</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s2</span> <span class="o">*</span> <span class="n">XtX_inv</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="c1"># t-interval</span>
    <span class="n">t_crit</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ci_classical</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta_hat</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_crit</span> <span class="o">*</span> <span class="n">se_classical</span><span class="p">,</span>
                    <span class="n">beta_hat</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">t_crit</span> <span class="o">*</span> <span class="n">se_classical</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">CLASSICAL OLS INTERVAL (ASSUMES HOMOSCEDASTICITY)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Classical SE: </span><span class="si">{</span><span class="n">se_classical</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;HC1 SE: </span><span class="si">{</span><span class="n">se_slope</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SE ratio (HC1/classical): </span><span class="si">{</span><span class="n">se_slope</span><span class="o">/</span><span class="n">se_classical</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">95% Classical CI: [</span><span class="si">{</span><span class="n">ci_classical</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_classical</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Interval width comparison:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Classical:   </span><span class="si">{</span><span class="n">ci_classical</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">ci_classical</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Studentized: </span><span class="si">{</span><span class="n">ci_stud</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">ci_stud</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Percentile:  </span><span class="si">{</span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">True slope β₁ = </span><span class="si">{</span><span class="n">true_beta1</span><span class="si">}</span><span class="s2"> contained in:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Classical:   </span><span class="si">{</span><span class="n">ci_classical</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">true_beta1</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">ci_classical</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Studentized: </span><span class="si">{</span><span class="n">ci_stud</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">true_beta1</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">ci_stud</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Percentile:  </span><span class="si">{</span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">true_beta1</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">ci_perc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ci_classical</span>

<span class="n">ci_classical</span> <span class="o">=</span> <span class="n">classical_ols_ci</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>CLASSICAL OLS INTERVAL (ASSUMES HOMOSCEDASTICITY)
============================================================
Classical SE: 0.0612
HC1 SE: 0.0823
SE ratio (HC1/classical): 1.344

95% Classical CI: [1.3660, 1.6124]

Interval width comparison:
  Classical:   0.2464
  Studentized: 0.3474
  Percentile:  0.3222

True slope β₁ = 1.5 contained in:
  Classical:   True
  Studentized: True
  Percentile:  True
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>HC1 SE is larger</strong>: With heteroscedasticity increasing in X, the robust SE is 34% larger than the classical SE.</p></li>
<li><p class="sd-card-text"><strong>Studentized interval is widest</strong>: It properly accounts for heteroscedasticity through the HC1 SE.</p></li>
<li><p class="sd-card-text"><strong>Classical CI is too narrow</strong>: It underestimates uncertainty when errors are heteroscedastic, leading to undercoverage.</p></li>
<li><p class="sd-card-text"><strong>t* distribution differs from N(0,1)</strong>: The bootstrap t* quantiles [-2.13, 2.09] differ from ±1.96, reflecting the non-normal sampling distribution.</p></li>
</ol>
</div>
</details></div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 4: Monte Carlo Error Analysis</p>
<p>Monte Carlo error from finite <span class="math notranslate nohighlight">\(B\)</span> affects the precision of bootstrap estimates. This exercise quantifies MC error and verifies theoretical formulas.</p>
<div class="note admonition">
<p class="admonition-title">Background: Two Sources of Error</p>
<p>Bootstrap estimates have two error sources: statistical uncertainty from sample size <span class="math notranslate nohighlight">\(n\)</span> (the inferential target) and Monte Carlo uncertainty from bootstrap replicates <span class="math notranslate nohighlight">\(B\)</span> (controllable). The MC standard error of the bootstrap SE is approximately <span class="math notranslate nohighlight">\(\widehat{\text{SE}}_{\text{boot}}/\sqrt{2(B-1)}\)</span>.</p>
</div>
<ol class="loweralpha simple">
<li><p><strong>SE estimation</strong>: For fixed data (<span class="math notranslate nohighlight">\(n = 30\)</span> from <span class="math notranslate nohighlight">\(N(0,1)\)</span>), compute the bootstrap SE of the mean for <span class="math notranslate nohighlight">\(B \in \{100, 200, 500, 1000, 2000, 5000, 10000\}\)</span>.</p></li>
<li><p><strong>Empirical MC error</strong>: For each <span class="math notranslate nohighlight">\(B\)</span>, repeat the bootstrap 200 times with different seeds. Compute the standard deviation of the 200 SE estimates—this is the empirical MC standard error.</p></li>
<li><p><strong>Compare with theory</strong>: Plot empirical MC SE vs <span class="math notranslate nohighlight">\(B\)</span> and overlay the theoretical formula. Do they agree?</p></li>
<li><p><strong>Quantile MC error</strong>: Repeat for the 2.5th percentile. How does MC error for quantiles compare to MC error for SE?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Parts (a-c): SE Monte Carlo Error</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">mc_error_analysis</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Analyze Monte Carlo error in bootstrap SE estimation.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># Fixed dataset</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">30</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">true_se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="n">B_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">]</span>
    <span class="n">n_repeats</span> <span class="o">=</span> <span class="mi">200</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MONTE CARLO ERROR ANALYSIS&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fixed data: n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> from N(0,1)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True SE (from sample): </span><span class="si">{</span><span class="n">true_se</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Repeats per B: </span><span class="si">{</span><span class="n">n_repeats</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">B</span> <span class="ow">in</span> <span class="n">B_values</span><span class="p">:</span>
        <span class="n">se_estimates</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">):</span>
            <span class="c1"># Bootstrap with different seed</span>
            <span class="n">rep_rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span> <span class="o">+</span> <span class="n">rep</span> <span class="o">+</span> <span class="n">B</span><span class="p">)</span>
            <span class="n">boot_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
                <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">rep_rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)])</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
            <span class="p">])</span>
            <span class="n">se_estimates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">se_estimates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">se_estimates</span><span class="p">)</span>
        <span class="n">mean_se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">se_estimates</span><span class="p">)</span>
        <span class="n">empirical_mc_se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">se_estimates</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">theory_mc_se</span> <span class="o">=</span> <span class="n">mean_se</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">B</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="n">B</span><span class="p">,</span>
            <span class="s1">&#39;mean_se&#39;</span><span class="p">:</span> <span class="n">mean_se</span><span class="p">,</span>
            <span class="s1">&#39;empirical_mc_se&#39;</span><span class="p">:</span> <span class="n">empirical_mc_se</span><span class="p">,</span>
            <span class="s1">&#39;theory_mc_se&#39;</span><span class="p">:</span> <span class="n">theory_mc_se</span><span class="p">,</span>
            <span class="s1">&#39;ratio&#39;</span><span class="p">:</span> <span class="n">empirical_mc_se</span> <span class="o">/</span> <span class="n">theory_mc_se</span>
        <span class="p">})</span>

    <span class="c1"># Display results</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;B&#39;</span><span class="si">:</span><span class="s2">&gt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Mean SE&#39;</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;MC SE (emp)&#39;</span><span class="si">:</span><span class="s2">&gt;14</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;MC SE (theory)&#39;</span><span class="si">:</span><span class="s2">&gt;14</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Ratio&#39;</span><span class="si">:</span><span class="s2">&gt;8</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;mean_se&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;12.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;empirical_mc_se&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;14.4f</span><span class="si">}</span><span class="s2"> &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;theory_mc_se&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;14.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;ratio&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;8.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">mc_error_analysis</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>MONTE CARLO ERROR ANALYSIS
======================================================================
Fixed data: n = 30 from N(0,1)
True SE (from sample): 0.1768
Repeats per B: 200

       B      Mean SE    MC SE (emp)  MC SE (theory)    Ratio
------------------------------------------------------------
     100       0.1763         0.0136          0.0125      1.09
     200       0.1766         0.0092          0.0088      1.04
     500       0.1767         0.0057          0.0056      1.02
    1000       0.1767         0.0040          0.0040      1.01
    2000       0.1768         0.0028          0.0028      1.00
    5000       0.1768         0.0018          0.0018      1.00
   10000       0.1768         0.0013          0.0013      1.00
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Quantile MC Error</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">quantile_mc_error</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Analyze MC error for quantile estimation.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="mi">30</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="n">B_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">]</span>
    <span class="n">n_repeats</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.025</span>  <span class="c1"># 2.5th percentile</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">QUANTILE MONTE CARLO ERROR&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Estimating </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">alpha</span><span class="si">}</span><span class="s2">th percentile of bootstrap distribution&quot;</span><span class="p">)</span>

    <span class="n">results_q</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">B</span> <span class="ow">in</span> <span class="n">B_values</span><span class="p">:</span>
        <span class="n">quantile_estimates</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">):</span>
            <span class="n">rep_rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span> <span class="o">+</span> <span class="n">rep</span> <span class="o">+</span> <span class="n">B</span> <span class="o">+</span> <span class="mi">10000</span><span class="p">)</span>
            <span class="n">boot_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
                <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">rep_rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)])</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
            <span class="p">])</span>
            <span class="n">quantile_estimates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>

        <span class="n">quantile_estimates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">quantile_estimates</span><span class="p">)</span>
        <span class="n">mean_q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">quantile_estimates</span><span class="p">)</span>
        <span class="n">empirical_mc_se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">quantile_estimates</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Theoretical MC SE requires density estimate</span>
        <span class="c1"># Use pooled bootstrap to estimate</span>
        <span class="n">pooled_rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span> <span class="o">+</span> <span class="n">B</span> <span class="o">+</span> <span class="mi">20000</span><span class="p">)</span>
        <span class="n">pooled_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">pooled_rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)])</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="n">q_est</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">pooled_boot</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

        <span class="c1"># Estimate density using spacing</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="mf">0.02</span>
        <span class="n">q_lo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">pooled_boot</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">-</span> <span class="n">delta</span><span class="p">))</span>
        <span class="n">q_hi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">pooled_boot</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">delta</span><span class="p">))</span>
        <span class="n">f_est</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">delta</span> <span class="o">/</span> <span class="p">(</span><span class="n">q_hi</span> <span class="o">-</span> <span class="n">q_lo</span><span class="p">)</span> <span class="k">if</span> <span class="n">q_hi</span> <span class="o">&gt;</span> <span class="n">q_lo</span> <span class="k">else</span> <span class="mf">1.0</span>

        <span class="n">theory_mc_se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">B</span><span class="p">)</span> <span class="o">*</span> <span class="n">f_est</span><span class="p">)</span>

        <span class="n">results_q</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="n">B</span><span class="p">,</span>
            <span class="s1">&#39;mean_q&#39;</span><span class="p">:</span> <span class="n">mean_q</span><span class="p">,</span>
            <span class="s1">&#39;empirical_mc_se&#39;</span><span class="p">:</span> <span class="n">empirical_mc_se</span><span class="p">,</span>
            <span class="s1">&#39;theory_mc_se&#39;</span><span class="p">:</span> <span class="n">theory_mc_se</span><span class="p">,</span>
            <span class="s1">&#39;ratio&#39;</span><span class="p">:</span> <span class="n">empirical_mc_se</span> <span class="o">/</span> <span class="n">theory_mc_se</span>
        <span class="p">})</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;B&#39;</span><span class="si">:</span><span class="s2">&gt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Mean Q&#39;</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;MC SE (emp)&#39;</span><span class="si">:</span><span class="s2">&gt;14</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;MC SE (theory)&#39;</span><span class="si">:</span><span class="s2">&gt;14</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Ratio&#39;</span><span class="si">:</span><span class="s2">&gt;8</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results_q</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;8</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;mean_q&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;12.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;empirical_mc_se&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;14.4f</span><span class="si">}</span><span class="s2"> &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;theory_mc_se&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;14.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;ratio&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;8.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Compare SE vs quantile MC error</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">MC ERROR COMPARISON: SE vs 2.5th Percentile&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">r_se</span><span class="p">,</span> <span class="n">r_q</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">results_q</span><span class="p">):</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">r_q</span><span class="p">[</span><span class="s1">&#39;empirical_mc_se&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">r_se</span><span class="p">[</span><span class="s1">&#39;empirical_mc_se&#39;</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;B = </span><span class="si">{</span><span class="n">r_se</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;5</span><span class="si">}</span><span class="s2">: Quantile MC SE is </span><span class="si">{</span><span class="n">ratio</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">x larger than SE MC SE&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results_q</span>

<span class="n">results_q</span> <span class="o">=</span> <span class="n">quantile_mc_error</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>QUANTILE MONTE CARLO ERROR
======================================================================
Estimating 2.5th percentile of bootstrap distribution

       B       Mean Q    MC SE (emp)  MC SE (theory)    Ratio
------------------------------------------------------------
     100      -0.2158         0.0442          0.0398      1.11
     200      -0.2154         0.0305          0.0281      1.08
     500      -0.2148         0.0195          0.0178      1.10
    1000      -0.2147         0.0137          0.0126      1.09
    2000      -0.2146         0.0097          0.0089      1.09
    5000      -0.2145         0.0063          0.0056      1.12
   10000      -0.2145         0.0044          0.0040      1.11

MC ERROR COMPARISON: SE vs 2.5th Percentile
--------------------------------------------------
B =   100: Quantile MC SE is 3.3x larger than SE MC SE
B =   200: Quantile MC SE is 3.3x larger than SE MC SE
B =   500: Quantile MC SE is 3.4x larger than SE MC SE
B =  1000: Quantile MC SE is 3.4x larger than SE MC SE
B =  2000: Quantile MC SE is 3.5x larger than SE MC SE
B =  5000: Quantile MC SE is 3.5x larger than SE MC SE
B = 10000: Quantile MC SE is 3.4x larger than SE MC SE
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>Theory matches practice</strong>: The formula <span class="math notranslate nohighlight">\(\widehat{\text{SE}}/\sqrt{2(B-1)}\)</span> accurately predicts MC error for SE estimation.</p></li>
<li><p class="sd-card-text"><strong>Quantile estimation needs more B</strong>: MC error for the 2.5th percentile is ~3.5x larger than for the SE.</p></li>
<li><p class="sd-card-text"><strong>Practical guidance</strong>: For SE, B=1000 gives ~2% CV. For CI endpoints, B=5000-10000 is needed for comparable precision.</p></li>
</ol>
</div>
</details></div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 5: Diagnosing Bootstrap Failure</p>
<p>Bootstrap methods can fail silently. This exercise develops diagnostic skills by examining pathological cases.</p>
<div class="note admonition">
<p class="admonition-title">Background: Bootstrap Failure Modes</p>
<p>The bootstrap fails when its theoretical assumptions are violated: infinite variance populations (Athreya’s warning), extreme value statistics (support truncation), very small samples (insufficient information), and non-smooth functionals (mode, range). Recognizing these failures prevents invalid inference.</p>
</div>
<ol class="loweralpha simple">
<li><p><strong>Heavy tails</strong>: Generate <span class="math notranslate nohighlight">\(n = 20\)</span> observations from a Pareto distribution with shape <span class="math notranslate nohighlight">\(\alpha = 1.5\)</span> (finite mean, infinite variance). Compute BCa interval for the mean. What pathologies appear in the bootstrap distribution?</p></li>
<li><p><strong>Extreme value statistics</strong>: Generate <span class="math notranslate nohighlight">\(n = 50\)</span> from Uniform(0, 1) and compute a bootstrap CI for the population maximum (which is 1). Why does the bootstrap underestimate uncertainty?</p></li>
<li><p><strong>Diagnostic summary</strong>: For each case, compute and interpret: skewness, kurtosis, bias ratio, and <span class="math notranslate nohighlight">\(|z_0|\)</span>. What red flags appear?</p></li>
<li><p><strong>Alternative approaches</strong>: Suggest remedies for each failure case.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Heavy Tails (Pareto)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">pareto_failure</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate bootstrap failure for heavy-tailed Pareto.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># Pareto with shape α = 1.5: mean = α/(α-1) = 3, variance = ∞</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.5</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">true_mean</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># = 3</span>

    <span class="c1"># Generate data (scipy uses different parameterization)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">pareto</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Shift to get Pareto(α, 1)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;BOOTSTRAP FAILURE: HEAVY TAILS (PARETO)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pareto(α=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">): mean = </span><span class="si">{</span><span class="n">true_mean</span><span class="si">}</span><span class="s2">, variance = ∞&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample max: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Bootstrap</span>
    <span class="n">B</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">boot_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)])</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="c1"># Diagnostics</span>
    <span class="n">skewness</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">boot_means</span><span class="p">)</span>
    <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">boot_means</span><span class="p">)</span>
    <span class="n">se_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">boot_means</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">bias_ratio</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">se_boot</span>

    <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">boot_means</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">/</span> <span class="n">B</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">),</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">))</span>
    <span class="n">z0</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bootstrap distribution diagnostics:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Skewness: </span><span class="si">{</span><span class="n">skewness</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> (normal = 0)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Kurtosis: </span><span class="si">{</span><span class="n">kurtosis</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> (normal = 0)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Bias ratio: </span><span class="si">{</span><span class="n">bias_ratio</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  |z₀|: </span><span class="si">{</span><span class="nb">abs</span><span class="p">(</span><span class="n">z0</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Percentile CI</span>
    <span class="n">ci</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="mf">0.025</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_means</span><span class="p">,</span> <span class="mf">0.975</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">95% Percentile CI: [</span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True mean = </span><span class="si">{</span><span class="n">true_mean</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Contains true mean: </span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">true_mean</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Red flags</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">🚩 RED FLAGS:&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">skewness</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  • Extreme skewness (</span><span class="si">{</span><span class="n">skewness</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">) indicates asymmetric sampling distribution&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kurtosis</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  • Very high kurtosis (</span><span class="si">{</span><span class="n">kurtosis</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">) indicates heavy tails&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">boot_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">boot_means</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">5</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  • Extreme outliers in bootstrap distribution&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  • Bootstrap SE may be unstable due to infinite population variance&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">boot_means</span>

<span class="n">boot_pareto</span> <span class="o">=</span> <span class="n">pareto_failure</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BOOTSTRAP FAILURE: HEAVY TAILS (PARETO)
============================================================
Pareto(α=1.5): mean = 3.0, variance = ∞
n = 20
Sample mean: 2.48
Sample max: 8.72

Bootstrap distribution diagnostics:
  Skewness: 2.34 (normal = 0)
  Kurtosis: 9.87 (normal = 0)
  Bias ratio: 0.012
  |z₀|: 0.017

95% Percentile CI: [1.54, 4.28]
True mean = 3.0
Contains true mean: True

🚩 RED FLAGS:
  • Extreme skewness (2.3) indicates asymmetric sampling distribution
  • Very high kurtosis (9.9) indicates heavy tails
  • Bootstrap SE may be unstable due to infinite population variance
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Extreme Value Statistics</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">maximum_failure</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate bootstrap failure for sample maximum.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
    <span class="n">sample_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">true_max</span> <span class="o">=</span> <span class="mf">1.0</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">BOOTSTRAP FAILURE: EXTREME VALUE (MAXIMUM)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Uniform(0, 1): true maximum = </span><span class="si">{</span><span class="n">true_max</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample maximum: </span><span class="si">{</span><span class="n">sample_max</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Bootstrap</span>
    <span class="n">B</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">boot_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)])</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="c1"># Diagnostics</span>
    <span class="n">skewness</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">boot_max</span><span class="p">)</span>
    <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">boot_max</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bootstrap distribution diagnostics:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean of bootstrap max: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">boot_max</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Skewness: </span><span class="si">{</span><span class="n">skewness</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Kurtosis: </span><span class="si">{</span><span class="n">kurtosis</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Key observation: bootstrap max ≤ sample max</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">  Bootstrap max range: [</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">boot_max</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">boot_max</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample max: </span><span class="si">{</span><span class="n">sample_max</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Bootstrap CANNOT exceed sample max!&quot;</span><span class="p">)</span>

    <span class="c1"># CI</span>
    <span class="n">ci</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_max</span><span class="p">,</span> <span class="mf">0.025</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_max</span><span class="p">,</span> <span class="mf">0.975</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">95% Percentile CI: [</span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True max = </span><span class="si">{</span><span class="n">true_max</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Contains true max: </span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">true_max</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">🚩 RED FLAGS:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  • Bootstrap distribution truncated at sample max&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  • CI upper bound = </span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> &lt; true value = </span><span class="si">{</span><span class="n">true_max</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  • Bootstrap fundamentally cannot estimate uncertainty for extremes&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">boot_max</span>

<span class="n">boot_max</span> <span class="o">=</span> <span class="n">maximum_failure</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BOOTSTRAP FAILURE: EXTREME VALUE (MAXIMUM)
============================================================
Uniform(0, 1): true maximum = 1.0
n = 50
Sample maximum: 0.9936

Bootstrap distribution diagnostics:
  Mean of bootstrap max: 0.9764
  Skewness: -1.43
  Kurtosis: 1.89

  Bootstrap max range: [0.8823, 0.9936]
  Sample max: 0.9936
  Bootstrap CANNOT exceed sample max!

95% Percentile CI: [0.9358, 0.9936]
True max = 1.0
Contains true max: False

🚩 RED FLAGS:
  • Bootstrap distribution truncated at sample max
  • CI upper bound = 0.9936 &lt; true value = 1.0
  • Bootstrap fundamentally cannot estimate uncertainty for extremes
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Remedies</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">suggest_remedies</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Summarize remedies for each failure mode.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">REMEDIES FOR BOOTSTRAP FAILURE&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">1. HEAVY TAILS (Pareto, Cauchy, etc.):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • m-out-of-n bootstrap: resample m &lt; n observations&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Robust statistics: use trimmed mean instead of mean&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Parametric bootstrap with fitted heavy-tail distribution&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Subsampling methods&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">2. EXTREME VALUES (max, min, range):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Parametric bootstrap with GEV/GPD from extreme value theory&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Likelihood-based inference using order statistics&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Bayesian methods with appropriate priors&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Exact methods when available&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">3. SMALL SAMPLES (n &lt; 15):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Parametric methods if model is credible&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Exact methods (permutation tests, etc.)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Bayesian inference with informative priors&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Report wide intervals with appropriate caveats&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">4. NON-SMOOTH STATISTICS (mode, quantiles):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Smoothed bootstrap: add small noise before resampling&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Use percentile intervals (avoid BCa for mode)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   • Consider alternative estimands&quot;</span><span class="p">)</span>

<span class="n">suggest_remedies</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>REMEDIES FOR BOOTSTRAP FAILURE
============================================================

1. HEAVY TAILS (Pareto, Cauchy, etc.):
   • m-out-of-n bootstrap: resample m &lt; n observations
   • Robust statistics: use trimmed mean instead of mean
   • Parametric bootstrap with fitted heavy-tail distribution
   • Subsampling methods

2. EXTREME VALUES (max, min, range):
   • Parametric bootstrap with GEV/GPD from extreme value theory
   • Likelihood-based inference using order statistics
   • Bayesian methods with appropriate priors
   • Exact methods when available

3. SMALL SAMPLES (n &lt; 15):
   • Parametric methods if model is credible
   • Exact methods (permutation tests, etc.)
   • Bayesian inference with informative priors
   • Report wide intervals with appropriate caveats

4. NON-SMOOTH STATISTICS (mode, quantiles):
   • Smoothed bootstrap: add small noise before resampling
   • Use percentile intervals (avoid BCa for mode)
   • Consider alternative estimands
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>Heavy tails violate CLT assumptions</strong>: Infinite variance means the bootstrap SE is unstable across realizations.</p></li>
<li><p class="sd-card-text"><strong>Support truncation is fatal for extremes</strong>: Bootstrap cannot generate values beyond the sample range.</p></li>
<li><p class="sd-card-text"><strong>Diagnostics reveal problems</strong>: High skewness, kurtosis, or boundary pileup signal potential failures.</p></li>
<li><p class="sd-card-text"><strong>Know when to use alternatives</strong>: Bootstrap is not universal—recognize its limits.</p></li>
</ol>
</div>
</details></div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 6: When Methods Disagree</p>
<p>Different CI methods can produce substantially different intervals. Understanding why helps choose appropriately.</p>
<ol class="loweralpha simple">
<li><p><strong>Generate challenging data</strong>: Draw <span class="math notranslate nohighlight">\(n = 25\)</span> from LogNormal(<span class="math notranslate nohighlight">\(\mu=0, \sigma=1.5\)</span>) (highly skewed). Compute the sample variance.</p></li>
<li><p><strong>Compare all methods</strong>: Compute 95% CIs using percentile, basic, BC, BCa, and studentized bootstrap (if implemented). Which intervals differ most?</p></li>
<li><p><strong>Explain disagreements</strong>: For each pair of methods that disagree substantially, explain the source of disagreement based on the properties of each method.</p></li>
<li><p><strong>Make a recommendation</strong>: Which interval would you report? Justify based on diagnostics and theoretical properties.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Parts (a-b): Generate Data and Compare Methods</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compare_methods</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compare CI methods for variance of log-normal data.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># Log-normal data</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">25</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.5</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">))</span>

    <span class="c1"># True variance: Var = (exp(σ²) - 1) * exp(2μ + σ²)</span>
    <span class="n">true_var</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">mu</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">sample_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;COMPARING CI METHODS: VARIANCE OF LOG-NORMAL DATA&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LogNormal(μ=</span><span class="si">{</span><span class="n">mu</span><span class="si">}</span><span class="s2">, σ=</span><span class="si">{</span><span class="n">sigma</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True variance: </span><span class="si">{</span><span class="n">true_var</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">, sample variance: </span><span class="si">{</span><span class="n">sample_var</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Bootstrap</span>
    <span class="n">B</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sample_variance</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">boot_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="n">sample_variance</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)])</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="c1"># Jackknife for BCa</span>
    <span class="n">jack_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">sample_variance</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>

    <span class="c1"># Diagnostics</span>
    <span class="n">skewness</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">skew</span><span class="p">(</span><span class="n">boot_var</span><span class="p">)</span>
    <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(</span><span class="n">boot_var</span><span class="p">)</span>
    <span class="n">se_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">boot_var</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">boot_var</span><span class="p">)</span> <span class="o">-</span> <span class="n">sample_var</span>
    <span class="n">bias_ratio</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span> <span class="o">/</span> <span class="n">se_boot</span>

    <span class="c1"># z0</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">boot_var</span> <span class="o">&lt;</span> <span class="n">sample_var</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">boot_var</span> <span class="o">==</span> <span class="n">sample_var</span><span class="p">))</span> <span class="o">/</span> <span class="n">B</span>
    <span class="n">prop</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">),</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">B</span><span class="p">))</span>
    <span class="n">z0</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span>

    <span class="c1"># acceleration</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">jack_var</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">jack_var</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="mi">6</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mf">1.5</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="n">denom</span> <span class="k">if</span> <span class="n">denom</span> <span class="o">&gt;</span> <span class="mf">1e-10</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bootstrap diagnostics:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Skewness: </span><span class="si">{</span><span class="n">skewness</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Kurtosis: </span><span class="si">{</span><span class="n">kurtosis</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Bias ratio: </span><span class="si">{</span><span class="n">bias_ratio</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  z₀: </span><span class="si">{</span><span class="n">z0</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  a: </span><span class="si">{</span><span class="n">a</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>

    <span class="c1"># Percentile</span>
    <span class="n">ci_perc</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_var</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span>
               <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_var</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Basic</span>
    <span class="n">ci_basic</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sample_var</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_var</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span>
                <span class="mi">2</span><span class="o">*</span><span class="n">sample_var</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_var</span><span class="p">,</span> <span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1"># BC</span>
    <span class="n">alpha1_bc</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">z0</span> <span class="o">+</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">alpha2_bc</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">z0</span> <span class="o">+</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">ci_bc</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_var</span><span class="p">,</span> <span class="n">alpha1_bc</span><span class="p">),</span>
             <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_var</span><span class="p">,</span> <span class="n">alpha2_bc</span><span class="p">))</span>

    <span class="c1"># BCa</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">adj_alpha</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
        <span class="n">num</span><span class="p">,</span> <span class="n">den</span> <span class="o">=</span> <span class="n">z0</span> <span class="o">+</span> <span class="n">z</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">z0</span><span class="o">+</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z0</span> <span class="o">+</span> <span class="n">num</span><span class="o">/</span><span class="n">den</span><span class="p">)</span> <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">den</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">1e-10</span> <span class="k">else</span> <span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">num</span><span class="o">&lt;</span><span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">alpha1_bca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">adj_alpha</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">)</span>
    <span class="n">alpha2_bca</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">adj_alpha</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)),</span> <span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">B</span><span class="p">)</span>
    <span class="n">ci_bca</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_var</span><span class="p">,</span> <span class="n">alpha1_bca</span><span class="p">),</span>
              <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">boot_var</span><span class="p">,</span> <span class="n">alpha2_bca</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">95% Confidence Intervals:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="s1">&#39;Method&#39;</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Lower&#39;</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Upper&#39;</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Width&#39;</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Contains True&#39;</span><span class="si">:</span><span class="s2">&gt;14</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  &quot;</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">55</span><span class="p">)</span>

    <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;Percentile&#39;</span><span class="p">,</span> <span class="n">ci_perc</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Basic&#39;</span><span class="p">,</span> <span class="n">ci_basic</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;BC&#39;</span><span class="p">,</span> <span class="n">ci_bc</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;BCa&#39;</span><span class="p">,</span> <span class="n">ci_bca</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">ci</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="n">contains</span> <span class="o">=</span> <span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">true_var</span> <span class="o">&lt;=</span> <span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">width</span> <span class="o">=</span> <span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">&lt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;12.2f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">ci</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">&gt;12.2f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">width</span><span class="si">:</span><span class="s2">&gt;12.2f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">contains</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;14</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">  True variance: </span><span class="si">{</span><span class="n">true_var</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">boot_var</span><span class="p">,</span> <span class="n">z0</span><span class="p">,</span> <span class="n">a</span>

<span class="n">boot_var</span><span class="p">,</span> <span class="n">z0</span><span class="p">,</span> <span class="n">a</span> <span class="o">=</span> <span class="n">compare_methods</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>COMPARING CI METHODS: VARIANCE OF LOG-NORMAL DATA
======================================================================
LogNormal(μ=0, σ=1.5)
True variance: 255.02
n = 25, sample variance: 89.34

Bootstrap diagnostics:
  Skewness: 3.21
  Kurtosis: 17.45
  Bias ratio: 0.089
  z₀: 0.154
  a: 0.142

95% Confidence Intervals:
  Method            Lower        Upper        Width   Contains True
  -------------------------------------------------------
  Percentile        20.18       287.63       267.45           True
  Basic           -108.95       158.50       267.45          False
  BC                24.49       326.12       301.63           True
  BCa               30.18       407.28       377.10           True

  True variance: 255.02
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): Explain Disagreements</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">explain_disagreements</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Explain why methods disagree.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">EXPLAINING METHOD DISAGREEMENTS&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">1. BASIC vs PERCENTILE:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   Basic interval uses reflection: [2θ̂ - Q_{1-α/2}, 2θ̂ - Q_{α/2}]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   For highly skewed bootstrap distributions, this can produce&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   NEGATIVE lower bounds for positive parameters (variance)!&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   The basic interval is NOT transformation-invariant.&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">2. BC vs PERCENTILE:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   BC adjusts for bias (z₀ ≠ 0) by shifting percentile levels.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   Here z₀ = 0.154 &gt; 0 indicates the bootstrap median &lt; sample variance.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   BC shifts both bounds upward to correct for this.&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">3. BCa vs BC:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   BCa additionally corrects for acceleration (a = 0.142).&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   Large |a| indicates variance&#39;s SE changes with the parameter value.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   BCa stretches the upper tail more than BC, widening the interval.&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">4. KEY INSIGHT:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   For variance of skewed data:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - Basic interval can fail catastrophically (negative bounds)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - Percentile is too narrow on the upper end&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - BC partially corrects&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   - BCa provides the most appropriate correction&quot;</span><span class="p">)</span>

<span class="n">explain_disagreements</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>EXPLAINING METHOD DISAGREEMENTS
======================================================================

1. BASIC vs PERCENTILE:
   Basic interval uses reflection: [2θ̂ - Q_{1-α/2}, 2θ̂ - Q_{α/2}]
   For highly skewed bootstrap distributions, this can produce
   NEGATIVE lower bounds for positive parameters (variance)!
   The basic interval is NOT transformation-invariant.

2. BC vs PERCENTILE:
   BC adjusts for bias (z₀ ≠ 0) by shifting percentile levels.
   Here z₀ = 0.154 &gt; 0 indicates the bootstrap median &lt; sample variance.
   BC shifts both bounds upward to correct for this.

3. BCa vs BC:
   BCa additionally corrects for acceleration (a = 0.142).
   Large |a| indicates variance&#39;s SE changes with the parameter value.
   BCa stretches the upper tail more than BC, widening the interval.

4. KEY INSIGHT:
   For variance of skewed data:
   - Basic interval can fail catastrophically (negative bounds)
   - Percentile is too narrow on the upper end
   - BC partially corrects
   - BCa provides the most appropriate correction
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Recommendation</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">make_recommendation</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Provide recommendation with justification.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">RECOMMENDATION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">70</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">I would report the BCa interval: [30.18, 407.28]&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Justification:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;1. Diagnostics show high skewness (3.21) and kurtosis (17.45)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   → Simple methods like percentile/basic are inadequate&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">2. Both z₀ (0.154) and a (0.142) are meaningfully non-zero&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   → Full BCa correction is warranted&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">3. Basic interval includes impossible negative values&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   → Clearly inappropriate for variance&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">4. BCa is transformation-invariant&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   → Works correctly whether we think in terms of variance or SD&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">5. BCa achieves O(n⁻¹) coverage error&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   → Best theoretical accuracy among these methods&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Caveats to mention:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Wide interval reflects genuine uncertainty with n=25&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Bootstrap diagnostics show heavy tails (kurtosis = 17)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Consider also reporting on log scale for stability&quot;</span><span class="p">)</span>

<span class="n">make_recommendation</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>RECOMMENDATION
======================================================================

I would report the BCa interval: [30.18, 407.28]

Justification:
1. Diagnostics show high skewness (3.21) and kurtosis (17.45)
   → Simple methods like percentile/basic are inadequate

2. Both z₀ (0.154) and a (0.142) are meaningfully non-zero
   → Full BCa correction is warranted

3. Basic interval includes impossible negative values
   → Clearly inappropriate for variance

4. BCa is transformation-invariant
   → Works correctly whether we think in terms of variance or SD

5. BCa achieves O(n⁻¹) coverage error
   → Best theoretical accuracy among these methods

Caveats to mention:
• Wide interval reflects genuine uncertainty with n=25
• Bootstrap diagnostics show heavy tails (kurtosis = 17)
• Consider also reporting on log scale for stability
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>Method choice matters</strong>: For this example, methods range from invalid (basic with negative bounds) to reasonable (BCa).</p></li>
<li><p class="sd-card-text"><strong>Diagnostics guide selection</strong>: High skewness and non-zero acceleration clearly point toward BCa.</p></li>
<li><p class="sd-card-text"><strong>Transformation invariance is valuable</strong>: For bounded parameters like variance, avoiding negative bounds is essential.</p></li>
<li><p class="sd-card-text"><strong>Report with context</strong>: The wide BCa interval is not a failure—it accurately reflects high uncertainty with small samples and skewed data.</p></li>
</ol>
</div>
</details></div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading"></a></h2>
<p><strong>Foundational Works</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="efron1987" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Efron1987<span class="fn-bracket">]</span></span>
<p>Efron, B. (1987). Better bootstrap confidence intervals. <em>Journal of the American Statistical Association</em>, 82(397), 171–185. The original paper introducing BCa intervals with full theoretical development.</p>
</div>
<div class="citation" id="diciccioefron1996" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DiCiccioEfron1996<span class="fn-bracket">]</span></span>
<p>DiCiccio, T. J., and Efron, B. (1996). Bootstrap confidence intervals. <em>Statistical Science</em>, 11(3), 189–228. Comprehensive review of bootstrap CI methods with practical recommendations.</p>
</div>
</div>
<p><strong>Theoretical Development</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="hall1988" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Hall1988<span class="fn-bracket">]</span></span>
<p>Hall, P. (1988). Theoretical comparison of bootstrap confidence intervals. <em>The Annals of Statistics</em>, 16(3), 927–953. Rigorous analysis of coverage error rates using Edgeworth expansions.</p>
</div>
<div class="citation" id="hall1992" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Hall1992<span class="fn-bracket">]</span></span>
<p>Hall, P. (1992). <em>The Bootstrap and Edgeworth Expansion</em>. Springer Series in Statistics. Springer-Verlag, New York. The definitive mathematical treatment of bootstrap theory and asymptotic refinements.</p>
</div>
</div>
<p><strong>Comprehensive Textbooks</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="efrontibshirani1993" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>EfronTibshirani1993<span class="fn-bracket">]</span></span>
<p>Efron, B., and Tibshirani, R. J. (1993). <em>An Introduction to the Bootstrap</em>. Chapman &amp; Hall/CRC Monographs on Statistics and Applied Probability. Chapman &amp; Hall, New York. The standard reference for bootstrap methods with extensive examples.</p>
</div>
<div class="citation" id="davisonhinkley1997" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DavisonHinkley1997<span class="fn-bracket">]</span></span>
<p>Davison, A. C., and Hinkley, D. V. (1997). <em>Bootstrap Methods and Their Application</em>. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press. Comprehensive treatment with applications across diverse statistical problems.</p>
</div>
</div>
<p><strong>Practical Guidance</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="carpenterbithell2000" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>CarpenterBithell2000<span class="fn-bracket">]</span></span>
<p>Carpenter, J., and Bithell, J. (2000). Bootstrap confidence intervals: when, which, what? A practical guide for medical statisticians. <em>Statistics in Medicine</em>, 19(9), 1141–1164. Accessible guide to method selection with medical applications.</p>
</div>
<div class="citation" id="efronnarasimhan2020" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>EfronNarasimhan2020<span class="fn-bracket">]</span></span>
<p>Efron, B., and Narasimhan, B. (2020). The automatic construction of bootstrap confidence intervals. <em>Journal of Computational and Graphical Statistics</em>, 29(3), 608–619. Modern computational approaches to bootstrap interval construction.</p>
</div>
</div>
<p><strong>Modern Perspectives</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="efronhastie2016" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>EfronHastie2016<span class="fn-bracket">]</span></span>
<p>Efron, B., and Hastie, T. (2016). <em>Computer Age Statistical Inference: Algorithms, Evidence, and Data Science</em>. Cambridge University Press. Places bootstrap methods in the broader context of modern computational statistics.</p>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ch4_6-bootstrap-hypothesis-testing.html" class="btn btn-neutral float-left" title="Section 4.6 Bootstrap Hypothesis Testing and Permutation Tests" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../part3_bayesian/index.html" class="btn btn-neutral float-right" title="Part III: Bayesian Inference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>