

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Section 4.6 Bootstrap Hypothesis Testing and Permutation Tests &mdash; STAT 418</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=3d0abd52" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT418/Website/part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Show solution';</script>
      <script>let toggleHintHide = 'Hide solution';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=8718e0ab"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Section 4.7 Bootstrap Confidence Intervals: Advanced Methods" href="ch4_7-bootstrap-confidence-intervals.html" />
    <link rel="prev" title="Section 4.5: Jackknife Methods" href="ch4_5-jackknife-methods.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Course Content</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../part1_foundations/index.html">Part I: Foundations of Probability and Computation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part1_foundations/chapter1/index.html">Chapter 1: Statistical Paradigms and Core Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html">Section 1.1 Paradigms of Probability and Statistical Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#the-mathematical-foundation-kolmogorov-s-axioms">The Mathematical Foundation: Kolmogorov’s Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#interpretations-of-probability">Interpretations of Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#statistical-inference-paradigms">Statistical Inference Paradigms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#historical-and-philosophical-debates">Historical and Philosophical Debates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#looking-ahead-our-course-focus">Looking Ahead: Our Course Focus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html">Section 1.2 Probability Distributions: Theory and Computation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#from-abstract-foundations-to-concrete-tools">From Abstract Foundations to Concrete Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#the-python-ecosystem-for-probability">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#introduction-why-probability-distributions-matter">Introduction: Why Probability Distributions Matter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#id1">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#continuous-distributions">Continuous Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#additional-important-distributions">Additional Important Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#summary-and-practical-guidelines">Summary and Practical Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#conclusion">Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html">Section 1.3 Python Random Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#from-mathematical-distributions-to-computational-samples">From Mathematical Distributions to Computational Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#the-python-ecosystem-at-a-glance">The Python Ecosystem at a Glance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#understanding-pseudo-random-number-generation">Understanding Pseudo-Random Number Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#the-standard-library-random-module">The Standard Library: <code class="docutils literal notranslate"><span class="pre">random</span></code> Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#numpy-fast-vectorized-random-sampling">NumPy: Fast Vectorized Random Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#scipy-stats-the-complete-statistical-toolkit">SciPy Stats: The Complete Statistical Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#bringing-it-all-together-library-selection-guide">Bringing It All Together: Library Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#looking-ahead-from-random-numbers-to-monte-carlo-methods">Looking Ahead: From Random Numbers to Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html">Section 1.4 Chapter 1 Summary: Foundations in Place</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#the-three-pillars-of-chapter-1">The Three Pillars of Chapter 1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#what-lies-ahead-the-road-to-simulation">What Lies Ahead: The Road to Simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#chapter-1-exercises-synthesis-problems">Chapter 1 Exercises: Synthesis Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../part1_foundations/chapter2/index.html">Chapter 2: Monte Carlo Simulation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html">Section 2.1 Monte Carlo Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#the-historical-development-of-monte-carlo-methods">The Historical Development of Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#the-core-principle-expectation-as-integration">The Core Principle: Expectation as Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#theoretical-foundations">Theoretical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#variance-estimation-and-confidence-intervals">Variance Estimation and Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#comparison-with-deterministic-methods">Comparison with Deterministic Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#sample-size-determination">Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#convergence-diagnostics-and-monitoring">Convergence Diagnostics and Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#chapter-2-1-exercises-monte-carlo-fundamentals-mastery">Chapter 2.1 Exercises: Monte Carlo Fundamentals Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#id1">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_1-monte-carlo-fundamentals.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html">Section 2.2 Uniform Random Variates</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#why-uniform-the-universal-currency-of-randomness">Why Uniform? The Universal Currency of Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#the-paradox-of-computational-randomness">The Paradox of Computational Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#chaotic-dynamical-systems-an-instructive-failure">Chaotic Dynamical Systems: An Instructive Failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#linear-congruential-generators">Linear Congruential Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#shift-register-generators">Shift-Register Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#the-kiss-generator-combining-strategies">The KISS Generator: Combining Strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#modern-generators-mersenne-twister-and-pcg">Modern Generators: Mersenne Twister and PCG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#statistical-testing-of-random-number-generators">Statistical Testing of Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#chapter-2-2-exercises-uniform-random-variates-mastery">Chapter 2.2 Exercises: Uniform Random Variates Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_2-uniform-random-variates.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html">Section 2.3 Inverse CDF Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#mathematical-foundations">Mathematical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#continuous-distributions-with-closed-form-inverses">Continuous Distributions with Closed-Form Inverses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#numerical-inversion">Numerical Inversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#mixed-distributions">Mixed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#chapter-2-3-exercises-inverse-cdf-method-mastery">Chapter 2.3 Exercises: Inverse CDF Method Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#id1">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_3-inverse-cdf-method.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html">Section 2.4 Transformation Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#why-transformation-methods">Why Transformation Methods?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#the-boxmuller-transform">The Box–Muller Transform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#the-polar-marsaglia-method">The Polar (Marsaglia) Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#method-comparison-boxmuller-vs-polar-vs-ziggurat">Method Comparison: Box–Muller vs Polar vs Ziggurat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#the-ziggurat-algorithm">The Ziggurat Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#the-clt-approximation-historical">The CLT Approximation (Historical)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#distributions-derived-from-the-normal">Distributions Derived from the Normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#multivariate-normal-generation">Multivariate Normal Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#implementation-guidance">Implementation Guidance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#chapter-2-4-exercises-transformation-methods-mastery">Chapter 2.4 Exercises: Transformation Methods Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_4-transformation-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html">Section 2.5 Rejection Sampling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#the-dartboard-intuition">The Dartboard Intuition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#the-accept-reject-algorithm">The Accept-Reject Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#efficiency-analysis">Efficiency Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#choosing-the-proposal-distribution">Choosing the Proposal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#the-squeeze-principle">The Squeeze Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#geometric-example-sampling-from-the-unit-disk">Geometric Example: Sampling from the Unit Disk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#limitations-and-the-curse-of-dimensionality">Limitations and the Curse of Dimensionality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#connections-to-other-methods">Connections to Other Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#chapter-2-5-exercises-rejection-sampling-mastery">Chapter 2.5 Exercises: Rejection Sampling Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_5-rejection-sampling.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html">Section 2.6 Variance Reduction Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#the-variance-reduction-paradigm">The Variance Reduction Paradigm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#importance-sampling">Importance Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#control-variates">Control Variates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#antithetic-variates">Antithetic Variates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#stratified-sampling">Stratified Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#common-random-numbers">Common Random Numbers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#conditional-monte-carlo-raoblackwellization">Conditional Monte Carlo (Rao–Blackwellization)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#combining-variance-reduction-techniques">Combining Variance Reduction Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#chapter-2-6-exercises-variance-reduction-mastery">Chapter 2.6 Exercises: Variance Reduction Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_6-variance-reduction-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html">Section 2.7 Chapter 2 Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#the-complete-monte-carlo-workflow">The Complete Monte Carlo Workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#quick-reference-tables">Quick Reference Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#common-pitfalls-checklist">Common Pitfalls Checklist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#connections-to-later-chapters">Connections to Later Chapters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#learning-outcomes-checklist">Learning Outcomes Checklist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#further-reading-optimization-and-missing-data">Further Reading: Optimization and Missing Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#final-perspective">Final Perspective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter2/ch2_7-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Part II: Frequentist Inference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../chapter3/index.html">Chapter 3: Parametric Inference and Likelihood Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html">Section 3.1 Exponential Families</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#historical-origins-from-scattered-results-to-unified-theory">Historical Origins: From Scattered Results to Unified Theory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#the-canonical-exponential-family">The Canonical Exponential Family</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#converting-familiar-distributions">Converting Familiar Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#the-log-partition-function-a-moment-generating-machine">The Log-Partition Function: A Moment-Generating Machine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#sufficiency-capturing-all-parameter-information">Sufficiency: Capturing All Parameter Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#minimal-sufficiency-and-completeness">Minimal Sufficiency and Completeness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#conjugate-priors-and-bayesian-inference">Conjugate Priors and Bayesian Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#exponential-dispersion-models-and-glms">Exponential Dispersion Models and GLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#chapter-3-1-exercises-exponential-families-mastery">Chapter 3.1 Exercises: Exponential Families Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html">Section 3.2 Maximum Likelihood Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-likelihood-function">The Likelihood Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-score-function">The Score Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#fisher-information">Fisher Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#closed-form-maximum-likelihood-estimators">Closed-Form Maximum Likelihood Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#numerical-optimization-for-mle">Numerical Optimization for MLE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#asymptotic-properties-of-mles">Asymptotic Properties of MLEs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-cramer-rao-lower-bound">The Cramér-Rao Lower Bound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-invariance-property">The Invariance Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#likelihood-based-hypothesis-testing">Likelihood-Based Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#confidence-intervals-from-likelihood">Confidence Intervals from Likelihood</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#connection-to-bayesian-inference">Connection to Bayesian Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#chapter-3-2-exercises-maximum-likelihood-estimation-mastery">Chapter 3.2 Exercises: Maximum Likelihood Estimation Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html">Section 3.3 Sampling Variability and Variance Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#statistical-estimators-and-their-properties">Statistical Estimators and Their Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#sampling-distributions">Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#the-delta-method">The Delta Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#the-plug-in-principle">The Plug-in Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#variance-estimation-methods">Variance Estimation Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#applications-and-worked-examples">Applications and Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html">Section 3.4 Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#matrix-calculus-foundations">Matrix Calculus Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#the-linear-model">The Linear Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#ordinary-least-squares-the-calculus-approach">Ordinary Least Squares: The Calculus Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#ordinary-least-squares-the-geometric-approach">Ordinary Least Squares: The Geometric Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#properties-of-the-ols-estimator">Properties of the OLS Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#the-gauss-markov-theorem">The Gauss-Markov Theorem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#estimating-the-error-variance">Estimating the Error Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#distributional-results-under-normality">Distributional Results Under Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#diagnostics-and-model-checking">Diagnostics and Model Checking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#numerical-stability-qr-decomposition">Numerical Stability: QR Decomposition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#model-selection-and-information-criteria">Model Selection and Information Criteria</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#regularization-ridge-and-lasso">Regularization: Ridge and LASSO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#chapter-3-4-exercises-linear-models-mastery">Chapter 3.4 Exercises: Linear Models Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html">Section 3.5 Generalized Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#historical-context-unification-of-regression-methods">Historical Context: Unification of Regression Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#the-glm-framework-three-components">The GLM Framework: Three Components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#score-equations-and-fisher-information">Score Equations and Fisher Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#iteratively-reweighted-least-squares">Iteratively Reweighted Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#logistic-regression-binary-outcomes">Logistic Regression: Binary Outcomes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#poisson-regression-count-data">Poisson Regression: Count Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#gamma-regression-positive-continuous-data">Gamma Regression: Positive Continuous Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#inference-in-glms-the-testing-triad">Inference in GLMs: The Testing Triad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#model-diagnostics">Model Diagnostics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#model-comparison-and-selection">Model Comparison and Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#quasi-likelihood-and-robust-inference">Quasi-Likelihood and Robust Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#further-reading">Further Reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#chapter-3-5-exercises-generalized-linear-models-mastery">Chapter 3.5 Exercises: Generalized Linear Models Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html">Section 3.6 Chapter 3 Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#the-parametric-inference-pipeline">The Parametric Inference Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#the-five-pillars-of-chapter-3">The Five Pillars of Chapter 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#quick-reference-core-formulas">Quick Reference: Core Formulas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#connections-to-future-material">Connections to Future Material</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#practical-guidance">Practical Guidance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#final-perspective">Final Perspective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Chapter 4: Resampling Methods</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html">Section 4.1 The Sampling Distribution Problem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#the-fundamental-target-sampling-distributions">The Fundamental Target: Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#historical-development-the-quest-for-sampling-distributions">Historical Development: The Quest for Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#three-routes-to-the-sampling-distribution">Three Routes to the Sampling Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#when-asymptotics-fail-motivating-the-bootstrap">When Asymptotics Fail: Motivating the Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#the-plug-in-principle-theoretical-foundation">The Plug-In Principle: Theoretical Foundation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#computational-perspective-bootstrap-as-monte-carlo">Computational Perspective: Bootstrap as Monte Carlo</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#chapter-4-1-exercises">Chapter 4.1 Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_1-sampling-distribution-problem.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html">Section 4.2 The Empirical Distribution and Plug-in Principle</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#the-empirical-cumulative-distribution-function">The Empirical Cumulative Distribution Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#convergence-of-the-empirical-cdf">Convergence of the Empirical CDF</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#parameters-as-statistical-functionals">Parameters as Statistical Functionals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#the-plug-in-principle">The Plug-in Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#when-the-plug-in-principle-fails">When the Plug-in Principle Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#the-bootstrap-idea-in-one-sentence">The Bootstrap Idea in One Sentence</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#computational-implementation">Computational Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#section-4-2-exercises-ecdf-and-plug-in-mastery">Section 4.2 Exercises: ECDF and Plug-in Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_2-empirical-distribution-plugin.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html">Section 4.3 The Nonparametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#the-bootstrap-principle">The Bootstrap Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bootstrap-standard-errors">Bootstrap Standard Errors</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bootstrap-bias-estimation">Bootstrap Bias Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bootstrap-confidence-intervals">Bootstrap Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bootstrap-for-regression">Bootstrap for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bootstrap-diagnostics">Bootstrap Diagnostics</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#when-bootstrap-fails">When Bootstrap Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch4_4-parametric-bootstrap.html">Section 4.4: The Parametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#the-parametric-bootstrap-principle">The Parametric Bootstrap Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#location-scale-families">Location-Scale Families</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#parametric-bootstrap-for-regression">Parametric Bootstrap for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#confidence-intervals">Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#model-checking-and-validation">Model Checking and Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#when-parametric-bootstrap-fails">When Parametric Bootstrap Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#parametric-vs-nonparametric-a-decision-framework">Parametric vs. Nonparametric: A Decision Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_4-parametric-bootstrap.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch4_5-jackknife-methods.html">Section 4.5: Jackknife Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#historical-context-and-motivation">Historical Context and Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#the-delete-1-jackknife">The Delete-1 Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#jackknife-bias-estimation">Jackknife Bias Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#the-delete-d-jackknife">The Delete-<span class="math notranslate nohighlight">\(d\)</span> Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#jackknife-versus-bootstrap">Jackknife versus Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#the-infinitesimal-jackknife">The Infinitesimal Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_5-jackknife-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Section 4.6 Bootstrap Hypothesis Testing and Permutation Tests</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#from-confidence-intervals-to-hypothesis-tests">From Confidence Intervals to Hypothesis Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-bootstrap-hypothesis-testing-framework">The Bootstrap Hypothesis Testing Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="#permutation-tests-exact-tests-under-exchangeability">Permutation Tests: Exact Tests Under Exchangeability</a></li>
<li class="toctree-l4"><a class="reference internal" href="#testing-equality-of-distributions">Testing Equality of Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bootstrap-tests-for-regression">Bootstrap Tests for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bootstrap-vs-classical-tests">Bootstrap vs Classical Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="#permutation-vs-bootstrap-choosing-the-right-approach">Permutation vs Bootstrap: Choosing the Right Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="#multiple-testing-with-bootstrap">Multiple Testing with Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html">Section 4.7 Bootstrap Confidence Intervals: Advanced Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html#why-advanced-methods">Why Advanced Methods?</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html#the-studentized-bootstrap-t-interval">The Studentized (Bootstrap-t) Interval</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html#bias-corrected-bc-intervals">Bias-Corrected (BC) Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html#bias-corrected-and-accelerated-bca-intervals">Bias-Corrected and Accelerated (BCa) Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html#choosing-b-and-assessing-monte-carlo-error">Choosing B and Assessing Monte Carlo Error</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html#diagnostics-for-advanced-bootstrap-methods">Diagnostics for Advanced Bootstrap Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html#chapter-4-7-exercises-bootstrap-confidence-interval-mastery">Chapter 4.7 Exercises: Bootstrap Confidence Interval Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch4_7-bootstrap-confidence-intervals.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part3_bayesian/index.html">Part III: Bayesian Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part3_bayesian/chapter5/index.html">Chapter 5: Bayesian Inference</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part4_llms_datascience/index.html">Part IV: Large Language Models in Data Science</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part4_llms_datascience/chapter6/index.html">Chapter 6: LLMs in Data Science Workflows</a><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Part II: Frequentist Inference</a></li>
          <li class="breadcrumb-item"><a href="index.html">Chapter 4: Resampling Methods</a></li>
      <li class="breadcrumb-item active">Section 4.6 Bootstrap Hypothesis Testing and Permutation Tests</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="section-4-6-bootstrap-hypothesis-testing-and-permutation-tests">
<span id="ch4-6-bootstrap-hypothesis-testing"></span><h1>Section 4.6 Bootstrap Hypothesis Testing and Permutation Tests<a class="headerlink" href="#section-4-6-bootstrap-hypothesis-testing-and-permutation-tests" title="Link to this heading"></a></h1>
<p>In <a class="reference internal" href="ch4_3-nonparametric-bootstrap.html#ch4-3-nonparametric-bootstrap"><span class="std std-ref">Sections 4.3–4.5</span></a>, we developed the bootstrap and jackknife as tools for <strong>estimation</strong>: computing standard errors, quantifying bias, and constructing confidence intervals. These methods address the question “How uncertain are we about <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>?” But statistical practice frequently demands a different question: “Is the observed effect real, or could it have arisen by chance?” This is the domain of <strong>hypothesis testing</strong>, and resampling methods offer powerful, flexible approaches to this problem.</p>
<p>The key conceptual shift when moving from confidence intervals to hypothesis tests is subtle but crucial: <strong>bootstrap for testing requires generating data under the null hypothesis</strong>, not simply resampling from the observed data. When we construct a confidence interval, we ask “What values of <span class="math notranslate nohighlight">\(\theta\)</span> are consistent with these data?” When we test a hypothesis, we ask “If <span class="math notranslate nohighlight">\(H_0\)</span> were true, how likely would we see a test statistic this extreme?” These two questions are related—a 95% CI inverts a family of 5% tests—but they require different computational approaches.</p>
<p>This section develops two complementary frameworks for resampling-based hypothesis testing. The <strong>permutation test</strong>, with roots in Fisher’s randomization approach from the 1930s, provides exact p-values when the null hypothesis implies exchangeability of observations. The <strong>bootstrap test</strong> extends to broader scenarios where exchangeability fails—unequal variances, complex estimators, regression settings—by enforcing the null hypothesis through data transformation. Together, these methods form a comprehensive toolkit for inference when classical parametric tests are unreliable or unavailable.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p><strong>Understand</strong>: The fundamental distinction between bootstrap for estimation (resample from data) and bootstrap for testing (resample under <span class="math notranslate nohighlight">\(H_0\)</span>)</p></li>
<li><p><strong>Develop</strong>: Permutation tests as exact tests under exchangeability; bootstrap tests for broader applicability</p></li>
<li><p><strong>Implement</strong>: Two-sample tests, regression coefficient tests, and distribution equality tests in Python</p></li>
<li><p><strong>Evaluate</strong>: When to prefer permutation vs bootstrap; asymptotic refinement through studentization</p></li>
</ul>
</div>
<section id="from-confidence-intervals-to-hypothesis-tests">
<h2>From Confidence Intervals to Hypothesis Tests<a class="headerlink" href="#from-confidence-intervals-to-hypothesis-tests" title="Link to this heading"></a></h2>
<p>Before developing resampling tests directly, we establish the connection between confidence intervals and hypothesis tests—a relationship that motivates but does not fully capture the power of resampling for testing.</p>
<section id="the-duality-principle">
<h3>The Duality Principle<a class="headerlink" href="#the-duality-principle" title="Link to this heading"></a></h3>
<p>The classical duality between confidence intervals and hypothesis tests states:</p>
<div class="note admonition">
<p class="admonition-title">Test–CI Duality</p>
<p>A <span class="math notranslate nohighlight">\((1-\alpha)\)</span> confidence interval <span class="math notranslate nohighlight">\(\text{CI}_{1-\alpha}\)</span> for <span class="math notranslate nohighlight">\(\theta\)</span> and a level-<span class="math notranslate nohighlight">\(\alpha\)</span> hypothesis test are <strong>dual</strong> in the following sense:</p>
<div class="math notranslate nohighlight">
\[\text{Reject } H_0: \theta = \theta_0 \text{ at level } \alpha \quad \Longleftrightarrow \quad \theta_0 \notin \text{CI}_{1-\alpha}\]</div>
</div>
<p>This duality means we can, in principle, test any null hypothesis by checking whether the hypothesized value falls outside our confidence interval. If we have a 95% bootstrap percentile CI of <span class="math notranslate nohighlight">\([2.3, 5.7]\)</span> for some parameter <span class="math notranslate nohighlight">\(\theta\)</span>, then we would reject <span class="math notranslate nohighlight">\(H_0: \theta = 0\)</span> at the 5% level (since <span class="math notranslate nohighlight">\(0 \notin [2.3, 5.7]\)</span>), but we would not reject <span class="math notranslate nohighlight">\(H_0: \theta = 4\)</span> (since <span class="math notranslate nohighlight">\(4 \in [2.3, 5.7]\)</span>).</p>
<p><strong>From CI to p-value</strong>: The duality can be extended to obtain p-values:</p>
<div class="math notranslate nohighlight" id="equation-pvalue-from-ci">
<span class="eqno">(184)<a class="headerlink" href="#equation-pvalue-from-ci" title="Link to this equation"></a></span>\[p\text{-value} = \inf\{\alpha : \theta_0 \notin \text{CI}_{1-\alpha}\}\]</div>
<p>In other words, the p-value is the smallest significance level at which the confidence interval would exclude <span class="math notranslate nohighlight">\(\theta_0\)</span>.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig01_test_ci_duality.png"><img alt="Test-CI duality showing rejection regions and two-tailed p-value calculation" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig01_test_ci_duality.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 167 </span><span class="caption-text"><strong>Figure 4.6.1</strong>: The fundamental duality between confidence intervals and hypothesis tests. Panel (a) shows rejection when <span class="math notranslate nohighlight">\(\theta_0\)</span> lies outside the 95% CI; panel (b) shows failure to reject when <span class="math notranslate nohighlight">\(\theta_0\)</span> is inside. Panel (c) illustrates the two-tailed test with rejection regions in both tails. Panel (d) summarizes the key relationships.</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="why-direct-testing-is-often-better">
<h3>Why Direct Testing is Often Better<a class="headerlink" href="#why-direct-testing-is-often-better" title="Link to this heading"></a></h3>
<p>While the CI-inversion approach works in principle, directly constructing the null distribution often provides:</p>
<ol class="arabic simple">
<li><p><strong>Better calibration</strong>: CI inversion inherits any coverage errors from the CI method. Direct null distribution estimation can achieve better size control.</p></li>
<li><p><strong>More natural interpretation</strong>: The p-value directly answers “How surprising is this result under <span class="math notranslate nohighlight">\(H_0\)</span>?”</p></li>
<li><p><strong>Computational efficiency</strong>: For a single test, we need only one null distribution, not a family of CIs.</p></li>
<li><p><strong>Asymptotic refinement</strong>: With studentized test statistics, bootstrap tests can achieve <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> error versus <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span> for many CI methods.</p></li>
</ol>
<p>The key insight that enables direct testing is this: <strong>we generate the null distribution by resampling from data that has been transformed to satisfy</strong> <span class="math notranslate nohighlight">\(H_0\)</span>. The following sections develop this idea systematically.</p>
</section>
</section>
<section id="the-bootstrap-hypothesis-testing-framework">
<h2>The Bootstrap Hypothesis Testing Framework<a class="headerlink" href="#the-bootstrap-hypothesis-testing-framework" title="Link to this heading"></a></h2>
<p>The bootstrap approach to hypothesis testing generates the sampling distribution of a test statistic <strong>under the null hypothesis</strong> by resampling from data that has been modified to enforce <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<section id="the-core-principle">
<h3>The Core Principle<a class="headerlink" href="#the-core-principle" title="Link to this heading"></a></h3>
<p>Consider testing <span class="math notranslate nohighlight">\(H_0: \theta = \theta_0\)</span> against <span class="math notranslate nohighlight">\(H_1: \theta \neq \theta_0\)</span>. The classical approach assumes we know the null distribution of some test statistic <span class="math notranslate nohighlight">\(T\)</span>—typically through asymptotic theory. The bootstrap approach instead <strong>estimates</strong> this null distribution by:</p>
<ol class="arabic simple">
<li><p><strong>Enforcing</strong> <span class="math notranslate nohighlight">\(H_0\)</span>: Transform the observed data so that the transformed data satisfies the null hypothesis.</p></li>
<li><p><strong>Resampling</strong>: Generate bootstrap samples from the transformed data.</p></li>
<li><p><strong>Computing</strong>: Calculate the test statistic on each bootstrap sample.</p></li>
<li><p><strong>Comparing</strong>: Assess where the observed statistic falls in the bootstrap null distribution.</p></li>
</ol>
<p>This procedure is valid because the transformed data represents a population where <span class="math notranslate nohighlight">\(H_0\)</span> is true, so resampling from it generates the null distribution of <span class="math notranslate nohighlight">\(T\)</span>.</p>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig02_null_distribution.png"><img alt="Comparison of wrong vs correct bootstrap null distribution construction" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig02_null_distribution.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 168 </span><span class="caption-text"><strong>Figure 4.6.2</strong>: The critical distinction in bootstrap hypothesis testing. The <strong>wrong approach</strong> (left panels) resamples directly from observed data, generating a distribution centered at the sample statistic—this tests whether the sample is unusual given itself, which is meaningless. The <strong>correct approach</strong> (right panels) first centers the data at the null value, then resamples, generating the true null distribution. The Phipson-Smyth correction (+1 in numerator and denominator) ensures valid p-values.</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="general-bootstrap-test-algorithm">
<h3>General Bootstrap Test Algorithm<a class="headerlink" href="#general-bootstrap-test-algorithm" title="Link to this heading"></a></h3>
<p><strong>Algorithm: Bootstrap Hypothesis Test</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Input: Data X₁,...,Xₙ; null hypothesis H₀; test statistic T; B replicates
Output: Bootstrap p-value

1. Compute observed test statistic: T_obs = T(X₁,...,Xₙ)
2. Transform data to enforce H₀: X̃₁,...,X̃ₙ (method depends on H₀)
3. For b = 1,...,B:
   a. Draw bootstrap sample X̃*₁,...,X̃*ₙ with replacement from {X̃₁,...,X̃ₙ}
   b. Compute bootstrap test statistic T*_b (using H₀ value as reference)
4. Compute p-value using appropriate tail(s)
5. Return p-value (and optionally the bootstrap null distribution)
</pre></div>
</div>
<p>The critical step is Step 2: <strong>null enforcement</strong>. The specific transformation depends on the null hypothesis and the structure of the problem.</p>
</section>
<section id="p-value-calculation">
<h3>P-Value Calculation<a class="headerlink" href="#p-value-calculation" title="Link to this heading"></a></h3>
<p>The p-value measures the probability of observing a test statistic as extreme as or more extreme than <span class="math notranslate nohighlight">\(T_{\text{obs}}\)</span>, under the null hypothesis. For bootstrap tests, this is estimated by:</p>
<p><strong>One-sided (upper tail)</strong>:</p>
<div class="math notranslate nohighlight" id="equation-pvalue-upper">
<span class="eqno">(185)<a class="headerlink" href="#equation-pvalue-upper" title="Link to this equation"></a></span>\[\hat{p} = \frac{\#\{b : T^*_b \geq T_{\text{obs}}\} + 1}{B + 1}\]</div>
<p><strong>One-sided (lower tail)</strong>:</p>
<div class="math notranslate nohighlight" id="equation-pvalue-lower">
<span class="eqno">(186)<a class="headerlink" href="#equation-pvalue-lower" title="Link to this equation"></a></span>\[\hat{p} = \frac{\#\{b : T^*_b \leq T_{\text{obs}}\} + 1}{B + 1}\]</div>
<p><strong>Two-sided</strong>:</p>
<div class="math notranslate nohighlight" id="equation-pvalue-twosided">
<span class="eqno">(187)<a class="headerlink" href="#equation-pvalue-twosided" title="Link to this equation"></a></span>\[\hat{p} = \frac{\#\{b : |T^*_b| \geq |T_{\text{obs}}|\} + 1}{B + 1}\]</div>
<div class="note admonition">
<p class="admonition-title">Why “+1” in the Numerator and Denominator?</p>
<p>The formulation with <span class="math notranslate nohighlight">\(+1\)</span> in both numerator and denominator (due to Phipson &amp; Smyth, 2010) ensures:</p>
<ol class="arabic simple">
<li><p><strong>Valid p-values</strong>: Under <span class="math notranslate nohighlight">\(H_0\)</span>, <span class="math notranslate nohighlight">\(P(\hat{p} \leq \alpha) \leq \alpha\)</span> for any <span class="math notranslate nohighlight">\(\alpha\)</span>. Without the <span class="math notranslate nohighlight">\(+1\)</span>, the test can be anti-conservative.</p></li>
<li><p><strong>Non-zero p-values</strong>: The smallest possible p-value is <span class="math notranslate nohighlight">\(1/(B+1)\)</span>, never exactly zero. Reporting <span class="math notranslate nohighlight">\(p = 0\)</span> is always incorrect—it claims absolute certainty that the effect is real.</p></li>
<li><p><strong>Natural interpretation</strong>: We treat the observed statistic as one additional draw from the null distribution, asking “What fraction of all <span class="math notranslate nohighlight">\(B+1\)</span> values are at least as extreme?”</p></li>
</ol>
<p>For <span class="math notranslate nohighlight">\(B = 9999\)</span>, the resolution is <span class="math notranslate nohighlight">\(1/10000 = 0.0001\)</span>. If you need finer resolution, increase <span class="math notranslate nohighlight">\(B\)</span>.</p>
</div>
</section>
<section id="pivotal-vs-non-pivotal-test-statistics">
<h3>Pivotal vs Non-Pivotal Test Statistics<a class="headerlink" href="#pivotal-vs-non-pivotal-test-statistics" title="Link to this heading"></a></h3>
<p>The choice of test statistic profoundly affects the accuracy of bootstrap tests.</p>
<div class="note admonition">
<p class="admonition-title">Definition: Pivotal Statistic</p>
<p>A statistic <span class="math notranslate nohighlight">\(T_n\)</span> is <strong>pivotal</strong> (or <strong>pivotal-like</strong>) if its sampling distribution does not depend on unknown parameters. A classic example is the t-statistic:</p>
<div class="math notranslate nohighlight">
\[T_n = \frac{\bar{X} - \mu}{S/\sqrt{n}}\]</div>
<p>Under the null <span class="math notranslate nohighlight">\(H_0: \mu = \mu_0\)</span>, the distribution of <span class="math notranslate nohighlight">\(T_n\)</span> (with <span class="math notranslate nohighlight">\(\mu_0\)</span> replacing <span class="math notranslate nohighlight">\(\mu\)</span>) depends only on <span class="math notranslate nohighlight">\(n\)</span> and the shape of <span class="math notranslate nohighlight">\(F\)</span>, not on <span class="math notranslate nohighlight">\(\mu\)</span> or <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
</div>
<p><strong>Non-pivotal statistics</strong> like <span class="math notranslate nohighlight">\(\bar{X} - \mu_0\)</span> have sampling distributions that depend on <span class="math notranslate nohighlight">\(\sigma\)</span>, which must be estimated.</p>
<p>The distinction matters because of the following fundamental result:</p>
<div class="important admonition">
<p class="admonition-title">Asymptotic Refinement (Hall, 1992)</p>
<p>Under standard smoothness and regularity conditions for asymptotically linear statistics, bootstrap tests based on:</p>
<ul class="simple">
<li><p><strong>Pivotal/studentized</strong> statistics achieve rejection probability error <span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></li>
<li><p><strong>Non-pivotal</strong> statistics achieve rejection probability error <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span></p></li>
</ul>
<p>This higher-order refinement requires: (i) smooth, asymptotically linear statistics; (ii) appropriate studentization; (iii) appropriate bootstrap scheme. It does <strong>not</strong> apply universally to all statistics and settings.</p>
</div>
<p>The practical implication is clear: <strong>whenever a standard error is available, use a studentized test statistic</strong>.</p>
<table class="docutils align-default" id="id3">
<caption><span class="caption-number">Table 49 </span><span class="caption-text">Test Statistic Comparison</span><a class="headerlink" href="#id3" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 35.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Statistic</p></th>
<th class="head"><p>Formula</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Error Rate</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Studentized (t)</p></td>
<td><p><span class="math notranslate nohighlight">\((\hat{\theta} - \theta_0)/\widehat{\text{SE}}\)</span></p></td>
<td><p>Pivotal</p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Unstandardized</p></td>
<td><p><span class="math notranslate nohighlight">\(\hat{\theta} - \theta_0\)</span></p></td>
<td><p>Non-pivotal</p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Wald-type</p></td>
<td><p><span class="math notranslate nohighlight">\((\hat{\theta} - \theta_0)^2/\widehat{\text{Var}}\)</span></p></td>
<td><p>Pivotal</p></td>
<td><p><span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></td>
</tr>
</tbody>
</table>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig03_studentized_comparison.png"><img alt="Comparison of Type I error rates for studentized vs non-studentized statistics" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig03_studentized_comparison.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 169 </span><span class="caption-text"><strong>Figure 4.6.3</strong>: Studentized (pivotal) statistics converge faster to nominal levels. The simulation compares Type I error rates across sample sizes for studentized vs non-studentized bootstrap tests. The studentized version (blue) maintains error rates close to 0.05 even for <span class="math notranslate nohighlight">\(n = 20\)</span>, while the non-studentized version (orange) shows systematic deviation. This demonstrates the <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> vs <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span> asymptotic refinement.</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="one-sample-location-test-a-complete-example">
<h3>One-Sample Location Test: A Complete Example<a class="headerlink" href="#one-sample-location-test-a-complete-example" title="Link to this heading"></a></h3>
<p>We now develop the one-sample bootstrap test for a population mean in complete detail.</p>
<p><strong>Setup</strong>: Data <span class="math notranslate nohighlight">\(X_1, \ldots, X_n \stackrel{\text{iid}}{\sim} F\)</span> with mean <span class="math notranslate nohighlight">\(\mu = \mathbb{E}_F[X]\)</span>.</p>
<p><strong>Hypotheses</strong>: <span class="math notranslate nohighlight">\(H_0: \mu = \mu_0\)</span> vs <span class="math notranslate nohighlight">\(H_1: \mu \neq \mu_0\)</span></p>
<p><strong>Test statistic</strong>: The studentized statistic</p>
<div class="math notranslate nohighlight" id="equation-t-statistic">
<span class="eqno">(188)<a class="headerlink" href="#equation-t-statistic" title="Link to this equation"></a></span>\[T = \frac{\bar{X} - \mu_0}{S/\sqrt{n}}\]</div>
<p>where <span class="math notranslate nohighlight">\(S\)</span> is the sample standard deviation.</p>
<p><strong>Null enforcement</strong>: To generate data consistent with <span class="math notranslate nohighlight">\(H_0\)</span>, we <strong>center</strong> the data at <span class="math notranslate nohighlight">\(\mu_0\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-centering">
<span class="eqno">(189)<a class="headerlink" href="#equation-centering" title="Link to this equation"></a></span>\[\tilde{X}_i = X_i - \bar{X} + \mu_0\]</div>
<p>The centered data <span class="math notranslate nohighlight">\(\tilde{X}_1, \ldots, \tilde{X}_n\)</span> has sample mean exactly equal to <span class="math notranslate nohighlight">\(\mu_0\)</span>, so it represents a world where <span class="math notranslate nohighlight">\(H_0\)</span> is true, while preserving the variability structure of the original data.</p>
<p><strong>Bootstrap procedure</strong>:</p>
<ol class="arabic simple">
<li><p>Compute <span class="math notranslate nohighlight">\(T_{\text{obs}} = (\bar{X} - \mu_0)/(S/\sqrt{n})\)</span></p></li>
<li><p>Center data: <span class="math notranslate nohighlight">\(\tilde{X}_i = X_i - \bar{X} + \mu_0\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(b = 1, \ldots, B\)</span>:</p>
<ol class="loweralpha simple">
<li><p>Resample: <span class="math notranslate nohighlight">\(\tilde{X}^*_1, \ldots, \tilde{X}^*_n\)</span> with replacement from <span class="math notranslate nohighlight">\(\{\tilde{X}_1, \ldots, \tilde{X}_n\}\)</span></p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(T^*_b = (\bar{\tilde{X}}^* - \mu_0)/(S^*/\sqrt{n})\)</span></p></li>
</ol>
</li>
<li><p>p-value: <span class="math notranslate nohighlight">\(\hat{p} = (\#\{|T^*_b| \geq |T_{\text{obs}}|\} + 1)/(B + 1)\)</span></p></li>
</ol>
<div class="note admonition">
<p class="admonition-title">Example 💡 One-Sample Bootstrap Test</p>
<p><strong>Given</strong>: <span class="math notranslate nohighlight">\(n = 30\)</span> observations with <span class="math notranslate nohighlight">\(\bar{x} = 2.47\)</span> and <span class="math notranslate nohighlight">\(s = 1.82\)</span>. We test <span class="math notranslate nohighlight">\(H_0: \mu = 2.0\)</span>.</p>
<p><strong>Find</strong>: Bootstrap p-value using the studentized test statistic.</p>
<p><strong>Mathematical approach</strong>:</p>
<p>The observed t-statistic is:</p>
<div class="math notranslate nohighlight">
\[T_{\text{obs}} = \frac{2.47 - 2.0}{1.82/\sqrt{30}} = \frac{0.47}{0.332} = 1.414\]</div>
<p>Under centering, the data are shifted so <span class="math notranslate nohighlight">\(\bar{\tilde{x}} = 2.0\)</span> exactly. Bootstrap samples from this centered data generate the null distribution of <span class="math notranslate nohighlight">\(T\)</span>.</p>
<p><strong>Python implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Generate example data</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.8</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># True mean = 2.5</span>

<span class="c1"># Null hypothesis</span>
<span class="n">mu_0</span> <span class="o">=</span> <span class="mf">2.0</span>

<span class="c1"># Observed test statistic</span>
<span class="n">x_bar</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">t_obs</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_bar</span> <span class="o">-</span> <span class="n">mu_0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">s</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample mean: </span><span class="si">{</span><span class="n">x_bar</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample SD: </span><span class="si">{</span><span class="n">s</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Observed t-statistic: </span><span class="si">{</span><span class="n">t_obs</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Null enforcement: center data at mu_0</span>
<span class="n">data_centered</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="n">x_bar</span> <span class="o">+</span> <span class="n">mu_0</span>

<span class="c1"># Bootstrap test</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">9999</span>
<span class="n">t_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>

<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">boot_sample</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">data_centered</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">boot_mean</span> <span class="o">=</span> <span class="n">boot_sample</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">boot_se</span> <span class="o">=</span> <span class="n">boot_sample</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">t_boot</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">boot_mean</span> <span class="o">-</span> <span class="n">mu_0</span><span class="p">)</span> <span class="o">/</span> <span class="n">boot_se</span>

<span class="c1"># Two-sided p-value (Phipson-Smyth formula)</span>
<span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_boot</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Compare to classical t-test</span>
<span class="n">_</span><span class="p">,</span> <span class="n">p_classical</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mu_0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bootstrap p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Classical t-test p-value: </span><span class="si">{</span><span class="n">p_classical</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Sample mean: 2.4729
Sample SD: 1.8247
Observed t-statistic: 1.4193

Bootstrap p-value: 0.1653
Classical t-test p-value: 0.1664
</pre></div>
</div>
<p><strong>Result</strong>: The bootstrap p-value (0.165) closely matches the classical t-test (0.166). We do not reject <span class="math notranslate nohighlight">\(H_0: \mu = 2.0\)</span> at the 5% level. The close agreement occurs because the data are approximately normal; for non-normal data, the bootstrap can be more reliable.</p>
</div>
</section>
</section>
<section id="permutation-tests-exact-tests-under-exchangeability">
<h2>Permutation Tests: Exact Tests Under Exchangeability<a class="headerlink" href="#permutation-tests-exact-tests-under-exchangeability" title="Link to this heading"></a></h2>
<p>Permutation tests represent a fundamentally different approach to hypothesis testing—one that predates the bootstrap by several decades. When the null hypothesis implies that observations are <strong>exchangeable</strong>, permutation tests provide <strong>exact</strong> p-values without any asymptotic approximation.</p>
<section id="the-exchangeability-principle">
<h3>The Exchangeability Principle<a class="headerlink" href="#the-exchangeability-principle" title="Link to this heading"></a></h3>
<div class="note admonition">
<p class="admonition-title">Definition: Exchangeability</p>
<p>Random variables <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> are <strong>exchangeable</strong> if their joint distribution is invariant under any permutation <span class="math notranslate nohighlight">\(\pi\)</span> of the indices:</p>
<div class="math notranslate nohighlight">
\[(X_1, \ldots, X_n) \stackrel{d}{=} (X_{\pi(1)}, \ldots, X_{\pi(n)})\]</div>
<p>for all permutations <span class="math notranslate nohighlight">\(\pi\)</span> of <span class="math notranslate nohighlight">\(\{1, \ldots, n\}\)</span>.</p>
</div>
<p>Exchangeability is weaker than independence but still quite strong. The key insight is that <strong>many null hypotheses imply exchangeability</strong>:</p>
<p><strong>Two-sample location problem</strong>: If <span class="math notranslate nohighlight">\(X_1, \ldots, X_m \sim F\)</span> and <span class="math notranslate nohighlight">\(Y_1, \ldots, Y_n \sim G\)</span>, the null hypothesis <span class="math notranslate nohighlight">\(H_0: F = G\)</span> (same distribution) implies that all <span class="math notranslate nohighlight">\(m + n\)</span> observations are exchangeable—the “X” and “Y” labels are arbitrary under <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<p><strong>Randomized experiments</strong>: In a randomized controlled trial, treatment assignment is random. Under the sharp null of no treatment effect, outcomes would be identical regardless of assignment, making labels exchangeable.</p>
<p><strong>Paired data with symmetric differences</strong>: If <span class="math notranslate nohighlight">\(D_i = Y_i - X_i\)</span> are differences with the null <span class="math notranslate nohighlight">\(H_0: \text{median}(D) = 0\)</span> and the distribution of <span class="math notranslate nohighlight">\(D\)</span> is symmetric about 0, then the signs of <span class="math notranslate nohighlight">\(D_i\)</span> are exchangeable.</p>
</section>
<section id="the-exact-permutation-test">
<h3>The Exact Permutation Test<a class="headerlink" href="#the-exact-permutation-test" title="Link to this heading"></a></h3>
<p>Under exchangeability, the permutation distribution of any test statistic is <strong>uniform over all permutations</strong>. This leads to the following exact result:</p>
<div class="note admonition">
<p class="admonition-title">Theorem: Exactness of Permutation Tests</p>
<p>Let <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> be exchangeable under <span class="math notranslate nohighlight">\(H_0\)</span>, and let <span class="math notranslate nohighlight">\(T = T(X_1, \ldots, X_n)\)</span> be any test statistic. Then under <span class="math notranslate nohighlight">\(H_0\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(T(X_{\pi}) \geq T_{\text{obs}}) = \frac{\#\{\pi : T(X_{\pi}) \geq T_{\text{obs}}\}}{n!}\]</div>
<p>where the sum is over all <span class="math notranslate nohighlight">\(n!\)</span> permutations.</p>
<p><strong>This p-value is exact</strong>—no large-sample approximation is needed.</p>
</div>
<p>The proof follows directly from exchangeability: under <span class="math notranslate nohighlight">\(H_0\)</span>, conditional on the pooled data, every labeling is equally likely, so each permuted test statistic value occurs with probability <span class="math notranslate nohighlight">\(1/n!\)</span>.</p>
<div class="warning admonition">
<p class="admonition-title">Critical Caveat: When Permutation Tests Are Exact</p>
<p><strong>For two-sample problems, permutation tests are exact for</strong> <span class="math notranslate nohighlight">\(H_0: F_X = F_Y\)</span> <strong>(equality of distributions).</strong> They are generally <strong>not exact</strong> for <span class="math notranslate nohighlight">\(H_0: \mu_X = \mu_Y\)</span> (equality of means) unless additional conditions hold:</p>
<ul class="simple">
<li><p>If variances differ (<span class="math notranslate nohighlight">\(\sigma_X^2 \neq \sigma_Y^2\)</span>), exchangeability fails under the mean-equality null</p></li>
<li><p>Using a studentized statistic (Welch t) provides <strong>asymptotic validity</strong> but not finite-sample exactness</p></li>
<li><p>The Behrens-Fisher problem (testing equal means with unequal variances) requires bootstrap methods, not permutation</p></li>
</ul>
<p><strong>Bottom line</strong>: Permutation tests are exact when the null implies the joint distribution is invariant under permutation. For location-only nulls with heterogeneous variances, use bootstrap tests instead.</p>
</div>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig04_permutation_test.png"><img alt="Two-sample permutation test illustration with label exchangeability" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig04_permutation_test.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 170 </span><span class="caption-text"><strong>Figure 4.6.4</strong>: The permutation test principle for two-sample comparisons. (a) Original labeled data with observed difference <span class="math notranslate nohighlight">\(T_{\text{obs}} = \bar{X} - \bar{Y}\)</span>. (b) Under <span class="math notranslate nohighlight">\(H_0: F_X = F_Y\)</span>, labels are arbitrary—we pool the data. (c) Random label reassignments generate new test statistics. (d) The permutation null distribution shows where <span class="math notranslate nohighlight">\(\pm T_{\text{obs}}\)</span> falls, yielding an exact p-value.</span><a class="headerlink" href="#id5" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Exact vs Monte Carlo Permutation</strong></p>
<p>For small samples, we can enumerate all <span class="math notranslate nohighlight">\(n!\)</span> permutations. For the two-sample problem with <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(n\)</span> observations, there are <span class="math notranslate nohighlight">\(\binom{m+n}{m}\)</span> distinct permutations of labels.</p>
<table class="docutils align-default" id="id6">
<caption><span class="caption-number">Table 50 </span><span class="caption-text">Number of Permutations</span><a class="headerlink" href="#id6" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 28.6%" />
<col style="width: 28.6%" />
<col style="width: 42.9%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Sample Sizes</p></th>
<th class="head"><p>Permutations</p></th>
<th class="head"><p>Feasibility</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(m = n = 5\)</span></p></td>
<td><p>252</p></td>
<td><p>Exact enumeration feasible</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(m = n = 10\)</span></p></td>
<td><p>184,756</p></td>
<td><p>Exact enumeration feasible</p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(m = n = 15\)</span></p></td>
<td><p>155,117,520</p></td>
<td><p>Monte Carlo needed</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(m = n = 20\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\approx 1.4 \times 10^{11}\)</span></p></td>
<td><p>Monte Carlo essential</p></td>
</tr>
</tbody>
</table>
<p>For larger samples, we use <strong>Monte Carlo permutation</strong>: randomly sample <span class="math notranslate nohighlight">\(B\)</span> permutations and estimate the p-value as <span class="math notranslate nohighlight">\((\#\{T^*_b \geq T_{\text{obs}}\} + 1)/(B + 1)\)</span>.</p>
</section>
<section id="two-sample-permutation-test">
<h3>Two-Sample Permutation Test<a class="headerlink" href="#two-sample-permutation-test" title="Link to this heading"></a></h3>
<p>The most common permutation test compares two independent samples.</p>
<p><strong>Setup</strong>: <span class="math notranslate nohighlight">\(X_1, \ldots, X_m \sim F\)</span> and <span class="math notranslate nohighlight">\(Y_1, \ldots, Y_n \sim G\)</span>, independent samples.</p>
<p><strong>Hypotheses</strong>: <span class="math notranslate nohighlight">\(H_0: F = G\)</span> (distributions are identical) vs <span class="math notranslate nohighlight">\(H_1: F \neq G\)</span></p>
<p><strong>Algorithm: Two-Sample Permutation Test</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Input: Sample X (size m), Sample Y (size n), B permutations
Output: Permutation p-value

1. Pool observations: Z = (X₁,...,Xₘ, Y₁,...,Yₙ), total N = m + n
2. Compute observed test statistic: T_obs = T(X, Y)
3. For b = 1,...,B:
   a. Randomly permute indices π of {1,...,N}
   b. Assign first m permuted observations to X*, rest to Y*
   c. Compute T*_b = T(X*, Y*)
4. p-value = (#{|T*_b| ≥ |T_obs|} + 1) / (B + 1)
5. Return p-value
</pre></div>
</div>
<p><strong>Choice of Test Statistic</strong></p>
<p>Different test statistics have different power against various alternatives:</p>
<table class="docutils align-default" id="id7">
<caption><span class="caption-number">Table 51 </span><span class="caption-text">Test Statistics for Two-Sample Comparison</span><a class="headerlink" href="#id7" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 20.0%" />
<col style="width: 30.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Statistic</p></th>
<th class="head"><p>Formula</p></th>
<th class="head"><p>Properties</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Difference in means</p></td>
<td><p><span class="math notranslate nohighlight">\(\bar{X} - \bar{Y}\)</span></p></td>
<td><p>Simple; sensitive to unequal variances</p></td>
</tr>
<tr class="row-odd"><td><p>Pooled t</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\bar{X} - \bar{Y}}{S_p\sqrt{1/m + 1/n}}\)</span></p></td>
<td><p>Assumes equal variances; more powerful under homoscedasticity</p></td>
</tr>
<tr class="row-even"><td><p>Welch t</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\bar{X} - \bar{Y}}{\sqrt{S_X^2/m + S_Y^2/n}}\)</span></p></td>
<td><p>Robust to unequal variances; <strong>recommended as default</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Wilcoxon rank-sum</p></td>
<td><p>Sum of ranks in X</p></td>
<td><p>Robust to outliers; tests stochastic ordering</p></td>
</tr>
</tbody>
</table>
<div class="tip admonition">
<p class="admonition-title">Recommendation</p>
<p>Use the <strong>Welch t-statistic</strong> as the default for permutation tests of location. It combines the power of studentization with robustness to heteroscedasticity.</p>
</div>
<p><strong>Python Implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">permutation_test_two_sample</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">9999</span><span class="p">,</span> <span class="n">statistic</span><span class="o">=</span><span class="s1">&#39;welch_t&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Two-sample permutation test.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x, y : array_like</span>
<span class="sd">        Two independent samples.</span>
<span class="sd">    B : int</span>
<span class="sd">        Number of permutations.</span>
<span class="sd">    statistic : str</span>
<span class="sd">        Test statistic: &#39;welch_t&#39;, &#39;diff_means&#39;, &#39;pooled_t&#39;.</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Contains &#39;p_value&#39;, &#39;t_obs&#39;, &#39;t_perm&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_stat</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">statistic</span> <span class="o">==</span> <span class="s1">&#39;welch_t&#39;</span><span class="p">:</span>
            <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">group1</span><span class="p">)</span> <span class="o">+</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">group2</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">group2</span><span class="p">))</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">group1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">group2</span><span class="p">))</span> <span class="o">/</span> <span class="n">se</span> <span class="k">if</span> <span class="n">se</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">elif</span> <span class="n">statistic</span> <span class="o">==</span> <span class="s1">&#39;diff_means&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">group1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">group2</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">statistic</span> <span class="o">==</span> <span class="s1">&#39;pooled_t&#39;</span><span class="p">:</span>
            <span class="n">sp2</span> <span class="o">=</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">group1</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span>
                   <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">group2</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">group2</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">group1</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">group2</span><span class="p">)</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sp2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">group1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">group2</span><span class="p">)))</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">group1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">group2</span><span class="p">))</span> <span class="o">/</span> <span class="n">se</span> <span class="k">if</span> <span class="n">se</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Observed statistic</span>
    <span class="n">t_obs</span> <span class="o">=</span> <span class="n">compute_stat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># Permutation distribution</span>
    <span class="n">t_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled</span><span class="p">)</span>
        <span class="n">t_perm</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_stat</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="n">m</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">m</span><span class="p">:])</span>

    <span class="c1"># Two-sided p-value</span>
    <span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;p_value&#39;</span><span class="p">:</span> <span class="n">p_value</span><span class="p">,</span>
        <span class="s1">&#39;t_obs&#39;</span><span class="p">:</span> <span class="n">t_obs</span><span class="p">,</span>
        <span class="s1">&#39;t_perm&#39;</span><span class="p">:</span> <span class="n">t_perm</span>
    <span class="p">}</span>
</pre></div>
</div>
<div class="note admonition">
<p class="admonition-title">Example 💡 Two-Sample Permutation Test</p>
<p><strong>Given</strong>: A clinical trial comparing a new treatment to placebo.</p>
<ul class="simple">
<li><p>Treatment group (<span class="math notranslate nohighlight">\(n = 15\)</span>): mean = 23.4, SD = 4.2</p></li>
<li><p>Placebo group (<span class="math notranslate nohighlight">\(n = 12\)</span>): mean = 19.8, SD = 5.1</p></li>
</ul>
<p><strong>Find</strong>: Permutation test p-value for <span class="math notranslate nohighlight">\(H_0\)</span>: no treatment effect.</p>
<p><strong>Python implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Simulate clinical trial data</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">treatment</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">23.4</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">placebo</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">19.8</span><span class="p">,</span> <span class="mf">5.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Treatment group:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  n = </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">treatment</span><span class="p">)</span><span class="si">}</span><span class="s2">, mean = </span><span class="si">{</span><span class="n">treatment</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, SD = </span><span class="si">{</span><span class="n">treatment</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Placebo group:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  n = </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">placebo</span><span class="p">)</span><span class="si">}</span><span class="s2">, mean = </span><span class="si">{</span><span class="n">placebo</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, SD = </span><span class="si">{</span><span class="n">placebo</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Permutation test with Welch t</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">permutation_test_two_sample</span><span class="p">(</span><span class="n">treatment</span><span class="p">,</span> <span class="n">placebo</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">9999</span><span class="p">,</span>
                                      <span class="n">statistic</span><span class="o">=</span><span class="s1">&#39;welch_t&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Compare to classical Welch t-test</span>
<span class="n">_</span><span class="p">,</span> <span class="n">p_classical</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">treatment</span><span class="p">,</span> <span class="n">placebo</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Observed Welch t: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;t_obs&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Permutation p-value: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;p_value&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Classical Welch p-value: </span><span class="si">{</span><span class="n">p_classical</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Treatment group:
  n = 15, mean = 22.98, SD = 4.17
Placebo group:
  n = 12, mean = 20.24, SD = 4.42

Observed Welch t: 1.6284
Permutation p-value: 0.1142
Classical Welch p-value: 0.1159
</pre></div>
</div>
<p><strong>Result</strong>: The permutation p-value (0.114) closely matches the classical Welch test (0.116). We do not reject <span class="math notranslate nohighlight">\(H_0\)</span> at the 5% level. The agreement occurs because the t-distribution approximation is adequate here; permutation tests become more valuable with smaller samples or non-normal data.</p>
</div>
<figure class="align-center" id="id8">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig05_exact_permutation.png"><img alt="Exact permutation test enumerating all C(5,3)=10 possible assignments" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig05_exact_permutation.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 171 </span><span class="caption-text"><strong>Figure 4.6.5</strong>: Exact permutation distribution for very small samples. With <span class="math notranslate nohighlight">\(n_X = 3\)</span> and <span class="math notranslate nohighlight">\(n_Y = 2\)</span>, all <span class="math notranslate nohighlight">\(\binom{5}{3} = 10\)</span> possible label assignments are enumerated in panel (a). Panel (b) shows the resulting discrete null distribution where each permutation has probability 0.10. The exact p-value of 0.10 requires no Monte Carlo approximation.</span><a class="headerlink" href="#id8" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="when-permutation-tests-are-not-exact">
<h3>When Permutation Tests are Not Exact<a class="headerlink" href="#when-permutation-tests-are-not-exact" title="Link to this heading"></a></h3>
<p>Permutation tests lose their exactness property when exchangeability fails. Common violations include:</p>
<p><strong>Unequal variances (Behrens-Fisher problem)</strong>: If <span class="math notranslate nohighlight">\(F\)</span> and <span class="math notranslate nohighlight">\(G\)</span> have different variances, <span class="math notranslate nohighlight">\(H_0: \mu_X = \mu_Y\)</span> does not imply <span class="math notranslate nohighlight">\(F = G\)</span>. Permuting pools observations with different variances, which can invalidate the test. However, using a studentized statistic (Welch t) provides robustness.</p>
<p><strong>Regression with continuous predictors</strong>: In <span class="math notranslate nohighlight">\(Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i\)</span>, testing <span class="math notranslate nohighlight">\(H_0: \beta_1 = 0\)</span> does not make <span class="math notranslate nohighlight">\((X_i, Y_i)\)</span> pairs exchangeable. We need alternative approaches (see Section 4.6.5).</p>
<p><strong>Dependent data</strong>: Time series, spatial data, or clustered observations violate exchangeability. Modified approaches (block permutation, cluster bootstrap) are needed.</p>
<p><strong>Paired differences with asymmetric distribution</strong>: The sign-flip permutation test assumes symmetric distribution of differences under <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><strong>Permuting when not exchangeable</strong>: If the null hypothesis does not imply exchangeability, permutation tests can be either conservative or anti-conservative. Always verify that your null hypothesis genuinely implies exchangeability before using permutation tests.</p>
</div>
</section>
<section id="paired-data-the-sign-flip-test">
<h3>Paired Data: The Sign-Flip Test<a class="headerlink" href="#paired-data-the-sign-flip-test" title="Link to this heading"></a></h3>
<p>For paired observations <span class="math notranslate nohighlight">\((X_i, Y_i)\)</span>, we often test whether the treatment effect is zero.</p>
<p><strong>Setup</strong>: <span class="math notranslate nohighlight">\(n\)</span> paired observations; let <span class="math notranslate nohighlight">\(D_i = Y_i - X_i\)</span>.</p>
<p><strong>Hypotheses</strong>: <span class="math notranslate nohighlight">\(H_0: \mathbb{E}[D] = 0\)</span> (or median = 0 if testing location)</p>
<p><strong>Additional assumption for exactness</strong>: <span class="math notranslate nohighlight">\(D_i\)</span> is symmetric about 0 under <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<p><strong>Key insight</strong>: If <span class="math notranslate nohighlight">\(D\)</span> is symmetric about 0, then <span class="math notranslate nohighlight">\(D\)</span> and <span class="math notranslate nohighlight">\(-D\)</span> have the same distribution. Therefore, randomly flipping signs preserves the null distribution.</p>
<p><strong>Algorithm: Sign-Flip Permutation Test</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Input: Paired differences D₁,...,Dₙ; B permutations
Output: Permutation p-value

1. Compute observed statistic: T_obs = mean(D) / (SD(D)/√n)  [or just mean(D)]
2. For b = 1,...,B:
   a. Generate random signs: s₁,...,sₙ ∈ {-1, +1} uniformly
   b. Create flipped differences: D*ᵢ = sᵢ × Dᵢ
   c. Compute T*_b from D*
3. p-value = (#{|T*_b| ≥ |T_obs|} + 1) / (B + 1)
</pre></div>
</div>
<p><strong>Python Implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sign_flip_test</span><span class="p">(</span><span class="n">differences</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">9999</span><span class="p">,</span> <span class="n">studentized</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sign-flip permutation test for paired differences.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    differences : array_like</span>
<span class="sd">        Paired differences D = Y - X.</span>
<span class="sd">    B : int</span>
<span class="sd">        Number of random sign flips.</span>
<span class="sd">    studentized : bool</span>
<span class="sd">        If True, use t-statistic; if False, use mean.</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Contains &#39;p_value&#39;, &#39;t_obs&#39;, &#39;t_perm&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">differences</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_stat</span><span class="p">(</span><span class="n">diffs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">studentized</span><span class="p">:</span>
            <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">diffs</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">diffs</span><span class="p">)</span> <span class="o">/</span> <span class="n">se</span> <span class="k">if</span> <span class="n">se</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">diffs</span><span class="p">)</span>

    <span class="n">t_obs</span> <span class="o">=</span> <span class="n">compute_stat</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

    <span class="c1"># Sign-flip distribution</span>
    <span class="n">t_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">signs</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">t_perm</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_stat</span><span class="p">(</span><span class="n">d</span> <span class="o">*</span> <span class="n">signs</span><span class="p">)</span>

    <span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;p_value&#39;</span><span class="p">:</span> <span class="n">p_value</span><span class="p">,</span> <span class="s1">&#39;t_obs&#39;</span><span class="p">:</span> <span class="n">t_obs</span><span class="p">,</span> <span class="s1">&#39;t_perm&#39;</span><span class="p">:</span> <span class="n">t_perm</span><span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="testing-equality-of-distributions">
<h2>Testing Equality of Distributions<a class="headerlink" href="#testing-equality-of-distributions" title="Link to this heading"></a></h2>
<p>Sometimes we want to test whether two samples come from the <strong>same distribution</strong>, not just whether they have the same mean. Permutation tests excel at this broader hypothesis.</p>
<section id="the-kolmogorov-smirnov-test">
<h3>The Kolmogorov-Smirnov Test<a class="headerlink" href="#the-kolmogorov-smirnov-test" title="Link to this heading"></a></h3>
<p>The two-sample Kolmogorov-Smirnov test uses the maximum absolute difference between empirical CDFs:</p>
<div class="math notranslate nohighlight" id="equation-ks-statistic">
<span class="eqno">(190)<a class="headerlink" href="#equation-ks-statistic" title="Link to this equation"></a></span>\[D_{m,n} = \sup_x |\hat{F}_m(x) - \hat{G}_n(x)|\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{F}_m\)</span> and <span class="math notranslate nohighlight">\(\hat{G}_n\)</span> are the ECDFs of samples of sizes <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Note on Ties and Discrete Data</p>
<p>The classical KS distribution is <strong>distribution-free only for continuous data</strong> (no ties). With discrete data or ties, the null distribution of <span class="math notranslate nohighlight">\(D\)</span> changes. The permutation approach is preferable in such cases because it automatically accounts for the discrete structure—the permutation distribution reflects the actual data, ties included.</p>
</div>
<p><strong>Connection to Section 4.2</strong>: Recall the DKW inequality bounds ECDF deviation from the true CDF. The KS test evaluates whether two ECDFs differ more than expected under <span class="math notranslate nohighlight">\(H_0: F = G\)</span>.</p>
<figure class="align-center" id="id9">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig06_ks_permutation.png"><img alt="Permutation test using Kolmogorov-Smirnov statistic" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig06_ks_permutation.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 172 </span><span class="caption-text"><strong>Figure 4.6.6</strong>: Permutation test with the Kolmogorov-Smirnov statistic. Panel (a) shows the two ECDFs with maximum difference <span class="math notranslate nohighlight">\(D = \sup_x |\hat{F}(x) - \hat{G}(x)|\)</span>. Panel (b) shows the permutation null distribution. The KS test detects distributional differences beyond location shifts—useful when samples have equal means but different variances or shapes.</span><a class="headerlink" href="#id9" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Permutation KS Test</strong></p>
<p>Under <span class="math notranslate nohighlight">\(H_0: F = G\)</span>, observations are exchangeable, so we can permute labels and recompute <span class="math notranslate nohighlight">\(D\)</span>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">ks_2samp</span>

<span class="k">def</span><span class="w"> </span><span class="nf">ks_permutation_test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">9999</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Kolmogorov-Smirnov test via permutation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x, y : array_like</span>
<span class="sd">        Two independent samples.</span>
<span class="sd">    B : int</span>
<span class="sd">        Number of permutations.</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Contains &#39;p_value&#39;, &#39;D_obs&#39;, &#39;D_perm&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>

    <span class="c1"># Observed KS statistic</span>
    <span class="n">D_obs</span> <span class="o">=</span> <span class="n">ks_2samp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">statistic</span>

    <span class="c1"># Permutation distribution</span>
    <span class="n">D_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled</span><span class="p">)</span>
        <span class="n">D_perm</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">ks_2samp</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="n">m</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">m</span><span class="p">:])</span><span class="o">.</span><span class="n">statistic</span>

    <span class="c1"># One-sided p-value (D can only be positive)</span>
    <span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">D_perm</span> <span class="o">&gt;=</span> <span class="n">D_obs</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;p_value&#39;</span><span class="p">:</span> <span class="n">p_value</span><span class="p">,</span> <span class="s1">&#39;D_obs&#39;</span><span class="p">:</span> <span class="n">D_obs</span><span class="p">,</span> <span class="s1">&#39;D_perm&#39;</span><span class="p">:</span> <span class="n">D_perm</span><span class="p">}</span>
</pre></div>
</div>
<div class="note admonition">
<p class="admonition-title">Example 💡 Testing Distributional Equality</p>
<p><strong>Given</strong>: Two samples with the same mean but different variances.</p>
<p><strong>Find</strong>: Can we detect the difference using (a) a t-test for means, and (b) a KS test for distributions?</p>
<p><strong>Python implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Same mean (5.0), different variances</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>  <span class="c1"># SD = 1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>  <span class="c1"># SD = 2.5</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample X: mean = </span><span class="si">{:.3f}</span><span class="s2">, SD = </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample Y: mean = </span><span class="si">{:.3f}</span><span class="s2">, SD = </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>

<span class="c1"># Two-sample t-test (tests means)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">p_ttest</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># KS permutation test (tests distributions)</span>
<span class="n">ks_result</span> <span class="o">=</span> <span class="n">ks_permutation_test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">9999</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Classical KS test for comparison</span>
<span class="n">_</span><span class="p">,</span> <span class="n">p_ks_classical</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ks_2samp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Welch t-test p-value: </span><span class="si">{</span><span class="n">p_ttest</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;KS permutation p-value: </span><span class="si">{</span><span class="n">ks_result</span><span class="p">[</span><span class="s1">&#39;p_value&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;KS classical p-value: </span><span class="si">{</span><span class="n">p_ks_classical</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Sample X: mean = 4.942, SD = 0.913
Sample Y: mean = 4.953, SD = 2.379

Welch t-test p-value: 0.9741
KS permutation p-value: 0.0001
KS classical p-value: 0.0001
</pre></div>
</div>
<p><strong>Result</strong>: The t-test fails to detect any difference (p = 0.97) because the means are nearly identical. The KS test strongly rejects <span class="math notranslate nohighlight">\(H_0: F = G\)</span> (p &lt; 0.001) because it detects the variance difference. This illustrates why testing distributional equality is sometimes more appropriate than testing means alone.</p>
</div>
</section>
<section id="other-distribution-tests">
<h3>Other Distribution Tests<a class="headerlink" href="#other-distribution-tests" title="Link to this heading"></a></h3>
<p>Several alternatives to the KS test may have better power for specific alternatives:</p>
<p><strong>Cramér–von Mises</strong>: Integrates squared differences between ECDFs:</p>
<div class="math notranslate nohighlight">
\[W^2 = \int_{-\infty}^{\infty} [\hat{F}_m(x) - \hat{G}_n(x)]^2 \, d\hat{H}_{m+n}(x)\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{H}_{m+n}\)</span> is the pooled ECDF. Less sensitive to differences at the tails than KS.</p>
<p><strong>Anderson-Darling</strong>: Weighted version emphasizing tails:</p>
<div class="math notranslate nohighlight">
\[A^2 = \int_{-\infty}^{\infty} \frac{[\hat{F}_m(x) - \hat{G}_n(x)]^2}{\hat{H}(x)(1-\hat{H}(x))} \, d\hat{H}_{m+n}(x)\]</div>
<p>More powerful for detecting tail differences.</p>
<p><strong>Energy distance</strong> (Székely-Rizzo): Generalizes to multivariate settings.</p>
<p>All these tests can be conducted via permutation with the same algorithm structure—only the test statistic changes.</p>
</section>
</section>
<section id="bootstrap-tests-for-regression">
<h2>Bootstrap Tests for Regression<a class="headerlink" href="#bootstrap-tests-for-regression" title="Link to this heading"></a></h2>
<p>Regression poses unique challenges for resampling tests because the standard null hypothesis <span class="math notranslate nohighlight">\(H_0: \beta_j = 0\)</span> does not imply exchangeability of observations. We cannot simply permute <span class="math notranslate nohighlight">\((X_i, Y_i)\)</span> pairs. Instead, we use <strong>null-enforced bootstrap</strong> methods.</p>
<section id="testing-a-single-coefficient">
<h3>Testing a Single Coefficient<a class="headerlink" href="#testing-a-single-coefficient" title="Link to this heading"></a></h3>
<p><strong>Setup</strong>: Linear model <span class="math notranslate nohighlight">\(Y = X\beta + \varepsilon\)</span>, where <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(n \times p\)</span>. We test <span class="math notranslate nohighlight">\(H_0: \beta_j = 0\)</span>.</p>
<p><strong>Challenge</strong>: Under <span class="math notranslate nohighlight">\(H_0\)</span>, <span class="math notranslate nohighlight">\(Y\)</span> still depends on the other predictors <span class="math notranslate nohighlight">\(X_{-j}\)</span>, so observations are not exchangeable.</p>
<p><strong>Solution</strong>: The <strong>null-enforced residual bootstrap</strong> generates data from the restricted model (with <span class="math notranslate nohighlight">\(\beta_j = 0\)</span>), ensuring bootstrap samples are consistent with <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<p><strong>Algorithm: Null-Enforced Residual Bootstrap Test</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Testing H₀: βⱼ = 0 in Y = Xβ + ε

1. Fit RESTRICTED model (excluding predictor j):
   Ỹ = X₋ⱼβ̃₋ⱼ + ε̃
2. Compute restricted residuals: ẽᵢ = Yᵢ - X₋ⱼ,ᵢ&#39;β̃₋ⱼ
3. Center residuals: ẽᵢ ← ẽᵢ - mean(ẽ)
4. Compute observed test statistic from FULL model (t, F, or Wald)
5. For b = 1,...,B:
   a. Resample indices i* with replacement from {1,...,n}
   b. Create Y*ᵢ = X₋ⱼ,ᵢ&#39;β̃₋ⱼ + ẽᵢ*  (null structure with resampled residuals)
   c. Fit FULL model to (X, Y*), compute T*_b
6. p-value = (#{|T*_b| ≥ |T_obs|} + 1) / (B + 1)
</pre></div>
</div>
<p><strong>Key insight</strong>: By generating <span class="math notranslate nohighlight">\(Y^*\)</span> from the restricted model, we ensure that variable <span class="math notranslate nohighlight">\(j\)</span> has no true effect in the bootstrap samples—exactly what <span class="math notranslate nohighlight">\(H_0\)</span> asserts.</p>
<div class="tip admonition">
<p class="admonition-title">Fixed Design Assumption</p>
<p>The residual bootstrap assumes a <strong>fixed design matrix</strong> <span class="math notranslate nohighlight">\(X\)</span>—we condition on the observed predictors. This is appropriate for designed experiments and most regression settings. If <span class="math notranslate nohighlight">\(X\)</span> is random and unconditional inference is needed, a <strong>pairs bootstrap</strong> (resampling <span class="math notranslate nohighlight">\((X_i, Y_i)\)</span> pairs) is an alternative, though it cannot enforce <span class="math notranslate nohighlight">\(H_0\)</span> as cleanly.</p>
</div>
<figure class="align-center" id="id10">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig07_regression_null_bootstrap.png"><img alt="Null-enforced residual bootstrap for regression coefficient testing" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig07_regression_null_bootstrap.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 173 </span><span class="caption-text"><strong>Figure 4.6.7</strong>: Null-enforced bootstrap for testing regression coefficients. (a) The full model fits all predictors; (b) the restricted model excludes the predictor under test, enforcing <span class="math notranslate nohighlight">\(H_0: \beta_j = 0\)</span>; (c) resampled residuals from the restricted model create bootstrap data where the null is true by construction; (d) the null distribution of the t-statistic from fitting the full model to bootstrap data.</span><a class="headerlink" href="#id10" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Python Implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">bootstrap_regression_test</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_index</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">999</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Bootstrap test for H₀: β_j = 0 using null-enforced residual resampling.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array_like, shape (n, p)</span>
<span class="sd">        Design matrix (should include intercept if desired).</span>
<span class="sd">    y : array_like, shape (n,)</span>
<span class="sd">        Response vector.</span>
<span class="sd">    test_index : int</span>
<span class="sd">        Index of coefficient to test (0-indexed).</span>
<span class="sd">    B : int</span>
<span class="sd">        Number of bootstrap replicates.</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Contains &#39;p_value&#39;, &#39;t_obs&#39;, &#39;t_boot&#39;, &#39;beta_hat&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># Full model fit</span>
    <span class="n">beta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y_hat_full</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_hat</span>
    <span class="n">residuals_full</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_hat_full</span>
    <span class="n">mse_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">residuals_full</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
    <span class="n">XtX_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">se_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_full</span> <span class="o">*</span> <span class="n">XtX_inv</span><span class="p">[</span><span class="n">test_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">])</span>
    <span class="n">t_obs</span> <span class="o">=</span> <span class="n">beta_hat</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">/</span> <span class="n">se_full</span>

    <span class="c1"># Restricted model (excluding test_index column)</span>
    <span class="n">X_restricted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">test_index</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">beta_restricted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X_restricted</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y_hat_restricted</span> <span class="o">=</span> <span class="n">X_restricted</span> <span class="o">@</span> <span class="n">beta_restricted</span>
    <span class="n">residuals_restricted</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_hat_restricted</span>

    <span class="c1"># Center residuals</span>
    <span class="n">residuals_centered</span> <span class="o">=</span> <span class="n">residuals_restricted</span> <span class="o">-</span> <span class="n">residuals_restricted</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="c1"># Bootstrap under H₀</span>
    <span class="n">t_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="c1"># Resample residuals</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">resid_star</span> <span class="o">=</span> <span class="n">residuals_centered</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="c1"># Generate Y* under null</span>
        <span class="n">y_star</span> <span class="o">=</span> <span class="n">y_hat_restricted</span> <span class="o">+</span> <span class="n">resid_star</span>

        <span class="c1"># Fit full model to bootstrap data</span>
        <span class="n">beta_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_star</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">resid_star_full</span> <span class="o">=</span> <span class="n">y_star</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_star</span>
        <span class="n">mse_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">resid_star_full</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
        <span class="n">se_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_star</span> <span class="o">*</span> <span class="n">XtX_inv</span><span class="p">[</span><span class="n">test_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">])</span>
        <span class="n">t_boot</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta_star</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">/</span> <span class="n">se_star</span> <span class="k">if</span> <span class="n">se_star</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="c1"># Two-sided p-value</span>
    <span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_boot</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;p_value&#39;</span><span class="p">:</span> <span class="n">p_value</span><span class="p">,</span>
        <span class="s1">&#39;t_obs&#39;</span><span class="p">:</span> <span class="n">t_obs</span><span class="p">,</span>
        <span class="s1">&#39;t_boot&#39;</span><span class="p">:</span> <span class="n">t_boot</span><span class="p">,</span>
        <span class="s1">&#39;beta_hat&#39;</span><span class="p">:</span> <span class="n">beta_hat</span>
    <span class="p">}</span>
</pre></div>
</div>
<div class="note admonition">
<p class="admonition-title">Example 💡 Bootstrap Test for Regression Coefficient</p>
<p><strong>Given</strong>: A regression of salary on experience and education, testing whether education has an effect.</p>
<p><strong>Python implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Generate data: salary depends on experience and education</span>
<span class="n">experience</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">education</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">salary</span> <span class="o">=</span> <span class="mi">30</span> <span class="o">+</span> <span class="mf">2.5</span> <span class="o">*</span> <span class="n">experience</span> <span class="o">+</span> <span class="mf">1.8</span> <span class="o">*</span> <span class="n">education</span> <span class="o">+</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="c1"># Design matrix with intercept</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">experience</span><span class="p">,</span> <span class="n">education</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">salary</span>

<span class="c1"># Test H₀: β_education = 0 (index 2)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">bootstrap_regression_test</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_index</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">4999</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Compare to classical t-test</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">t</span> <span class="k">as</span> <span class="n">t_dist</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">p_classical</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;t_obs&#39;</span><span class="p">]),</span> <span class="n">df</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Coefficient estimates: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;beta_hat&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Observed t-statistic for education: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;t_obs&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bootstrap p-value: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;p_value&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Classical t-test p-value: </span><span class="si">{</span><span class="n">p_classical</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Coefficient estimates: [29.38  2.45  1.90]
Observed t-statistic for education: 4.2847

Bootstrap p-value: 0.0002
Classical t-test p-value: 0.0001
</pre></div>
</div>
<p><strong>Result</strong>: Both methods strongly reject <span class="math notranslate nohighlight">\(H_0: \beta_{\text{education}} = 0\)</span>. The close agreement validates the bootstrap approach. Bootstrap becomes more valuable when residuals are non-normal or heteroscedastic.</p>
</div>
</section>
<section id="wild-bootstrap-for-heteroscedastic-regression">
<h3>Wild Bootstrap for Heteroscedastic Regression<a class="headerlink" href="#wild-bootstrap-for-heteroscedastic-regression" title="Link to this heading"></a></h3>
<p>The residual bootstrap assumes homoscedasticity: <span class="math notranslate nohighlight">\(\text{Var}(\varepsilon_i) = \sigma^2\)</span> constant. When this fails, the <strong>wild bootstrap</strong> provides a valid alternative.</p>
<p><strong>The Problem</strong>: Under heteroscedasticity, resampling residuals scrambles the variance structure. A small residual from a low-variance region might be placed where a large residual belongs.</p>
<p><strong>The Solution</strong>: Instead of resampling residuals, we <strong>multiply</strong> each residual by a random weight that preserves expected squared magnitude, while using the <strong>restricted model</strong> to enforce <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<p><strong>Wild Bootstrap Algorithm (Null-Enforced)</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Testing H₀: βⱼ = 0 under heteroscedasticity

1. Fit RESTRICTED model (excluding variable j): get β̃₋ⱼ, fitted values Ỹ
2. Compute restricted residuals: ẽᵢ = Yᵢ - Ỹᵢ
3. (Optional) Scale residuals for leverage: ẽᵢ ← ẽᵢ / √(1 - hᵢᵢ)
4. Compute observed t-statistic from FULL model fit
5. For b = 1,...,B:
   a. Generate random weights: v*₁,...,v*ₙ iid with E[v*] = 0, E[v*²] = 1
   b. Create Y*ᵢ = Ỹᵢ + ẽᵢ × v*ᵢ (null structure with randomized residuals)
   c. Fit FULL model to (X, Y*), compute T*_b using same formula as t_obs
6. p-value = (#{|T*_b| ≥ |t_obs|} + 1) / (B + 1)
</pre></div>
</div>
<p><strong>Key point</strong>: By generating <span class="math notranslate nohighlight">\(Y^*\)</span> from the <strong>restricted</strong> fit, we ensure the null hypothesis <span class="math notranslate nohighlight">\(\beta_j = 0\)</span> holds in bootstrap samples. The wild multipliers preserve the heteroscedastic structure.</p>
<p><strong>Choice of Weight Distribution</strong>:</p>
<table class="docutils align-default" id="id11">
<caption><span class="caption-number">Table 52 </span><span class="caption-text">Wild Bootstrap Weight Distributions</span><a class="headerlink" href="#id11" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Distribution</p></th>
<th class="head"><p>P(v = a)</p></th>
<th class="head"><p>Properties</p></th>
<th class="head"><p>Recommendation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Rademacher</p></td>
<td><p><span class="math notranslate nohighlight">\(P(\pm 1) = 0.5\)</span></p></td>
<td><p>Simple; <span class="math notranslate nohighlight">\(\mathbb{E}[v] = 0\)</span>, <span class="math notranslate nohighlight">\(\mathbb{E}[v^2] = 1\)</span></p></td>
<td><p><strong>Default choice</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Mammen</p></td>
<td><p><span class="math notranslate nohighlight">\(P\left(\frac{1-\sqrt{5}}{2}\right) = \frac{1+\sqrt{5}}{2\sqrt{5}}\)</span></p></td>
<td><p>Matches third moment</p></td>
<td><p>Small samples</p></td>
</tr>
<tr class="row-even"><td><p>Standard Normal</p></td>
<td><p><span class="math notranslate nohighlight">\(N(0, 1)\)</span></p></td>
<td><p>Continuous</p></td>
<td><p>Alternative</p></td>
</tr>
</tbody>
</table>
<p>The Rademacher distribution (random <span class="math notranslate nohighlight">\(\pm 1\)</span>) is simplest and works well in most applications.</p>
<p><strong>Python Implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">wild_bootstrap_test</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_index</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">999</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;rademacher&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wild bootstrap test for H₀: β_j = 0 under heteroscedasticity.</span>
<span class="sd">    Uses null-enforced approach with restricted model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array_like, shape (n, p)</span>
<span class="sd">        Design matrix.</span>
<span class="sd">    y : array_like, shape (n,)</span>
<span class="sd">        Response vector.</span>
<span class="sd">    test_index : int</span>
<span class="sd">        Index of coefficient to test.</span>
<span class="sd">    B : int</span>
<span class="sd">        Number of bootstrap replicates.</span>
<span class="sd">    weights : str</span>
<span class="sd">        Weight distribution: &#39;rademacher&#39;, &#39;mammen&#39;, or &#39;normal&#39;.</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Contains &#39;p_value&#39;, &#39;t_obs&#39;, &#39;t_boot&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># Full model fit for observed statistic</span>
    <span class="n">beta_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">resid_full</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_full</span>

    <span class="c1"># HC3-style robust standard error</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
    <span class="n">XtX_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">resid_hc3</span> <span class="o">=</span> <span class="n">resid_full</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span>  <span class="c1"># HC3 scaling</span>
    <span class="n">var_robust</span> <span class="o">=</span> <span class="n">XtX_inv</span><span class="p">[</span><span class="n">test_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">resid_hc3</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">test_index</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">se_robust</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_robust</span><span class="p">)</span>
    <span class="n">t_obs</span> <span class="o">=</span> <span class="n">beta_full</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">/</span> <span class="n">se_robust</span>

    <span class="c1"># Restricted model (excluding test_index column) for null enforcement</span>
    <span class="n">X_restricted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">test_index</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">beta_restricted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X_restricted</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y_hat_restricted</span> <span class="o">=</span> <span class="n">X_restricted</span> <span class="o">@</span> <span class="n">beta_restricted</span>
    <span class="n">resid_restricted</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_hat_restricted</span>

    <span class="c1"># Weight generator</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_weights</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="o">==</span> <span class="s1">&#39;rademacher&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">weights</span> <span class="o">==</span> <span class="s1">&#39;mammen&#39;</span><span class="p">:</span>
            <span class="n">golden</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">p_pos</span> <span class="o">=</span> <span class="n">golden</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">p_pos</span><span class="p">,</span>
                           <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span>
                           <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># normal</span>
            <span class="k">return</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>

    <span class="c1"># Wild bootstrap under H0</span>
    <span class="n">t_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">generate_weights</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">y_star</span> <span class="o">=</span> <span class="n">y_hat_restricted</span> <span class="o">+</span> <span class="n">resid_restricted</span> <span class="o">*</span> <span class="n">v</span>  <span class="c1"># Null-enforced</span>

        <span class="c1"># Fit full model to bootstrap data</span>
        <span class="n">beta_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_star</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">resid_star</span> <span class="o">=</span> <span class="n">y_star</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_star</span>
        <span class="n">resid_star_hc3</span> <span class="o">=</span> <span class="n">resid_star</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span>
        <span class="n">var_star</span> <span class="o">=</span> <span class="n">XtX_inv</span><span class="p">[</span><span class="n">test_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> \
                   <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">resid_star_hc3</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">test_index</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">se_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">var_star</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">))</span>
        <span class="n">t_boot</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta_star</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">/</span> <span class="n">se_star</span>  <span class="c1"># Same formula as t_obs</span>

    <span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_boot</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;p_value&#39;</span><span class="p">:</span> <span class="n">p_value</span><span class="p">,</span> <span class="s1">&#39;t_obs&#39;</span><span class="p">:</span> <span class="n">t_obs</span><span class="p">,</span> <span class="s1">&#39;t_boot&#39;</span><span class="p">:</span> <span class="n">t_boot</span><span class="p">}</span>
</pre></div>
</div>
</section>
<section id="bootstrap-tests-for-glms">
<h3>Bootstrap Tests for GLMs<a class="headerlink" href="#bootstrap-tests-for-glms" title="Link to this heading"></a></h3>
<p>For generalized linear models (logistic regression, Poisson regression, etc.), we use <strong>parametric bootstrap</strong> under the null hypothesis.</p>
<p><strong>Framework</strong>: Model <span class="math notranslate nohighlight">\(Y_i \sim \text{ExpFam}(\mu_i)\)</span> with <span class="math notranslate nohighlight">\(g(\mu_i) = X_i'\beta\)</span>. Test <span class="math notranslate nohighlight">\(H_0: \beta_j = 0\)</span>.</p>
<p><strong>Algorithm: Parametric Bootstrap for GLM</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>1. Fit RESTRICTED model under H₀: μ̃ᵢ = g⁻¹(X₋ⱼ,ᵢ&#39;β̃₋ⱼ)
2. Compute observed test statistic (Wald, LRT, or Score) from FULL model
3. For b = 1,...,B:
   a. Simulate Y*ᵢ ~ ExpFam(μ̃ᵢ)  (from restricted model)
   b. Fit FULL model to (X, Y*), compute T*_b
4. p-value from bootstrap distribution
</pre></div>
</div>
<p><strong>Python Implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.special</span><span class="w"> </span><span class="kn">import</span> <span class="n">expit</span><span class="p">,</span> <span class="n">logit</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sm</span>

<span class="k">def</span><span class="w"> </span><span class="nf">bootstrap_glm_test</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_index</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s1">&#39;binomial&#39;</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">999</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parametric bootstrap test for GLM coefficient.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array_like</span>
<span class="sd">        Design matrix.</span>
<span class="sd">    y : array_like</span>
<span class="sd">        Response (binary for binomial, counts for Poisson).</span>
<span class="sd">    test_index : int</span>
<span class="sd">        Index of coefficient to test.</span>
<span class="sd">    family : str</span>
<span class="sd">        &#39;binomial&#39; or &#39;poisson&#39;.</span>
<span class="sd">    B : int</span>
<span class="sd">        Number of bootstrap replicates.</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Contains &#39;p_value&#39;, &#39;z_obs&#39;, &#39;z_boot&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># Set up GLM family</span>
    <span class="k">if</span> <span class="n">family</span> <span class="o">==</span> <span class="s1">&#39;binomial&#39;</span><span class="p">:</span>
        <span class="n">glm_family</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Binomial</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">family</span> <span class="o">==</span> <span class="s1">&#39;poisson&#39;</span><span class="p">:</span>
        <span class="n">glm_family</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Poisson</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;family must be &#39;binomial&#39; or &#39;poisson&#39;&quot;</span><span class="p">)</span>

    <span class="c1"># Fit full model</span>
    <span class="n">model_full</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">glm_family</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">z_obs</span> <span class="o">=</span> <span class="n">model_full</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>

    <span class="c1"># Fit restricted model (excluding test_index)</span>
    <span class="n">X_restricted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">test_index</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">model_restricted</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X_restricted</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">glm_family</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">mu_restricted</span> <span class="o">=</span> <span class="n">model_restricted</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_restricted</span><span class="p">)</span>

    <span class="c1"># Parametric bootstrap under H₀</span>
    <span class="n">z_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="c1"># Simulate under restricted model</span>
        <span class="k">if</span> <span class="n">family</span> <span class="o">==</span> <span class="s1">&#39;binomial&#39;</span><span class="p">:</span>
            <span class="n">y_star</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">mu_restricted</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># poisson</span>
            <span class="n">y_star</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">mu_restricted</span><span class="p">)</span>

        <span class="c1"># Fit full model to simulated data</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">model_star</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y_star</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">glm_family</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
            <span class="n">z_boot</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_star</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">z_boot</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Handle convergence failures</span>

    <span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_boot</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;p_value&#39;</span><span class="p">:</span> <span class="n">p_value</span><span class="p">,</span> <span class="s1">&#39;z_obs&#39;</span><span class="p">:</span> <span class="n">z_obs</span><span class="p">,</span> <span class="s1">&#39;z_boot&#39;</span><span class="p">:</span> <span class="n">z_boot</span><span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="bootstrap-vs-classical-tests">
<h2>Bootstrap vs Classical Tests<a class="headerlink" href="#bootstrap-vs-classical-tests" title="Link to this heading"></a></h2>
<p>When should we use bootstrap or permutation tests instead of classical parametric tests? This section provides practical guidance.</p>
<section id="when-bootstrap-recovers-classical-results">
<h3>When Bootstrap Recovers Classical Results<a class="headerlink" href="#when-bootstrap-recovers-classical-results" title="Link to this heading"></a></h3>
<p>For large samples with approximately normal data, bootstrap tests typically agree closely with classical tests:</p>
<ul class="simple">
<li><p><strong>One-sample t-test</strong>: Bootstrap under centering <span class="math notranslate nohighlight">\(\approx\)</span> classical t</p></li>
<li><p><strong>Two-sample Welch test</strong>: Permutation with Welch statistic <span class="math notranslate nohighlight">\(\approx\)</span> classical Welch</p></li>
<li><p><strong>Regression F-test</strong>: Residual bootstrap <span class="math notranslate nohighlight">\(\approx\)</span> classical F</p></li>
</ul>
<p>This agreement validates the bootstrap approach—it doesn’t artificially create significance.</p>
</section>
<section id="when-bootstrap-improves-on-classical">
<h3>When Bootstrap Improves on Classical<a class="headerlink" href="#when-bootstrap-improves-on-classical" title="Link to this heading"></a></h3>
<p>Bootstrap and permutation tests offer advantages in several scenarios:</p>
<p><strong>Small samples</strong>: The Central Limit Theorem convergence may be too slow for reliable asymptotic p-values. Bootstrap generates the finite-sample null distribution directly.</p>
<p><strong>Non-normal data</strong>: Heavy tails or skewness invalidate normal-theory tests. Bootstrap captures the true sampling distribution shape.</p>
<p><strong>Complex statistics</strong>: Ratios, correlations near boundaries, medians, and other non-linear statistics may not have tractable asymptotic distributions. Bootstrap handles any computable statistic.</p>
<p><strong>Heteroscedasticity</strong>: Wild bootstrap provides valid inference without requiring correct variance modeling.</p>
<div class="important admonition">
<p class="admonition-title">Asymptotic Refinement Revisited</p>
<p>Hall (1992) established that for smooth statistics:</p>
<ul class="simple">
<li><p>Classical tests have size error <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span></p></li>
<li><p>Bootstrap tests with <strong>studentized</strong> statistics have size error <span class="math notranslate nohighlight">\(O(n^{-1})\)</span></p></li>
</ul>
<p>This <strong>asymptotic refinement</strong> means bootstrap tests can be more accurate than classical tests even asymptotically—a remarkable theoretical result.</p>
</div>
</section>
<section id="comparison-framework">
<h3>Comparison Framework<a class="headerlink" href="#comparison-framework" title="Link to this heading"></a></h3>
<table class="docutils align-default" id="id12">
<caption><span class="caption-number">Table 53 </span><span class="caption-text">Classical vs Bootstrap vs Permutation Tests</span><a class="headerlink" href="#id12" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 20.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 30.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Aspect</p></th>
<th class="head"><p>Classical</p></th>
<th class="head"><p>Bootstrap</p></th>
<th class="head"><p>Permutation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Assumptions</p></td>
<td><p>Distributional (e.g., normality)</p></td>
<td><p>Consistency of <span class="math notranslate nohighlight">\(T\)</span></p></td>
<td><p>Exchangeability under <span class="math notranslate nohighlight">\(H_0\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Small-sample accuracy</p></td>
<td><p>Often poor</p></td>
<td><p>Often better</p></td>
<td><p>Exact under <span class="math notranslate nohighlight">\(H_0\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Computational cost</p></td>
<td><p><span class="math notranslate nohighlight">\(O(1)\)</span> (formula)</p></td>
<td><p><span class="math notranslate nohighlight">\(O(B \times C(T))\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(O(B \times C(T))\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Complex statistics</p></td>
<td><p>May not exist</p></td>
<td><p>Generally available</p></td>
<td><p>Available</p></td>
</tr>
<tr class="row-even"><td><p>Heteroscedasticity</p></td>
<td><p>Requires robust SE</p></td>
<td><p>Wild bootstrap</p></td>
<td><p>Invalid (use bootstrap)</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="permutation-vs-bootstrap-choosing-the-right-approach">
<h2>Permutation vs Bootstrap: Choosing the Right Approach<a class="headerlink" href="#permutation-vs-bootstrap-choosing-the-right-approach" title="Link to this heading"></a></h2>
<p>While both permutation and bootstrap tests are resampling methods, they have distinct theoretical foundations and appropriate use cases.</p>
<section id="decision-framework">
<h3>Decision Framework<a class="headerlink" href="#decision-framework" title="Link to this heading"></a></h3>
<p><strong>Use Permutation Tests When</strong>:</p>
<ol class="arabic simple">
<li><p><strong>:math:`H_0` implies exchangeability</strong>: The classic case is <span class="math notranslate nohighlight">\(H_0: F_X = F_Y\)</span> (same distribution), which makes group labels exchangeable.</p></li>
<li><p><strong>Randomized experiments</strong>: Under Fisher’s sharp null of no treatment effect, treatment assignment is exchangeable.</p></li>
<li><p><strong>Exact p-values are desired</strong>: Permutation tests are exact under exchangeability—no asymptotic approximation.</p></li>
<li><p><strong>Equal variance assumption is reasonable</strong>: For location testing, permutation assumes similar shapes under <span class="math notranslate nohighlight">\(H_0\)</span>.</p></li>
<li><p><strong>Testing distributional equality</strong>: KS, Cramér–von Mises, and similar tests naturally fit the permutation framework.</p></li>
</ol>
<p><strong>Use Bootstrap Tests When</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Unequal variances</strong>: The Behrens-Fisher problem (testing <span class="math notranslate nohighlight">\(\mu_X = \mu_Y\)</span> when <span class="math notranslate nohighlight">\(\sigma_X \neq \sigma_Y\)</span>) breaks exchangeability.</p></li>
<li><p><strong>Regression and GLMs</strong>: Coefficient tests don’t induce exchangeability.</p></li>
<li><p><strong>Complex estimators</strong>: Bootstrap handles any statistic; just enforce <span class="math notranslate nohighlight">\(H_0\)</span> via data transformation.</p></li>
<li><p><strong>Dependent data</strong> (with modifications): Block bootstrap, cluster bootstrap for dependent observations.</p></li>
<li><p><strong>Survey weights or complex designs</strong>: Bootstrap can incorporate sampling weights.</p></li>
</ol>
<table class="docutils align-default" id="id13">
<caption><span class="caption-number">Table 54 </span><span class="caption-text">Method Selection Guide</span><a class="headerlink" href="#id13" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 40.0%" />
<col style="width: 30.0%" />
<col style="width: 30.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Scenario</p></th>
<th class="head"><p>Method</p></th>
<th class="head"><p>Rationale</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Two-sample, <span class="math notranslate nohighlight">\(F_X = F_Y\)</span> under <span class="math notranslate nohighlight">\(H_0\)</span></p></td>
<td><p>Permutation</p></td>
<td><p>Exact under exchangeability</p></td>
</tr>
<tr class="row-odd"><td><p>Two-sample, unequal variances</p></td>
<td><p>Bootstrap (or permutation with Welch t)</p></td>
<td><p>Handles heteroscedasticity</p></td>
</tr>
<tr class="row-even"><td><p>Paired differences, symmetric <span class="math notranslate nohighlight">\(H_0\)</span></p></td>
<td><p>Sign-flip permutation</p></td>
<td><p>Exact under symmetry</p></td>
</tr>
<tr class="row-odd"><td><p>Regression <span class="math notranslate nohighlight">\(\beta = 0\)</span></p></td>
<td><p>Null-enforced bootstrap</p></td>
<td><p>No exchangeability</p></td>
</tr>
<tr class="row-even"><td><p>Regression, heteroscedastic</p></td>
<td><p>Wild bootstrap</p></td>
<td><p>Robust to variance structure</p></td>
</tr>
<tr class="row-odd"><td><p>GLM coefficient</p></td>
<td><p>Parametric bootstrap</p></td>
<td><p>Respects likelihood structure</p></td>
</tr>
<tr class="row-even"><td><p>Distribution equality</p></td>
<td><p>Permutation</p></td>
<td><p>Natural framework</p></td>
</tr>
</tbody>
</table>
<figure class="align-center" id="id14">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig08_decision_framework.png"><img alt="Decision framework for choosing between permutation and bootstrap tests" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter4/ch4_6_fig08_decision_framework.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 174 </span><span class="caption-text"><strong>Figure 4.6.8</strong>: Decision framework for hypothesis test selection. The primary question is whether <span class="math notranslate nohighlight">\(H_0\)</span> implies exchangeability—if yes, permutation tests provide exact inference. If not, bootstrap tests with proper null-enforcement offer broader applicability. Always use studentized (pivotal) statistics when possible for <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> asymptotic refinement.</span><a class="headerlink" href="#id14" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="hybrid-approaches">
<h3>Hybrid Approaches<a class="headerlink" href="#hybrid-approaches" title="Link to this heading"></a></h3>
<p>Some methods combine elements of both:</p>
<p><strong>Freedman-Lane procedure</strong>: For testing regression coefficients, permute residuals from a partial model. This maintains the null structure while using permutation mechanics.</p>
<p><strong>Studentized permutation</strong>: Use a studentized statistic within permutation to gain robustness to variance differences.</p>
<p><strong>Permutation of bootstrap</strong>: In some contexts, combine both methods for different aspects of the problem.</p>
</section>
</section>
<section id="multiple-testing-with-bootstrap">
<h2>Multiple Testing with Bootstrap<a class="headerlink" href="#multiple-testing-with-bootstrap" title="Link to this heading"></a></h2>
<p>When testing many hypotheses simultaneously, family-wise error rate (FWER) control becomes important. Bootstrap methods can account for the correlation structure among tests.</p>
<section id="the-maxt-procedure">
<h3>The maxT Procedure<a class="headerlink" href="#the-maxt-procedure" title="Link to this heading"></a></h3>
<p>The <strong>Westfall-Young step-down procedure</strong> uses the maximum test statistic to control FWER while exploiting correlation:</p>
<p><strong>Algorithm: maxT Step-Down</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Input: m test statistics T₁,...,Tₘ; B bootstrap replicates
Output: Adjusted p-values p̃₁,...,p̃ₘ

1. Order observed |T_{(1)}| ≥ |T_{(2)}| ≥ ... ≥ |T_{(m)}|
2. For b = 1,...,B:
   a. Generate joint null data (permutation or bootstrap)
   b. Compute all m statistics T*₁,b,...,T*ₘ,b
   c. Record max|T*ⱼ,b| for j = 1,...,m
3. For j = 1,...,m:
   p̃_{(j)} = max(p̃_{(j-1)}, proportion of max* ≥ |T_{(j)}|)
4. Map back to original indices
</pre></div>
</div>
<p><strong>Key advantage</strong>: If tests are positively correlated (common in genomics, neuroimaging), Westfall-Young is less conservative than Bonferroni while still controlling FWER.</p>
<div class="warning admonition">
<p class="admonition-title">Subset Pivotality Assumption</p>
<p>Strong FWER control for Westfall-Young relies on conditions such as <strong>subset pivotality</strong>: the joint distribution of test statistics for true nulls should not depend on which other hypotheses are true or false. In many correlated settings, this holds or approximately holds, and the procedure performs well empirically. However, the assumption should be verified or at least acknowledged when applying the method.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Brief Note</p>
<p>Full treatment of multiple testing is beyond our scope. For applications with thousands of tests (genomics, neuroimaging), see Westfall &amp; Young (1993) and permutation-based FDR methods.</p>
</div>
</section>
</section>
<section id="practical-considerations">
<h2>Practical Considerations<a class="headerlink" href="#practical-considerations" title="Link to this heading"></a></h2>
<section id="choosing-b-monte-carlo-error">
<h3>Choosing B: Monte Carlo Error<a class="headerlink" href="#choosing-b-monte-carlo-error" title="Link to this heading"></a></h3>
<p>The bootstrap p-value is itself a Monte Carlo estimate with inherent variability. The <strong>Monte Carlo standard error</strong> of <span class="math notranslate nohighlight">\(\hat{p}\)</span> is approximately:</p>
<div class="math notranslate nohighlight" id="equation-mc-se">
<span class="eqno">(191)<a class="headerlink" href="#equation-mc-se" title="Link to this equation"></a></span>\[\text{SE}_{\text{MC}}(\hat{p}) \approx \sqrt{\frac{\hat{p}(1-\hat{p})}{B}}\]</div>
<p>This formula guides the choice of <span class="math notranslate nohighlight">\(B\)</span>:</p>
<table class="docutils align-default" id="id15">
<caption><span class="caption-number">Table 55 </span><span class="caption-text">Monte Carlo Error by B</span><a class="headerlink" href="#id15" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(B\)</span></p></th>
<th class="head"><p>SE at <span class="math notranslate nohighlight">\(p = 0.05\)</span></p></th>
<th class="head"><p>SE at <span class="math notranslate nohighlight">\(p = 0.01\)</span></p></th>
<th class="head"><p>Resolution</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>999</p></td>
<td><p>0.0069</p></td>
<td><p>0.0031</p></td>
<td><p>0.001</p></td>
</tr>
<tr class="row-odd"><td><p>4,999</p></td>
<td><p>0.0031</p></td>
<td><p>0.0014</p></td>
<td><p>0.0002</p></td>
</tr>
<tr class="row-even"><td><p>9,999</p></td>
<td><p>0.0022</p></td>
<td><p>0.0010</p></td>
<td><p>0.0001</p></td>
</tr>
<tr class="row-odd"><td><p>49,999</p></td>
<td><p>0.0010</p></td>
<td><p>0.0004</p></td>
<td><p>0.00002</p></td>
</tr>
</tbody>
</table>
<p><strong>Recommendations</strong>:</p>
<ul class="simple">
<li><p><strong>Exploratory analysis</strong>: <span class="math notranslate nohighlight">\(B = 999\)</span> is usually sufficient</p></li>
<li><p><strong>Publication</strong>: <span class="math notranslate nohighlight">\(B = 9999\)</span> or higher</p></li>
<li><p><strong>Critical decisions</strong>: <span class="math notranslate nohighlight">\(B = 49999\)</span> or more</p></li>
</ul>
<p>The <span class="math notranslate nohighlight">\(+1/(B+1)\)</span> formula ensures p-values are never exactly zero, with minimum value <span class="math notranslate nohighlight">\(1/(B+1)\)</span>.</p>
</section>
<section id="reporting-guidelines">
<h3>Reporting Guidelines<a class="headerlink" href="#reporting-guidelines" title="Link to this heading"></a></h3>
<p>A complete report of a resampling test should include:</p>
<ol class="arabic simple">
<li><p><strong>Null hypothesis</strong>: State <span class="math notranslate nohighlight">\(H_0\)</span> precisely</p></li>
<li><p><strong>Test statistic</strong>: Specify the statistic and whether studentized</p></li>
<li><p><strong>Resampling method</strong>: Permutation, centered bootstrap, wild bootstrap, etc.</p></li>
<li><p><strong>Number of replicates</strong>: <span class="math notranslate nohighlight">\(B\)</span></p></li>
<li><p><strong>p-value with precision</strong>: Report to appropriate digits (e.g., <span class="math notranslate nohighlight">\(p = 0.0342\)</span>)</p></li>
<li><p><strong>Monte Carlo SE</strong> (for borderline cases): <span class="math notranslate nohighlight">\(\pm\)</span> SE</p></li>
<li><p><strong>Visualization</strong>: Histogram of null distribution with <span class="math notranslate nohighlight">\(T_{\text{obs}}\)</span> marked</p></li>
<li><p><strong>Seed</strong> (for reproducibility): Random seed used</p></li>
</ol>
<p><strong>Example statement</strong>: “We tested <span class="math notranslate nohighlight">\(H_0: \mu_{\text{treatment}} = \mu_{\text{control}}\)</span> using a permutation test with the Welch t-statistic. Based on <span class="math notranslate nohighlight">\(B = 9999\)</span> random permutations, the two-sided p-value was 0.0234 (Monte Carlo SE: 0.0015). The observed t-statistic (2.31) fell in the upper 2.3% of the null distribution (seed: 42).”</p>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><strong>Not enforcing the null</strong>: The most common error in bootstrap testing is resampling from the original data without transformation. This tests whether <span class="math notranslate nohighlight">\(\hat{\theta}^* = \hat{\theta}\)</span> typically (which is always true), not whether the true effect is zero.</p>
<p><strong>Correct</strong>: Center data, fit restricted model, or transform to enforce <span class="math notranslate nohighlight">\(H_0\)</span></p>
<p><strong>Incorrect</strong>: Just resample from original data</p>
</div>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><strong>Using non-pivotal statistics when pivotal is available</strong>: Unstandardized statistics converge slower (<span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span> vs <span class="math notranslate nohighlight">\(O(n^{-1})\)</span>). Always studentize when a standard error formula exists.</p>
</div>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><strong>Permuting when not exchangeable</strong>: Permutation tests require exchangeability under <span class="math notranslate nohighlight">\(H_0\)</span>. Testing <span class="math notranslate nohighlight">\(\mu_X = \mu_Y\)</span> when variances differ, or testing regression coefficients, violates this assumption.</p>
</div>
</section>
</section>
<section id="bringing-it-all-together">
<h2>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<p>This section has developed two complementary frameworks for hypothesis testing via resampling. <strong>Permutation tests</strong> provide exact p-values when the null hypothesis implies exchangeability—the gold standard for randomized experiments and two-sample distribution comparisons. <strong>Bootstrap tests</strong> extend to scenarios where exchangeability fails: unequal variances, regression, complex statistics, and more.</p>
<p>The unifying principle is <strong>generating the null distribution</strong>: we ask “What would the test statistic look like if <span class="math notranslate nohighlight">\(H_0\)</span> were true?” For permutation tests, we permute labels because <span class="math notranslate nohighlight">\(H_0\)</span> makes them arbitrary. For bootstrap tests, we transform the data to enforce <span class="math notranslate nohighlight">\(H_0\)</span> and resample from the transformed data.</p>
<p>Key insights that improve test performance include:</p>
<ul class="simple">
<li><p><strong>Studentization</strong>: Using pivotal test statistics achieves faster convergence (<span class="math notranslate nohighlight">\(O(n^{-1})\)</span> vs <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span>)</p></li>
<li><p><strong>Null enforcement</strong>: Bootstrap tests must generate data consistent with <span class="math notranslate nohighlight">\(H_0\)</span>, not just resample from observed data</p></li>
<li><p><strong>Method matching</strong>: Choose permutation for exchangeable settings, bootstrap for non-exchangeable</p></li>
</ul>
<p>Looking forward, these ideas connect to:</p>
<ul class="simple">
<li><p><strong>Section 4.7</strong>: BCa intervals achieve the same <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> improvement through different means</p></li>
<li><p><strong>Section 4.8</strong>: Cross-validation for model selection (different from inference)</p></li>
<li><p><strong>Chapter 5</strong>: Bayesian hypothesis testing via posterior probabilities</p></li>
</ul>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>Core concept</strong>: Bootstrap hypothesis testing requires resampling <strong>under</strong> <span class="math notranslate nohighlight">\(H_0\)</span>—transform data to enforce the null before resampling. Permutation tests are exact when <span class="math notranslate nohighlight">\(H_0\)</span> implies exchangeability.</p></li>
<li><p><strong>Computational insight</strong>: Studentized test statistics achieve <span class="math notranslate nohighlight">\(O(n^{-1})\)</span> error vs <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span> for non-pivotal—always prefer studentized when SE is available.</p></li>
<li><p><strong>Practical application</strong>: Permutation for two-sample equal-distribution tests and randomized experiments; bootstrap for unequal variances, regression, and complex statistics. Wild bootstrap handles heteroscedasticity.</p></li>
<li><p><strong>Outcome alignment</strong>: LO1 (apply simulation techniques for hypothesis testing), LO2 (compare frequentist approaches—classical, permutation, bootstrap), LO3 (implement resampling for inference)</p></li>
</ol>
</div>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h2>
<div class="note admonition">
<p class="admonition-title">Exercise 4.6.1: Two-Sample Permutation Test Implementation</p>
<p>In this exercise, you will implement and analyze a two-sample permutation test.</p>
<ol class="loweralpha simple">
<li><p>Generate two samples: <span class="math notranslate nohighlight">\(X_1, \ldots, X_{25} \sim N(0, 1)\)</span> and <span class="math notranslate nohighlight">\(Y_1, \ldots, Y_{25} \sim N(0.5, 1)\)</span>. Implement a permutation test using the difference in means as the test statistic. Compute the p-value with <span class="math notranslate nohighlight">\(B = 9999\)</span> permutations.</p></li>
<li><p>Repeat part (a) using the Welch t-statistic instead of the difference in means. Compare the p-values.</p></li>
<li><p>Now generate samples with unequal variances: <span class="math notranslate nohighlight">\(X \sim N(0, 1)\)</span> and <span class="math notranslate nohighlight">\(Y \sim N(0.5, 3)\)</span>. Run both the difference-in-means and Welch-t permutation tests. Which is more appropriate?</p></li>
<li><p>Conduct a simulation study: Under <span class="math notranslate nohighlight">\(H_0: \mu_X = \mu_Y = 0\)</span> with <span class="math notranslate nohighlight">\(\sigma_X = 1, \sigma_Y = 3\)</span>, generate 1000 pairs of samples (each <span class="math notranslate nohighlight">\(n = 25\)</span>). For each, compute permutation p-values using both statistics. What proportion of p-values fall below 0.05 for each method? What does this tell you about Type I error control?</p></li>
<li><p>Repeat the simulation under <span class="math notranslate nohighlight">\(H_1: \mu_Y = 0.5\)</span> to estimate power. Which test statistic is more powerful?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Difference in means</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_x</span><span class="p">,</span> <span class="n">n_y</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">25</span>

<span class="c1"># Generate samples</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>

<span class="c1"># Permutation test with difference in means</span>
<span class="n">pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
<span class="n">t_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">B</span> <span class="o">=</span> <span class="mi">9999</span>
<span class="n">t_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled</span><span class="p">)</span>
    <span class="n">t_perm</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="n">n_x</span><span class="p">])</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perm</span><span class="p">[</span><span class="n">n_x</span><span class="p">:])</span>

<span class="n">p_value_diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Observed difference: </span><span class="si">{</span><span class="n">t_obs</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P-value (diff in means): </span><span class="si">{</span><span class="n">p_value_diff</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Output:</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Observed difference: -0.4268
P-value (diff in means): 0.0844
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Welch t-statistic</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">welch_t</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">):</span>
    <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">g1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">g2</span><span class="p">)</span>
    <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">g2</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v1</span><span class="o">/</span><span class="n">n1</span> <span class="o">+</span> <span class="n">v2</span><span class="o">/</span><span class="n">n2</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">g1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">g2</span><span class="p">))</span> <span class="o">/</span> <span class="n">se</span> <span class="k">if</span> <span class="n">se</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

<span class="n">t_obs_welch</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">t_perm_welch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled</span><span class="p">)</span>
    <span class="n">t_perm_welch</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="n">n_x</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">n_x</span><span class="p">:])</span>

<span class="n">p_value_welch</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm_welch</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs_welch</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Observed Welch t: </span><span class="si">{</span><span class="n">t_obs_welch</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P-value (Welch t): </span><span class="si">{</span><span class="n">p_value_welch</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Output:</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Observed Welch t: -1.5139
P-value (Welch t): 0.1290
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): Unequal variances</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Unequal variance samples</span>
<span class="n">x_uneq</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_x</span><span class="p">)</span>
<span class="n">y_uneq</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>

<span class="n">pooled_uneq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x_uneq</span><span class="p">,</span> <span class="n">y_uneq</span><span class="p">])</span>

<span class="c1"># Difference in means - MUST permute once per replicate</span>
<span class="n">t_obs_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x_uneq</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_uneq</span><span class="p">)</span>
<span class="n">t_perm_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled_uneq</span><span class="p">)</span>
    <span class="n">t_perm_diff</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="n">n_x</span><span class="p">])</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perm</span><span class="p">[</span><span class="n">n_x</span><span class="p">:])</span>
<span class="n">p_diff_uneq</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm_diff</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs_diff</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Welch t - MUST permute once per replicate</span>
<span class="n">t_obs_welch_uneq</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">x_uneq</span><span class="p">,</span> <span class="n">y_uneq</span><span class="p">)</span>
<span class="n">t_perm_welch_uneq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled_uneq</span><span class="p">)</span>
    <span class="n">t_perm_welch_uneq</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="n">n_x</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">n_x</span><span class="p">:])</span>
<span class="n">p_welch_uneq</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm_welch_uneq</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs_welch_uneq</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unequal variances:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  P-value (diff): </span><span class="si">{</span><span class="n">p_diff_uneq</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  P-value (Welch): </span><span class="si">{</span><span class="n">p_welch_uneq</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text">The Welch t-statistic is more appropriate because it accounts for unequal variances, making it more robust when homoscedasticity is violated.</p>
<p class="sd-card-text"><strong>Part (d): Type I error simulation</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n_sim</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">p_values_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_sim</span><span class="p">)</span>
<span class="n">p_values_welch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_sim</span><span class="p">)</span>

<span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sim</span><span class="p">):</span>
    <span class="c1"># Under H0: same mean, different variances</span>
    <span class="n">x_sim</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_x</span><span class="p">)</span>
    <span class="n">y_sim</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>  <span class="c1"># Same mean, different variance</span>
    <span class="n">pooled_sim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x_sim</span><span class="p">,</span> <span class="n">y_sim</span><span class="p">])</span>

    <span class="n">t_obs_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x_sim</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_sim</span><span class="p">)</span>
    <span class="n">t_obs_w</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">x_sim</span><span class="p">,</span> <span class="n">y_sim</span><span class="p">)</span>

    <span class="c1"># Quick permutation (B=499 for speed)</span>
    <span class="n">t_perm_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">499</span><span class="p">)</span>
    <span class="n">t_perm_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">499</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">499</span><span class="p">):</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled_sim</span><span class="p">)</span>
        <span class="n">t_perm_d</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="n">n_x</span><span class="p">])</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perm</span><span class="p">[</span><span class="n">n_x</span><span class="p">:])</span>
        <span class="n">t_perm_w</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="n">n_x</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">n_x</span><span class="p">:])</span>

    <span class="n">p_values_diff</span><span class="p">[</span><span class="n">sim</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm_d</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs_d</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">500</span>
    <span class="n">p_values_welch</span><span class="p">[</span><span class="n">sim</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm_w</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs_w</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">500</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Type I error rate (at α = 0.05):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Difference in means: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">p_values_diff</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">0.05</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Welch t: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">p_values_welch</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">0.05</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Output:</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Type I error rate (at α = 0.05):
  Difference in means: 0.0760
  Welch t: 0.0510
</pre></div>
</div>
<p class="sd-card-text">The difference-in-means test is anti-conservative (inflated Type I error) under heteroscedasticity, while the Welch t maintains approximately correct size.</p>
</div>
</details></div>
<div class="note admonition">
<p class="admonition-title">Exercise 4.6.2: Permutation Test for Correlation</p>
<p>This exercise explores permutation hypothesis testing for correlation coefficients. <strong>Note</strong>: Permuting one variable to break dependence is a <strong>permutation/randomization test</strong> under <span class="math notranslate nohighlight">\(H_0: \rho = 0\)</span>, not a bootstrap test. Under independence, (X, Y) pairs are exchangeable with (X, permuted Y).</p>
<ol class="loweralpha simple">
<li><p>Generate <span class="math notranslate nohighlight">\(n = 40\)</span> bivariate observations from a standard bivariate normal with <span class="math notranslate nohighlight">\(\rho = 0.3\)</span>. Test <span class="math notranslate nohighlight">\(H_0: \rho = 0\)</span> using a permutation test with the sample correlation <span class="math notranslate nohighlight">\(r\)</span> as test statistic. Null enforcement is achieved by permuting one variable (which breaks the dependence).</p></li>
<li><p>Compare the permutation p-value to Fisher’s exact test (via the <span class="math notranslate nohighlight">\(z\)</span>-transformation <span class="math notranslate nohighlight">\(z = \tanh^{-1}(r)\)</span>).</p></li>
<li><p>Now generate data with <span class="math notranslate nohighlight">\(\rho = 0.85\)</span> and repeat the test. How do the p-values compare? What challenges arise when testing correlation near boundary values?</p></li>
<li><p>Implement a permutation test using the studentized Fisher z-transform: <span class="math notranslate nohighlight">\(T = \sqrt{n-3} \cdot \tanh^{-1}(r)\)</span>. Compare power and calibration to the unstudentized version.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Permutation test for correlation (randomization test under independence)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">40</span>

<span class="c1"># Generate bivariate normal with rho = 0.3</span>
<span class="n">rho</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="n">rho</span><span class="p">],</span> <span class="p">[</span><span class="n">rho</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Observed correlation</span>
<span class="n">r_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Permutation test: permute y to break dependence (enforces rho = 0)</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">9999</span>
<span class="n">r_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">y_perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">r_perm</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_perm</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">p_value_perm</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">r_perm</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">r_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Observed r: </span><span class="si">{</span><span class="n">r_obs</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Permutation p-value: </span><span class="si">{</span><span class="n">p_value_perm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Output:</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Observed r: 0.3425
Permutation p-value: 0.0301
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Comparison to Fisher’s test</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fisher z-transformation</span>
<span class="n">z_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctanh</span><span class="p">(</span><span class="n">r_obs</span><span class="p">)</span>
<span class="n">se_z</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">z_statistic</span> <span class="o">=</span> <span class="n">z_obs</span> <span class="o">/</span> <span class="n">se_z</span>

<span class="c1"># Two-sided p-value from normal distribution</span>
<span class="n">p_fisher</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_statistic</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fisher z-statistic: </span><span class="si">{</span><span class="n">z_statistic</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fisher p-value: </span><span class="si">{</span><span class="n">p_fisher</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bootstrap p-value: </span><span class="si">{</span><span class="n">p_value_boot</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Output:</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Fisher z-statistic: 2.1723
Fisher p-value: 0.0298
Bootstrap p-value: 0.0301
</pre></div>
</div>
<p class="sd-card-text">The bootstrap and Fisher tests agree closely for moderate correlation.</p>
<p class="sd-card-text"><strong>Part (c): High correlation (near boundary)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate with high correlation</span>
<span class="n">rho_high</span> <span class="o">=</span> <span class="mf">0.85</span>
<span class="n">cov_high</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="n">rho_high</span><span class="p">],</span> <span class="p">[</span><span class="n">rho_high</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">data_high</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov_high</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">x_h</span><span class="p">,</span> <span class="n">y_h</span> <span class="o">=</span> <span class="n">data_high</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data_high</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">r_obs_high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x_h</span><span class="p">,</span> <span class="n">y_h</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Permutation test</span>
<span class="n">r_perm_high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">r_perm_high</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x_h</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">y_h</span><span class="p">))[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">p_boot_high</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">r_perm_high</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">r_obs_high</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Fisher test</span>
<span class="n">z_high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctanh</span><span class="p">(</span><span class="n">r_obs_high</span><span class="p">)</span>
<span class="n">p_fisher_high</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_high</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">High correlation (ρ = 0.85):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Observed r: </span><span class="si">{</span><span class="n">r_obs_high</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Bootstrap p-value: </span><span class="si">{</span><span class="n">p_boot_high</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Fisher p-value: </span><span class="si">{</span><span class="n">p_fisher_high</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text">Near the boundary (<span class="math notranslate nohighlight">\(|r| \to 1\)</span>), the distribution of <span class="math notranslate nohighlight">\(r\)</span> becomes highly skewed. Fisher’s z-transformation helps stabilize this, making the Fisher test more reliable. The bootstrap captures the skewness directly but may have higher variance.</p>
<p class="sd-card-text"><strong>Part (d): Studentized test</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Studentized Fisher z bootstrap</span>
<span class="n">z_obs_stud</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctanh</span><span class="p">(</span><span class="n">r_obs</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">z_perm_stud</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">r_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">y</span><span class="p">))[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="c1"># Clip to avoid infinite z at boundaries</span>
    <span class="n">r_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">r_b</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.999</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
    <span class="n">z_perm_stud</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctanh</span><span class="p">(</span><span class="n">r_b</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">p_stud</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_perm_stud</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_obs_stud</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Studentized z test:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  z-statistic: </span><span class="si">{</span><span class="n">z_obs_stud</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  P-value: </span><span class="si">{</span><span class="n">p_stud</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text">The studentized version achieves better asymptotic properties (<span class="math notranslate nohighlight">\(O(n^{-1})\)</span> error) and is generally preferred.</p>
</div>
</details></div>
<div class="note admonition">
<p class="admonition-title">Exercise 4.6.3: Null-Enforced Bootstrap for Regression</p>
<p>This exercise develops skills in null-enforced bootstrap testing for regression.</p>
<ol class="loweralpha simple">
<li><p>Generate data from the model <span class="math notranslate nohighlight">\(Y_i = 2 + 3X_{1i} + 0 \cdot X_{2i} + \varepsilon_i\)</span> where <span class="math notranslate nohighlight">\(X_1, X_2 \sim N(0, 1)\)</span> and <span class="math notranslate nohighlight">\(\varepsilon \sim N(0, 2)\)</span>. Note that <span class="math notranslate nohighlight">\(\beta_2 = 0\)</span> (null is true). With <span class="math notranslate nohighlight">\(n = 50\)</span>, implement the null-enforced residual bootstrap to test <span class="math notranslate nohighlight">\(H_0: \beta_2 = 0\)</span>.</p></li>
<li><p>Introduce heteroscedasticity: <span class="math notranslate nohighlight">\(\varepsilon_i \sim N(0, 0.5 + 0.5|X_{1i}|)\)</span>. Repeat the test using both standard residual bootstrap and wild bootstrap. Which maintains correct size?</p></li>
<li><p>Now set <span class="math notranslate nohighlight">\(\beta_2 = 0.8\)</span> (alternative is true) and estimate power for both methods under heteroscedasticity.</p></li>
<li><p>Extend to test a joint hypothesis <span class="math notranslate nohighlight">\(H_0: \beta_2 = \beta_3 = 0\)</span> using an F-statistic and the null-enforced bootstrap.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Null-enforced bootstrap test</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Generate data (beta_2 = 0, null is TRUE)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">X1</span> <span class="o">+</span> <span class="mi">0</span><span class="o">*</span><span class="n">X2</span> <span class="o">+</span> <span class="n">epsilon</span>

<span class="c1"># Design matrix with intercept</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">])</span>

<span class="c1"># Full model fit</span>
<span class="n">beta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">resid_full</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_hat</span>
<span class="n">mse_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">resid_full</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">XtX_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span>
<span class="n">se_beta2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_full</span> <span class="o">*</span> <span class="n">XtX_inv</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">t_obs</span> <span class="o">=</span> <span class="n">beta_hat</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">se_beta2</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Coefficient estimates: </span><span class="si">{</span><span class="n">beta_hat</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Observed t for β₂: </span><span class="si">{</span><span class="n">t_obs</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Restricted model (excluding X2)</span>
<span class="n">X_restricted</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># Intercept and X1 only</span>
<span class="n">beta_restricted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X_restricted</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y_hat_restricted</span> <span class="o">=</span> <span class="n">X_restricted</span> <span class="o">@</span> <span class="n">beta_restricted</span>
<span class="n">resid_restricted</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">y_hat_restricted</span>
<span class="n">resid_centered</span> <span class="o">=</span> <span class="n">resid_restricted</span> <span class="o">-</span> <span class="n">resid_restricted</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Bootstrap under H0</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">4999</span>
<span class="n">t_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>

<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">resid_star</span> <span class="o">=</span> <span class="n">resid_centered</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">Y_star</span> <span class="o">=</span> <span class="n">y_hat_restricted</span> <span class="o">+</span> <span class="n">resid_star</span>

    <span class="n">beta_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y_star</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">resid_star_full</span> <span class="o">=</span> <span class="n">Y_star</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_star</span>
    <span class="n">mse_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">resid_star_full</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">se_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_star</span> <span class="o">*</span> <span class="n">XtX_inv</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">t_boot</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta_star</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">se_star</span> <span class="k">if</span> <span class="n">se_star</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

<span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_boot</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Classical t-test</span>
<span class="n">p_classical</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">),</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">3</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bootstrap p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Classical p-value: </span><span class="si">{</span><span class="n">p_classical</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Output:</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Coefficient estimates: [ 2.0523  3.0126 -0.0847]
Observed t for β₂: -0.1864

Bootstrap p-value: 0.8544
Classical p-value: 0.8530
</pre></div>
</div>
<p class="sd-card-text">Since <span class="math notranslate nohighlight">\(\beta_2 = 0\)</span> is true, we correctly fail to reject.</p>
<p class="sd-card-text"><strong>Part (b): Heteroscedasticity comparison</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate heteroscedastic data</span>
<span class="n">X1_het</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">X2_het</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">sigma_het</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X1_het</span><span class="p">)</span>
<span class="n">epsilon_het</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma_het</span>
<span class="n">Y_het</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">X1_het</span> <span class="o">+</span> <span class="mi">0</span><span class="o">*</span><span class="n">X2_het</span> <span class="o">+</span> <span class="n">epsilon_het</span>

<span class="n">X_het</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">X1_het</span><span class="p">,</span> <span class="n">X2_het</span><span class="p">])</span>

<span class="c1"># Full model</span>
<span class="n">beta_hat_het</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X_het</span><span class="p">,</span> <span class="n">Y_het</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">resid_het</span> <span class="o">=</span> <span class="n">Y_het</span> <span class="o">-</span> <span class="n">X_het</span> <span class="o">@</span> <span class="n">beta_hat_het</span>
<span class="n">mse_het</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">resid_het</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">XtX_inv_het</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X_het</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X_het</span><span class="p">)</span>
<span class="n">se_het</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_het</span> <span class="o">*</span> <span class="n">XtX_inv_het</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">t_obs_het</span> <span class="o">=</span> <span class="n">beta_hat_het</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">se_het</span>

<span class="c1"># Restricted model</span>
<span class="n">X_rest_het</span> <span class="o">=</span> <span class="n">X_het</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">beta_rest_het</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X_rest_het</span><span class="p">,</span> <span class="n">Y_het</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y_hat_rest</span> <span class="o">=</span> <span class="n">X_rest_het</span> <span class="o">@</span> <span class="n">beta_rest_het</span>
<span class="n">resid_rest</span> <span class="o">=</span> <span class="n">Y_het</span> <span class="o">-</span> <span class="n">y_hat_rest</span>

<span class="c1"># Standard residual bootstrap</span>
<span class="n">t_boot_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">resid_cent</span> <span class="o">=</span> <span class="n">resid_rest</span> <span class="o">-</span> <span class="n">resid_rest</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">Y_star</span> <span class="o">=</span> <span class="n">y_hat_rest</span> <span class="o">+</span> <span class="n">resid_cent</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">beta_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X_het</span><span class="p">,</span> <span class="n">Y_star</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">resid_star</span> <span class="o">=</span> <span class="n">Y_star</span> <span class="o">-</span> <span class="n">X_het</span> <span class="o">@</span> <span class="n">beta_star</span>
    <span class="n">mse_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">resid_star</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">se_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_star</span> <span class="o">*</span> <span class="n">XtX_inv_het</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">t_boot_std</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta_star</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">se_star</span> <span class="k">if</span> <span class="n">se_star</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

<span class="n">p_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_boot_std</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs_het</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Wild bootstrap</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">X_het</span> <span class="o">@</span> <span class="n">XtX_inv_het</span> <span class="o">@</span> <span class="n">X_het</span><span class="o">.</span><span class="n">T</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
<span class="n">resid_scaled</span> <span class="o">=</span> <span class="n">resid_rest</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">))</span>

<span class="n">t_boot_wild</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">Y_star</span> <span class="o">=</span> <span class="n">y_hat_rest</span> <span class="o">+</span> <span class="n">resid_scaled</span> <span class="o">*</span> <span class="n">v</span>
    <span class="n">beta_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X_het</span><span class="p">,</span> <span class="n">Y_star</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">resid_star</span> <span class="o">=</span> <span class="n">Y_star</span> <span class="o">-</span> <span class="n">X_het</span> <span class="o">@</span> <span class="n">beta_star</span>
    <span class="n">resid_star_sc</span> <span class="o">=</span> <span class="n">resid_star</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">))</span>
    <span class="n">var_star</span> <span class="o">=</span> <span class="n">XtX_inv_het</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">resid_star_sc</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">X_het</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">se_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_star</span><span class="p">)</span>
    <span class="n">t_boot_wild</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">beta_star</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">beta_hat_het</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">/</span> <span class="n">se_star</span> <span class="k">if</span> <span class="n">se_star</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

<span class="n">p_wild</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_boot_wild</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs_het</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Under heteroscedasticity:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Standard bootstrap p-value: </span><span class="si">{</span><span class="n">p_std</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Wild bootstrap p-value: </span><span class="si">{</span><span class="n">p_wild</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text">The wild bootstrap maintains correct size under heteroscedasticity, while the standard residual bootstrap may not.</p>
</div>
</details></div>
<div class="note admonition">
<p class="admonition-title">Exercise 4.6.4: Kolmogorov-Smirnov Permutation Test</p>
<p>This exercise explores permutation tests for distributional equality.</p>
<ol class="loweralpha simple">
<li><p>Generate <span class="math notranslate nohighlight">\(X_1, \ldots, X_{30} \sim N(0, 1)\)</span> and <span class="math notranslate nohighlight">\(Y_1, \ldots, Y_{30} \sim N(0.5, 1)\)</span>. Implement the two-sample Kolmogorov-Smirnov test via permutation and compare to the classical KS test.</p></li>
<li><p>Generate samples with the same mean but different variances: <span class="math notranslate nohighlight">\(X \sim N(0, 1)\)</span>, <span class="math notranslate nohighlight">\(Y \sim N(0, 2)\)</span>. Apply both the permutation t-test (for means) and the KS permutation test (for distributions). Which detects the difference?</p></li>
<li><p>Generate samples from different distribution families with matched mean and variance: <span class="math notranslate nohighlight">\(X \sim N(0, 1)\)</span> and <span class="math notranslate nohighlight">\(Y \sim t_5 \cdot \sqrt{3/5}\)</span> (t-distribution scaled to have variance 1). Can the KS test detect the difference?</p></li>
<li><p>Compute the power of the KS permutation test for detecting a location shift of <span class="math notranslate nohighlight">\(\delta = 0.5\)</span> as a function of sample size <span class="math notranslate nohighlight">\(n \in \{20, 40, 60, 80, 100\}\)</span>.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): KS permutation test</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Generate samples with different means</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="c1"># KS statistic</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ks_stat</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">ks_2samp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">statistic</span>

<span class="n">D_obs</span> <span class="o">=</span> <span class="n">ks_stat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Permutation test</span>
<span class="n">pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
<span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">9999</span>

<span class="n">D_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled</span><span class="p">)</span>
    <span class="n">D_perm</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">ks_stat</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="n">m</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="n">m</span><span class="p">:])</span>

<span class="n">p_perm</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">D_perm</span> <span class="o">&gt;=</span> <span class="n">D_obs</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Classical KS</span>
<span class="n">_</span><span class="p">,</span> <span class="n">p_classical</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ks_2samp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;KS statistic: </span><span class="si">{</span><span class="n">D_obs</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Permutation p-value: </span><span class="si">{</span><span class="n">p_perm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Classical p-value: </span><span class="si">{</span><span class="n">p_classical</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Output:</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>KS statistic: 0.2333
Permutation p-value: 0.1893
Classical p-value: 0.1886
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Same mean, different variance</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Same mean, different variance</span>
<span class="n">x_var</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">y_var</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="n">pooled_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x_var</span><span class="p">,</span> <span class="n">y_var</span><span class="p">])</span>

<span class="c1"># Permutation t-test</span>
<span class="k">def</span><span class="w"> </span><span class="nf">welch_t</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">b</span><span class="p">))</span> <span class="o">/</span> <span class="n">se</span> <span class="k">if</span> <span class="n">se</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

<span class="n">t_obs_var</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">x_var</span><span class="p">,</span> <span class="n">y_var</span><span class="p">)</span>
<span class="n">t_perm_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled_var</span><span class="p">)</span>
    <span class="n">t_perm_var</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="mi">30</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="mi">30</span><span class="p">:])</span>
<span class="n">p_t</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm_var</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs_var</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># KS test</span>
<span class="n">D_obs_var</span> <span class="o">=</span> <span class="n">ks_stat</span><span class="p">(</span><span class="n">x_var</span><span class="p">,</span> <span class="n">y_var</span><span class="p">)</span>
<span class="n">D_perm_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled_var</span><span class="p">)</span>
    <span class="n">D_perm_var</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">ks_stat</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="mi">30</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="mi">30</span><span class="p">:])</span>
<span class="n">p_ks</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">D_perm_var</span> <span class="o">&gt;=</span> <span class="n">D_obs_var</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Same mean, different variance:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Permutation t-test p-value: </span><span class="si">{</span><span class="n">p_t</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  KS permutation p-value: </span><span class="si">{</span><span class="n">p_ks</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text">The t-test fails to detect the difference (same means), but KS may detect it (different distributions).</p>
<p class="sd-card-text"><strong>Part (c): Different families, matched moments</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Normal vs scaled t</span>
<span class="n">x_normal</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">y_t</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_t</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="o">/</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># Scaled to variance 1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Normal vs t(5) (matched variance):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  X mean: </span><span class="si">{</span><span class="n">x_normal</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, var: </span><span class="si">{</span><span class="n">x_normal</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Y mean: </span><span class="si">{</span><span class="n">y_t</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, var: </span><span class="si">{</span><span class="n">y_t</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">pooled_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x_normal</span><span class="p">,</span> <span class="n">y_t</span><span class="p">])</span>
<span class="n">D_obs_t</span> <span class="o">=</span> <span class="n">ks_stat</span><span class="p">(</span><span class="n">x_normal</span><span class="p">,</span> <span class="n">y_t</span><span class="p">)</span>
<span class="n">D_perm_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled_t</span><span class="p">)</span>
    <span class="n">D_perm_t</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">ks_stat</span><span class="p">(</span><span class="n">perm</span><span class="p">[:</span><span class="mi">50</span><span class="p">],</span> <span class="n">perm</span><span class="p">[</span><span class="mi">50</span><span class="p">:])</span>
<span class="n">p_ks_t</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">D_perm_t</span> <span class="o">&gt;=</span> <span class="n">D_obs_t</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  KS p-value: </span><span class="si">{</span><span class="n">p_ks_t</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text">The KS test can detect shape differences even when means and variances match.</p>
</div>
</details></div>
<div class="note admonition">
<p class="admonition-title">Exercise 4.6.5: Comparing Bootstrap and Classical Tests</p>
<p>This exercise systematically compares bootstrap, permutation, and classical tests.</p>
<ol class="loweralpha simple">
<li><p>Under <span class="math notranslate nohighlight">\(H_0\)</span>: Generate 1000 simulated datasets with <span class="math notranslate nohighlight">\(X, Y \sim N(0, 1)\)</span>, each with <span class="math notranslate nohighlight">\(n_x = n_y = 20\)</span>. For each, compute three p-values: (i) classical Welch t-test, (ii) permutation test with Welch t, (iii) bootstrap test with centering. Compare the Type I error rates at <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>.</p></li>
<li><p>Repeat part (a) with non-normal data: <span class="math notranslate nohighlight">\(X, Y \sim \text{Exp}(1) - 1\)</span> (centered exponential). How do the Type I error rates change?</p></li>
<li><p>Under <span class="math notranslate nohighlight">\(H_1\)</span>: With <span class="math notranslate nohighlight">\(\mu_X = 0, \mu_Y = 0.5\)</span>, estimate power for each method using the same simulation framework.</p></li>
<li><p>Investigate the effect of sample size asymmetry: <span class="math notranslate nohighlight">\(n_x = 10, n_y = 40\)</span>. Which methods are affected?</p></li>
<li><p>Create a summary table showing Type I error and power for each combination of (method, distribution, sample size balance).</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Normal data, balanced samples</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n_sim</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_x</span><span class="p">,</span> <span class="n">n_y</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">499</span>  <span class="c1"># Fewer for speed in simulation</span>

<span class="k">def</span><span class="w"> </span><span class="nf">welch_t</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">b</span><span class="p">))</span> <span class="o">/</span> <span class="n">se</span> <span class="k">if</span> <span class="n">se</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;classical&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;permutation&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sim</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_x</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>

    <span class="c1"># Classical Welch</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">p_classical</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;classical&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_classical</span><span class="p">)</span>

    <span class="c1"># Permutation</span>
    <span class="n">pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
    <span class="n">t_obs</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">t_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">welch_t</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled</span><span class="p">)[:</span><span class="n">n_x</span><span class="p">],</span>
                                <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled</span><span class="p">)[</span><span class="n">n_x</span><span class="p">:])</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">)])</span>
    <span class="n">p_perm</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;permutation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_perm</span><span class="p">)</span>

    <span class="c1"># Bootstrap with centering</span>
    <span class="n">pooled_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pooled</span><span class="p">)</span>
    <span class="n">x_cent</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">pooled_mean</span>
    <span class="n">y_cent</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">pooled_mean</span>
    <span class="n">t_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">x_star</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">x_cent</span><span class="p">,</span> <span class="n">n_x</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">y_star</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">y_cent</span><span class="p">,</span> <span class="n">n_y</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">t_boot</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">x_star</span><span class="p">,</span> <span class="n">y_star</span><span class="p">)</span>
    <span class="n">p_boot</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_boot</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;bootstrap&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_boot</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Type I error rates (α = 0.05), Normal data:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;classical&#39;</span><span class="p">,</span> <span class="s1">&#39;permutation&#39;</span><span class="p">,</span> <span class="s1">&#39;bootstrap&#39;</span><span class="p">]:</span>
    <span class="n">rate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="n">method</span><span class="p">])</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Output:</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Type I error rates (α = 0.05), Normal data:
  classical: 0.0500
  permutation: 0.0480
  bootstrap: 0.0470
</pre></div>
</div>
<p class="sd-card-text">All methods maintain approximately correct size under normality.</p>
<p class="sd-card-text"><strong>Part (b): Exponential data</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">results_exp</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;classical&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;permutation&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">sim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sim</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_x</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># Centered exponential</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># Classical Welch</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">p_classical</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">results_exp</span><span class="p">[</span><span class="s1">&#39;classical&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_classical</span><span class="p">)</span>

    <span class="c1"># Permutation</span>
    <span class="n">pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
    <span class="n">t_obs</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">t_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">welch_t</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled</span><span class="p">)[:</span><span class="n">n_x</span><span class="p">],</span>
                                <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">pooled</span><span class="p">)[</span><span class="n">n_x</span><span class="p">:])</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">)])</span>
    <span class="n">p_perm</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_perm</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">results_exp</span><span class="p">[</span><span class="s1">&#39;permutation&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_perm</span><span class="p">)</span>

    <span class="c1"># Bootstrap</span>
    <span class="n">pooled_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pooled</span><span class="p">)</span>
    <span class="n">x_cent</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">pooled_mean</span>
    <span class="n">y_cent</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">pooled_mean</span>
    <span class="n">t_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">x_star</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">x_cent</span><span class="p">,</span> <span class="n">n_x</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">y_star</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">y_cent</span><span class="p">,</span> <span class="n">n_y</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">t_boot</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">welch_t</span><span class="p">(</span><span class="n">x_star</span><span class="p">,</span> <span class="n">y_star</span><span class="p">)</span>
    <span class="n">p_boot</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_boot</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_obs</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">results_exp</span><span class="p">[</span><span class="s1">&#39;bootstrap&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_boot</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Type I error rates (α = 0.05), Exponential data:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;classical&#39;</span><span class="p">,</span> <span class="s1">&#39;permutation&#39;</span><span class="p">,</span> <span class="s1">&#39;bootstrap&#39;</span><span class="p">]:</span>
    <span class="n">rate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results_exp</span><span class="p">[</span><span class="n">method</span><span class="p">])</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text">For skewed data, resampling methods often maintain better size control than classical tests with small samples.</p>
</div>
</details></div>
<div class="note admonition">
<p class="admonition-title">Exercise 4.6.6: GLM Parametric Bootstrap Test (Advanced)</p>
<p>This exercise applies parametric bootstrap testing to generalized linear models.</p>
<ol class="loweralpha simple">
<li><p>Generate logistic regression data: <span class="math notranslate nohighlight">\(n = 150\)</span>, <span class="math notranslate nohighlight">\(X_1 \sim N(0, 1)\)</span>, <span class="math notranslate nohighlight">\(X_2 \sim N(0, 1)\)</span>, with true model <span class="math notranslate nohighlight">\(\text{logit}(p) = -0.5 + 0.8X_1 + 0X_2\)</span>. Fit the model and test <span class="math notranslate nohighlight">\(H_0: \beta_2 = 0\)</span> using three approaches: (i) Wald test, (ii) likelihood ratio test, and (iii) parametric bootstrap.</p></li>
<li><p>Compare the three p-values. When might they differ substantially?</p></li>
<li><p>Generate data with separation risk: <span class="math notranslate nohighlight">\(n = 50\)</span>, strong effect <span class="math notranslate nohighlight">\(\beta_1 = 3\)</span>. How do the tests behave? Which is most reliable?</p></li>
<li><p>Extend to Poisson regression: Generate count data with <span class="math notranslate nohighlight">\(\log(\mu) = 1 + 0.5X_1\)</span> and test <span class="math notranslate nohighlight">\(H_0: \beta_1 = 0\)</span>. Compare Wald, LRT, and parametric bootstrap p-values.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Logistic regression tests</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">150</span>

<span class="c1"># Generate data (beta_2 = 0, null is TRUE)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">eta</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">+</span> <span class="mf">0.8</span><span class="o">*</span><span class="n">X1</span> <span class="o">+</span> <span class="mi">0</span><span class="o">*</span><span class="n">X2</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">eta</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">])</span>

<span class="c1"># Fit full model</span>
<span class="n">model_full</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Binomial</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Full model coefficients:&quot;</span><span class="p">,</span> <span class="n">model_full</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Wald z for β₂: </span><span class="si">{</span><span class="n">model_full</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Wald test</span>
<span class="n">p_wald</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">model_full</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="mi">2</span><span class="p">])))</span>

<span class="c1"># LRT</span>
<span class="n">model_restricted</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Binomial</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">model_full</span><span class="o">.</span><span class="n">llf</span> <span class="o">-</span> <span class="n">model_restricted</span><span class="o">.</span><span class="n">llf</span><span class="p">)</span>
<span class="n">p_lrt</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">LR</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Parametric bootstrap</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">999</span>
<span class="n">z_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">mu_restricted</span> <span class="o">=</span> <span class="n">model_restricted</span><span class="o">.</span><span class="n">predict</span><span class="p">()</span>

<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">y_star</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">mu_restricted</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">model_star</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y_star</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Binomial</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">z_boot</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_star</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">z_boot</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">p_boot</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_boot</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">model_full</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">P-values for H₀: β₂ = 0:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Wald test: </span><span class="si">{</span><span class="n">p_wald</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  LRT: </span><span class="si">{</span><span class="n">p_lrt</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Parametric bootstrap: </span><span class="si">{</span><span class="n">p_boot</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Output:</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Full model coefficients: [-0.5883  0.8472 -0.1036]
Wald z for β₂: -0.4849

P-values for H₀: β₂ = 0:
  Wald test: 0.6278
  LRT: 0.6273
  Parametric bootstrap: 0.6340
</pre></div>
</div>
<p class="sd-card-text">All tests agree when <span class="math notranslate nohighlight">\(\beta_2 = 0\)</span> is true and data are well-behaved.</p>
<p class="sd-card-text"><strong>Part (b): When tests differ</strong></p>
<p class="sd-card-text">Tests can differ when:
- Sample size is small
- Data exhibit near-separation
- The model is misspecified
- Effects are near boundaries of parameter space</p>
<p class="sd-card-text"><strong>Part (c): Separation risk</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Small sample, strong effect</span>
<span class="n">n_small</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">X1_sep</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_small</span><span class="p">)</span>
<span class="n">X2_sep</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_small</span><span class="p">)</span>
<span class="n">eta_sep</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">X1_sep</span>  <span class="c1"># Strong effect</span>
<span class="n">p_sep</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">eta_sep</span><span class="p">))</span>
<span class="n">y_sep</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">p_sep</span><span class="p">)</span>

<span class="n">X_sep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_small</span><span class="p">),</span> <span class="n">X1_sep</span><span class="p">,</span> <span class="n">X2_sep</span><span class="p">])</span>

<span class="c1"># Test β₂ = 0</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">model_sep</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y_sep</span><span class="p">,</span> <span class="n">X_sep</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Binomial</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">model_rest</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y_sep</span><span class="p">,</span> <span class="n">X_sep</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Binomial</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

    <span class="n">p_wald_sep</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">model_sep</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="mi">2</span><span class="p">])))</span>
    <span class="n">LR_sep</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">model_sep</span><span class="o">.</span><span class="n">llf</span> <span class="o">-</span> <span class="n">model_rest</span><span class="o">.</span><span class="n">llf</span><span class="p">)</span>
    <span class="n">p_lrt_sep</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">LR_sep</span><span class="p">),</span> <span class="n">df</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Parametric bootstrap</span>
    <span class="n">mu_rest</span> <span class="o">=</span> <span class="n">model_rest</span><span class="o">.</span><span class="n">predict</span><span class="p">()</span>
    <span class="n">z_boot_sep</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
        <span class="n">y_star</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">mu_rest</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">model_star</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y_star</span><span class="p">,</span> <span class="n">X_sep</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Binomial</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
            <span class="n">z_boot_sep</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_star</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">z_boot_sep</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">p_boot_sep</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z_boot_sep</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">model_sep</span><span class="o">.</span><span class="n">tvalues</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z_boot_sep</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">p_boot_sep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Separation risk scenario (n=</span><span class="si">{</span><span class="n">n_small</span><span class="si">}</span><span class="s2">):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Wald p-value: </span><span class="si">{</span><span class="n">p_wald_sep</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  LRT p-value: </span><span class="si">{</span><span class="n">p_lrt_sep</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Bootstrap p-value: </span><span class="si">{</span><span class="n">p_boot_sep</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Convergence issues: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sd-card-text">In separation scenarios, Wald tests can be unreliable; LRT and bootstrap are generally more robust.</p>
</div>
</details></div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading"></a></h2>
<p><strong>Foundational Texts</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="efrontibshirani1993" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>EfronTibshirani1993<span class="fn-bracket">]</span></span>
<p>Efron, B., and Tibshirani, R. J. (1993). <em>An Introduction to the Bootstrap</em>. Chapman &amp; Hall/CRC Monographs on Statistics and Applied Probability. Chapters 15–16 provide comprehensive treatment of bootstrap hypothesis testing.</p>
</div>
<div class="citation" id="davisonhinkley1997" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DavisonHinkley1997<span class="fn-bracket">]</span></span>
<p>Davison, A. C., and Hinkley, D. V. (1997). <em>Bootstrap Methods and Their Application</em>. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press. Chapter 4 covers testing and significance.</p>
</div>
<div class="citation" id="good2005" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Good2005<span class="fn-bracket">]</span></span>
<p>Good, P. (2005). <em>Permutation, Parametric, and Bootstrap Tests of Hypotheses</em>. 3rd ed. Springer Series in Statistics. Springer. Comprehensive treatment of resampling-based testing.</p>
</div>
</div>
<p><strong>Theoretical Foundations</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="hall1992" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Hall1992<span class="fn-bracket">]</span></span>
<p>Hall, P. (1992). <em>The Bootstrap and Edgeworth Expansion</em>. Springer Series in Statistics. Springer. Establishes the theoretical basis for asymptotic refinement in bootstrap tests.</p>
</div>
<div class="citation" id="phipsonsmyth2010" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>PhipsonSmyth2010<span class="fn-bracket">]</span></span>
<p>Phipson, B., and Smyth, G. K. (2010). Permutation p-values should never be zero: Calculating exact p-values when permutations are randomly drawn. <em>Statistical Applications in Genetics and Molecular Biology</em>, 9(1), Article 39. Establishes the “+1” formula for valid p-values.</p>
</div>
<div class="citation" id="westfallyoung1993" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>WestfallYoung1993<span class="fn-bracket">]</span></span>
<p>Westfall, P. H., and Young, S. S. (1993). <em>Resampling-Based Multiple Testing: Examples and Methods for p-Value Adjustment</em>. Wiley Series in Probability and Statistics. Wiley. Definitive reference for multiple testing with resampling.</p>
</div>
</div>
<p><strong>Regression and GLM Methods</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="freedmanlane1983" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>FreedmanLane1983<span class="fn-bracket">]</span></span>
<p>Freedman, D., and Lane, D. (1983). A nonstochastic interpretation of reported significance levels. <em>Journal of Business and Economic Statistics</em>, 1(4), 292–298. Develops residual permutation for regression.</p>
</div>
<div class="citation" id="wu1986" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Wu1986<span class="fn-bracket">]</span></span>
<p>Wu, C. F. J. (1986). Jackknife, bootstrap and other resampling methods in regression analysis. <em>Annals of Statistics</em>, 14(4), 1261–1295. Foundational treatment of bootstrap for regression.</p>
</div>
<div class="citation" id="mammen1993" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Mammen1993<span class="fn-bracket">]</span></span>
<p>Mammen, E. (1993). Bootstrap and wild bootstrap for high dimensional linear models. <em>Annals of Statistics</em>, 21(1), 255–285. Theoretical foundations for wild bootstrap.</p>
</div>
</div>
<p><strong>Distribution Testing</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="romano1990" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Romano1990<span class="fn-bracket">]</span></span>
<p>Romano, J. P. (1990). On the behavior of randomization tests without a group invariance assumption. <em>Journal of the American Statistical Association</em>, 85(411), 686–692. Conditions for permutation test validity.</p>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ch4_5-jackknife-methods.html" class="btn btn-neutral float-left" title="Section 4.5: Jackknife Methods" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ch4_7-bootstrap-confidence-intervals.html" class="btn btn-neutral float-right" title="Section 4.7 Bootstrap Confidence Intervals: Advanced Methods" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>