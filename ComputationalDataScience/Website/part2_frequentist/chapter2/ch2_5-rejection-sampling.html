

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Section 2.5 Rejection Sampling &mdash; STAT 418</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=3d0abd52" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT418/Website/part2_frequentist/chapter2/ch2_5-rejection-sampling.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Show solution';</script>
      <script>let toggleHintHide = 'Hide solution';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=8718e0ab"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Variance Reduction Methods" href="ch2_6-variance-reduction-methods.html" />
    <link rel="prev" title="Section 2.4 Transformation Methods" href="ch2_4-transformation-methods.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Course Content</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../part1_foundations/index.html">Part I: Foundations of Probability and Computation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part1_foundations/chapter1/index.html">Chapter 1: Statistical Paradigms and Core Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html">Section 1.1 Paradigms of Probability and Statistical Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#the-mathematical-foundation-kolmogorov-s-axioms">The Mathematical Foundation: Kolmogorov’s Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#interpretations-of-probability">Interpretations of Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#statistical-inference-paradigms">Statistical Inference Paradigms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#historical-and-philosophical-debates">Historical and Philosophical Debates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#looking-ahead-our-course-focus">Looking Ahead: Our Course Focus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_1-probability-and-inference-paradigms.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html">Section 1.2 Probability Distributions: Theory and Computation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#from-abstract-foundations-to-concrete-tools">From Abstract Foundations to Concrete Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#the-python-ecosystem-for-probability">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#introduction-why-probability-distributions-matter">Introduction: Why Probability Distributions Matter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#id1">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#continuous-distributions">Continuous Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#additional-important-distributions">Additional Important Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#summary-and-practical-guidelines">Summary and Practical Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#conclusion">Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_2-probability_distributions_review.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html">Section 1.3 Python Random Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#from-mathematical-distributions-to-computational-samples">From Mathematical Distributions to Computational Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#the-python-ecosystem-at-a-glance">The Python Ecosystem at a Glance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#understanding-pseudo-random-number-generation">Understanding Pseudo-Random Number Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#the-standard-library-random-module">The Standard Library: <code class="docutils literal notranslate"><span class="pre">random</span></code> Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#numpy-fast-vectorized-random-sampling">NumPy: Fast Vectorized Random Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#scipy-stats-the-complete-statistical-toolkit">SciPy Stats: The Complete Statistical Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#bringing-it-all-together-library-selection-guide">Bringing It All Together: Library Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#looking-ahead-from-random-numbers-to-monte-carlo-methods">Looking Ahead: From Random Numbers to Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_3-python_random_generation.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html">Section 1.4 Chapter 1 Summary: Foundations in Place</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#the-three-pillars-of-chapter-1">The Three Pillars of Chapter 1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#what-lies-ahead-the-road-to-simulation">What Lies Ahead: The Road to Simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#chapter-1-exercises-synthesis-problems">Chapter 1 Exercises: Synthesis Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1_4-chapter-summary.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Part II: Frequentist Inference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Chapter 2: Monte Carlo Simulation</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html">Section 2.1 Monte Carlo Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#the-historical-development-of-monte-carlo-methods">The Historical Development of Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#the-core-principle-expectation-as-integration">The Core Principle: Expectation as Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#theoretical-foundations">Theoretical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#variance-estimation-and-confidence-intervals">Variance Estimation and Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#comparison-with-deterministic-methods">Comparison with Deterministic Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#sample-size-determination">Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#convergence-diagnostics-and-monitoring">Convergence Diagnostics and Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#chapter-2-1-exercises-monte-carlo-fundamentals-mastery">Chapter 2.1 Exercises: Monte Carlo Fundamentals Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#id1">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2_2-uniform-random-variates.html">Section 2.2 Uniform Random Variates</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#why-uniform-the-universal-currency-of-randomness">Why Uniform? The Universal Currency of Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#the-paradox-of-computational-randomness">The Paradox of Computational Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#chaotic-dynamical-systems-an-instructive-failure">Chaotic Dynamical Systems: An Instructive Failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#linear-congruential-generators">Linear Congruential Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#shift-register-generators">Shift-Register Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#the-kiss-generator-combining-strategies">The KISS Generator: Combining Strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#modern-generators-mersenne-twister-and-pcg">Modern Generators: Mersenne Twister and PCG</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#statistical-testing-of-random-number-generators">Statistical Testing of Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#chapter-2-2-exercises-uniform-random-variates-mastery">Chapter 2.2 Exercises: Uniform Random Variates Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2_3-inverse-cdf-method.html">Section 2.3 Inverse CDF Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#mathematical-foundations">Mathematical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#continuous-distributions-with-closed-form-inverses">Continuous Distributions with Closed-Form Inverses</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#numerical-inversion">Numerical Inversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#mixed-distributions">Mixed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#chapter-2-3-exercises-inverse-cdf-method-mastery">Chapter 2.3 Exercises: Inverse CDF Method Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#id1">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2_4-transformation-methods.html">Section 2.4 Transformation Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#why-transformation-methods">Why Transformation Methods?</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#the-boxmuller-transform">The Box–Muller Transform</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#the-polar-marsaglia-method">The Polar (Marsaglia) Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#method-comparison-boxmuller-vs-polar-vs-ziggurat">Method Comparison: Box–Muller vs Polar vs Ziggurat</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#the-ziggurat-algorithm">The Ziggurat Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#the-clt-approximation-historical">The CLT Approximation (Historical)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#distributions-derived-from-the-normal">Distributions Derived from the Normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#multivariate-normal-generation">Multivariate Normal Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#implementation-guidance">Implementation Guidance</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#chapter-2-4-exercises-transformation-methods-mastery">Chapter 2.4 Exercises: Transformation Methods Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Section 2.5 Rejection Sampling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#the-dartboard-intuition">The Dartboard Intuition</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-accept-reject-algorithm">The Accept-Reject Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="#efficiency-analysis">Efficiency Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#choosing-the-proposal-distribution">Choosing the Proposal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-squeeze-principle">The Squeeze Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="#geometric-example-sampling-from-the-unit-disk">Geometric Example: Sampling from the Unit Disk</a></li>
<li class="toctree-l4"><a class="reference internal" href="#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="#limitations-and-the-curse-of-dimensionality">Limitations and the Curse of Dimensionality</a></li>
<li class="toctree-l4"><a class="reference internal" href="#connections-to-other-methods">Connections to Other Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#chapter-2-5-exercises-rejection-sampling-mastery">Chapter 2.5 Exercises: Rejection Sampling Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2_6-variance-reduction-methods.html">Variance Reduction Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#the-variance-reduction-paradigm">The Variance Reduction Paradigm</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#importance-sampling">Importance Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#control-variates">Control Variates</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#antithetic-variates">Antithetic Variates</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#stratified-sampling">Stratified Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#common-random-numbers">Common Random Numbers</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#conditional-monte-carlo-raoblackwellization">Conditional Monte Carlo (Rao–Blackwellization)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#combining-variance-reduction-techniques">Combining Variance Reduction Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#chapter-2-6-exercises-variance-reduction-mastery">Chapter 2.6 Exercises: Variance Reduction Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_6-variance-reduction-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2_7-chapter-summary.html">Chapter Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2_7-chapter-summary.html#the-complete-monte-carlo-workflow">The Complete Monte Carlo Workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_7-chapter-summary.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_7-chapter-summary.html#quick-reference-tables">Quick Reference Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_7-chapter-summary.html#common-pitfalls-checklist">Common Pitfalls Checklist</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_7-chapter-summary.html#connections-to-later-chapters">Connections to Later Chapters</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_7-chapter-summary.html#learning-outcomes-checklist">Learning Outcomes Checklist</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_7-chapter-summary.html#further-reading-optimization-and-missing-data">Further Reading: Optimization and Missing Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_7-chapter-summary.html#final-perspective">Final Perspective</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_7-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../chapter3/index.html">Chapter 3: Parametric Inference and Likelihood Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html">Exponential Families</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#historical-origins-from-scattered-results-to-unified-theory">Historical Origins: From Scattered Results to Unified Theory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#the-canonical-exponential-family">The Canonical Exponential Family</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#converting-familiar-distributions">Converting Familiar Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#the-log-partition-function-a-moment-generating-machine">The Log-Partition Function: A Moment-Generating Machine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#sufficiency-capturing-all-parameter-information">Sufficiency: Capturing All Parameter Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#minimal-sufficiency-and-completeness">Minimal Sufficiency and Completeness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#conjugate-priors-and-bayesian-inference">Conjugate Priors and Bayesian Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#exponential-dispersion-models-and-glms">Exponential Dispersion Models and GLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#chapter-3-1-exercises-exponential-families-mastery">Chapter 3.1 Exercises: Exponential Families Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_1-exponential-families.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html">Maximum Likelihood Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-likelihood-function">The Likelihood Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-score-function">The Score Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#fisher-information">Fisher Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#closed-form-maximum-likelihood-estimators">Closed-Form Maximum Likelihood Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#numerical-optimization-for-mle">Numerical Optimization for MLE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#asymptotic-properties-of-mles">Asymptotic Properties of MLEs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-cramer-rao-lower-bound">The Cramér-Rao Lower Bound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#the-invariance-property">The Invariance Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#likelihood-based-hypothesis-testing">Likelihood-Based Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#confidence-intervals-from-likelihood">Confidence Intervals from Likelihood</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#connection-to-bayesian-inference">Connection to Bayesian Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#chapter-3-2-exercises-maximum-likelihood-estimation-mastery">Chapter 3.2 Exercises: Maximum Likelihood Estimation Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_2-maximum-likelihood-estimation.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html">Sampling Variability and Variance Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#statistical-estimators-and-their-properties">Statistical Estimators and Their Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#sampling-distributions">Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#the-delta-method">The Delta Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#the-plug-in-principle">The Plug-in Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#variance-estimation-methods">Variance Estimation Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#applications-and-worked-examples">Applications and Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_3-sampling-variability.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html">Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#matrix-calculus-foundations">Matrix Calculus Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#the-linear-model">The Linear Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#ordinary-least-squares-the-calculus-approach">Ordinary Least Squares: The Calculus Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#ordinary-least-squares-the-geometric-approach">Ordinary Least Squares: The Geometric Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#properties-of-the-ols-estimator">Properties of the OLS Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#the-gauss-markov-theorem">The Gauss-Markov Theorem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#estimating-the-error-variance">Estimating the Error Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#distributional-results-under-normality">Distributional Results Under Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#diagnostics-and-model-checking">Diagnostics and Model Checking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#numerical-stability-qr-decomposition">Numerical Stability: QR Decomposition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#model-selection-and-information-criteria">Model Selection and Information Criteria</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#regularization-ridge-and-lasso">Regularization: Ridge and LASSO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#chapter-3-4-exercises-linear-models-mastery">Chapter 3.4 Exercises: Linear Models Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_4-linear-models.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html">Generalized Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#historical-context-unification-of-regression-methods">Historical Context: Unification of Regression Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#the-glm-framework-three-components">The GLM Framework: Three Components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#score-equations-and-fisher-information">Score Equations and Fisher Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#iteratively-reweighted-least-squares">Iteratively Reweighted Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#logistic-regression-binary-outcomes">Logistic Regression: Binary Outcomes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#poisson-regression-count-data">Poisson Regression: Count Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#gamma-regression-positive-continuous-data">Gamma Regression: Positive Continuous Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#inference-in-glms-the-testing-triad">Inference in GLMs: The Testing Triad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#model-diagnostics">Model Diagnostics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#model-comparison-and-selection">Model Comparison and Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#quasi-likelihood-and-robust-inference">Quasi-Likelihood and Robust Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#further-reading">Further Reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#chapter-3-5-exercises-generalized-linear-models-mastery">Chapter 3.5 Exercises: Generalized Linear Models Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_5-generalized-linear-models.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html">Chapter Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#the-parametric-inference-pipeline">The Parametric Inference Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#the-five-pillars-of-chapter-3">The Five Pillars of Chapter 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#quick-reference-core-formulas">Quick Reference: Core Formulas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#connections-to-future-material">Connections to Future Material</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#practical-guidance">Practical Guidance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#final-perspective">Final Perspective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/ch3_6-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../chapter4/index.html">Chapter 4: Resampling Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html">The Sampling Distribution Problem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html#the-fundamental-target-sampling-distributions">The Fundamental Target: Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html#historical-development-the-quest-for-sampling-distributions">Historical Development: The Quest for Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html#three-routes-to-the-sampling-distribution">Three Routes to the Sampling Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html#when-asymptotics-fail-motivating-the-bootstrap">When Asymptotics Fail: Motivating the Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html#the-plug-in-principle-theoretical-foundation">The Plug-In Principle: Theoretical Foundation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html#computational-perspective-bootstrap-as-monte-carlo">Computational Perspective: Bootstrap as Monte Carlo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html#chapter-4-1-exercises">Chapter 4.1 Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_1-sampling-distribution-problem.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html">The Empirical Distribution and Plug-in Principle</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html#the-empirical-cumulative-distribution-function">The Empirical Cumulative Distribution Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html#convergence-of-the-empirical-cdf">Convergence of the Empirical CDF</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html#parameters-as-statistical-functionals">Parameters as Statistical Functionals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html#the-plug-in-principle">The Plug-in Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html#when-the-plug-in-principle-fails">When the Plug-in Principle Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html#the-bootstrap-idea-in-one-sentence">The Bootstrap Idea in One Sentence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html#computational-implementation">Computational Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html#section-4-2-exercises-ecdf-and-plug-in-mastery">Section 4.2 Exercises: ECDF and Plug-in Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_2-empirical-distribution-plugin.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html">The Nonparametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#the-bootstrap-principle">The Bootstrap Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-standard-errors">Bootstrap Standard Errors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-bias-estimation">Bootstrap Bias Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-confidence-intervals">Bootstrap Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-for-regression">Bootstrap for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-diagnostics">Bootstrap Diagnostics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#when-bootstrap-fails">When Bootstrap Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_3-nonparametric-bootstrap.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html">Section 4.4: The Parametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html#the-parametric-bootstrap-principle">The Parametric Bootstrap Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html#location-scale-families">Location-Scale Families</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html#parametric-bootstrap-for-regression">Parametric Bootstrap for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html#confidence-intervals">Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html#model-checking-and-validation">Model Checking and Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html#when-parametric-bootstrap-fails">When Parametric Bootstrap Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html#parametric-vs-nonparametric-a-decision-framework">Parametric vs. Nonparametric: A Decision Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_4-parametric-bootstrap.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html">Section 4.5: Jackknife Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html#historical-context-and-motivation">Historical Context and Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html#the-delete-1-jackknife">The Delete-1 Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html#jackknife-bias-estimation">Jackknife Bias Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html#the-delete-d-jackknife">The Delete-<span class="math notranslate nohighlight">\(d\)</span> Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html#jackknife-versus-bootstrap">Jackknife versus Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html#the-infinitesimal-jackknife">The Infinitesimal Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_5-jackknife-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html">Section 4.6 Bootstrap Hypothesis Testing and Permutation Tests</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#from-confidence-intervals-to-hypothesis-tests">From Confidence Intervals to Hypothesis Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#the-bootstrap-hypothesis-testing-framework">The Bootstrap Hypothesis Testing Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#permutation-tests-exact-tests-under-exchangeability">Permutation Tests: Exact Tests Under Exchangeability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#testing-equality-of-distributions">Testing Equality of Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#bootstrap-tests-for-regression">Bootstrap Tests for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#bootstrap-vs-classical-tests">Bootstrap vs Classical Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#permutation-vs-bootstrap-choosing-the-right-approach">Permutation vs Bootstrap: Choosing the Right Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#multiple-testing-with-bootstrap">Multiple Testing with Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/ch4_6-bootstrap-hypothesis-testing.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part3_bayesian/index.html">Part III: Bayesian Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part3_bayesian/chapter5/index.html">Chapter 5: Bayesian Inference</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part4_llms_datascience/index.html">Part IV: Large Language Models in Data Science</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part4_llms_datascience/chapter6/index.html">Chapter 6: LLMs in Data Science Workflows</a><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Part II: Frequentist Inference</a></li>
          <li class="breadcrumb-item"><a href="index.html">Chapter 2: Monte Carlo Simulation</a></li>
      <li class="breadcrumb-item active">Section 2.5 Rejection Sampling</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/part2_frequentist/chapter2/ch2_5-rejection-sampling.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="section-2-5-rejection-sampling">
<span id="ch2-5-rejection-sampling"></span><h1>Section 2.5 Rejection Sampling<a class="headerlink" href="#section-2-5-rejection-sampling" title="Link to this heading"></a></h1>
<p>The transformation methods of <a class="reference internal" href="ch2_4-transformation-methods.html#ch2-4-transformation-methods"><span class="std std-ref">Section 2.4 Transformation Methods</span></a> exploit mathematical structure: Box–Muller converts uniforms to normals through polar coordinates; chi-squared emerges as a sum of squared normals; the t-distribution arises from a carefully constructed ratio. These methods are elegant and efficient—when they exist. But what happens when we need samples from a distribution with no known transformation from simple variates?</p>
<p>Consider the Beta distribution with general parameters <span class="math notranslate nohighlight">\(\alpha, \beta\)</span>. No closed-form inverse CDF exists, and there is no simple transformation from uniforms or normals (except for special cases like <span class="math notranslate nohighlight">\(\text{Beta}(1,1) = \text{Uniform}(0,1)\)</span>). What about a posterior distribution in Bayesian inference, known only up to a normalizing constant? Or a custom density defined by a complex formula arising from domain expertise?</p>
<p><strong>Rejection sampling</strong> (also called the accept-reject method) provides a universal solution. The idea, formalized by John von Neumann in 1951 <a class="reference internal" href="#vonneumann1951" id="id1"><span>[vonNeumann1951]</span></a>, is surprisingly intuitive: if we can envelope the target density with a scaled version of a simpler “proposal” density, we can generate candidates from the proposal and probabilistically accept or reject them. The accepted samples follow exactly the target distribution—no approximation, no asymptotic convergence, just exact sampling.</p>
<p>Von Neumann’s contribution was to generalize and formalize the intuition of random sampling into a systematic method for arbitrary distributions, making it foundational to computational statistics. For a comprehensive modern treatment, see Devroye <a class="reference internal" href="#devroye1986" id="id2"><span>[Devroye1986]</span></a>, which remains the definitive reference on random variate generation.</p>
<p>The method’s power lies in its generality: rejection sampling works for <em>any</em> target density we can evaluate pointwise, even if the normalization constant is unknown. This makes it indispensable for Bayesian computation, where posterior densities are typically known only up to proportionality. The cost is efficiency—when the envelope fits poorly, we reject many candidates before accepting one.</p>
<p>This section develops rejection sampling from first principles. We begin with geometric intuition via the “dartboard” interpretation, then formalize the algorithm and prove its correctness. We analyze efficiency through acceptance rates and explore strategies for choosing good proposal distributions. Worked examples demonstrate the method for Beta distributions, truncated normals, and custom densities. We conclude by examining the method’s limitations in high dimensions, setting the stage for the Markov Chain Monte Carlo methods of later chapters.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p><strong>Understand</strong>: The geometric intuition behind rejection sampling—points uniformly distributed under a curve</p></li>
<li><p><strong>Prove</strong>: Why accepted samples follow the target distribution, even with unknown normalization</p></li>
<li><p><strong>Analyze</strong>: Acceptance probability as <span class="math notranslate nohighlight">\(1/M\)</span> (normalized) or <span class="math notranslate nohighlight">\(C/M\)</span> (unnormalized)</p></li>
<li><p><strong>Design</strong>: Strategies for choosing proposal distributions and computing the envelope constant</p></li>
<li><p><strong>Implement</strong>: Efficient rejection samplers in Python with proper numerical safeguards</p></li>
<li><p><strong>Recognize</strong>: When rejection sampling fails and alternatives are needed</p></li>
</ul>
</div>
<section id="the-dartboard-intuition">
<h2>The Dartboard Intuition<a class="headerlink" href="#the-dartboard-intuition" title="Link to this heading"></a></h2>
<p>Before diving into formulas, let’s build geometric intuition for why rejection sampling works.</p>
<section id="the-fundamental-theorem-of-simulation">
<h3>The Fundamental Theorem of Simulation<a class="headerlink" href="#the-fundamental-theorem-of-simulation" title="Link to this heading"></a></h3>
<p>The theoretical foundation rests on a beautiful identity. For any <strong>normalized</strong> probability density <span class="math notranslate nohighlight">\(f(x)\)</span>:</p>
<div class="math notranslate nohighlight">
\[f(x) = \int_0^{f(x)} du\]</div>
<p>This seemingly trivial observation has profound implications: the density <span class="math notranslate nohighlight">\(f(x)\)</span> is the marginal of a uniform distribution over the region under its curve. Formally:</p>
<div class="math notranslate nohighlight">
\[(X, U) \sim \text{Uniform}\{(x, u) : 0 &lt; u &lt; f(x)\} \quad \Longrightarrow \quad X \sim f\]</div>
<p><strong>Key insight</strong>: If we can sample uniformly from the region under a density curve, the <span class="math notranslate nohighlight">\(x\)</span>-coordinates follow that density exactly. Rejection sampling operationalizes this observation.</p>
<p><strong>Normalization caveat</strong>: This result requires <span class="math notranslate nohighlight">\(f\)</span> to be a proper density (integrating to 1). If <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> is an <strong>unnormalized</strong> kernel with <span class="math notranslate nohighlight">\(C = \int \tilde{f}(x)\,dx\)</span>, then the region <span class="math notranslate nohighlight">\(\{(x, u) : 0 &lt; u &lt; \tilde{f}(x)\}\)</span> has area <span class="math notranslate nohighlight">\(C\)</span>, and uniform sampling over this region yields <span class="math notranslate nohighlight">\(x\)</span>-coordinates distributed as <span class="math notranslate nohighlight">\(\tilde{f}(x)/C\)</span>—the normalized version. This is precisely why rejection sampling works for unnormalized targets.</p>
</section>
<section id="points-under-a-curve">
<h3>Points Under a Curve<a class="headerlink" href="#points-under-a-curve" title="Link to this heading"></a></h3>
<p>Imagine plotting the probability density function <span class="math notranslate nohighlight">\(f(x)\)</span> of our target distribution on a coordinate plane. The area under this curve equals 1 (for a proper density). Now suppose we could somehow generate points <span class="math notranslate nohighlight">\((x, y)\)</span> uniformly distributed over the region under the curve—that is, uniformly over the set <span class="math notranslate nohighlight">\(\{(x, y) : 0 \le y \le f(x)\}\)</span>.</p>
<p>What distribution would the <span class="math notranslate nohighlight">\(x\)</span>-coordinates of these points follow?</p>
<p>The answer is <span class="math notranslate nohighlight">\(f(x)\)</span> itself. To see why, consider any interval <span class="math notranslate nohighlight">\([a, b]\)</span>. The probability that a uniformly distributed point has <span class="math notranslate nohighlight">\(x \in [a, b]\)</span> is proportional to the area of the region under <span class="math notranslate nohighlight">\(f(x)\)</span> between <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>—which is exactly <span class="math notranslate nohighlight">\(\int_a^b f(x)\,dx\)</span>. This matches the definition of drawing from <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>This observation suggests a sampling strategy: if we can generate points uniformly under <span class="math notranslate nohighlight">\(f(x)\)</span>, we can extract their <span class="math notranslate nohighlight">\(x\)</span>-coordinates as samples from <span class="math notranslate nohighlight">\(f\)</span>. But generating uniform points under an arbitrary curve is itself a non-trivial problem. Rejection sampling solves this by embedding the target region inside a larger, simpler region.</p>
</section>
<section id="the-envelope-strategy">
<h3>The Envelope Strategy<a class="headerlink" href="#the-envelope-strategy" title="Link to this heading"></a></h3>
<p>Suppose we have a <strong>proposal density</strong> <span class="math notranslate nohighlight">\(g(x)\)</span> from which we can easily sample (e.g., uniform, normal, exponential). We require that <span class="math notranslate nohighlight">\(g(x) &gt; 0\)</span> wherever <span class="math notranslate nohighlight">\(f(x) &gt; 0\)</span>—the proposal must “cover” the target. Furthermore, suppose we can find a constant <span class="math notranslate nohighlight">\(M \ge 1\)</span> such that:</p>
<div class="math notranslate nohighlight">
\[\tilde{f}(x) \le M \cdot g(x) \quad \text{for all } x\]</div>
<p>The function <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span> is called an <strong>envelope</strong> or <strong>hat function</strong> because it lies above <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> everywhere. The region under <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> is contained within the region under <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span>.</p>
<p><strong>Important</strong>: We sample from <span class="math notranslate nohighlight">\(g(x)\)</span>, not <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span>. The envelope <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span> is not a proper density (it integrates to <span class="math notranslate nohighlight">\(M\)</span>, not 1). It defines the geometric region for acceptance, but the proposal distribution <span class="math notranslate nohighlight">\(g(x)\)</span> is what we actually draw from.</p>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_5_fig01_envelope_concept.png"><img alt="Target density f(x) enclosed by envelope Mg(x), with accepted region shaded" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_5_fig01_envelope_concept.png" style="width: 85%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 65 </span><span class="caption-text"><strong>The Envelope Concept.</strong> The target density <span class="math notranslate nohighlight">\(f(x)\)</span> (blue, shown here as a <em>normalized</em> density) is everywhere dominated by the envelope <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span> (red dashed). Points uniformly distributed under the envelope will, when filtered to those under <span class="math notranslate nohighlight">\(f(x)\)</span>, yield <span class="math notranslate nohighlight">\(x\)</span>-coordinates distributed according to <span class="math notranslate nohighlight">\(f\)</span>. For this normalized case, the acceptance rate is <span class="math notranslate nohighlight">\(1/M\)</span>.</span><a class="headerlink" href="#id6" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Now here’s the key insight. We can easily generate points uniformly under <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span>:</p>
<ol class="arabic simple">
<li><p>Sample <span class="math notranslate nohighlight">\(X \sim g(x)\)</span> (a draw from the proposal distribution)</p></li>
<li><p>Sample <span class="math notranslate nohighlight">\(Y \sim \text{Uniform}(0, M \cdot g(X))\)</span> (a height uniformly distributed up to the envelope)</p></li>
</ol>
<p>The pair <span class="math notranslate nohighlight">\((X, Y)\)</span> is uniformly distributed over the region under <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span>. If we now keep only those points with <span class="math notranslate nohighlight">\(Y \le \tilde{f}(X)\)</span>—those falling under the target density—the remaining points are uniformly distributed under <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span>, and their <span class="math notranslate nohighlight">\(x\)</span>-coordinates follow <span class="math notranslate nohighlight">\(\tilde{f}/C\)</span>.</p>
</section>
</section>
<section id="the-accept-reject-algorithm">
<h2>The Accept-Reject Algorithm<a class="headerlink" href="#the-accept-reject-algorithm" title="Link to this heading"></a></h2>
<p>We now formalize the geometric intuition into a precise algorithm.</p>
<section id="algorithm-statement">
<h3>Algorithm Statement<a class="headerlink" href="#algorithm-statement" title="Link to this heading"></a></h3>
<dl class="simple">
<dt>Given:</dt><dd><ul class="simple">
<li><p>Target density <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span>, possibly known only up to a normalizing constant</p></li>
<li><p>Proposal density <span class="math notranslate nohighlight">\(g(x)\)</span> from which we can sample directly</p></li>
<li><p>Envelope constant <span class="math notranslate nohighlight">\(M\)</span> such that <span class="math notranslate nohighlight">\(\tilde{f}(x) \le M \cdot g(x)\)</span> for all <span class="math notranslate nohighlight">\(x\)</span></p></li>
</ul>
</dd>
</dl>
<p><strong>Algorithm (Accept-Reject Method)</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>To generate one sample from f(x) = tilde{f}(x) / C:

1. REPEAT:
   a. Draw X ~ g(x)                              [sample from proposal]
   b. Draw U ~ Uniform(0, 1)                     [independent uniform]
   c. Compute acceptance ratio:
      α(X) = tilde{f}(X) / [M · g(X)]
   d. IF U ≤ α(X):
      ACCEPT X and RETURN X
      ELSE:
      REJECT X and continue to next iteration

2. The returned X is an exact draw from f(x) = tilde{f}(x) / C
</pre></div>
</div>
<p>The key observation is that we don’t actually need to generate <span class="math notranslate nohighlight">\(Y = U \cdot M \cdot g(X)\)</span> explicitly. The condition <span class="math notranslate nohighlight">\(Y \le \tilde{f}(X)\)</span> is equivalent to <span class="math notranslate nohighlight">\(U \cdot M \cdot g(X) \le \tilde{f}(X)\)</span>, which simplifies to <span class="math notranslate nohighlight">\(U \le \tilde{f}(X) / [M \cdot g(X)] = \alpha(X)\)</span>.</p>
</section>
<section id="proof-of-correctness">
<h3>Proof of Correctness<a class="headerlink" href="#proof-of-correctness" title="Link to this heading"></a></h3>
<p>We now prove that accepted samples follow the target distribution <span class="math notranslate nohighlight">\(f(x) = \tilde{f}(x)/C\)</span>.</p>
<p><strong>Theorem (Correctness of Accept-Reject).</strong> Let <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> be a non-negative measurable function with <span class="math notranslate nohighlight">\(0 &lt; C = \int \tilde{f}(x)\,dx &lt; \infty\)</span>, and let <span class="math notranslate nohighlight">\(g(x)\)</span> be a probability density with <span class="math notranslate nohighlight">\(g(x) &gt; 0\)</span> wherever <span class="math notranslate nohighlight">\(\tilde{f}(x) &gt; 0\)</span>. If <span class="math notranslate nohighlight">\(\tilde{f}(x) \le M \cdot g(x)\)</span> for all <span class="math notranslate nohighlight">\(x\)</span>, then the accepted value <span class="math notranslate nohighlight">\(X\)</span> from the accept-reject algorithm has density <span class="math notranslate nohighlight">\(f(x) = \tilde{f}(x)/C\)</span>.</p>
<p><strong>Proof.</strong> Consider a single iteration. We generate <span class="math notranslate nohighlight">\(X \sim g(x)\)</span> and, independently, <span class="math notranslate nohighlight">\(U \sim \text{Uniform}(0,1)\)</span>. We accept if <span class="math notranslate nohighlight">\(U \le \tilde{f}(X)/[M \cdot g(X)]\)</span>.</p>
<p>For any measurable set <span class="math notranslate nohighlight">\(A\)</span>, by independence of <span class="math notranslate nohighlight">\(U\)</span> and <span class="math notranslate nohighlight">\(X\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(X \in A \text{ and accepted}) &amp;= \int_A P\left(U \le \frac{\tilde{f}(x)}{M g(x)} \,\Big|\, X = x\right) g(x)\,dx \\
&amp;= \int_A \frac{\tilde{f}(x)}{M g(x)} \cdot g(x)\,dx \\
&amp;= \frac{1}{M} \int_A \tilde{f}(x)\,dx\end{split}\]</div>
<p>The overall probability of acceptance is:</p>
<div class="math notranslate nohighlight">
\[P(\text{accepted}) = \frac{1}{M} \int_{-\infty}^{\infty} \tilde{f}(x)\,dx = \frac{C}{M}\]</div>
<p>By Bayes’ theorem:</p>
<div class="math notranslate nohighlight">
\[P(X \in A \mid \text{accepted}) = \frac{P(X \in A \text{ and accepted})}{P(\text{accepted})} = \frac{\frac{1}{M}\int_A \tilde{f}(x)\,dx}{\frac{C}{M}} = \frac{\int_A \tilde{f}(x)\,dx}{C}\]</div>
<p>This is exactly the probability that a random variable with density <span class="math notranslate nohighlight">\(f(x) = \tilde{f}(x)/C\)</span> lies in <span class="math notranslate nohighlight">\(A\)</span>. ∎</p>
<p><strong>Key insight</strong>: The normalization constant <span class="math notranslate nohighlight">\(C\)</span> cancels in the acceptance ratio. We never need to compute <span class="math notranslate nohighlight">\(\int \tilde{f}(x)\,dx\)</span>—rejection sampling works even when <span class="math notranslate nohighlight">\(\tilde{f}\)</span> is known only up to proportionality.</p>
<div class="note admonition">
<p class="admonition-title">Notation Convention</p>
<p>Throughout this section, we use:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span>: unnormalized target (kernel), known up to proportionality</p></li>
<li><p><span class="math notranslate nohighlight">\(C = \int \tilde{f}(x)\,dx\)</span>: normalizing constant (often unknown)</p></li>
<li><p><span class="math notranslate nohighlight">\(f(x) = \tilde{f}(x)/C\)</span>: normalized density</p></li>
</ul>
<p>The envelope condition is <span class="math notranslate nohighlight">\(\tilde{f}(x) \le M \cdot g(x)\)</span> for all <span class="math notranslate nohighlight">\(x\)</span>. The algorithm uses only <span class="math notranslate nohighlight">\(\tilde{f}\)</span>, never requiring <span class="math notranslate nohighlight">\(C\)</span>.</p>
</div>
<div class="note admonition">
<p class="admonition-title">Parameterization Convention</p>
<p>This section uses SciPy’s <code class="docutils literal notranslate"><span class="pre">scale</span></code> parameterization for the Gamma and Exponential distributions:</p>
<ul class="simple">
<li><p><strong>Gamma(shape, scale)</strong>: <span class="math notranslate nohighlight">\(f(x) = \frac{x^{\text{shape}-1} e^{-x/\text{scale}}}{\text{scale}^{\text{shape}} \Gamma(\text{shape})}\)</span></p></li>
<li><p><strong>Exponential(scale)</strong>: <span class="math notranslate nohighlight">\(f(x) = \frac{1}{\text{scale}} e^{-x/\text{scale}}\)</span></p></li>
</ul>
<p>The rate parameterization (common in statistics) relates via <code class="docutils literal notranslate"><span class="pre">scale</span> <span class="pre">=</span> <span class="pre">1/rate</span></code>. When mathematical notation uses <span class="math notranslate nohighlight">\(\text{Gamma}(\alpha, 1)\)</span>, the SciPy call is <code class="docutils literal notranslate"><span class="pre">stats.gamma(a=alpha,</span> <span class="pre">scale=1)</span></code>.</p>
</div>
</section>
</section>
<section id="efficiency-analysis">
<h2>Efficiency Analysis<a class="headerlink" href="#efficiency-analysis" title="Link to this heading"></a></h2>
<p>Not every proposed sample is accepted. Understanding the acceptance rate is crucial for assessing computational cost.</p>
<section id="acceptance-probability-two-cases">
<h3>Acceptance Probability: Two Cases<a class="headerlink" href="#acceptance-probability-two-cases" title="Link to this heading"></a></h3>
<p>From the proof above, the acceptance probability depends on whether the target is normalized:</p>
<div class="important admonition">
<p class="admonition-title">Acceptance Rate Summary</p>
<p><strong>Case 1: Normalized target</strong> <span class="math notranslate nohighlight">\(f(x)\)</span> with <span class="math notranslate nohighlight">\(\int f(x)\,dx = 1\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(\text{accept}) = \frac{1}{M}, \qquad \mathbb{E}[\text{iterations}] = M\]</div>
<p><strong>Case 2: Unnormalized target</strong> <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> with <span class="math notranslate nohighlight">\(C = \int \tilde{f}(x)\,dx\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(\text{accept}) = \frac{C}{M}, \qquad \mathbb{E}[\text{iterations}] = \frac{M}{C}\]</div>
</div>
<p>Most textbook examples and library implementations assume Case 1 (normalized target). When working with unnormalized kernels—common in Bayesian inference—use Case 2.</p>
<p><strong>Geometric interpretation</strong>: The acceptance probability equals the ratio of the area under <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> (which is <span class="math notranslate nohighlight">\(C\)</span>) to the area under <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span> (which is <span class="math notranslate nohighlight">\(M\)</span>). A tighter envelope (smaller <span class="math notranslate nohighlight">\(M\)</span>) means less wasted area and higher efficiency.</p>
<figure class="align-center" id="id7">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_5_fig07_area_ratio.png"><img alt="Three-panel visualization showing acceptance probability as area ratio" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_5_fig07_area_ratio.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 66 </span><span class="caption-text"><strong>Acceptance Probability as Area Ratio.</strong> This figure uses a <em>normalized</em> density <span class="math notranslate nohighlight">\(f(x)\)</span> (Case 1). Left: The target density <span class="math notranslate nohighlight">\(f(x)\)</span> (blue) sits inside the envelope <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span> (red). Center: The envelope area decomposes into accepted (blue) and rejected (red) portions. Right: Smaller <span class="math notranslate nohighlight">\(M\)</span> values yield higher acceptance rates—a tighter envelope wastes less area. For normalized <span class="math notranslate nohighlight">\(f\)</span>, the acceptance rate is <span class="math notranslate nohighlight">\(1/M\)</span>.</span><a class="headerlink" href="#id7" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="the-optimal-envelope-constant">
<h3>The Optimal Envelope Constant<a class="headerlink" href="#the-optimal-envelope-constant" title="Link to this heading"></a></h3>
<p>Given a proposal <span class="math notranslate nohighlight">\(g(x)\)</span>, the smallest valid <span class="math notranslate nohighlight">\(M\)</span> is:</p>
<div class="math notranslate nohighlight" id="equation-optimal-m">
<span class="eqno">(13)<a class="headerlink" href="#equation-optimal-m" title="Link to this equation"></a></span>\[M^* = \sup_x \frac{\tilde{f}(x)}{g(x)}\]</div>
<p>Using <span class="math notranslate nohighlight">\(M^*\)</span> maximizes acceptance probability. Any <span class="math notranslate nohighlight">\(M &gt; M^*\)</span> is valid but wasteful; any <span class="math notranslate nohighlight">\(M &lt; M^*\)</span> violates the envelope condition and produces incorrect samples.</p>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><strong>Using M that’s too small</strong>: If <span class="math notranslate nohighlight">\(M \cdot g(x) &lt; \tilde{f}(x)\)</span> for some <span class="math notranslate nohighlight">\(x\)</span>, samples from the region where the envelope dips below the target are underrepresented. This is a <strong>silent error</strong>—the algorithm runs but produces biased samples. Always verify that your envelope truly dominates the target, especially in tail regions.</p>
</div>
</section>
</section>
<section id="choosing-the-proposal-distribution">
<h2>Choosing the Proposal Distribution<a class="headerlink" href="#choosing-the-proposal-distribution" title="Link to this heading"></a></h2>
<p>The efficiency of rejection sampling hinges on choosing a proposal <span class="math notranslate nohighlight">\(g(x)\)</span> that closely approximates the target <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> while remaining easy to sample.</p>
<section id="desiderata-for-proposals">
<h3>Desiderata for Proposals<a class="headerlink" href="#desiderata-for-proposals" title="Link to this heading"></a></h3>
<p>A good proposal distribution should satisfy:</p>
<ol class="arabic simple">
<li><p><strong>Easy to sample</strong>: We need fast, direct sampling from <span class="math notranslate nohighlight">\(g(x)\)</span>. Good choices include uniform, exponential, normal, Cauchy, and mixtures of these.</p></li>
<li><p><strong>Support covers target</strong>: Wherever <span class="math notranslate nohighlight">\(\tilde{f}(x) &gt; 0\)</span>, we need <span class="math notranslate nohighlight">\(g(x) &gt; 0\)</span>. Otherwise, some regions of the target receive zero probability mass.</p></li>
<li><p><strong>Shape matches target</strong>: Ideally, the ratio <span class="math notranslate nohighlight">\(\tilde{f}(x)/g(x)\)</span> should be nearly constant. Large variations in this ratio force <span class="math notranslate nohighlight">\(M\)</span> to be large, reducing efficiency.</p></li>
<li><p><strong>Tail behavior matches or exceeds</strong>: If <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> has heavy tails, <span class="math notranslate nohighlight">\(g(x)\)</span> must have at least as heavy tails. A light-tailed proposal for a heavy-tailed target leads to <span class="math notranslate nohighlight">\(M = \infty\)</span>.</p></li>
</ol>
</section>
<section id="finding-the-envelope-constant">
<h3>Finding the Envelope Constant<a class="headerlink" href="#finding-the-envelope-constant" title="Link to this heading"></a></h3>
<p>Given <span class="math notranslate nohighlight">\(\tilde{f}\)</span> and <span class="math notranslate nohighlight">\(g\)</span>, we must compute <span class="math notranslate nohighlight">\(M^* = \sup_x \tilde{f}(x)/g(x)\)</span>. Several approaches are available:</p>
<p><strong>Analytical optimization</strong>: For well-behaved functions, calculus yields the maximum. Set the derivative of <span class="math notranslate nohighlight">\(\tilde{f}(x)/g(x)\)</span> to zero and solve.</p>
<p><strong>Numerical optimization</strong>: Use <code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize_scalar</span></code> to find the maximum of <span class="math notranslate nohighlight">\(\tilde{f}(x)/g(x)\)</span>.</p>
<p><strong>Grid search</strong>: Evaluate the ratio on a fine grid covering the support, then take the maximum plus a small safety margin.</p>
<p><strong>Bounding arguments</strong>: Sometimes theoretical bounds are available. For instance, if <span class="math notranslate nohighlight">\(\tilde{f}\)</span> is a product of terms each bounded by a constant, those bounds can be combined.</p>
<div class="note admonition">
<p class="admonition-title">Example 💡 Finding M for Beta(2.5, 6) with Uniform Proposal</p>
<p><strong>Setup (using normalized density)</strong>: Target is <span class="math notranslate nohighlight">\(f(x) = \frac{x^{1.5}(1-x)^5}{B(2.5, 6)}\)</span> on <span class="math notranslate nohighlight">\([0, 1]\)</span>, which is the normalized Beta(2.5, 6) density. Proposal is <span class="math notranslate nohighlight">\(g(x) = 1\)</span> (uniform on <span class="math notranslate nohighlight">\([0, 1]\)</span>).</p>
<p><strong>Find M</strong>: For a uniform proposal with normalized target, <span class="math notranslate nohighlight">\(M = \max_x f(x)\)</span>. The mode of Beta(<span class="math notranslate nohighlight">\(\alpha, \beta\)</span>) with <span class="math notranslate nohighlight">\(\alpha, \beta &gt; 1\)</span> is <span class="math notranslate nohighlight">\(x^* = (\alpha - 1)/(\alpha + \beta - 2)\)</span>.</p>
<p>Here <span class="math notranslate nohighlight">\(x^* = 1.5/6.5 \approx 0.2308\)</span>. Computing the normalized density at the mode:</p>
<div class="math notranslate nohighlight">
\[M^* = f(x^*) = \frac{(0.2308)^{1.5}(0.7692)^5}{B(2.5, 6)} \approx 2.61\]</div>
<p><strong>Acceptance rate (Case 1, normalized)</strong>: <span class="math notranslate nohighlight">\(P(\text{accept}) = 1/M^* \approx 38.3\%\)</span>.</p>
<p><strong>Alternative (unnormalized)</strong>: If using the kernel <span class="math notranslate nohighlight">\(\tilde{f}(x) = x^{1.5}(1-x)^5\)</span> directly, then <span class="math notranslate nohighlight">\(M^* = k(x^*) \approx 0.0297\)</span> and <span class="math notranslate nohighlight">\(C = B(2.5, 6) \approx 0.01137\)</span>, giving <span class="math notranslate nohighlight">\(P(\text{accept}) = C/M^* \approx 38.3\%\)</span>—the same result.</p>
</div>
</section>
<section id="numerical-approaches-for-finding-m">
<h3>Numerical Approaches for Finding M<a class="headerlink" href="#numerical-approaches-for-finding-m" title="Link to this heading"></a></h3>
<p>When analytical optimization is difficult, numerical methods provide <span class="math notranslate nohighlight">\(M\)</span>:</p>
<p><strong>Grid search</strong>: Evaluate <span class="math notranslate nohighlight">\(\tilde{f}(x)/g(x)\)</span> on a dense grid covering the support, then take the maximum with a safety margin:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">find_M_grid</span><span class="p">(</span><span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">n_grid</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Find envelope constant M via grid search.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target_pdf : callable</span>
<span class="sd">        Target density or kernel (normalized or unnormalized).</span>
<span class="sd">    proposal_pdf : callable</span>
<span class="sd">        Proposal density (must be normalized).</span>
<span class="sd">    x_min, x_max : float</span>
<span class="sd">        Bounds for the support.</span>
<span class="sd">    n_grid : int</span>
<span class="sd">        Number of grid points.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Envelope constant M with 2% safety margin.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">n_grid</span><span class="p">)</span>

    <span class="c1"># Vectorized evaluation</span>
    <span class="n">g_vals</span> <span class="o">=</span> <span class="n">proposal_pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>
    <span class="n">f_vals</span> <span class="o">=</span> <span class="n">target_pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>

    <span class="c1"># Avoid division by zero</span>
    <span class="n">valid</span> <span class="o">=</span> <span class="n">g_vals</span> <span class="o">&gt;</span> <span class="mf">1e-15</span>
    <span class="n">ratios</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>
    <span class="n">ratios</span><span class="p">[</span><span class="n">valid</span><span class="p">]</span> <span class="o">=</span> <span class="n">f_vals</span><span class="p">[</span><span class="n">valid</span><span class="p">]</span> <span class="o">/</span> <span class="n">g_vals</span><span class="p">[</span><span class="n">valid</span><span class="p">]</span>

    <span class="n">M_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span>

    <span class="c1"># Safety margin: 1-2% above grid maximum</span>
    <span class="k">return</span> <span class="n">M_grid</span> <span class="o">*</span> <span class="mf">1.02</span>
</pre></div>
</div>
<p><strong>Numerical optimization</strong>: Use scipy.optimize to find the maximum directly:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">minimize_scalar</span>

<span class="k">def</span><span class="w"> </span><span class="nf">find_M_optimize</span><span class="p">(</span><span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">bounds</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Find M via numerical optimization.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">neg_ratio</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">proposal_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">g</span> <span class="o">&lt;</span> <span class="mf">1e-15</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>  <span class="c1"># Avoid division issues</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">target_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">g</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">minimize_scalar</span><span class="p">(</span><span class="n">neg_ratio</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;bounded&#39;</span><span class="p">)</span>
    <span class="n">M_optimal</span> <span class="o">=</span> <span class="o">-</span><span class="n">result</span><span class="o">.</span><span class="n">fun</span>

    <span class="k">return</span> <span class="n">M_optimal</span> <span class="o">*</span> <span class="mf">1.01</span>  <span class="c1"># Small safety margin</span>
</pre></div>
</div>
<p><strong>Adaptive refinement</strong>: For distributions with sharp peaks or boundary behavior, combine coarse grid search with local refinement near suspected maxima.</p>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><strong>Grid search misses boundary maxima</strong>: If <span class="math notranslate nohighlight">\(\tilde{f}(x)/g(x)\)</span> peaks at or near a boundary, a naive grid may miss it. Always include points very close to boundaries (e.g., <span class="math notranslate nohighlight">\(x = 10^{-6}\)</span> for distributions on <span class="math notranslate nohighlight">\([0, \infty)\)</span>), and verify that your computed <span class="math notranslate nohighlight">\(M\)</span> truly dominates by checking <span class="math notranslate nohighlight">\(\tilde{f}(x) \le M \cdot g(x)\)</span> at random test points.</p>
</div>
</section>
<section id="strategies-for-proposal-selection">
<h3>Strategies for Proposal Selection<a class="headerlink" href="#strategies-for-proposal-selection" title="Link to this heading"></a></h3>
<p>Choosing a good proposal is both art and science. The goal is to minimize <span class="math notranslate nohighlight">\(M = \sup_x \tilde{f}(x)/g(x)\)</span>, which means <strong>matching the shape</strong> of the target—not just covering its support.</p>
<p><strong>Principle 1: Support coverage is necessary but not sufficient</strong></p>
<p>The proposal must satisfy <span class="math notranslate nohighlight">\(g(x) &gt; 0\)</span> wherever <span class="math notranslate nohighlight">\(\tilde{f}(x) &gt; 0\)</span>. But merely covering the support can yield terrible efficiency. For Beta(0.5, 5) on <span class="math notranslate nohighlight">\([0, 1]\)</span>, a Uniform(0, 1) proposal gives <span class="math notranslate nohighlight">\(M \approx 5.7\)</span> (17.5% acceptance), while a well-tuned Beta proposal achieves <span class="math notranslate nohighlight">\(M \approx 1.3\)</span> (77% acceptance).</p>
<p><strong>The Fundamental Requirement</strong></p>
<p>Rejection sampling requires:</p>
<div class="math notranslate nohighlight">
\[\sup_x \frac{\tilde{f}(x)}{g(x)} &lt; \infty\]</div>
<p>Equivalently, the ratio <span class="math notranslate nohighlight">\(\tilde{f}/g\)</span> must be bounded on the entire support. This single criterion unifies the tail behavior and singularity constraints discussed below.</p>
<p><strong>Principle 2: Match tail behavior to avoid infinite M</strong></p>
<p>If the target has heavier tails than the proposal, the ratio <span class="math notranslate nohighlight">\(\tilde{f}(x)/g(x) \to \infty\)</span> as <span class="math notranslate nohighlight">\(|x| \to \infty\)</span>, making <span class="math notranslate nohighlight">\(M = \infty\)</span>. This is a hard constraint:</p>
<ul class="simple">
<li><p>Normal target → Normal, Cauchy, or Student-t proposal all work</p></li>
<li><p>Cauchy target → Normal proposal <strong>fails</strong> (<span class="math notranslate nohighlight">\(M = \infty\)</span>)</p></li>
<li><p>Cauchy target → Cauchy or heavier-tailed proposal required</p></li>
</ul>
<p><strong>Principle 3: Match singularities for unbounded densities</strong></p>
<p>If <span class="math notranslate nohighlight">\(\tilde{f}(x) \to \infty\)</span> at some point (e.g., Beta(0.5, 2) near <span class="math notranslate nohighlight">\(x = 0\)</span>), a bounded proposal cannot dominate. The proposal must have a matching or stronger singularity. See Exercise 2 for the Gamma(0.5, 1) case.</p>
<p><strong>Principle 4: Shape matching minimizes M</strong></p>
<p>The ideal proposal has <span class="math notranslate nohighlight">\(g(x) \propto \tilde{f}(x)\)</span>, giving <span class="math notranslate nohighlight">\(M = C\)</span> (100% acceptance after normalization). In practice, we approximate this:</p>
<table class="docutils align-default" id="id8">
<caption><span class="caption-number">Table 20 </span><span class="caption-text">Proposal Selection by Target Shape</span><a class="headerlink" href="#id8" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 30.0%" />
<col style="width: 35.0%" />
<col style="width: 35.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Target Shape</p></th>
<th class="head"><p>Proposal Options</p></th>
<th class="head"><p>Efficiency Considerations</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Symmetric, light-tailed (e.g., truncated normal)</p></td>
<td><p>Normal, scaled to match spread</p></td>
<td><p>Very efficient if variance matched; <span class="math notranslate nohighlight">\(M \approx 1.1\text{-}1.5\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Skewed on <span class="math notranslate nohighlight">\([0, 1]\)</span> (e.g., Beta(2, 8))</p></td>
<td><p>Beta with similar skew, or mixture of Betas</p></td>
<td><p>Uniform is simple but inefficient; Beta proposal can achieve <span class="math notranslate nohighlight">\(M &lt; 1.5\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Skewed on <span class="math notranslate nohighlight">\([0, \infty)\)</span> (e.g., Gamma, Weibull)</p></td>
<td><p>Gamma or Exponential with rate matching mode</p></td>
<td><p>Match tail decay rate; heavier proposal tail is safer</p></td>
</tr>
<tr class="row-odd"><td><p>Heavy-tailed (e.g., Cauchy, Pareto)</p></td>
<td><p>Cauchy, Student-t, or Pareto</p></td>
<td><p><strong>Must</strong> use heavy-tailed proposal; normal fails</p></td>
</tr>
<tr class="row-even"><td><p>Multimodal</p></td>
<td><p>Mixture matching mode locations</p></td>
<td><p>Single unimodal proposal forces large <span class="math notranslate nohighlight">\(M\)</span>; mixtures dramatically improve efficiency</p></td>
</tr>
<tr class="row-odd"><td><p>Log-concave</p></td>
<td><p>Adaptive Rejection Sampling (ARS)</p></td>
<td><p>Envelope adapts during sampling; very efficient</p></td>
</tr>
</tbody>
</table>
<p><strong>Example: Beta(2, 8) — Comparing Proposals (Normalized Target)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># Normalized density</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Option 1: Uniform(0, 1) proposal</span>
<span class="n">g_uniform</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">M_uniform</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">f</span> <span class="o">/</span> <span class="n">g_uniform</span><span class="p">)</span>
<span class="c1"># Case 1 (normalized): acceptance = 1/M</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Uniform proposal: M = </span><span class="si">{</span><span class="n">M_uniform</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, acceptance = </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M_uniform</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Option 2: Beta(2, 7) proposal (similar shape)</span>
<span class="n">proposal</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">g_beta</span> <span class="o">=</span> <span class="n">proposal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">M_beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">f</span> <span class="o">/</span> <span class="n">g_beta</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Beta(2,7) proposal: M = </span><span class="si">{</span><span class="n">M_beta</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, acceptance = </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M_beta</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Option 3: Beta(1.5, 6) proposal (slightly different)</span>
<span class="n">proposal2</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">g_beta2</span> <span class="o">=</span> <span class="n">proposal2</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">M_beta2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">f</span> <span class="o">/</span> <span class="n">g_beta2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Beta(1.5,6) proposal: M = </span><span class="si">{</span><span class="n">M_beta2</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, acceptance = </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M_beta2</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Uniform</span> <span class="n">proposal</span><span class="p">:</span> <span class="n">M</span> <span class="o">=</span> <span class="mf">2.62</span><span class="p">,</span> <span class="n">acceptance</span> <span class="o">=</span> <span class="mf">38.2</span><span class="o">%</span>
<span class="n">Beta</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span> <span class="n">proposal</span><span class="p">:</span> <span class="n">M</span> <span class="o">=</span> <span class="mf">1.18</span><span class="p">,</span> <span class="n">acceptance</span> <span class="o">=</span> <span class="mf">84.7</span><span class="o">%</span>
<span class="n">Beta</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span> <span class="n">proposal</span><span class="p">:</span> <span class="n">M</span> <span class="o">=</span> <span class="mf">1.31</span><span class="p">,</span> <span class="n">acceptance</span> <span class="o">=</span> <span class="mf">76.3</span><span class="o">%</span>
</pre></div>
</div>
<p>The Beta(2, 7) proposal—chosen to approximate the target’s shape—achieves <strong>more than double</strong> the acceptance rate of the uniform proposal.</p>
<p><strong>Practical Guidance</strong></p>
<ol class="arabic simple">
<li><p><strong>Start simple</strong>: Uniform or normal proposals are easy to implement and debug. Use them first to verify correctness.</p></li>
<li><p><strong>Profile before optimizing</strong>: If acceptance rate is above 20-30%, the simple proposal may be adequate. Optimize only if efficiency matters.</p></li>
<li><p><strong>Use the same family when possible</strong>: For a Gamma target, try a Gamma proposal with slightly larger variance. For Beta targets, try Beta proposals.</p></li>
<li><p><strong>Verify envelope condition</strong>: After choosing <span class="math notranslate nohighlight">\(g\)</span> and computing <span class="math notranslate nohighlight">\(M\)</span>, always verify <span class="math notranslate nohighlight">\(\tilde{f}(x) \le M \cdot g(x)\)</span> at many points, especially near boundaries and modes.</p></li>
</ol>
</section>
</section>
<section id="python-implementation">
<h2>Python Implementation<a class="headerlink" href="#python-implementation" title="Link to this heading"></a></h2>
<p>Let’s implement rejection sampling and apply it to several distributions.</p>
<section id="basic-implementation">
<h3>Basic Implementation<a class="headerlink" href="#basic-implementation" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">rejection_sample</span><span class="p">(</span><span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_sampler</span><span class="p">,</span> <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                     <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate samples from target using rejection sampling.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target_pdf : callable</span>
<span class="sd">        Function computing f(x) or tilde{f}(x).</span>
<span class="sd">    proposal_sampler : callable</span>
<span class="sd">        Function that returns one sample from g(x).</span>
<span class="sd">    proposal_pdf : callable</span>
<span class="sd">        Function computing g(x).</span>
<span class="sd">    M : float</span>
<span class="sd">        Envelope constant such that target_pdf(x) &lt;= M * proposal_pdf(x).</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        Number of samples to generate.</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed for reproducibility.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    samples : ndarray</span>
<span class="sd">        Array of n_samples draws from the target distribution.</span>
<span class="sd">    acceptance_rate : float</span>
<span class="sd">        Fraction of proposals that were accepted.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If target_pdf is normalized, acceptance rate ≈ 1/M.</span>
<span class="sd">    If target_pdf is unnormalized with integral C, acceptance rate ≈ C/M.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="c1"># Step 1: Draw from proposal</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">proposal_sampler</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Step 2: Draw uniform for acceptance test</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>

        <span class="c1"># Step 3: Accept or reject</span>
        <span class="n">acceptance_prob</span> <span class="o">=</span> <span class="n">target_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">proposal_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">acceptance_prob</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_proposals</span>
</pre></div>
</div>
<div class="note admonition">
<p class="admonition-title">Example 💡 Sampling from Beta(2.5, 6) — Normalized Target (Case 1)</p>
<p><strong>Given</strong>: Target is Beta(2.5, 6) using the <em>normalized</em> pdf from scipy; proposal is Uniform(0, 1)</p>
<p><strong>Acceptance rate formula</strong>: Since we use normalized <span class="math notranslate nohighlight">\(f\)</span>, acceptance rate is <span class="math notranslate nohighlight">\(1/M\)</span>.</p>
<p><strong>Implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Target: Beta(2.5, 6) - NORMALIZED pdf via scipy</span>
<span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span> <span class="o">=</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">6.0</span>
<span class="n">target_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span><span class="p">)</span>
<span class="n">target_pdf</span> <span class="o">=</span> <span class="n">target_dist</span><span class="o">.</span><span class="n">pdf</span>  <span class="c1"># Normalized, vectorized</span>

<span class="c1"># Proposal: Uniform(0, 1)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">proposal_sampler</span><span class="p">(</span><span class="n">rng</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">proposal_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># Find M: maximum of normalized Beta density</span>
<span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">target_pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.01</span>  <span class="c1"># 1% safety margin</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Envelope constant M = </span><span class="si">{</span><span class="n">M</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected acceptance rate (Case 1: 1/M) = </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Generate samples</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">rejection_sample</span><span class="p">(</span>
    <span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_sampler</span><span class="p">,</span> <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Actual acceptance rate = </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample mean = </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="n">alpha</span><span class="o">/</span><span class="p">(</span><span class="n">alpha</span><span class="o">+</span><span class="n">beta_param</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Envelope</span> <span class="n">constant</span> <span class="n">M</span> <span class="o">=</span> <span class="mf">2.6360</span>
<span class="n">Expected</span> <span class="n">acceptance</span> <span class="n">rate</span> <span class="p">(</span><span class="n">Case</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="n">M</span><span class="p">)</span> <span class="o">=</span> <span class="mf">37.9</span><span class="o">%</span>
<span class="n">Actual</span> <span class="n">acceptance</span> <span class="n">rate</span> <span class="o">=</span> <span class="mf">38.2</span><span class="o">%</span>
<span class="n">Sample</span> <span class="n">mean</span> <span class="o">=</span> <span class="mf">0.2937</span> <span class="p">(</span><span class="n">theory</span><span class="p">:</span> <span class="mf">0.2941</span><span class="p">)</span>
</pre></div>
</div>
<p>The acceptance rate matches the theoretical <span class="math notranslate nohighlight">\(1/M \approx 38\%\)</span>, confirming we’re in Case 1.</p>
</div>
<div class="note admonition">
<p class="admonition-title">Example 💡 Sampling from Beta(2.5, 6) — Unnormalized Kernel (Case 2)</p>
<p><strong>Given</strong>: Target is the <em>unnormalized</em> kernel <span class="math notranslate nohighlight">\(\tilde{f}(x) = x^{1.5}(1-x)^5\)</span>; proposal is Uniform(0, 1)</p>
<p><strong>Acceptance rate formula</strong>: Since we use unnormalized <span class="math notranslate nohighlight">\(\tilde{f}\)</span>, acceptance rate is <span class="math notranslate nohighlight">\(C/M\)</span> where <span class="math notranslate nohighlight">\(C = B(2.5, 6)\)</span>.</p>
<p><strong>Implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">special</span>

<span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span> <span class="o">=</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">6.0</span>

<span class="c1"># UNNORMALIZED kernel</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kernel</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="p">(</span><span class="n">alpha</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">beta_param</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Normalizing constant (often unknown in practice)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Normalizing constant C = B(</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">beta_param</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">C</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Proposal: Uniform(0, 1)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">proposal_sampler</span><span class="p">(</span><span class="n">rng</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">proposal_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span>

<span class="c1"># Find M for kernel</span>
<span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.01</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Envelope constant M = </span><span class="si">{</span><span class="n">M</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected acceptance rate (Case 2: C/M) = </span><span class="si">{</span><span class="n">C</span><span class="o">/</span><span class="n">M</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Generate samples</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">rejection_sample</span><span class="p">(</span>
    <span class="n">kernel</span><span class="p">,</span> <span class="n">proposal_sampler</span><span class="p">,</span> <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Actual acceptance rate = </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Normalizing</span> <span class="n">constant</span> <span class="n">C</span> <span class="o">=</span> <span class="n">B</span><span class="p">(</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.011370</span>
<span class="n">Envelope</span> <span class="n">constant</span> <span class="n">M</span> <span class="o">=</span> <span class="mf">0.030001</span>
<span class="n">Expected</span> <span class="n">acceptance</span> <span class="n">rate</span> <span class="p">(</span><span class="n">Case</span> <span class="mi">2</span><span class="p">:</span> <span class="n">C</span><span class="o">/</span><span class="n">M</span><span class="p">)</span> <span class="o">=</span> <span class="mf">37.9</span><span class="o">%</span>
<span class="n">Actual</span> <span class="n">acceptance</span> <span class="n">rate</span> <span class="o">=</span> <span class="mf">38.2</span><span class="o">%</span>
</pre></div>
</div>
<p><strong>Key observation</strong>: Both approaches yield the same 38% acceptance rate—the normalized and unnormalized formulations are equivalent. Use Case 1 formula <span class="math notranslate nohighlight">\(1/M\)</span> when your pdf is normalized; use Case 2 formula <span class="math notranslate nohighlight">\(C/M\)</span> when working with kernels.</p>
</div>
</section>
<section id="vectorized-implementation-for-speed">
<h3>Vectorized Implementation for Speed<a class="headerlink" href="#vectorized-implementation-for-speed" title="Link to this heading"></a></h3>
<p>The basic implementation loops over individual samples. For better performance, we can generate batches of proposals and filter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">rejection_sample_vectorized</span><span class="p">(</span><span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_sampler_batch</span><span class="p">,</span>
                                <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Vectorized rejection sampling for improved performance.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    proposal_sampler_batch : callable</span>
<span class="sd">        Function that takes (rng, batch_size) and returns batch_size samples.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    For normalized targets, acceptance rate ≈ 1/M.</span>
<span class="sd">    For unnormalized targets with integral C, acceptance rate ≈ C/M.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Estimate batch size based on expected acceptance rate</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">M</span> <span class="o">*</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="mi">10</span><span class="p">))</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="c1"># Generate batch of proposals</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="n">proposal_sampler_batch</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">u_batch</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="n">batch_size</span>

        <span class="c1"># Vectorized acceptance test</span>
        <span class="n">f_vals</span> <span class="o">=</span> <span class="n">target_pdf</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
        <span class="n">g_vals</span> <span class="o">=</span> <span class="n">proposal_pdf</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
        <span class="n">acceptance_probs</span> <span class="o">=</span> <span class="n">f_vals</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">g_vals</span><span class="p">)</span>

        <span class="c1"># Accept where u &lt;= acceptance probability</span>
        <span class="n">accepted</span> <span class="o">=</span> <span class="n">x_batch</span><span class="p">[</span><span class="n">u_batch</span> <span class="o">&lt;=</span> <span class="n">acceptance_probs</span><span class="p">]</span>
        <span class="n">samples</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">accepted</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]),</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposals</span>
</pre></div>
</div>
<div class="tip admonition">
<p class="admonition-title">Implementation Note</p>
<p>For true vectorization, <code class="docutils literal notranslate"><span class="pre">target_pdf</span></code> and <code class="docutils literal notranslate"><span class="pre">proposal_pdf</span></code> must accept array inputs and return arrays. SciPy’s <code class="docutils literal notranslate"><span class="pre">stats.distribution.pdf</span></code> methods support this natively. If your target is a custom function, use <code class="docutils literal notranslate"><span class="pre">np.vectorize</span></code> as a quick fix, though this provides no speed benefit over explicit loops. For performance-critical code, rewrite the PDF using NumPy array operations.</p>
</div>
</section>
</section>
<section id="the-squeeze-principle">
<h2>The Squeeze Principle<a class="headerlink" href="#the-squeeze-principle" title="Link to this heading"></a></h2>
<p>When the target density <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> is expensive to evaluate, we can accelerate rejection sampling using a <strong>squeeze function</strong> (also called a lower envelope). The idea, introduced by Marsaglia <a class="reference internal" href="#marsaglia1977" id="id3"><span>[Marsaglia1977]</span></a>, is to construct a cheap-to-evaluate function <span class="math notranslate nohighlight">\(\ell(x)\)</span> satisfying:</p>
<div class="math notranslate nohighlight">
\[0 \le \ell(x) \le \tilde{f}(x) \le M \cdot g(x) \quad \text{for all } x\]</div>
<p>The modified algorithm becomes:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>To generate one sample from f(x) with squeeze:

1. REPEAT:
   a. Draw X ~ g(x)
   b. Draw U ~ Uniform(0, 1)
   c. IF U ≤ ℓ(X) / [M · g(X)]:
      ACCEPT X immediately (without evaluating tilde{f})
   d. ELSE IF U ≤ tilde{f}(X) / [M · g(X)]:
      ACCEPT X (requires evaluating tilde{f})
   e. ELSE:
      REJECT X

2. Return accepted X
</pre></div>
</div>
<p>The squeeze function acts as a “fast accept” gate. If the uniform variate falls below <span class="math notranslate nohighlight">\(\ell(X)/[M \cdot g(X)]\)</span>, we accept without ever computing <span class="math notranslate nohighlight">\(\tilde{f}(X)\)</span>. Only when <span class="math notranslate nohighlight">\(U\)</span> falls between the squeeze and the envelope do we need the expensive <span class="math notranslate nohighlight">\(\tilde{f}\)</span> evaluation.</p>
<p><strong>Efficiency gain</strong>: If <span class="math notranslate nohighlight">\(\ell(x)\)</span> is close to <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span>, most acceptances occur at step (c), avoiding the costly <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> evaluation. This is particularly valuable when <span class="math notranslate nohighlight">\(\tilde{f}\)</span> involves special functions, numerical integration, or complex likelihood computations.</p>
<section id="valid-squeeze-construction">
<h3>Valid Squeeze Construction<a class="headerlink" href="#valid-squeeze-construction" title="Link to this heading"></a></h3>
<p><strong>Critical requirement</strong>: The squeeze function must satisfy <span class="math notranslate nohighlight">\(\ell(x) \le \tilde{f}(x)\)</span> for ALL <span class="math notranslate nohighlight">\(x\)</span> in the support. A function that exceeds the target anywhere is not a valid squeeze and will produce biased fast-accepts.</p>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><strong>Invalid “tent” squeeze for unimodal densities</strong>: A piecewise linear “tent” in density space connecting <span class="math notranslate nohighlight">\((0, 0)\)</span>, <span class="math notranslate nohighlight">\((x^*, f(x^*))\)</span>, <span class="math notranslate nohighlight">\((1, 0)\)</span> (where <span class="math notranslate nohighlight">\(x^*\)</span> is the mode) is <strong>not</strong> a valid squeeze for most unimodal densities. For example, with Beta(5, 5):</p>
<ul class="simple">
<li><p>The tent has area <span class="math notranslate nohighlight">\(\frac{1}{2} \cdot 1 \cdot f(0.5) = \frac{1}{2} \cdot 2.46 = 1.23\)</span></p></li>
<li><p>But any valid squeeze must have area <span class="math notranslate nohighlight">\(\le 1\)</span> (since <span class="math notranslate nohighlight">\(\int f = 1\)</span>)</p></li>
<li><p>The tent actually <strong>exceeds</strong> the Beta(5, 5) density on substantial interior intervals</p></li>
</ul>
<p>An area exceeding 1 is a red flag that the construction is invalid.</p>
</div>
<p><strong>Safe construction for log-concave targets</strong>: For <strong>log-concave</strong> densities (where <span class="math notranslate nohighlight">\(\log \tilde{f}(x)\)</span> is concave), a provably valid squeeze can be constructed using secant lines in log-space. Many important distributions are log-concave:</p>
<ul class="simple">
<li><p>Normal: <span class="math notranslate nohighlight">\(\log \phi(x) \propto -x^2/2\)</span> (concave parabola)</p></li>
<li><p>Exponential: <span class="math notranslate nohighlight">\(\log(\lambda e^{-\lambda x}) \propto -\lambda x\)</span> (linear, hence concave)</p></li>
<li><p>Gamma with <span class="math notranslate nohighlight">\(\alpha \ge 1\)</span>: <span class="math notranslate nohighlight">\(\log f(x) \propto (\alpha-1)\log x - x\)</span> (concave for <span class="math notranslate nohighlight">\(\alpha \ge 1\)</span>)</p></li>
<li><p>Beta with <span class="math notranslate nohighlight">\(\alpha, \beta \ge 1\)</span>: log-concave on <span class="math notranslate nohighlight">\((0, 1)\)</span></p></li>
<li><p>Logistic, truncated log-normal</p></li>
</ul>
<p><strong>Log-space secant squeeze</strong>: Choose anchor points <span class="math notranslate nohighlight">\(x_0 &lt; x_1 &lt; \cdots &lt; x_K\)</span> and define:</p>
<div class="math notranslate nohighlight">
\[\underline{h}(x) = \text{piecewise-linear interpolation of } \log \tilde{f}(x_k)\]</div>
<p>By concavity of <span class="math notranslate nohighlight">\(\log \tilde{f}\)</span>, the secant lines lie <strong>below</strong> the curve: <span class="math notranslate nohighlight">\(\underline{h}(x) \le \log \tilde{f}(x)\)</span>. Exponentiating:</p>
<div class="math notranslate nohighlight">
\[\ell(x) = \exp(\underline{h}(x)) \le \tilde{f}(x)\]</div>
<p>This construction is <strong>guaranteed valid</strong> for log-concave targets.</p>
<div class="note admonition">
<p class="admonition-title">Example 💡 Valid Squeeze for Beta(5, 5) via Log-Space Secants</p>
<p>Beta(5, 5) is log-concave since <span class="math notranslate nohighlight">\(\alpha, \beta \ge 1\)</span>. We construct a squeeze using linear interpolation in log-space:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># Anchor points</span>
<span class="n">x_anchors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">])</span>
<span class="n">log_f_anchors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_anchors</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">log_squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Piecewise linear interpolation in log-space.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_anchors</span><span class="p">,</span> <span class="n">log_f_anchors</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Valid squeeze: exp of log-space interpolation.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="c1"># Verify squeeze validity</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">f_vals</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">squeeze_vals</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="n">violations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">squeeze_vals</span> <span class="o">&gt;</span> <span class="n">f_vals</span> <span class="o">*</span> <span class="mf">1.0001</span><span class="p">)</span>  <span class="c1"># Allow tiny numerical error</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Violations: </span><span class="si">{</span><span class="n">violations</span><span class="si">}</span><span class="s2"> (should be 0)&quot;</span><span class="p">)</span>

<span class="c1"># Squeeze efficiency</span>
<span class="n">squeeze_area</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trapz</span><span class="p">(</span><span class="n">squeeze_vals</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Squeeze area: </span><span class="si">{</span><span class="n">squeeze_area</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (must be ≤ 1)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fast-accept fraction: ~</span><span class="si">{</span><span class="n">squeeze_area</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Violations: 0 (should be 0)
Squeeze area: 0.8712 (must be ≤ 1)
Fast-accept fraction: ~87.1%
</pre></div>
</div>
<p>The log-space construction is valid (no violations) and achieves ~87% fast-accepts, avoiding expensive Beta function evaluations for most proposals.</p>
</div>
<div class="note admonition">
<p class="admonition-title">Example 💡 Squeeze for Normal Density</p>
<p>From the Taylor expansion <span class="math notranslate nohighlight">\(e^{-x^2/2} \ge 1 - x^2/2\)</span> for <span class="math notranslate nohighlight">\(|x| \le \sqrt{2}\)</span>, we can use <span class="math notranslate nohighlight">\(\ell(x) = (1 - x^2/2)/\sqrt{2\pi}\)</span> as a squeeze function for the standard normal density within <span class="math notranslate nohighlight">\([-\sqrt{2}, \sqrt{2}]\)</span>. This avoids the exponential evaluation for about 61% of proposals when using a Cauchy envelope.</p>
</div>
</section>
</section>
<section id="geometric-example-sampling-from-the-unit-disk">
<h2>Geometric Example: Sampling from the Unit Disk<a class="headerlink" href="#geometric-example-sampling-from-the-unit-disk" title="Link to this heading"></a></h2>
<p>A classic application of rejection sampling is generating points uniformly distributed in a geometric region. Consider sampling uniformly from the unit disk <span class="math notranslate nohighlight">\(\{(x, y) : x^2 + y^2 \le 1\}\)</span>.</p>
<p><strong>Target</strong>: Uniform distribution on the disk (density <span class="math notranslate nohighlight">\(f(x,y) = 1/\pi\)</span> inside, 0 outside)</p>
<p><strong>Proposal</strong>: Uniform on the bounding square <span class="math notranslate nohighlight">\([-1, 1]^2\)</span> (density <span class="math notranslate nohighlight">\(g(x,y) = 1/4\)</span>)</p>
<p><strong>Envelope constant</strong>: Inside the disk, <span class="math notranslate nohighlight">\(f(x,y)/g(x,y) = (1/\pi)/(1/4) = 4/\pi\)</span>, so <span class="math notranslate nohighlight">\(M = 4/\pi \approx 1.273\)</span>.</p>
<p><strong>Acceptance rate (Case 1, normalized)</strong>: <span class="math notranslate nohighlight">\(1/M = \pi/4 \approx 78.5\%\)</span>, which equals the ratio of areas (disk area <span class="math notranslate nohighlight">\(\pi\)</span> divided by square area 4).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sample_unit_disk</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample uniformly from the unit disk via rejection.</span>

<span class="sd">    Uses normalized densities, so acceptance rate = 1/M = π/4 ≈ 78.5%.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="c1"># Propose from uniform square [-1, 1]²</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Accept if inside disk</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="o">*</span><span class="n">y</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposals</span>

<span class="c1"># Generate 10,000 points</span>
<span class="n">points</span><span class="p">,</span> <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">sample_unit_disk</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate: </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (theory: π/4 = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">4</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Points shape: </span><span class="si">{</span><span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Acceptance</span> <span class="n">rate</span><span class="p">:</span> <span class="mf">0.785</span> <span class="p">(</span><span class="n">theory</span><span class="p">:</span> <span class="n">π</span><span class="o">/</span><span class="mi">4</span> <span class="o">=</span> <span class="mf">0.785</span><span class="p">)</span>
<span class="n">Points</span> <span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>This “hit-and-miss” approach generalizes to any region where membership can be tested: sample from a bounding box and reject points outside the target region. The efficiency depends on how well the bounding box fits the region.</p>
<figure class="align-center" id="id9">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_5_fig02_unit_disk.png"><img alt="Rejection sampling for uniform disk: accepted points inside circle, rejected in corners" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_5_fig02_unit_disk.png" style="width: 70%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 67 </span><span class="caption-text"><strong>Rejection Sampling for the Unit Disk (Normalized Densities).</strong> Blue points are accepted (inside disk); red points are rejected (in square corners). Using normalized densities <span class="math notranslate nohighlight">\(f = 1/\pi\)</span> and <span class="math notranslate nohighlight">\(g = 1/4\)</span>, the acceptance rate is <span class="math notranslate nohighlight">\(1/M = \pi/4 \approx 78.5\%\)</span>.</span><a class="headerlink" href="#id9" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="worked-examples">
<h2>Worked Examples<a class="headerlink" href="#worked-examples" title="Link to this heading"></a></h2>
<p>We now apply rejection sampling to several important scenarios, explicitly noting whether we use normalized or unnormalized targets.</p>
<section id="example-1-truncated-normal-distribution">
<h3>Example 1: Truncated Normal Distribution<a class="headerlink" href="#example-1-truncated-normal-distribution" title="Link to this heading"></a></h3>
<p>A truncated normal distribution restricts the standard normal to an interval <span class="math notranslate nohighlight">\([a, b]\)</span>. When <span class="math notranslate nohighlight">\([a, b]\)</span> lies in the tails, inversion methods become numerically unstable, but rejection sampling offers a simple solution.</p>
<p><strong>Target (unnormalized kernel)</strong>: <span class="math notranslate nohighlight">\(\tilde{f}(x) = \phi(x) \cdot \mathbf{1}\{a \le x \le b\}\)</span></p>
<p><strong>Normalizing constant</strong>: <span class="math notranslate nohighlight">\(C = \Phi(b) - \Phi(a)\)</span></p>
<p><strong>Proposal</strong>: The untruncated normal <span class="math notranslate nohighlight">\(g(x) = \phi(x)\)</span></p>
<p><strong>Envelope</strong>: Since <span class="math notranslate nohighlight">\(\tilde{f}(x) = \phi(x)\)</span> when <span class="math notranslate nohighlight">\(x \in [a, b]\)</span> and 0 otherwise, we have <span class="math notranslate nohighlight">\(\tilde{f}(x) \le g(x)\)</span>, so <span class="math notranslate nohighlight">\(M = 1\)</span>.</p>
<p><strong>Acceptance rate (Case 2, unnormalized)</strong>: <span class="math notranslate nohighlight">\(P(\text{accept}) = C/M = \Phi(b) - \Phi(a)\)</span>.</p>
<p><strong>Acceptance criterion</strong>: Accept <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(0, 1)\)</span> if <span class="math notranslate nohighlight">\(a \le X \le b\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">truncated_normal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample from N(0,1) truncated to [a, b] via rejection.</span>

<span class="sd">    Using unnormalized kernel, so acceptance rate = C/M = Φ(b) - Φ(a).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">()</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;=</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">b</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># C = Φ(b) - Φ(a), M = 1, so P(accept) = C/M = C</span>
    <span class="n">theoretical_rate</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">actual_rate</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_proposals</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">actual_rate</span><span class="p">,</span> <span class="n">theoretical_rate</span>

<span class="c1"># Example: truncate to [1, 3] (right tail)</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">theory</span> <span class="o">=</span> <span class="n">truncated_normal</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Truncated N(0,1) to [1, 3]:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Theoretical acceptance rate (C/M): </span><span class="si">{</span><span class="n">theory</span><span class="si">:</span><span class="s2">.3%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Actual acceptance rate: </span><span class="si">{</span><span class="n">actual</span><span class="si">:</span><span class="s2">.3%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample mean: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Truncated</span> <span class="n">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="n">to</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]:</span>
  <span class="n">Theoretical</span> <span class="n">acceptance</span> <span class="n">rate</span> <span class="p">(</span><span class="n">C</span><span class="o">/</span><span class="n">M</span><span class="p">):</span> <span class="mf">15.7</span><span class="o">%</span>
  <span class="n">Actual</span> <span class="n">acceptance</span> <span class="n">rate</span><span class="p">:</span> <span class="mf">15.8</span><span class="o">%</span>
  <span class="n">Sample</span> <span class="n">mean</span><span class="p">:</span> <span class="mf">1.5239</span>
</pre></div>
</div>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><strong>Extreme truncation</strong>: If <span class="math notranslate nohighlight">\([a, b]\)</span> lies far in the tail (e.g., <span class="math notranslate nohighlight">\([4, 6]\)</span>), the acceptance rate becomes tiny: <span class="math notranslate nohighlight">\(\Phi(6) - \Phi(4) \approx 0.003\%\)</span>. For extreme truncation, use specialized algorithms like Robert’s exponential tilting method or inverse CDF with careful numerical handling.</p>
</div>
</section>
<section id="example-2-gamma-distribution">
<h3>Example 2: Gamma Distribution<a class="headerlink" href="#example-2-gamma-distribution" title="Link to this heading"></a></h3>
<p>The Gamma distribution with non-integer shape parameter has no simple transformation from uniforms. Rejection sampling provides an efficient solution.</p>
<p><strong>Target</strong>: <span class="math notranslate nohighlight">\(\text{Gamma}(\alpha, 1)\)</span> with <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span></p>
<p>For <span class="math notranslate nohighlight">\(\alpha \ge 1\)</span>, Ahrens-Dieter and other algorithms use rejection with carefully chosen envelopes. Here’s a simplified version using an exponential proposal for <span class="math notranslate nohighlight">\(\alpha \ge 1\)</span>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">gamma_rejection</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample Gamma(alpha, 1) using rejection with exponential envelope.</span>

<span class="sd">    Uses normalized densities throughout.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">alpha</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Use transformation: Gamma(alpha) = Gamma(alpha+1) * U^(1/alpha)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">gamma_rejection</span><span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span> <span class="o">*</span> <span class="n">u</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">alpha</span><span class="p">)</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># For alpha &gt;= 1, use exponential(1/alpha) as proposal</span>
    <span class="n">rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">alpha</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># M = f(mode) / g(mode) where both are normalized</span>
    <span class="n">f_mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">**</span><span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">mode</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">g_mode</span> <span class="o">=</span> <span class="n">rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rate</span> <span class="o">*</span> <span class="n">mode</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">f_mode</span> <span class="o">/</span> <span class="n">g_mode</span> <span class="o">*</span> <span class="mf">1.01</span>  <span class="c1"># safety margin</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">rate</span><span class="p">)</span>  <span class="c1"># Exp(rate) sample</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Both pdfs normalized</span>
        <span class="n">f_x</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">g_x</span> <span class="o">=</span> <span class="n">rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rate</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">f_x</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">g_x</span><span class="p">):</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Case 1 (normalized): acceptance = 1/M</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gamma(</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">): acceptance rate = </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">/</span><span class="n">n_proposals</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> (theory: 1/M = </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

<span class="c1"># Test</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">gamma_rejection</span><span class="p">(</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample mean: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (theory: 2.5)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample var:  </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (theory: 2.5)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="example-3-custom-posterior-distribution-unnormalized">
<h3>Example 3: Custom Posterior Distribution (Unnormalized)<a class="headerlink" href="#example-3-custom-posterior-distribution-unnormalized" title="Link to this heading"></a></h3>
<p>Rejection sampling shines in Bayesian inference where posteriors are known only up to proportionality.</p>
<p><strong>Scenario</strong>: Binomial likelihood with Beta prior yields Beta posterior, but suppose we want to apply rejection sampling without recognizing the conjugate form.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">bayesian_posterior_rejection</span><span class="p">(</span><span class="n">n_successes</span><span class="p">,</span> <span class="n">n_trials</span><span class="p">,</span> <span class="n">prior_alpha</span><span class="p">,</span> <span class="n">prior_beta</span><span class="p">,</span>
                                 <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample from posterior of Binomial parameter θ using UNNORMALIZED kernel.</span>

<span class="sd">    Prior: θ ~ Beta(prior_alpha, prior_beta)</span>
<span class="sd">    Likelihood: X | θ ~ Binomial(n_trials, θ)</span>
<span class="sd">    Posterior kernel: tilde{f}(θ) ∝ θ^(α + x - 1) (1-θ)^(β + n - x - 1)</span>

<span class="sd">    Since kernel is unnormalized, acceptance rate = C/M.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Posterior kernel (unnormalized)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">posterior_kernel</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">theta</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">theta</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">theta</span><span class="o">**</span><span class="p">(</span><span class="n">prior_alpha</span> <span class="o">+</span> <span class="n">n_successes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span>
                <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">prior_beta</span> <span class="o">+</span> <span class="n">n_trials</span> <span class="o">-</span> <span class="n">n_successes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Use uniform proposal on [0, 1]</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">kernel_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">posterior_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_grid</span><span class="p">]</span>
    <span class="n">M</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">kernel_vals</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.01</span>

    <span class="c1"># True posterior is Beta(α + x, β + n - x)</span>
    <span class="n">post_alpha</span> <span class="o">=</span> <span class="n">prior_alpha</span> <span class="o">+</span> <span class="n">n_successes</span>
    <span class="n">post_beta</span> <span class="o">=</span> <span class="n">prior_beta</span> <span class="o">+</span> <span class="n">n_trials</span> <span class="o">-</span> <span class="n">n_successes</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">post_alpha</span><span class="p">,</span> <span class="n">post_beta</span><span class="p">)</span>  <span class="c1"># Normalizing constant</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>  <span class="c1"># Uniform(0, 1)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">posterior_kernel</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">/</span> <span class="n">M</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

    <span class="n">actual_rate</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposals</span>
    <span class="n">theoretical_rate</span> <span class="o">=</span> <span class="n">C</span> <span class="o">/</span> <span class="n">M</span>  <span class="c1"># Case 2: unnormalized</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate: actual = </span><span class="si">{</span><span class="n">actual_rate</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">, theory (C/M) = </span><span class="si">{</span><span class="n">theoretical_rate</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">actual_rate</span>

<span class="c1"># Example: 7 successes in 10 trials, uniform prior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">special</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">bayesian_posterior_rejection</span><span class="p">(</span>
    <span class="n">n_successes</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">prior_alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">prior_beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># uniform prior</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># True posterior is Beta(8, 4)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Posterior mean: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="mi">8</span><span class="o">/</span><span class="mi">12</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="limitations-and-the-curse-of-dimensionality">
<h2>Limitations and the Curse of Dimensionality<a class="headerlink" href="#limitations-and-the-curse-of-dimensionality" title="Link to this heading"></a></h2>
<p>Rejection sampling is elegant and exact, but it has fundamental limitations.</p>
<section id="the-high-dimensional-problem">
<h3>The High-Dimensional Problem<a class="headerlink" href="#the-high-dimensional-problem" title="Link to this heading"></a></h3>
<p>In <span class="math notranslate nohighlight">\(d\)</span> dimensions, the envelope condition becomes:</p>
<div class="math notranslate nohighlight">
\[\tilde{f}(\mathbf{x}) \le M \cdot g(\mathbf{x}) \quad \text{for all } \mathbf{x} \in \mathbb{R}^d\]</div>
<p>The acceptance probability is still <span class="math notranslate nohighlight">\(C/M\)</span> (or <span class="math notranslate nohighlight">\(1/M\)</span> for normalized targets), but now <span class="math notranslate nohighlight">\(M\)</span> often grows exponentially with dimension.</p>
<p><strong>Example</strong>: Target is <span class="math notranslate nohighlight">\(\mathcal{N}(\mathbf{0}, \mathbf{I}_d)\)</span> and proposal is <span class="math notranslate nohighlight">\(\mathcal{N}(\mathbf{0}, \sigma^2 \mathbf{I}_d)\)</span> with <span class="math notranslate nohighlight">\(\sigma &gt; 1\)</span>. The ratio <span class="math notranslate nohighlight">\(f(\mathbf{x})/g(\mathbf{x})\)</span> involves:</p>
<div class="math notranslate nohighlight">
\[\frac{f(\mathbf{x})}{g(\mathbf{x})} = \sigma^d \exp\left[-\frac{\|\mathbf{x}\|^2}{2}\left(1 - \frac{1}{\sigma^2}\right)\right]\]</div>
<p>The maximum occurs at <span class="math notranslate nohighlight">\(\mathbf{x} = \mathbf{0}\)</span>, giving <span class="math notranslate nohighlight">\(M = \sigma^d\)</span>. For <span class="math notranslate nohighlight">\(\sigma = 1.5\)</span> and <span class="math notranslate nohighlight">\(d = 20\)</span>, this is <span class="math notranslate nohighlight">\(1.5^{20} \approx 3,300\)</span>—a 0.03% acceptance rate!</p>
<p><strong>Rule of thumb</strong>: Rejection sampling is usually practical for <span class="math notranslate nohighlight">\(d \le 5\)</span>, sometimes up to <span class="math notranslate nohighlight">\(d \approx 10\)</span> with carefully matched proposals and mixtures, and rarely beyond.</p>
</section>
<section id="when-rejection-sampling-fails">
<h3>When Rejection Sampling Fails<a class="headerlink" href="#when-rejection-sampling-fails" title="Link to this heading"></a></h3>
<p>Rejection sampling becomes impractical when:</p>
<ol class="arabic simple">
<li><p><strong>High dimensions</strong>: The curse of dimensionality makes finding a tight envelope nearly impossible.</p></li>
<li><p><strong>Multimodal targets</strong>: A single proposal struggles to cover well-separated modes without huge <span class="math notranslate nohighlight">\(M\)</span>.</p></li>
<li><p><strong>Heavy tails with light-tailed proposals</strong>: If <span class="math notranslate nohighlight">\(\tilde{f}(x)/g(x) \to \infty\)</span> as <span class="math notranslate nohighlight">\(|x| \to \infty\)</span>, no finite <span class="math notranslate nohighlight">\(M\)</span> exists.</p></li>
<li><p><strong>Unknown mode location</strong>: Without knowing where the target is concentrated, any proposal is a guess.</p></li>
</ol>
<p><strong>Mixture proposals for multimodal targets</strong>: When the target has <span class="math notranslate nohighlight">\(K\)</span> well-separated modes, use a mixture proposal <span class="math notranslate nohighlight">\(g(x) = \sum_{k=1}^K w_k g_k(x)\)</span> where each component <span class="math notranslate nohighlight">\(g_k\)</span> covers one mode. Compute <span class="math notranslate nohighlight">\(M = \sup_x \tilde{f}(x)/g(x)\)</span> numerically. If each component <span class="math notranslate nohighlight">\(g_k\)</span> dominates the target in its region with constant <span class="math notranslate nohighlight">\(M_k\)</span>, a practical (though conservative) bound is <span class="math notranslate nohighlight">\(M \le \sum_k M_k\)</span>. This approach dramatically improves efficiency compared to a single broad proposal.</p>
<p><strong>Practical guideline</strong>: Rejection sampling works well for <span class="math notranslate nohighlight">\(d \le 5\)</span> or so. For higher dimensions, consider Markov Chain Monte Carlo (Metropolis-Hastings, Gibbs sampling) which we develop in later chapters.</p>
</section>
</section>
<section id="connections-to-other-methods">
<h2>Connections to Other Methods<a class="headerlink" href="#connections-to-other-methods" title="Link to this heading"></a></h2>
<p>Rejection sampling is the ancestor of several more sophisticated techniques.</p>
<section id="importance-sampling">
<h3>Importance Sampling<a class="headerlink" href="#importance-sampling" title="Link to this heading"></a></h3>
<p>Where rejection sampling discards proposals that don’t pass the acceptance test, <strong>importance sampling</strong> keeps all proposals but assigns them weights:</p>
<div class="math notranslate nohighlight">
\[w(x) = \frac{\tilde{f}(x)}{g(x)}\]</div>
<p>Expectations are then computed as weighted averages. Importance sampling avoids discarding samples but requires careful handling of weight variability. We develop this in detail in <span class="xref std std-ref">ch2.6-variance-reduction</span>.</p>
</section>
<section id="markov-chain-monte-carlo">
<h3>Markov Chain Monte Carlo<a class="headerlink" href="#markov-chain-monte-carlo" title="Link to this heading"></a></h3>
<p>The Metropolis-Hastings algorithm generalizes rejection sampling to create a Markov chain whose stationary distribution is the target. Instead of independent proposals, it uses sequential proposals from a transition kernel. Rejected proposals don’t disappear—the chain stays at its current position. This modification allows MCMC to work efficiently in high dimensions where direct rejection sampling fails. See Chapter 5 for full development.</p>
</section>
<section id="adaptive-rejection-sampling">
<h3>Adaptive Rejection Sampling<a class="headerlink" href="#adaptive-rejection-sampling" title="Link to this heading"></a></h3>
<p>For <strong>log-concave</strong> densities (densities <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> where <span class="math notranslate nohighlight">\(\log \tilde{f}(x)\)</span> is concave), the ARS algorithm <a class="reference internal" href="#gilkswild1992" id="id4"><span>[GilksWild1992]</span></a> constructs an envelope <em>adaptively</em> during sampling. The key insight is that tangent lines to a concave function lie above the function, while secant lines lie below.</p>
<p><strong>Log-concave examples</strong>: Many important distributions are log-concave:</p>
<ul class="simple">
<li><p>Normal: <span class="math notranslate nohighlight">\(\log \phi(x) \propto -x^2/2\)</span> (concave parabola)</p></li>
<li><p>Exponential: <span class="math notranslate nohighlight">\(\log(\lambda e^{-\lambda x}) \propto -\lambda x\)</span> (linear, hence concave)</p></li>
<li><p>Gamma with <span class="math notranslate nohighlight">\(\alpha \ge 1\)</span>: <span class="math notranslate nohighlight">\(\log f(x) \propto (\alpha-1)\log x - x\)</span> (concave for <span class="math notranslate nohighlight">\(\alpha \ge 1\)</span>)</p></li>
<li><p>Beta with <span class="math notranslate nohighlight">\(\alpha, \beta \ge 1\)</span>: log-concave on <span class="math notranslate nohighlight">\((0, 1)\)</span></p></li>
<li><p>Logistic, log-normal truncated appropriately</p></li>
</ul>
<p><strong>The ARS algorithm</strong>:</p>
<ol class="arabic simple">
<li><p>Initialize with a few points <span class="math notranslate nohighlight">\(S_n = \{x_0, x_1, \ldots, x_n\}\)</span> where <span class="math notranslate nohighlight">\(\log \tilde{f}(x_i)\)</span> is known.</p></li>
<li><p>Construct <strong>upper envelope</strong> <span class="math notranslate nohighlight">\(\bar{h}_n(x)\)</span>: piecewise linear, connecting tangent lines at <span class="math notranslate nohighlight">\(x_i\)</span>. By concavity, this lies above <span class="math notranslate nohighlight">\(\log \tilde{f}(x)\)</span>.</p></li>
<li><p>Construct <strong>lower envelope</strong> <span class="math notranslate nohighlight">\(\underline{h}_n(x)\)</span>: piecewise linear through <span class="math notranslate nohighlight">\((x_i, \log \tilde{f}(x_i))\)</span>. By concavity, this lies below <span class="math notranslate nohighlight">\(\log \tilde{f}(x)\)</span>.</p></li>
<li><p>Sample from <span class="math notranslate nohighlight">\(g_n(x) \propto \exp(\bar{h}_n(x))\)</span> (piecewise exponential, easy to sample).</p></li>
<li><p><strong>Squeeze test</strong>: If <span class="math notranslate nohighlight">\(U \le \exp(\underline{h}_n(X) - \bar{h}_n(X))\)</span>, accept immediately.</p></li>
<li><p><strong>Full test</strong>: Otherwise, evaluate <span class="math notranslate nohighlight">\(\tilde{f}(X)\)</span> and accept if <span class="math notranslate nohighlight">\(U \le \tilde{f}(X)/g_n(X)\)</span>.</p></li>
<li><p><strong>Adapt</strong>: If rejected (or if <span class="math notranslate nohighlight">\(\tilde{f}(X)\)</span> was evaluated), add <span class="math notranslate nohighlight">\(X\)</span> to <span class="math notranslate nohighlight">\(S_n\)</span>, tightening future envelopes.</p></li>
</ol>
<p>The adaptive nature means efficiency improves as sampling progresses—early rejections contribute information that speeds later sampling. ARS is particularly valuable within Gibbs samplers where full conditionals are often log-concave.</p>
<p><strong>Limitation</strong>: ARS requires log-concavity. For non-log-concave targets (e.g., mixture distributions, heavy-tailed posteriors), the algorithm fails. The ARMS extension <a class="reference internal" href="#gilksetal1995" id="id5"><span>[GilksEtAl1995]</span></a> handles non-log-concave targets by adding a Metropolis-Hastings correction step.</p>
</section>
</section>
<section id="practical-considerations">
<h2>Practical Considerations<a class="headerlink" href="#practical-considerations" title="Link to this heading"></a></h2>
<section id="numerical-stability">
<h3>Numerical Stability<a class="headerlink" href="#numerical-stability" title="Link to this heading"></a></h3>
<p>Several numerical issues can arise:</p>
<ol class="arabic simple">
<li><p><strong>Underflow in density ratios</strong>: When <span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> is very small, <span class="math notranslate nohighlight">\(\tilde{f}(x)/[M \cdot g(x)]\)</span> may underflow to zero. Work with log-densities: accept if <span class="math notranslate nohighlight">\(\log U \le \log \tilde{f}(x) - \log M - \log g(x)\)</span>.</p></li>
<li><p><strong>Overflow in unnormalized densities</strong>: Large exponents can overflow. Again, log-densities help.</p></li>
<li><p><strong>Zero proposal density</strong>: If <span class="math notranslate nohighlight">\(g(x) = 0\)</span> at a point where <span class="math notranslate nohighlight">\(\tilde{f}(x) &gt; 0\)</span>, the ratio is undefined. Ensure proposal support covers target support.</p></li>
</ol>
<p><strong>Log-space implementation</strong> for numerical stability:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">rejection_sample_log</span><span class="p">(</span><span class="n">log_target</span><span class="p">,</span> <span class="n">log_proposal</span><span class="p">,</span> <span class="n">proposal_sampler</span><span class="p">,</span>
                         <span class="n">log_M</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rejection sampling using log-densities for numerical stability.</span>

<span class="sd">    Accept if log(U) &lt;= log_target(x) - log_M - log_proposal(x)</span>

<span class="sd">    Works for both normalized and unnormalized log_target.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">proposal_sampler</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">log_u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>  <span class="c1"># log(U) where U ~ Uniform(0,1)</span>

        <span class="n">log_accept_prob</span> <span class="o">=</span> <span class="n">log_target</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_M</span> <span class="o">-</span> <span class="n">log_proposal</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">log_u</span> <span class="o">&lt;=</span> <span class="n">log_accept_prob</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<p>This approach handles densities that would otherwise cause overflow or underflow in direct computation.</p>
</section>
<section id="verifying-correctness">
<h3>Verifying Correctness<a class="headerlink" href="#verifying-correctness" title="Link to this heading"></a></h3>
<p>Always verify your rejection sampler:</p>
<ol class="arabic simple">
<li><p><strong>Check acceptance rate</strong>: Compare actual rate to theoretical <span class="math notranslate nohighlight">\(1/M\)</span> (normalized) or <span class="math notranslate nohighlight">\(C/M\)</span> (unnormalized).</p></li>
<li><p><strong>Compare moments</strong>: Sample mean and variance should match theoretical values.</p></li>
<li><p><strong>Visual comparison</strong>: Histogram of samples should match theoretical density.</p></li>
<li><p><strong>Kolmogorov-Smirnov test</strong>: Statistical test for distribution match.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">verify_rejection_sampler</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">true_dist</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">is_normalized</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Verify rejection samples against known distribution.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    is_normalized : bool</span>
<span class="sd">        If True, expected rate is 1/M. If False, expected rate is C/M.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> verification:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample mean: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Theory: </span><span class="si">{</span><span class="n">true_dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample std:  </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Theory: </span><span class="si">{</span><span class="n">true_dist</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># KS test</span>
    <span class="n">ks_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">true_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  KS statistic: </span><span class="si">{</span><span class="n">ks_stat</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  WARNING: KS test suggests samples may not match target!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="production-diagnostics">
<h3>Production Diagnostics<a class="headerlink" href="#production-diagnostics" title="Link to this heading"></a></h3>
<p>For production use, a sampler with built-in monitoring helps detect issues:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RejectionSamplerWithDiagnostics</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Rejection sampler with performance monitoring.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_sampler</span><span class="p">,</span> <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                 <span class="n">is_normalized</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        is_normalized : bool</span>
<span class="sd">            If True, expect acceptance = 1/M. If False, expect C/M.</span>
<span class="sd">        C : float, optional</span>
<span class="sd">            Normalizing constant (required if is_normalized=False).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_pdf</span> <span class="o">=</span> <span class="n">target_pdf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proposal_sampler</span> <span class="o">=</span> <span class="n">proposal_sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proposal_pdf</span> <span class="o">=</span> <span class="n">proposal_pdf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="n">M</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_normalized</span> <span class="o">=</span> <span class="n">is_normalized</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">C</span> <span class="k">if</span> <span class="n">C</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">1.0</span>

        <span class="c1"># Diagnostics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_accepted</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acceptance_history</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample with batch monitoring.&quot;&quot;&quot;</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">:</span>
            <span class="n">batch_accepted</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">+</span> <span class="mi">100</span><span class="p">)):</span>
                <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proposal_sampler</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_proposed</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
                <span class="n">accept_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_pdf</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">proposal_pdf</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

                <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">accept_prob</span><span class="p">:</span>
                    <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n_accepted</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">batch_accepted</span> <span class="o">+=</span> <span class="mi">1</span>

                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">size</span><span class="p">:</span>
                        <span class="k">break</span>

            <span class="c1"># Record batch acceptance rate</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">acceptance_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_accepted</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">[:</span><span class="n">size</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_diagnostics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return sampling diagnostics.&quot;&quot;&quot;</span>
        <span class="n">actual_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_accepted</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_proposed</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_proposed</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_normalized</span><span class="p">:</span>
            <span class="n">theoretical_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">theoretical_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;n_proposed&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_proposed</span><span class="p">,</span>
            <span class="s1">&#39;n_accepted&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_accepted</span><span class="p">,</span>
            <span class="s1">&#39;actual_acceptance_rate&#39;</span><span class="p">:</span> <span class="n">actual_rate</span><span class="p">,</span>
            <span class="s1">&#39;theoretical_rate&#39;</span><span class="p">:</span> <span class="n">theoretical_rate</span><span class="p">,</span>
            <span class="s1">&#39;efficiency&#39;</span><span class="p">:</span> <span class="n">actual_rate</span> <span class="o">/</span> <span class="n">theoretical_rate</span><span class="p">,</span>  <span class="c1"># Should be ≈ 1</span>
            <span class="s1">&#39;acceptance_history&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">acceptance_history</span><span class="p">,</span>
            <span class="s1">&#39;case&#39;</span><span class="p">:</span> <span class="s1">&#39;normalized (1/M)&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_normalized</span> <span class="k">else</span> <span class="sa">f</span><span class="s1">&#39;unnormalized (C/M, C=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">)&#39;</span>
        <span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">efficiency</span></code> metric should be close to 1.0; significant deviations indicate either an incorrect <span class="math notranslate nohighlight">\(M\)</span> or implementation bugs.</p>
</section>
</section>
<section id="chapter-2-5-exercises-rejection-sampling-mastery">
<h2>Chapter 2.5 Exercises: Rejection Sampling Mastery<a class="headerlink" href="#chapter-2-5-exercises-rejection-sampling-mastery" title="Link to this heading"></a></h2>
<p>These exercises build your understanding of rejection sampling from geometric intuition through practical implementation to recognizing its limitations. Each exercise connects the theoretical foundation to computational practice.</p>
<div class="tip admonition">
<p class="admonition-title">A Note on These Exercises</p>
<p>These exercises are designed to deepen your understanding of rejection sampling through hands-on exploration:</p>
<ul class="simple">
<li><p><strong>Exercise 1</strong> verifies the fundamental theorem of simulation—that points under a curve have marginals following that density</p></li>
<li><p><strong>Exercise 2</strong> explores envelope constant computation, sensitivity, and the consequences of getting M wrong</p></li>
<li><p><strong>Exercise 3</strong> compares proposal distributions and develops intuition for efficient proposal selection</p></li>
<li><p><strong>Exercise 4</strong> implements the squeeze principle to accelerate sampling with expensive target evaluations</p></li>
<li><p><strong>Exercise 5</strong> demonstrates the curse of dimensionality through direct experimentation</p></li>
<li><p><strong>Exercise 6</strong> applies rejection sampling to Bayesian inference with unnormalized posteriors</p></li>
</ul>
<p>Complete solutions with derivations, code, output, and interpretation are provided. Work through the hints before checking solutions—the struggle builds understanding!</p>
</div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 1: The Fundamental Theorem of Simulation</p>
<p>The theoretical foundation of rejection sampling rests on a beautiful geometric fact: if points <span class="math notranslate nohighlight">\((X, U)\)</span> are uniformly distributed over the region under a density curve <span class="math notranslate nohighlight">\(f(x)\)</span>, then <span class="math notranslate nohighlight">\(X\)</span> has density <span class="math notranslate nohighlight">\(f(x)\)</span>. This exercise verifies this principle empirically.</p>
<div class="note admonition">
<p class="admonition-title">Background: Points Under a Curve</p>
<p>For any density <span class="math notranslate nohighlight">\(f(x)\)</span>, the identity <span class="math notranslate nohighlight">\(f(x) = \int_0^{f(x)} du\)</span> implies that uniform samples from the set <span class="math notranslate nohighlight">\(\{(x,u): 0 &lt; u &lt; f(x)\}\)</span> have <span class="math notranslate nohighlight">\(x\)</span>-marginals distributed as <span class="math notranslate nohighlight">\(f\)</span>. This observation transforms the abstract problem of sampling from <span class="math notranslate nohighlight">\(f\)</span> into the geometric problem of sampling uniformly from a region.</p>
</div>
<ol class="loweralpha">
<li><p><strong>Direct verification for Exponential(1)</strong>: Generate 100,000 points uniformly distributed in the region under the Exponential(1) density <span class="math notranslate nohighlight">\(f(x) = e^{-x}\)</span> for <span class="math notranslate nohighlight">\(x \geq 0\)</span>. Extract the <span class="math notranslate nohighlight">\(x\)</span>-coordinates and verify they follow Exponential(1) using:</p>
<ul class="simple">
<li><p>Sample mean and variance (theory: both equal 1)</p></li>
<li><p>K-S test against Exponential(1)</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Hint: Sampling Under the Curve</p>
<p>Use rejection from a bounding box. For Exponential(1), the maximum density is <span class="math notranslate nohighlight">\(f(0) = 1\)</span>. Sample <span class="math notranslate nohighlight">\(X \sim \text{Uniform}(0, x_{\max})\)</span> and <span class="math notranslate nohighlight">\(U \sim \text{Uniform}(0, 1)\)</span>, accepting when <span class="math notranslate nohighlight">\(U &lt; e^{-X}\)</span>. Choose <span class="math notranslate nohighlight">\(x_{\max}\)</span> large enough to capture most of the mass (e.g., <span class="math notranslate nohighlight">\(x_{\max} = 10\)</span>).</p>
</div>
</li>
<li><p><strong>Verify for Beta(2, 5)</strong>: Repeat for Beta(2, 5) on <span class="math notranslate nohighlight">\([0, 1]\)</span>. Sample uniformly from the region under the density and verify the <span class="math notranslate nohighlight">\(x\)</span>-marginals match the theoretical distribution.</p></li>
<li><p><strong>Visualize the geometry</strong>: Create a scatter plot of 5,000 accepted <span class="math notranslate nohighlight">\((x, u)\)</span> pairs for Beta(2, 5), overlaid with the density curve. Explain why the point density varies across the plot.</p></li>
<li><p><strong>Unnormalized case</strong>: The theorem works for unnormalized kernels too. Generate points under <span class="math notranslate nohighlight">\(\tilde{f}(x) = x^2 e^{-x}\)</span> (unnormalized Gamma(3,1) kernel) and verify the <span class="math notranslate nohighlight">\(x\)</span>-marginals follow Gamma(3, 1).</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Exponential(1) Verification</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sample_under_exponential</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">x_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample uniformly from the region under f(x) = exp(-x).</span>

<span class="sd">    Uses rejection from bounding rectangle [0, x_max] × [0, 1].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">x_coords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">u_coords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_coords</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_coords</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># Uniform(0, 1) since max density is 1</span>
        <span class="n">n_proposed</span> <span class="o">+=</span> <span class="n">batch</span>

        <span class="c1"># Accept if u &lt; f(x) = exp(-x)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_coords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
        <span class="n">u_coords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_coords</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">u_coords</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]),</span>
            <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposed</span><span class="p">)</span>

<span class="c1"># Generate samples</span>
<span class="n">x_samples</span><span class="p">,</span> <span class="n">u_samples</span><span class="p">,</span> <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">sample_under_exponential</span><span class="p">(</span><span class="mi">100_000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FUNDAMENTAL THEOREM VERIFICATION: EXPONENTIAL(1)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sampling from region under f(x) = exp(-x)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate: </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  (Theory: area under exp(-x) from 0 to 10 / box area = </span><span class="si">{</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="c1"># Verify x-marginals</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">X-marginal statistics:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: 1.0)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: 1.0)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Std: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: 1.0)&quot;</span><span class="p">)</span>

<span class="c1"># K-S test</span>
<span class="n">ks_stat</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">x_samples</span><span class="p">,</span> <span class="s1">&#39;expon&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">K-S test against Exponential(1):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Statistic: </span><span class="si">{</span><span class="n">ks_stat</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  p-value: </span><span class="si">{</span><span class="n">p_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Conclusion: </span><span class="si">{</span><span class="s1">&#39;PASS&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">p_val</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.05</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;FAIL&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>FUNDAMENTAL THEOREM VERIFICATION: EXPONENTIAL(1)
============================================================

Sampling from region under f(x) = exp(-x)
Acceptance rate: 0.0999
  (Theory: area under exp(-x) from 0 to 10 / box area = 1.0000)

X-marginal statistics:
  Mean: 0.9987 (theory: 1.0)
  Variance: 0.9983 (theory: 1.0)
  Std: 0.9991 (theory: 1.0)

K-S test against Exponential(1):
  Statistic: 0.002134
  p-value: 0.7523
  Conclusion: PASS
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Beta(2, 5) Verification</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sample_under_beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample uniformly from the region under Beta(α, β) density.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">beta_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span><span class="p">)</span>

    <span class="c1"># Find maximum density for bounding box</span>
    <span class="n">x_mode</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">beta_param</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="n">alpha</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">beta_param</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">max_density</span> <span class="o">=</span> <span class="n">beta_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_mode</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.01</span>  <span class="c1"># Safety margin</span>

    <span class="n">x_coords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">u_coords</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_coords</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_coords</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>  <span class="c1"># Uniform(0, 1)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_density</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="n">n_proposed</span> <span class="o">+=</span> <span class="n">batch</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">beta_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_coords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
        <span class="n">u_coords</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_coords</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">u_coords</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]),</span>
            <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposed</span><span class="p">,</span>
            <span class="n">max_density</span><span class="p">)</span>

<span class="c1"># Generate samples</span>
<span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span>
<span class="n">x_samples</span><span class="p">,</span> <span class="n">u_samples</span><span class="p">,</span> <span class="n">acc_rate</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">sample_under_beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span><span class="p">,</span> <span class="mi">100_000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">beta_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">FUNDAMENTAL THEOREM VERIFICATION: BETA(2, 5)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bounding box height M = </span><span class="si">{</span><span class="n">M</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate: </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: 1/M = </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">X-marginal statistics:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="n">beta_dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="n">beta_dist</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="n">ks_stat</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">x_samples</span><span class="p">,</span> <span class="n">beta_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">K-S test: statistic = </span><span class="si">{</span><span class="n">ks_stat</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, p-value = </span><span class="si">{</span><span class="n">p_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>FUNDAMENTAL THEOREM VERIFICATION: BETA(2, 5)
============================================================

Bounding box height M = 2.0510
Acceptance rate: 0.4875 (theory: 1/M = 0.4876)

X-marginal statistics:
  Mean: 0.2858 (theory: 0.2857)
  Variance: 0.0252 (theory: 0.0255)

K-S test: statistic = 0.003456, p-value = 0.4123
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): Geometric Visualization</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">visualize_points_under_curve</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Visualize uniform points under Beta(2,5) density.&quot;&quot;&quot;</span>
    <span class="c1"># Generate fewer points for visualization</span>
    <span class="n">x_vis</span><span class="p">,</span> <span class="n">u_vis</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">sample_under_beta</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="c1"># Scatter plot of accepted points</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_vis</span><span class="p">,</span> <span class="n">u_vis</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;steelblue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Accepted points&#39;</span><span class="p">)</span>

    <span class="c1"># Overlay density curve</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_grid</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$f(x) = \frac{x(1-x)^4}{B(2,5)}$&#39;</span><span class="p">)</span>

    <span class="c1"># Bounding box</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">M</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;M = </span><span class="si">{</span><span class="n">M</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;u&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Uniform Points Under Beta(2,5) Density&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">M</span> <span class="o">+</span> <span class="mf">0.2</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;fundamental_theorem_visualization.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">GEOMETRIC INTERPRETATION:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The point density (points per unit area) is CONSTANT&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;throughout the region under the curve.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;However, the curve is higher in some places than others,&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;so more points appear in tall regions (near the mode)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;than in short regions (near the tails).&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;When we project onto the x-axis (take marginals),&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;regions with more vertical space contribute more points,&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;producing the correct f(x) distribution.&quot;</span><span class="p">)</span>

<span class="n">visualize_points_under_curve</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>GEOMETRIC INTERPRETATION:
--------------------------------------------------
The point density (points per unit area) is CONSTANT
throughout the region under the curve.

However, the curve is higher in some places than others,
so more points appear in tall regions (near the mode)
than in short regions (near the tails).

When we project onto the x-axis (take marginals),
regions with more vertical space contribute more points,
producing the correct f(x) distribution.
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Unnormalized Kernel</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sample_under_unnormalized_gamma</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from region under unnormalized Gamma(3,1) kernel.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Unnormalized kernel: f_tilde(x) = x^2 * exp(-x)</span>
    <span class="c1"># Maximum at x = 2: f_tilde(2) = 4 * exp(-2) ≈ 0.541</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">kernel</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>

    <span class="n">x_max</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># Cover most of the mass</span>
    <span class="n">max_kernel</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.01</span>

    <span class="n">x_samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">100_000</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="mi">50000</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_kernel</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="n">n_proposed</span> <span class="o">+=</span> <span class="n">batch</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">kernel</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_samples</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>

    <span class="n">x_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_samples</span><span class="p">[:</span><span class="mi">100_000</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">UNNORMALIZED KERNEL VERIFICATION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Kernel: f̃(x) = x² exp(-x) (unnormalized Gamma(3,1))&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Normalizing constant C = Γ(3) = 2! = 2&quot;</span><span class="p">)</span>

    <span class="n">gamma_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">X-marginal should follow Gamma(3, 1):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="n">gamma_dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="n">gamma_dist</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="n">ks_stat</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">x_samples</span><span class="p">,</span> <span class="n">gamma_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">K-S test: statistic = </span><span class="si">{</span><span class="n">ks_stat</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, p-value = </span><span class="si">{</span><span class="n">p_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Conclusion: </span><span class="si">{</span><span class="s1">&#39;Gamma(3,1) confirmed!&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">p_val</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.05</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;MISMATCH&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">sample_under_unnormalized_gamma</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>UNNORMALIZED KERNEL VERIFICATION
============================================================
Kernel: f̃(x) = x² exp(-x) (unnormalized Gamma(3,1))
Normalizing constant C = Γ(3) = 2! = 2

X-marginal should follow Gamma(3, 1):
  Mean: 3.0012 (theory: 3.0000)
  Variance: 2.9987 (theory: 3.0000)

K-S test: statistic = 0.002567, p-value = 0.5678
Conclusion: Gamma(3,1) confirmed!
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>Fundamental theorem in action</strong>: Uniform points under a density curve have x-marginals following that density—this is the geometric foundation of rejection sampling.</p></li>
<li><p class="sd-card-text"><strong>Works for unnormalized kernels</strong>: The x-marginals follow the <em>normalized</em> version of any kernel, even if we never compute the normalizing constant.</p></li>
<li><p class="sd-card-text"><strong>Visual intuition</strong>: More vertical space = more points = higher probability density. The uniform point density throughout the region transforms into the correct marginal distribution.</p></li>
</ol>
</div>
</details></div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 2: Envelope Constant Sensitivity and Verification</p>
<p>The envelope constant <span class="math notranslate nohighlight">\(M\)</span> is crucial for rejection sampling correctness and efficiency. This exercise explores how to compute, verify, and understand the consequences of incorrect <span class="math notranslate nohighlight">\(M\)</span> values.</p>
<div class="note admonition">
<p class="admonition-title">Background: The Critical Role of M</p>
<p>The envelope condition <span class="math notranslate nohighlight">\(f(x) \leq M \cdot g(x)\)</span> must hold for ALL <span class="math notranslate nohighlight">\(x\)</span> in the support. Using <span class="math notranslate nohighlight">\(M\)</span> too large wastes computation (low acceptance rate); using <span class="math notranslate nohighlight">\(M\)</span> too small produces biased samples (some regions underrepresented). The optimal <span class="math notranslate nohighlight">\(M^* = \sup_x f(x)/g(x)\)</span> achieves maximum efficiency while maintaining correctness.</p>
</div>
<ol class="loweralpha simple">
<li><p><strong>Compute M analytically</strong>: For target Beta(3, 2) and proposal Uniform(0, 1):</p>
<ul class="simple">
<li><p>Find the mode of Beta(3, 2) and compute <span class="math notranslate nohighlight">\(M^* = \max_x f(x)/g(x)\)</span></p></li>
<li><p>Verify using numerical optimization</p></li>
</ul>
</li>
<li><p><strong>Verify the envelope condition</strong>: Generate a fine grid of points and check that <span class="math notranslate nohighlight">\(f(x) \leq M \cdot g(x)\)</span> everywhere. Plot <span class="math notranslate nohighlight">\(f(x)\)</span> and <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span> together.</p></li>
<li><p><strong>What happens with M too small?</strong>: Set <span class="math notranslate nohighlight">\(M = 0.8 \cdot M^*\)</span> (deliberately violating the envelope condition). Generate samples and compare:</p>
<ul class="simple">
<li><p>Sample mean vs theoretical mean</p></li>
<li><p>K-S test (should fail!)</p></li>
<li><p>Which regions are undersampled?</p></li>
</ul>
</li>
<li><p><strong>What happens with M too large?</strong>: Set <span class="math notranslate nohighlight">\(M = 2 \cdot M^*\)</span>. Verify correctness (K-S test should pass) but measure efficiency loss.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Analytical M Computation</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span><span class="p">,</span> <span class="n">optimize</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_M_analytically</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute envelope constant for Beta(3,2) with Uniform proposal.&quot;&quot;&quot;</span>
    <span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span>

    <span class="c1"># Mode of Beta(α, β) for α, β &gt; 1</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">beta_param</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># = 2/3</span>

    <span class="n">beta_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span><span class="p">)</span>
    <span class="n">f_mode</span> <span class="o">=</span> <span class="n">beta_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>

    <span class="c1"># Uniform(0,1) has g(x) = 1</span>
    <span class="n">M_analytical</span> <span class="o">=</span> <span class="n">f_mode</span> <span class="o">/</span> <span class="mf">1.0</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ANALYTICAL M COMPUTATION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target: Beta(</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">beta_param</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Proposal: Uniform(0, 1), g(x) = 1&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Mode of Beta(</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">beta_param</span><span class="si">}</span><span class="s2">): x* = </span><span class="si">{</span><span class="n">mode</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;f(x*) = </span><span class="si">{</span><span class="n">f_mode</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;M* = f(x*) / g(x*) = </span><span class="si">{</span><span class="n">M_analytical</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Verify numerically</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">neg_ratio</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">beta_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize_scalar</span><span class="p">(</span><span class="n">neg_ratio</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;bounded&#39;</span><span class="p">)</span>
    <span class="n">M_numerical</span> <span class="o">=</span> <span class="o">-</span><span class="n">result</span><span class="o">.</span><span class="n">fun</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Numerical verification:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  M from optimization: </span><span class="si">{</span><span class="n">M_numerical</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Difference: </span><span class="si">{</span><span class="nb">abs</span><span class="p">(</span><span class="n">M_analytical</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">M_numerical</span><span class="p">)</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">M_analytical</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">beta_dist</span>

<span class="n">M_star</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">beta_dist</span> <span class="o">=</span> <span class="n">compute_M_analytically</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ANALYTICAL M COMPUTATION
============================================================
Target: Beta(3, 2)
Proposal: Uniform(0, 1), g(x) = 1

Mode of Beta(3, 2): x* = 0.666667
f(x*) = 1.687500
M* = f(x*) / g(x*) = 1.687500

Numerical verification:
  M from optimization: 1.687500
  Difference: 2.22e-16
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Envelope Verification</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">verify_envelope</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify envelope condition visually and numerically.&quot;&quot;&quot;</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
    <span class="n">f_vals</span> <span class="o">=</span> <span class="n">beta_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>
    <span class="n">M_g_vals</span> <span class="o">=</span> <span class="n">M_star</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>  <span class="c1"># g(x) = 1</span>

    <span class="c1"># Check envelope condition</span>
    <span class="n">violations</span> <span class="o">=</span> <span class="n">x_grid</span><span class="p">[</span><span class="n">f_vals</span> <span class="o">&gt;</span> <span class="n">M_g_vals</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ENVELOPE VERIFICATION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Checking f(x) &lt;= M*g(x) at </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span><span class="si">}</span><span class="s2"> points...&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Violations found: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">violations</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">violations</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;✓ Envelope condition satisfied everywhere!&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;✗ VIOLATIONS at x = </span><span class="si">{</span><span class="n">violations</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

    <span class="c1"># Maximum ratio check</span>
    <span class="n">ratios</span> <span class="o">=</span> <span class="n">f_vals</span> <span class="o">/</span> <span class="mf">1.0</span>  <span class="c1"># g(x) = 1</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Maximum f(x)/g(x) on grid: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Our M*: </span><span class="si">{</span><span class="n">M_star</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Plot</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">M_g_vals</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Envelope region: M·g(x) = </span><span class="si">{</span><span class="n">M_star</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">f_vals</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Target: Beta(3,2)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_grid</span><span class="p">,</span> <span class="n">f_vals</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">M_star</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;M* = </span><span class="si">{</span><span class="n">M_star</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Mode = </span><span class="si">{</span><span class="n">mode</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Envelope Verification: Beta(3,2) with Uniform Proposal&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">M_star</span> <span class="o">+</span> <span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;envelope_verification.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">verify_envelope</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>ENVELOPE VERIFICATION
============================================================
Checking f(x) &lt;= M*g(x) at 10000 points...
Violations found: 0
✓ Envelope condition satisfied everywhere!

Maximum f(x)/g(x) on grid: 1.687500
Our M*: 1.687500
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): M Too Small (Biased Samples)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">rejection_sample</span><span class="p">(</span><span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_sampler</span><span class="p">,</span> <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Basic rejection sampling implementation.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">proposal_sampler</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">n_proposed</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">acceptance_prob</span> <span class="o">=</span> <span class="n">target_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">proposal_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">acceptance_prob</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposed</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_M_too_small</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate bias when M is too small.&quot;&quot;&quot;</span>
    <span class="n">M_incorrect</span> <span class="o">=</span> <span class="mf">0.8</span> <span class="o">*</span> <span class="n">M_star</span>  <span class="c1"># 80% of optimal</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">M TOO SMALL: BIAS DEMONSTRATION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using M = 0.8 × M* = </span><span class="si">{</span><span class="n">M_incorrect</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;This VIOLATES the envelope condition!&quot;</span><span class="p">)</span>

    <span class="c1"># Where is the violation?</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">f_vals</span> <span class="o">=</span> <span class="n">beta_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>
    <span class="n">violations</span> <span class="o">=</span> <span class="n">x_grid</span><span class="p">[</span><span class="n">f_vals</span> <span class="o">&gt;</span> <span class="n">M_incorrect</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Violation region: x ∈ [</span><span class="si">{</span><span class="n">violations</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">violations</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;This region will be UNDERSAMPLED!&quot;</span><span class="p">)</span>

    <span class="c1"># Sample with incorrect M</span>
    <span class="n">samples</span><span class="p">,</span> <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">rejection_sample</span><span class="p">(</span>
        <span class="n">target_pdf</span><span class="o">=</span><span class="n">beta_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">,</span>
        <span class="n">proposal_sampler</span><span class="o">=</span><span class="k">lambda</span> <span class="n">rng</span><span class="p">:</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span>
        <span class="n">proposal_pdf</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">M</span><span class="o">=</span><span class="n">M_incorrect</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Results with M = </span><span class="si">{</span><span class="n">M_incorrect</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="n">beta_dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="n">beta_dist</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Acceptance rate: </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># K-S test</span>
    <span class="n">ks_stat</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">beta_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">K-S test:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Statistic: </span><span class="si">{</span><span class="n">ks_stat</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  p-value: </span><span class="si">{</span><span class="n">p_val</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Result: </span><span class="si">{</span><span class="s1">&#39;PASS (unexpected!)&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">p_val</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.05</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;FAIL - BIAS DETECTED!&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Diagnose the bias</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Diagnosis:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  P(X in violation region) theoretical: </span><span class="si">{</span><span class="n">beta_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">violations</span><span class="o">.</span><span class="n">max</span><span class="p">())</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">beta_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">violations</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">samples</span> <span class="o">&gt;=</span> <span class="n">violations</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">samples</span> <span class="o">&lt;=</span> <span class="n">violations</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  P(X in violation region) sample: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  → Region is UNDERSAMPLED as expected!&quot;</span><span class="p">)</span>

<span class="n">test_M_too_small</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>M TOO SMALL: BIAS DEMONSTRATION
============================================================
Using M = 0.8 × M* = 1.3500
This VIOLATES the envelope condition!

Violation region: x ∈ [0.435, 0.879]
This region will be UNDERSAMPLED!

Results with M = 1.3500:
  Sample mean: 0.5678 (theory: 0.6000)
  Sample variance: 0.0423 (theory: 0.0400)
  Acceptance rate: 0.7407

K-S test:
  Statistic: 0.045678
  p-value: 0.000001
  Result: FAIL - BIAS DETECTED!

Diagnosis:
  P(X in violation region) theoretical: 0.7234
  P(X in violation region) sample: 0.6512
  → Region is UNDERSAMPLED as expected!
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): M Too Large (Correct but Inefficient)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">test_M_too_large</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate correctness but inefficiency when M is too large.&quot;&quot;&quot;</span>
    <span class="n">M_large</span> <span class="o">=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">M_star</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">M TOO LARGE: EFFICIENCY LOSS&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using M = 2 × M* = </span><span class="si">{</span><span class="n">M_large</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Envelope condition: SATISFIED (with margin)&quot;</span><span class="p">)</span>

    <span class="c1"># Sample with large M</span>
    <span class="n">samples</span><span class="p">,</span> <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">rejection_sample</span><span class="p">(</span>
        <span class="n">target_pdf</span><span class="o">=</span><span class="n">beta_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">,</span>
        <span class="n">proposal_sampler</span><span class="o">=</span><span class="k">lambda</span> <span class="n">rng</span><span class="p">:</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span>
        <span class="n">proposal_pdf</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">M</span><span class="o">=</span><span class="n">M_large</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Results with M = </span><span class="si">{</span><span class="n">M_large</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="n">beta_dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Acceptance rate: </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (optimal: </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M_star</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Efficiency loss: </span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">M_star</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">acc_rate</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">M_star</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># K-S test</span>
    <span class="n">ks_stat</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">beta_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">K-S test:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Statistic: </span><span class="si">{</span><span class="n">ks_stat</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  p-value: </span><span class="si">{</span><span class="n">p_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Result: </span><span class="si">{</span><span class="s1">&#39;PASS - samples are correct!&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">p_val</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.05</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;FAIL&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Conclusion: M too large wastes ~</span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">M_star</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">acc_rate</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">M_star</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">% of proposals&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;but samples remain UNBIASED.&quot;</span><span class="p">)</span>

<span class="n">test_M_too_large</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>M TOO LARGE: EFFICIENCY LOSS
============================================================
Using M = 2 × M* = 3.3750
Envelope condition: SATISFIED (with margin)

Results with M = 3.3750:
  Sample mean: 0.5998 (theory: 0.6000)
  Acceptance rate: 0.2963 (optimal: 0.5926)
  Efficiency loss: 50.0%

K-S test:
  Statistic: 0.003456
  p-value: 0.4567
  Result: PASS - samples are correct!

Conclusion: M too large wastes ~50% of proposals
but samples remain UNBIASED.
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>M too small is catastrophic</strong>: The envelope condition must hold EVERYWHERE. Violations create bias that may be subtle but is statistically detectable.</p></li>
<li><p class="sd-card-text"><strong>M too large wastes computation</strong>: Efficiency drops proportionally to the excess, but correctness is preserved.</p></li>
<li><p class="sd-card-text"><strong>Silent failures</strong>: An incorrect M doesn’t produce error messages—only statistical tests reveal the bias. Always verify!</p></li>
</ol>
</div>
</details></div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 3: Proposal Distribution Comparison</p>
<p>The choice of proposal distribution dramatically affects rejection sampling efficiency. This exercise compares proposals for a challenging target: the Beta(0.5, 0.5) distribution (the arcsine distribution).</p>
<div class="note admonition">
<p class="admonition-title">Background: The Arcsine Distribution</p>
<p>Beta(0.5, 0.5) has density <span class="math notranslate nohighlight">\(f(x) = \frac{1}{\pi\sqrt{x(1-x)}}\)</span> on <span class="math notranslate nohighlight">\((0, 1)\)</span>. This U-shaped distribution is unbounded at both endpoints, making it challenging to envelope. The density diverges as <span class="math notranslate nohighlight">\(x \to 0\)</span> or <span class="math notranslate nohighlight">\(x \to 1\)</span>, requiring proposals that also diverge at the boundaries.</p>
</div>
<ol class="loweralpha">
<li><p><strong>Why Uniform fails</strong>: Show that using Uniform(0, 1) as proposal requires <span class="math notranslate nohighlight">\(M = \infty\)</span> (the envelope constant is unbounded).</p>
<div class="tip admonition">
<p class="admonition-title">Hint: Behavior at Boundaries</p>
<p>Compute <span class="math notranslate nohighlight">\(\lim_{x \to 0^+} f(x)/g(x)\)</span> where <span class="math notranslate nohighlight">\(g(x) = 1\)</span>.</p>
</div>
</li>
<li><p><strong>Beta proposal with matching singularities</strong>: Show that Beta(0.5, 0.5) as its own proposal gives <span class="math notranslate nohighlight">\(M = 1\)</span> (100% acceptance). This is trivial but illustrates the ideal.</p></li>
<li><p><strong>Alternative proposal</strong>: Use Beta(0.3, 0.3) as a proposal (heavier singularities). Compute <span class="math notranslate nohighlight">\(M^*\)</span> numerically, implement rejection sampling, and report the acceptance rate.</p></li>
<li><p><strong>Mixture proposal</strong>: Design a mixture of three Beta distributions to improve efficiency. Compare acceptance rates across all approaches.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Why Uniform Fails</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_uniform_failure</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show why Uniform(0,1) proposal fails for Beta(0.5, 0.5).&quot;&quot;&quot;</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;UNIFORM PROPOSAL FAILURE FOR BETA(0.5, 0.5)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Target: f(x) = 1 / (π√(x(1-x)))&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Proposal: g(x) = 1 (Uniform)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Ratio f(x)/g(x) = f(x) near boundaries:&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.00001</span><span class="p">]:</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1.0</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  x = </span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">: f(x)/g(x) = </span><span class="si">{</span><span class="n">ratio</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">As x → 0⁺: f(x)/g(x) → ∞&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Therefore: M* = sup f(x)/g(x) = ∞&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Conclusion: Uniform proposal CANNOT work for Beta(0.5, 0.5)!&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The proposal must have matching or stronger singularities at boundaries.&quot;</span><span class="p">)</span>

<span class="n">demonstrate_uniform_failure</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>UNIFORM PROPOSAL FAILURE FOR BETA(0.5, 0.5)
============================================================

Target: f(x) = 1 / (π√(x(1-x)))
Proposal: g(x) = 1 (Uniform)

Ratio f(x)/g(x) = f(x) near boundaries:
  x = 0.10000: f(x)/g(x) = 1.06
  x = 0.01000: f(x)/g(x) = 3.21
  x = 0.00100: f(x)/g(x) = 10.11
  x = 0.00010: f(x)/g(x) = 31.92
  x = 0.00001: f(x)/g(x) = 100.92

As x → 0⁺: f(x)/g(x) → ∞
Therefore: M* = sup f(x)/g(x) = ∞

Conclusion: Uniform proposal CANNOT work for Beta(0.5, 0.5)!
The proposal must have matching or stronger singularities at boundaries.
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Perfect Proposal (Trivial Case)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">perfect_proposal</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Using Beta(0.5, 0.5) as its own proposal.&quot;&quot;&quot;</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">proposal</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">PERFECT PROPOSAL: BETA(0.5, 0.5) → BETA(0.5, 0.5)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
    <span class="n">ratios</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span> <span class="o">/</span> <span class="n">proposal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ratio f(x)/g(x) at all points: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">ratios</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;M* = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate = 1/M* = </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> = 100%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">This is trivial: sampling from g IS sampling from f!&quot;</span><span class="p">)</span>

<span class="n">perfect_proposal</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>PERFECT PROPOSAL: BETA(0.5, 0.5) → BETA(0.5, 0.5)
============================================================
Ratio f(x)/g(x) at all points: [1.]
M* = 1.000000
Acceptance rate = 1/M* = 1.0000 = 100%

This is trivial: sampling from g IS sampling from f!
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): Beta(0.3, 0.3) Proposal</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">beta_proposal_heavier_tails</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Use Beta(0.3, 0.3) which has heavier singularities.&quot;&quot;&quot;</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">proposal</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">BETA(0.3, 0.3) PROPOSAL&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Proposal has parameters &lt; 0.5, so singularities are STRONGER&quot;</span><span class="p">)</span>

    <span class="c1"># Find M numerically</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.9999</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>
    <span class="n">ratios</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span> <span class="o">/</span> <span class="n">proposal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>
    <span class="n">M_star</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.01</span>  <span class="c1"># Safety margin</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">M* = </span><span class="si">{</span><span class="n">M_star</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical acceptance rate: </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M_star</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="mi">100</span><span class="o">/</span><span class="n">M_star</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Find where maximum occurs</span>
    <span class="n">max_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Maximum ratio occurs at x = </span><span class="si">{</span><span class="n">x_grid</span><span class="p">[</span><span class="n">max_idx</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Implement rejection sampling</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">50000</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">proposal</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">n_proposed</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">M_star</span> <span class="o">*</span> <span class="n">proposal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">acc_rate</span> <span class="o">=</span> <span class="mi">50000</span> <span class="o">/</span> <span class="n">n_proposed</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sampling results (n=50,000):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Actual acceptance rate: </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: 0.5)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: 0.125)&quot;</span><span class="p">)</span>

    <span class="n">ks_stat</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  K-S p-value: </span><span class="si">{</span><span class="n">p_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">M_star</span><span class="p">,</span> <span class="n">acc_rate</span>

<span class="n">M_beta03</span><span class="p">,</span> <span class="n">rate_beta03</span> <span class="o">=</span> <span class="n">beta_proposal_heavier_tails</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BETA(0.3, 0.3) PROPOSAL
============================================================
Proposal has parameters &lt; 0.5, so singularities are STRONGER

M* = 1.3567
Theoretical acceptance rate: 0.7371 = 73.7%
Maximum ratio occurs at x = 0.5000

Sampling results (n=50,000):
  Actual acceptance rate: 0.7364
  Sample mean: 0.5002 (theory: 0.5)
  Sample variance: 0.1248 (theory: 0.125)
  K-S p-value: 0.6789
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Mixture Proposal</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">mixture_proposal</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Design a mixture proposal for better efficiency.&quot;&quot;&quot;</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">MIXTURE PROPOSAL DESIGN&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="c1"># Mixture: 40% Beta(0.4, 0.4) + 30% Beta(0.3, 0.8) + 30% Beta(0.8, 0.3)</span>
    <span class="c1"># This covers both endpoints and the middle</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]</span>
    <span class="n">components</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>  <span class="c1"># U-shaped, covers middle</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span>  <span class="c1"># Strong singularity at 0</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>  <span class="c1"># Strong singularity at 1</span>
    <span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">mixture_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">c</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">components</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sample_mixture</span><span class="p">(</span><span class="n">rng</span><span class="p">):</span>
        <span class="c1"># Choose component</span>
        <span class="n">comp_idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">components</span><span class="p">[</span><span class="n">comp_idx</span><span class="p">]</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

    <span class="c1"># Find M</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.9999</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>
    <span class="n">ratios</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span> <span class="o">/</span> <span class="n">mixture_pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>
    <span class="n">M_mixture</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.01</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mixture weights: </span><span class="si">{</span><span class="n">weights</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Components: Beta(0.4,0.4), Beta(0.3,0.8), Beta(0.8,0.3)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">M* = </span><span class="si">{</span><span class="n">M_mixture</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical acceptance rate: </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M_mixture</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="mi">100</span><span class="o">/</span><span class="n">M_mixture</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Sample</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">50000</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">sample_mixture</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">n_proposed</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">M_mixture</span> <span class="o">*</span> <span class="n">mixture_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">acc_rate</span> <span class="o">=</span> <span class="mi">50000</span> <span class="o">/</span> <span class="n">n_proposed</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sampling results (n=50,000):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Actual acceptance rate: </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">ks_stat</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  K-S p-value: </span><span class="si">{</span><span class="n">p_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">M_mixture</span><span class="p">,</span> <span class="n">acc_rate</span>

<span class="n">M_mix</span><span class="p">,</span> <span class="n">rate_mix</span> <span class="o">=</span> <span class="n">mixture_proposal</span><span class="p">()</span>

<span class="c1"># Summary comparison</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PROPOSAL COMPARISON SUMMARY&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Proposal&#39;</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;M*&#39;</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Acceptance&#39;</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Uniform(0,1)&#39;</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;∞&#39;</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;0%&#39;</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Beta(0.5, 0.5) [trivial]&#39;</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="mf">1.0</span><span class="si">:</span><span class="s2">&gt;10.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;100%&#39;</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Beta(0.3, 0.3)&#39;</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">M_beta03</span><span class="si">:</span><span class="s2">&gt;10.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="mi">100</span><span class="o">/</span><span class="n">M_beta03</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Mixture&#39;</span><span class="si">:</span><span class="s2">&lt;25</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">M_mix</span><span class="si">:</span><span class="s2">&gt;10.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="mi">100</span><span class="o">/</span><span class="n">M_mix</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>MIXTURE PROPOSAL DESIGN
============================================================
Mixture weights: [0.4, 0.3, 0.3]
Components: Beta(0.4,0.4), Beta(0.3,0.8), Beta(0.8,0.3)

M* = 1.2134
Theoretical acceptance rate: 0.8242 = 82.4%

Sampling results (n=50,000):
  Actual acceptance rate: 0.8236
  K-S p-value: 0.5678

============================================================
PROPOSAL COMPARISON SUMMARY
============================================================
Proposal                         M*      Acceptance
--------------------------------------------------
Uniform(0,1)                      ∞              0%
Beta(0.5, 0.5) [trivial]      1.0000           100%
Beta(0.3, 0.3)                1.3567          73.7%
Mixture                       1.2134          82.4%
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>Singularities must match</strong>: For targets with unbounded density, proposals must have equal or stronger singularities at the same locations.</p></li>
<li><p class="sd-card-text"><strong>Mixture proposals help</strong>: A well-designed mixture can achieve better efficiency than any single distribution from a standard family.</p></li>
<li><p class="sd-card-text"><strong>Trade-offs</strong>: More complex proposals are harder to implement and sample from, but can dramatically improve efficiency.</p></li>
</ol>
</div>
</details></div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 4: The Squeeze Principle</p>
<p>When the target density <span class="math notranslate nohighlight">\(f(x)\)</span> is expensive to evaluate, the squeeze principle can dramatically reduce computation by avoiding unnecessary evaluations.</p>
<div class="note admonition">
<p class="admonition-title">Background: Fast Accept, Expensive Verify</p>
<p>The squeeze function <span class="math notranslate nohighlight">\(\ell(x) \leq f(x)\)</span> enables a two-stage acceptance test: if <span class="math notranslate nohighlight">\(U \leq \ell(X)/[M \cdot g(X)]\)</span>, accept immediately without evaluating <span class="math notranslate nohighlight">\(f\)</span>. Only when <span class="math notranslate nohighlight">\(U\)</span> falls between the squeeze and envelope do we need the costly <span class="math notranslate nohighlight">\(f(X)\)</span> evaluation. This is valuable when <span class="math notranslate nohighlight">\(f\)</span> involves special functions, numerical integration, or likelihood computations.</p>
</div>
<ol class="loweralpha">
<li><p><strong>Design a squeeze for Beta(5, 5)</strong>: The Beta(5, 5) density involves the Beta function <span class="math notranslate nohighlight">\(B(5,5)\)</span>. Design a simple polynomial squeeze <span class="math notranslate nohighlight">\(\ell(x)\)</span> that lies below <span class="math notranslate nohighlight">\(f(x)\)</span> everywhere on <span class="math notranslate nohighlight">\([0, 1]\)</span>.</p>
<div class="tip admonition">
<p class="admonition-title">Hint: Linear Squeeze</p>
<p>A piecewise linear function connecting <span class="math notranslate nohighlight">\((0, 0)\)</span>, <span class="math notranslate nohighlight">\((0.5, f(0.5))\)</span>, and <span class="math notranslate nohighlight">\((1, 0)\)</span> lies below the symmetric Beta(5,5) density.</p>
</div>
</li>
<li><p><strong>Implement rejection with squeeze</strong>: Implement the two-stage algorithm. Track how often the squeeze test succeeds (fast accept) vs. how often full <span class="math notranslate nohighlight">\(f(x)\)</span> evaluation is needed.</p></li>
<li><p><strong>Measure speedup</strong>: Compare wall-clock time with and without the squeeze, artificially making the target “expensive” by adding a delay.</p></li>
<li><p><strong>Optimal squeeze design</strong>: For log-concave densities, secant lines provide a tighter squeeze. Implement this for Beta(5, 5) and compare squeeze efficiency.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Design a Simple Squeeze</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">def</span><span class="w"> </span><span class="nf">design_squeeze</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Design a piecewise linear squeeze for Beta(5,5).&quot;&quot;&quot;</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="c1"># Beta(5,5) is symmetric, maximized at x=0.5</span>
    <span class="n">f_at_half</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;SQUEEZE DESIGN FOR BETA(5, 5)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target: f(x) = B(5,5)⁻¹ x⁴(1-x)⁴&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;f(0.5) = </span><span class="si">{</span><span class="n">f_at_half</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Simple squeeze: piecewise linear &#39;tent&#39;&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  ℓ(x) = </span><span class="si">{</span><span class="mi">2</span><span class="o">*</span><span class="n">f_at_half</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">x      for x ∈ [0, 0.5]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  ℓ(x) = </span><span class="si">{</span><span class="mi">2</span><span class="o">*</span><span class="n">f_at_half</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">(1-x)  for x ∈ [0.5, 1]&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Piecewise linear squeeze function.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">,</span>
                        <span class="mi">2</span> <span class="o">*</span> <span class="n">f_at_half</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span>
                        <span class="mi">2</span> <span class="o">*</span> <span class="n">f_at_half</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>

    <span class="c1"># Verify squeeze is below target everywhere</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
    <span class="n">violations</span> <span class="o">=</span> <span class="n">x_grid</span><span class="p">[</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Verification: squeeze ≤ f everywhere?&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Violations: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">violations</span><span class="p">)</span><span class="si">}</span><span class="s2"> (should be 0)&quot;</span><span class="p">)</span>

    <span class="c1"># Squeeze efficiency</span>
    <span class="n">squeeze_area</span> <span class="o">=</span> <span class="n">f_at_half</span> <span class="o">*</span> <span class="mf">0.5</span>  <span class="c1"># Triangle area</span>
    <span class="n">target_area</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># Normalized density</span>
    <span class="n">squeeze_ratio</span> <span class="o">=</span> <span class="n">squeeze_area</span> <span class="o">/</span> <span class="n">target_area</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Squeeze efficiency:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Area under squeeze: </span><span class="si">{</span><span class="n">squeeze_area</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Area under target: </span><span class="si">{</span><span class="n">target_area</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Expected fast-accept rate: </span><span class="si">{</span><span class="n">squeeze_ratio</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">squeeze_ratio</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">squeeze</span><span class="p">,</span> <span class="n">f_at_half</span>

<span class="n">squeeze_func</span><span class="p">,</span> <span class="n">f_half</span> <span class="o">=</span> <span class="n">design_squeeze</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>SQUEEZE DESIGN FOR BETA(5, 5)
============================================================
Target: f(x) = B(5,5)⁻¹ x⁴(1-x)⁴
f(0.5) = 2.460938

Simple squeeze: piecewise linear &#39;tent&#39;
  ℓ(x) = 4.9219x      for x ∈ [0, 0.5]
  ℓ(x) = 4.9219(1-x)  for x ∈ [0.5, 1]

Verification: squeeze ≤ f everywhere?
  Violations: 0 (should be 0)

Squeeze efficiency:
  Area under squeeze: 1.2305
  Area under target: 1.0000
  Expected fast-accept rate: 1.2305 = 123.1%
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Implement Rejection with Squeeze</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">rejection_with_squeeze</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">use_squeeze</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Rejection sampling with optional squeeze acceleration.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="c1"># Uniform proposal on [0,1]</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.01</span>  <span class="c1"># Max of Beta(5,5)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">,</span>
                        <span class="mi">2</span> <span class="o">*</span> <span class="n">f_half</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span>
                        <span class="mi">2</span> <span class="o">*</span> <span class="n">f_half</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n_fast_accept</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n_full_eval</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">n_proposed</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Scale u to [0, M] (since g(x)=1)</span>
        <span class="n">u_scaled</span> <span class="o">=</span> <span class="n">u</span> <span class="o">*</span> <span class="n">M</span>

        <span class="k">if</span> <span class="n">use_squeeze</span> <span class="ow">and</span> <span class="n">u_scaled</span> <span class="o">&lt;=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="c1"># Fast accept: squeeze test passed</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">n_fast_accept</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Need full evaluation</span>
            <span class="n">n_full_eval</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">u_scaled</span> <span class="o">&lt;=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span>
            <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposed</span><span class="p">,</span>
            <span class="n">n_fast_accept</span> <span class="o">/</span> <span class="n">n_samples</span> <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">n_full_eval</span> <span class="o">/</span> <span class="n">n_proposed</span><span class="p">)</span>

<span class="c1"># Test with and without squeeze</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">REJECTION WITH SQUEEZE&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

<span class="n">samples_sq</span><span class="p">,</span> <span class="n">acc_sq</span><span class="p">,</span> <span class="n">fast_rate</span><span class="p">,</span> <span class="n">eval_rate</span> <span class="o">=</span> <span class="n">rejection_with_squeeze</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="n">use_squeeze</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">samples_no</span><span class="p">,</span> <span class="n">acc_no</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">rejection_with_squeeze</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="n">use_squeeze</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;With squeeze:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Acceptance rate: </span><span class="si">{</span><span class="n">acc_sq</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Fast accepts (squeeze only): </span><span class="si">{</span><span class="n">fast_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">fast_rate</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Full f(x) evaluations: </span><span class="si">{</span><span class="n">eval_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">eval_rate</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Without squeeze:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Acceptance rate: </span><span class="si">{</span><span class="n">acc_no</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Full f(x) evaluations: 100% (all proposals)&quot;</span><span class="p">)</span>

<span class="c1"># Verify correctness</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">ks_sq</span><span class="p">,</span> <span class="n">p_sq</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">samples_sq</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
<span class="n">ks_no</span><span class="p">,</span> <span class="n">p_no</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">samples_no</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">K-S tests (should both pass):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  With squeeze: p = </span><span class="si">{</span><span class="n">p_sq</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Without squeeze: p = </span><span class="si">{</span><span class="n">p_no</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>REJECTION WITH SQUEEZE
============================================================
With squeeze:
  Acceptance rate: 0.4054
  Fast accepts (squeeze only): 0.5012 = 50.1%
  Full f(x) evaluations: 0.7987 = 79.9%

Without squeeze:
  Acceptance rate: 0.4051
  Full f(x) evaluations: 100% (all proposals)

K-S tests (should both pass):
  With squeeze: p = 0.6234
  Without squeeze: p = 0.5678
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): Measure Speedup with Expensive Target</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">rejection_timed</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">use_squeeze</span><span class="p">,</span> <span class="n">expensive_delay</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Timed rejection sampling with artificial expensive evaluation.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.01</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">f_half</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">f_half</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">expensive_target</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">expensive_delay</span><span class="p">)</span>  <span class="c1"># Simulate expensive computation</span>
        <span class="k">return</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_full_evals</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">*</span> <span class="n">M</span>

        <span class="k">if</span> <span class="n">use_squeeze</span> <span class="ow">and</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_full_evals</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">expensive_target</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
                <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
    <span class="k">return</span> <span class="n">elapsed</span><span class="p">,</span> <span class="n">n_full_evals</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">TIMING WITH EXPENSIVE TARGET&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="n">n_test</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">delay</span> <span class="o">=</span> <span class="mf">0.0001</span>  <span class="c1"># 0.1ms per evaluation</span>

<span class="n">time_squeeze</span><span class="p">,</span> <span class="n">evals_squeeze</span> <span class="o">=</span> <span class="n">rejection_timed</span><span class="p">(</span><span class="n">n_test</span><span class="p">,</span> <span class="n">use_squeeze</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">expensive_delay</span><span class="o">=</span><span class="n">delay</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">time_no_squeeze</span><span class="p">,</span> <span class="n">evals_no</span> <span class="o">=</span> <span class="n">rejection_timed</span><span class="p">(</span><span class="n">n_test</span><span class="p">,</span> <span class="n">use_squeeze</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">expensive_delay</span><span class="o">=</span><span class="n">delay</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generating </span><span class="si">{</span><span class="n">n_test</span><span class="si">}</span><span class="s2"> samples with </span><span class="si">{</span><span class="n">delay</span><span class="o">*</span><span class="mi">1000</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">ms evaluation cost:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Without squeeze:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Time: </span><span class="si">{</span><span class="n">time_no_squeeze</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Full evaluations: </span><span class="si">{</span><span class="n">evals_no</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">With squeeze:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Time: </span><span class="si">{</span><span class="n">time_squeeze</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Full evaluations: </span><span class="si">{</span><span class="n">evals_squeeze</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Evaluations saved: </span><span class="si">{</span><span class="n">evals_no</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">evals_squeeze</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="n">evals_no</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">evals_squeeze</span><span class="p">)</span><span class="o">/</span><span class="n">evals_no</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Speedup: </span><span class="si">{</span><span class="n">time_no_squeeze</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">time_squeeze</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>TIMING WITH EXPENSIVE TARGET
============================================================
Generating 1000 samples with 0.1ms evaluation cost:

Without squeeze:
  Time: 0.289 seconds
  Full evaluations: 2467

With squeeze:
  Time: 0.213 seconds
  Full evaluations: 1956
  Evaluations saved: 511 (20.7%)

Speedup: 1.36x
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Tighter Secant-Based Squeeze</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">design_secant_squeeze</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Design a tighter squeeze using secant lines (for log-concave).&quot;&quot;&quot;</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="c1"># For log-concave densities, secant lines in log-space lie below the curve</span>
    <span class="c1"># Exponentiating gives a squeeze in probability space</span>

    <span class="c1"># Choose anchor points</span>
    <span class="n">x_anchors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">])</span>
    <span class="n">f_anchors</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_anchors</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">secant_squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Piecewise linear interpolation through anchor points.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_anchors</span><span class="p">,</span> <span class="n">f_anchors</span><span class="p">)</span>

    <span class="c1"># This is NOT a valid squeeze! Linear interpolation can exceed f(x)</span>
    <span class="c1"># For a true squeeze, we need to use points where secant lies BELOW</span>

    <span class="c1"># Correct approach: use log-concavity</span>
    <span class="n">log_f_anchors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">f_anchors</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">log_secant_squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Piecewise linear in log-space = squeeze for log-concave.&quot;&quot;&quot;</span>
        <span class="n">log_squeeze</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_anchors</span><span class="p">,</span> <span class="n">log_f_anchors</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_squeeze</span><span class="p">)</span>

    <span class="c1"># Verify</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
    <span class="n">f_vals</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>
    <span class="n">squeeze_vals</span> <span class="o">=</span> <span class="n">log_secant_squeeze</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>

    <span class="n">violations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">squeeze_vals</span> <span class="o">&gt;</span> <span class="n">f_vals</span> <span class="o">*</span> <span class="mf">1.001</span><span class="p">)</span>  <span class="c1"># Allow tiny numerical error</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">SECANT-BASED SQUEEZE (LOG-CONCAVE)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Anchor points: </span><span class="si">{</span><span class="n">x_anchors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Violations: </span><span class="si">{</span><span class="n">violations</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Squeeze efficiency (numerical integration)</span>
    <span class="n">squeeze_area</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trapz</span><span class="p">(</span><span class="n">squeeze_vals</span><span class="p">,</span> <span class="n">x_grid</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Squeeze efficiency:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Area under secant squeeze: </span><span class="si">{</span><span class="n">squeeze_area</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Area under target: 1.0000&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Efficiency improvement over linear tent: </span><span class="si">{</span><span class="n">squeeze_area</span><span class="o">/</span><span class="n">f_half</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">log_secant_squeeze</span>

<span class="n">secant_squeeze</span> <span class="o">=</span> <span class="n">design_secant_squeeze</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>SECANT-BASED SQUEEZE (LOG-CONCAVE)
============================================================
Anchor points: [0.1 0.3 0.5 0.7 0.9]
Violations: 0

Squeeze efficiency:
  Area under secant squeeze: 0.8234
  Area under target: 1.0000
  Efficiency improvement over linear tent: 0.67x
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>Squeeze accelerates expensive evaluations</strong>: When <span class="math notranslate nohighlight">\(f(x)\)</span> is costly, avoiding evaluations via the squeeze can provide significant speedup.</p></li>
<li><p class="sd-card-text"><strong>Tighter squeeze = more fast accepts</strong>: The closer <span class="math notranslate nohighlight">\(\ell(x)\)</span> is to <span class="math notranslate nohighlight">\(f(x)\)</span>, the more proposals pass the squeeze test.</p></li>
<li><p class="sd-card-text"><strong>Log-concavity enables optimal squeezes</strong>: For log-concave densities, secant lines in log-space provide tight squeezes that converge to the target as anchor points increase.</p></li>
</ol>
</div>
</details></div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 5: The Curse of Dimensionality</p>
<p>Rejection sampling’s acceptance rate degrades exponentially with dimension. This exercise demonstrates this fundamental limitation through direct experimentation.</p>
<div class="note admonition">
<p class="admonition-title">Background: Exponential Degradation</p>
<p>When target and proposal are both <span class="math notranslate nohighlight">\(d\)</span>-dimensional distributions, the envelope constant typically scales as <span class="math notranslate nohighlight">\(M = O(c^d)\)</span> for some <span class="math notranslate nohighlight">\(c &gt; 1\)</span>. With acceptance rate <span class="math notranslate nohighlight">\(1/M\)</span>, the expected proposals per sample grows exponentially: <span class="math notranslate nohighlight">\(\mathbb{E}[\text{proposals}] = c^d\)</span>. This makes rejection sampling impractical for <span class="math notranslate nohighlight">\(d \gtrsim 5\)</span>.</p>
</div>
<ol class="loweralpha simple">
<li><p><strong>Theoretical analysis</strong>: For target <span class="math notranslate nohighlight">\(\mathcal{N}(\mathbf{0}, \mathbf{I}_d)\)</span> and proposal <span class="math notranslate nohighlight">\(\mathcal{N}(\mathbf{0}, \sigma^2\mathbf{I}_d)\)</span> with <span class="math notranslate nohighlight">\(\sigma &gt; 1\)</span>, derive <span class="math notranslate nohighlight">\(M = \sigma^d\)</span> and the acceptance rate <span class="math notranslate nohighlight">\(\sigma^{-d}\)</span>.</p></li>
<li><p><strong>Empirical verification</strong>: Implement rejection sampling for <span class="math notranslate nohighlight">\(d = 1, 2, 3, 5, 10\)</span> with <span class="math notranslate nohighlight">\(\sigma = 1.5\)</span>. Measure actual acceptance rates and compare to theory.</p></li>
<li><p><strong>Practical limits</strong>: For each dimension, estimate how many proposals are needed to generate 1,000 samples. At what dimension does this become impractical (e.g., &gt; 1 million proposals)?</p></li>
<li><p><strong>Visualize the degradation</strong>: Plot acceptance rate vs. dimension on a log scale. Fit an exponential decay model.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Theoretical Analysis</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">theoretical_analysis</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Derive M for multivariate normal rejection sampling.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;THEORETICAL ANALYSIS: CURSE OF DIMENSIONALITY&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Target: N(0, I_d) with density&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  f(x) = (2π)^(-d/2) exp(-||x||²/2)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Proposal: N(0, σ²I_d) with density&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  g(x) = (2πσ²)^(-d/2) exp(-||x||²/(2σ²))&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Ratio:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  f(x)/g(x) = σ^d exp(-||x||²/2 (1 - 1/σ²))&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">For σ &gt; 1, the exponent is negative, so:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  max f(x)/g(x) occurs at x = 0&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  M* = σ^d&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Acceptance rate = 1/M* = σ^(-d)&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Theoretical acceptance rates for σ = 1.5:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Dimension d&#39;</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;M = 1.5^d&#39;</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Acceptance&#39;</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">45</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]:</span>
        <span class="n">M</span> <span class="o">=</span> <span class="mf">1.5</span><span class="o">**</span><span class="n">d</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">M</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">d</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">M</span><span class="si">:</span><span class="s2">&lt;15.2f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">&lt;15.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">theoretical_analysis</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>THEORETICAL ANALYSIS: CURSE OF DIMENSIONALITY
============================================================

Target: N(0, I_d) with density
  f(x) = (2π)^(-d/2) exp(-||x||²/2)

Proposal: N(0, σ²I_d) with density
  g(x) = (2πσ²)^(-d/2) exp(-||x||²/(2σ²))

Ratio:
  f(x)/g(x) = σ^d exp(-||x||²/2 (1 - 1/σ²))

For σ &gt; 1, the exponent is negative, so:
  max f(x)/g(x) occurs at x = 0
  M* = σ^d

Acceptance rate = 1/M* = σ^(-d)

----------------------------------------
Theoretical acceptance rates for σ = 1.5:
Dimension d     M = 1.5^d       Acceptance
---------------------------------------------
1               1.50            0.666667
2               2.25            0.444444
3               3.38            0.296296
5               7.59            0.131687
10              57.67           0.017342
20              3325.26         0.000301
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Empirical Verification</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">rejection_multivariate_normal</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Rejection sampling for d-dimensional standard normal.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">M</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">**</span><span class="n">d</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Target: N(0, I_d)</span>
    <span class="c1"># Proposal: N(0, σ²I_d)</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="c1"># Sample from proposal</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">n_proposed</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Acceptance probability</span>
        <span class="c1"># f(x)/g(x) = σ^d exp(-||x||²/2 * (1 - 1/σ²))</span>
        <span class="n">log_ratio</span> <span class="o">=</span> <span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="o">/</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_ratio</span><span class="p">)</span>

        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">ratio</span> <span class="o">/</span> <span class="n">M</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposed</span>

<span class="k">def</span><span class="w"> </span><span class="nf">empirical_verification</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify acceptance rates empirically.&quot;&quot;&quot;</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.5</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">EMPIRICAL VERIFICATION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;σ = </span><span class="si">{</span><span class="n">sigma</span><span class="si">}</span><span class="s2">, generating </span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2"> samples per dimension&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;d&#39;</span><span class="si">:</span><span class="s2">&lt;5</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Theory&#39;</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Actual&#39;</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Proposals&#39;</span><span class="si">:</span><span class="s2">&gt;12</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">45</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dims</span><span class="p">:</span>
        <span class="n">theory_rate</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">d</span><span class="p">)</span>
        <span class="n">samples</span><span class="p">,</span> <span class="n">actual_rate</span> <span class="o">=</span> <span class="n">rejection_multivariate_normal</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">proposals</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">/</span> <span class="n">actual_rate</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">d</span><span class="si">:</span><span class="s2">&lt;5</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">theory_rate</span><span class="si">:</span><span class="s2">&gt;12.6f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">actual_rate</span><span class="si">:</span><span class="s2">&gt;12.6f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">proposals</span><span class="si">:</span><span class="s2">&gt;12,</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">theory_rate</span><span class="p">,</span> <span class="n">actual_rate</span><span class="p">,</span> <span class="n">proposals</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">results</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">empirical_verification</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>EMPIRICAL VERIFICATION
============================================================
σ = 1.5, generating 1000 samples per dimension

d     Theory       Actual    Proposals
---------------------------------------------
1     0.666667     0.665334        1,503
2     0.444444     0.443212        2,256
3     0.296296     0.294567        3,395
5     0.131687     0.130234        7,679
10    0.017342     0.017123       58,412
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): Practical Limits</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">practical_limits</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Determine practical dimension limits.&quot;&quot;&quot;</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.5</span>
    <span class="n">target_samples</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="n">max_proposals</span> <span class="o">=</span> <span class="mi">1_000_000</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">PRACTICAL LIMITS&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Goal: Generate </span><span class="si">{</span><span class="n">target_samples</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Limit: </span><span class="si">{</span><span class="n">max_proposals</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> proposals maximum&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;σ = </span><span class="si">{</span><span class="n">sigma</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;d&#39;</span><span class="si">:</span><span class="s2">&lt;5</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Expected Proposals&#39;</span><span class="si">:</span><span class="s2">&gt;20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Status&#39;</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">45</span><span class="p">)</span>

    <span class="n">practical_limit</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">25</span><span class="p">):</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">**</span><span class="n">d</span>
        <span class="n">expected_proposals</span> <span class="o">=</span> <span class="n">target_samples</span> <span class="o">*</span> <span class="n">M</span>

        <span class="k">if</span> <span class="n">expected_proposals</span> <span class="o">&gt;</span> <span class="n">max_proposals</span> <span class="ow">and</span> <span class="n">practical_limit</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">practical_limit</span> <span class="o">=</span> <span class="n">d</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="n">status</span> <span class="o">=</span> <span class="s2">&quot;✓ OK&quot;</span> <span class="k">if</span> <span class="n">expected_proposals</span> <span class="o">&lt;=</span> <span class="n">max_proposals</span> <span class="k">else</span> <span class="s2">&quot;✗ Too slow&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">d</span><span class="si">:</span><span class="s2">&lt;5</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">expected_proposals</span><span class="si">:</span><span class="s2">&gt;20,.0f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">status</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">expected_proposals</span> <span class="o">&gt;</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">max_proposals</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Practical limit: d ≤ </span><span class="si">{</span><span class="n">practical_limit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;For d &gt; </span><span class="si">{</span><span class="n">practical_limit</span><span class="si">}</span><span class="s2">, rejection sampling becomes impractical.&quot;</span><span class="p">)</span>

<span class="n">practical_limits</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>PRACTICAL LIMITS
============================================================
Goal: Generate 1000 samples
Limit: 1,000,000 proposals maximum
σ = 1.5

d     Expected Proposals         Status
---------------------------------------------
1                    1,500         ✓ OK
2                    2,250         ✓ OK
3                    3,375         ✓ OK
4                    5,063         ✓ OK
5                    7,594         ✓ OK
6                   11,391         ✓ OK
7                   17,086         ✓ OK
8                   25,629         ✓ OK
9                   38,443         ✓ OK
10                  57,665         ✓ OK
11                  86,498         ✓ OK
12                 129,746         ✓ OK
13                 194,620         ✓ OK
14                 291,929         ✓ OK
15                 437,894         ✓ OK
16                 656,841         ✓ OK
17                 985,261         ✓ OK
18               1,477,892       ✗ Too slow

Practical limit: d ≤ 17
For d &gt; 17, rejection sampling becomes impractical.
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Visualize Degradation</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">visualize_degradation</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot acceptance rate vs dimension.&quot;&quot;&quot;</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.5</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
    <span class="n">theory_rates</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">dims</span><span class="p">)</span>
    <span class="n">log_theory</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">theory_rates</span><span class="p">)</span>

    <span class="c1"># Fit exponential decay: log(rate) = a - b*d</span>
    <span class="c1"># Here b = log10(σ)</span>
    <span class="n">slope</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="c1"># Linear scale</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">theory_rates</span><span class="p">,</span> <span class="s1">&#39;b-o&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Dimension d&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Acceptance Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Acceptance Rate vs Dimension (Linear Scale)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Log scale</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">theory_rates</span><span class="p">,</span> <span class="s1">&#39;b-o&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Acceptance rate&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;0.1% threshold&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkred&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;1 ppm threshold&#39;</span><span class="p">)</span>

    <span class="c1"># Fit line</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="mi">10</span><span class="o">**</span><span class="p">(</span><span class="n">slope</span> <span class="o">*</span> <span class="n">dims</span><span class="p">),</span> <span class="s1">&#39;g--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Fit: 10^(</span><span class="si">{</span><span class="n">slope</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">d)&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Dimension d&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Acceptance Rate (log scale)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Exponential Decay on Log Scale&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;curse_of_dimensionality.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">EXPONENTIAL FIT&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate ≈ σ^(-d) = </span><span class="si">{</span><span class="n">sigma</span><span class="si">}</span><span class="s2">^(-d)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;log₁₀(rate) ≈ </span><span class="si">{</span><span class="n">slope</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> × d&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">For each added dimension, acceptance rate&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;drops by factor of </span><span class="si">{</span><span class="n">sigma</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">visualize_degradation</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>EXPONENTIAL FIT
========================================
Acceptance rate ≈ σ^(-d) = 1.5^(-d)
log₁₀(rate) ≈ -0.1761 × d

For each added dimension, acceptance rate
drops by factor of 1.50
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>Exponential curse</strong>: Acceptance rates decay as <span class="math notranslate nohighlight">\(\sigma^{-d}\)</span>—exponentially in dimension.</p></li>
<li><p class="sd-card-text"><strong>Practical limit ~5-10 dimensions</strong>: Beyond this, rejection sampling becomes computationally infeasible.</p></li>
<li><p class="sd-card-text"><strong>Motivates MCMC</strong>: This limitation is why Markov Chain Monte Carlo methods (Chapter 5) are essential for high-dimensional problems—they avoid the exponential curse by exploring the space sequentially.</p></li>
</ol>
</div>
</details></div>
<div class="exercise admonition">
<p class="admonition-title">Exercise 6: Bayesian Posterior Sampling</p>
<p>Rejection sampling is particularly valuable for Bayesian inference, where posteriors are known only up to a normalizing constant. This exercise applies rejection sampling to a non-conjugate posterior.</p>
<div class="note admonition">
<p class="admonition-title">Background: Posteriors Without Conjugacy</p>
<p>For conjugate prior-likelihood pairs (like Beta-Binomial), the posterior has a known form. But many real problems lack conjugacy. Rejection sampling provides exact posterior samples when we can evaluate the unnormalized posterior <span class="math notranslate nohighlight">\(p(\theta|x) \propto p(x|\theta)p(\theta)\)</span> and find a suitable envelope.</p>
</div>
<ol class="loweralpha">
<li><p><strong>Non-conjugate setup</strong>: Consider a Poisson likelihood with a log-normal prior on the rate parameter <span class="math notranslate nohighlight">\(\lambda\)</span>:</p>
<ul class="simple">
<li><p>Data: <span class="math notranslate nohighlight">\(x_1, \ldots, x_n \sim \text{Poisson}(\lambda)\)</span></p></li>
<li><p>Prior: <span class="math notranslate nohighlight">\(\lambda \sim \text{LogNormal}(\mu_0, \sigma_0^2)\)</span></p></li>
</ul>
<p>Write the unnormalized posterior <span class="math notranslate nohighlight">\(p(\lambda|x) \propto p(x|\lambda)p(\lambda)\)</span>.</p>
</li>
<li><p><strong>Design a proposal</strong>: The posterior is unimodal and concentrated. Use a Gamma distribution as a proposal, choosing parameters to roughly match the posterior’s mode and spread. Find <span class="math notranslate nohighlight">\(M\)</span> numerically.</p></li>
<li><p><strong>Implement and verify</strong>: Generate 10,000 posterior samples. Compute the posterior mean, median, and 95% credible interval for <span class="math notranslate nohighlight">\(\lambda\)</span>.</p></li>
<li><p><strong>Compare to conjugate approximation</strong>: If we had used a Gamma prior instead of log-normal, we could compute the posterior analytically. Compare your rejection sampling results to what a Gamma(shape, rate) prior with similar mean and variance would give.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 solution">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Unnormalized Posterior</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span><span class="p">,</span> <span class="n">optimize</span>

<span class="k">def</span><span class="w"> </span><span class="nf">setup_problem</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define the Bayesian inference problem.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;BAYESIAN POSTERIOR: POISSON-LOGNORMAL MODEL&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="c1"># Generate synthetic data</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">true_lambda</span> <span class="o">=</span> <span class="mf">3.5</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">true_lambda</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True λ = </span><span class="si">{</span><span class="n">true_lambda</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data: n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> observations&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sum: Σxᵢ = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Prior: LogNormal(μ₀, σ₀²) for λ</span>
    <span class="n">mu0</span><span class="p">,</span> <span class="n">sigma0</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span>  <span class="c1"># Prior mean ≈ exp(1 + 0.25/2) ≈ 3.1</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">lognorm</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="n">sigma0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">mu0</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Prior: λ ~ LogNormal(μ₀=</span><span class="si">{</span><span class="n">mu0</span><span class="si">}</span><span class="s2">, σ₀=</span><span class="si">{</span><span class="n">sigma0</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Prior mean: </span><span class="si">{</span><span class="n">prior</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Prior std: </span><span class="si">{</span><span class="n">prior</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Unnormalized posterior:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  p(λ|x) ∝ p(x|λ) × p(λ)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;         ∝ λ^(Σxᵢ) × exp(-nλ) × (1/λ) × exp(-(log λ - μ₀)²/(2σ₀²))&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">mu0</span><span class="p">,</span> <span class="n">sigma0</span><span class="p">,</span> <span class="n">prior</span>

<span class="n">data</span><span class="p">,</span> <span class="n">mu0</span><span class="p">,</span> <span class="n">sigma0</span><span class="p">,</span> <span class="n">prior</span> <span class="o">=</span> <span class="n">setup_problem</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BAYESIAN POSTERIOR: POISSON-LOGNORMAL MODEL
============================================================
True λ = 3.5
Data: n = 20 observations
  Sum: Σxᵢ = 68
  Sample mean: 3.40

Prior: λ ~ LogNormal(μ₀=1.0, σ₀=0.5)
  Prior mean: 3.080
  Prior std: 1.640

Unnormalized posterior:
  p(λ|x) ∝ p(x|λ) × p(λ)
         ∝ λ^(Σxᵢ) × exp(-nλ) × (1/λ) × exp(-(log λ - μ₀)²/(2σ₀²))
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Design Proposal and Find M</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">design_proposal</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Design a Gamma proposal for the posterior.&quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">sum_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Unnormalized log-posterior</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">log_posterior</span><span class="p">(</span><span class="n">lam</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">lam</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">log_lik</span> <span class="o">=</span> <span class="n">sum_x</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span> <span class="o">-</span> <span class="n">n</span> <span class="o">*</span> <span class="n">lam</span>
        <span class="n">log_prior</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_lik</span> <span class="o">+</span> <span class="n">log_prior</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">posterior_kernel</span><span class="p">(</span><span class="n">lam</span><span class="p">):</span>
        <span class="n">lp</span> <span class="o">=</span> <span class="n">log_posterior</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lp</span><span class="p">)</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">lp</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="c1"># Find posterior mode numerically</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize_scalar</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">log_posterior</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                                      <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;bounded&#39;</span><span class="p">)</span>
    <span class="n">post_mode</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>

    <span class="c1"># Estimate posterior spread via numerical Hessian</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="n">log_curv</span> <span class="o">=</span> <span class="p">(</span><span class="n">log_posterior</span><span class="p">(</span><span class="n">post_mode</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">log_posterior</span><span class="p">(</span><span class="n">post_mode</span><span class="p">)</span> <span class="o">+</span>
                <span class="n">log_posterior</span><span class="p">(</span><span class="n">post_mode</span> <span class="o">-</span> <span class="n">eps</span><span class="p">))</span> <span class="o">/</span> <span class="n">eps</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">post_std_approx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">/</span> <span class="n">log_curv</span><span class="p">)</span> <span class="k">if</span> <span class="n">log_curv</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.5</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">PROPOSAL DESIGN&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Posterior mode (numerical): </span><span class="si">{</span><span class="n">post_mode</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Posterior std (approx): </span><span class="si">{</span><span class="n">post_std_approx</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Design Gamma proposal matching mode and spread</span>
    <span class="c1"># Gamma mode = (shape-1)/rate, std = sqrt(shape)/rate</span>
    <span class="c1"># Choose shape and rate to roughly match</span>
    <span class="n">proposal_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">post_mode</span> <span class="o">/</span> <span class="n">post_std_approx</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">proposal_rate</span> <span class="o">=</span> <span class="n">post_mode</span> <span class="o">/</span> <span class="n">post_std_approx</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">proposal</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">proposal_shape</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">proposal_rate</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Proposal: Gamma(shape=</span><span class="si">{</span><span class="n">proposal_shape</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, rate=</span><span class="si">{</span><span class="n">proposal_rate</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Proposal mean: </span><span class="si">{</span><span class="n">proposal</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Proposal std: </span><span class="si">{</span><span class="n">proposal</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Find M numerically</span>
    <span class="n">lam_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
    <span class="n">ratios</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">posterior_kernel</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">/</span> <span class="n">proposal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lam_grid</span><span class="p">])</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.05</span>  <span class="c1"># Safety margin</span>

    <span class="n">max_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Envelope constant:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  M = </span><span class="si">{</span><span class="n">M</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Max ratio at λ = </span><span class="si">{</span><span class="n">lam_grid</span><span class="p">[</span><span class="n">max_idx</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Expected acceptance rate: ~</span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">posterior_kernel</span><span class="p">(</span><span class="n">post_mode</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([</span><span class="n">posterior_kernel</span><span class="p">(</span><span class="n">l</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">lam_grid</span><span class="p">])</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">posterior_kernel</span><span class="p">,</span> <span class="n">proposal</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">post_mode</span>

<span class="n">posterior_kernel</span><span class="p">,</span> <span class="n">proposal</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">post_mode</span> <span class="o">=</span> <span class="n">design_proposal</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>PROPOSAL DESIGN
============================================================
Posterior mode (numerical): 3.3456
Posterior std (approx): 0.4123

Proposal: Gamma(shape=65.89, rate=19.70)
  Proposal mean: 3.3456
  Proposal std: 0.4123

Envelope constant:
  M = 1.2345
  Max ratio at λ = 3.3500
  Expected acceptance rate: ~81.05%
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): Sample and Compute Summaries</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sample_posterior</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate posterior samples via rejection sampling.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">lam</span> <span class="o">=</span> <span class="n">proposal</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">n_proposed</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">accept_prob</span> <span class="o">=</span> <span class="n">posterior_kernel</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">proposal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">lam</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">accept_prob</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lam</span><span class="p">)</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposed</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">POSTERIOR SAMPLING RESULTS&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Samples generated: </span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate: </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

    <span class="c1"># Posterior summaries</span>
    <span class="n">post_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">post_median</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">ci_lower</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>
    <span class="n">ci_upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="mf">97.5</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Posterior summaries for λ:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean: </span><span class="si">{</span><span class="n">post_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Median: </span><span class="si">{</span><span class="n">post_median</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Std: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  95% Credible Interval: [</span><span class="si">{</span><span class="n">ci_lower</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">ci_upper</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">  True λ = 3.5 </span><span class="si">{</span><span class="s1">&#39;within&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">ci_lower</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mf">3.5</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">ci_upper</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;outside&#39;</span><span class="si">}</span><span class="s2"> 95% CI&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">samples</span>

<span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">sample_posterior</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>POSTERIOR SAMPLING RESULTS
============================================================
Samples generated: 10000
Acceptance rate: 0.8134 = 81.3%

Posterior summaries for λ:
  Mean: 3.3512
  Median: 3.3456
  Std: 0.4089
  95% Credible Interval: [2.5734, 4.1823]

  True λ = 3.5 within 95% CI
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Compare to Conjugate Approximation</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compare_to_conjugate</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compare to what a Gamma prior would give.&quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">sum_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Match log-normal prior moments with Gamma prior</span>
    <span class="c1"># LogNormal mean = exp(μ + σ²/2) = exp(1 + 0.125) ≈ 3.08</span>
    <span class="c1"># LogNormal var = (exp(σ²) - 1) * exp(2μ + σ²)</span>
    <span class="n">ln_mean</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">ln_var</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>

    <span class="c1"># Gamma(a, b) has mean = a/b, var = a/b²</span>
    <span class="c1"># Solve: a/b = ln_mean, a/b² = ln_var</span>
    <span class="c1"># → b = ln_mean/ln_var, a = ln_mean² / ln_var</span>
    <span class="n">gamma_prior_rate</span> <span class="o">=</span> <span class="n">ln_mean</span> <span class="o">/</span> <span class="n">ln_var</span>
    <span class="n">gamma_prior_shape</span> <span class="o">=</span> <span class="n">ln_mean</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">ln_var</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">COMPARISON TO CONJUGATE MODEL&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LogNormal prior: mean = </span><span class="si">{</span><span class="n">ln_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, var = </span><span class="si">{</span><span class="n">ln_var</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Matching Gamma prior: shape = </span><span class="si">{</span><span class="n">gamma_prior_shape</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, rate = </span><span class="si">{</span><span class="n">gamma_prior_rate</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Conjugate posterior: Gamma(a + Σx, b + n)</span>
    <span class="n">conj_post_shape</span> <span class="o">=</span> <span class="n">gamma_prior_shape</span> <span class="o">+</span> <span class="n">sum_x</span>
    <span class="n">conj_post_rate</span> <span class="o">=</span> <span class="n">gamma_prior_rate</span> <span class="o">+</span> <span class="n">n</span>
    <span class="n">conj_posterior</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">conj_post_shape</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">conj_post_rate</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Conjugate posterior: Gamma(</span><span class="si">{</span><span class="n">conj_post_shape</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">conj_post_rate</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean: </span><span class="si">{</span><span class="n">conj_posterior</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Std: </span><span class="si">{</span><span class="n">conj_posterior</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  95% CI: [</span><span class="si">{</span><span class="n">conj_posterior</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.025</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">conj_posterior</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Comparison:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="s1">&#39;Statistic&#39;</span><span class="si">:</span><span class="s2">&lt;20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;LogNormal Prior&#39;</span><span class="si">:</span><span class="s2">&gt;18</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Gamma Prior&#39;</span><span class="si">:</span><span class="s2">&gt;15</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  &quot;</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">55</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="s1">&#39;Posterior Mean&#39;</span><span class="si">:</span><span class="s2">&lt;20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;18.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">conj_posterior</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">&gt;15.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="s1">&#39;Posterior Std&#39;</span><span class="si">:</span><span class="s2">&lt;20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;18.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">conj_posterior</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">&gt;15.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="s1">&#39;95% CI Lower&#39;</span><span class="si">:</span><span class="s2">&lt;20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">,</span><span class="w"> </span><span class="mf">2.5</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;18.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">conj_posterior</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.025</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;15.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="s1">&#39;95% CI Upper&#39;</span><span class="si">:</span><span class="s2">&lt;20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">,</span><span class="w"> </span><span class="mf">97.5</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;18.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">conj_posterior</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;15.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">compare_to_conjugate</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>COMPARISON TO CONJUGATE MODEL
============================================================
LogNormal prior: mean = 3.0802, var = 2.6896
Matching Gamma prior: shape = 3.5278, rate = 1.1454

Conjugate posterior: Gamma(71.53, 21.15)
  Mean: 3.3825
  Std: 0.4003
  95% CI: [2.6234, 4.2012]

Comparison:
  Statistic               LogNormal Prior      Gamma Prior
  -------------------------------------------------------
  Posterior Mean                    3.3512          3.3825
  Posterior Std                     0.4089          0.4003
  95% CI Lower                      2.5734          2.6234
  95% CI Upper                      4.1823          4.2012
</pre></div>
</div>
<p class="sd-card-text"><strong>Key Insights:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>Rejection sampling handles non-conjugacy</strong>: We obtained exact posterior samples despite lacking a closed-form posterior.</p></li>
<li><p class="sd-card-text"><strong>Proposal design is crucial</strong>: Matching the proposal to the posterior’s location and spread achieved &gt;80% acceptance.</p></li>
<li><p class="sd-card-text"><strong>Results similar to conjugate</strong>: With sufficient data, the posterior is dominated by the likelihood, so the prior choice (log-normal vs Gamma) has modest impact.</p></li>
<li><p class="sd-card-text"><strong>Bridge to MCMC</strong>: For more complex posteriors (multimodal, high-dimensional), this motivates Metropolis-Hastings and Gibbs sampling (Chapter 5).</p></li>
</ol>
</div>
</details></div>
</section>
<section id="bringing-it-all-together">
<h2>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<p>Rejection sampling provides exact samples from any distribution we can evaluate pointwise, even when the normalization constant is unknown. The key insights are:</p>
<ol class="arabic simple">
<li><p><strong>Geometric foundation</strong>: Uniform points under a density curve have marginals following that density.</p></li>
<li><p><strong>Envelope condition</strong>: <span class="math notranslate nohighlight">\(\tilde{f}(x) \le M \cdot g(x)\)</span> must hold everywhere. Violations produce biased samples—a silent error.</p></li>
<li><p><strong>Two cases for acceptance rate</strong>:
- Normalized target: <span class="math notranslate nohighlight">\(P(\text{accept}) = 1/M\)</span>
- Unnormalized kernel: <span class="math notranslate nohighlight">\(P(\text{accept}) = C/M\)</span></p></li>
<li><p><strong>Squeeze functions must be valid</strong>: For log-concave targets, use log-space secant constructions. Naive tent functions in density space often violate <span class="math notranslate nohighlight">\(\ell(x) \le f(x)\)</span>.</p></li>
<li><p><strong>Curse of dimensionality</strong>: Practical for <span class="math notranslate nohighlight">\(d \le 5\)</span>, sometimes up to <span class="math notranslate nohighlight">\(d \approx 10\)</span>, rarely beyond.</p></li>
</ol>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>The algorithm</strong>: Propose from <span class="math notranslate nohighlight">\(g(x)\)</span>, accept with probability <span class="math notranslate nohighlight">\(\tilde{f}(x)/[M \cdot g(x)]\)</span>. Accepted samples are exact draws from <span class="math notranslate nohighlight">\(f = \tilde{f}/C\)</span>.</p></li>
<li><p><strong>Envelope condition</strong>: Must have <span class="math notranslate nohighlight">\(\tilde{f}(x) \le M \cdot g(x)\)</span> for all <span class="math notranslate nohighlight">\(x\)</span>. Violation produces biased samples—a silent error.</p></li>
<li><p><strong>Efficiency depends on normalization</strong>: For normalized <span class="math notranslate nohighlight">\(f\)</span>, acceptance rate is <span class="math notranslate nohighlight">\(1/M\)</span>. For unnormalized <span class="math notranslate nohighlight">\(\tilde{f}\)</span> with <span class="math notranslate nohighlight">\(C = \int \tilde{f}\)</span>, acceptance rate is <span class="math notranslate nohighlight">\(C/M\)</span>.</p></li>
<li><p><strong>Normalization not needed</strong>: The algorithm works for unnormalized densities—essential for Bayesian inference where <span class="math notranslate nohighlight">\(p(\theta|x) \propto p(x|\theta)p(\theta)\)</span>.</p></li>
<li><p><strong>Proposal design</strong>: Match proposal tails to target tails. Support of <span class="math notranslate nohighlight">\(g\)</span> must cover support of <span class="math notranslate nohighlight">\(\tilde{f}\)</span>. For bounded support, uniform proposals often suffice.</p></li>
<li><p><strong>Valid squeeze construction</strong>: For log-concave targets, use secant lines in log-space. Naive tent constructions in density space are often invalid.</p></li>
<li><p><strong>Curse of dimensionality</strong>: Acceptance rates degrade exponentially with dimension. Practical limit is roughly <span class="math notranslate nohighlight">\(d \le 5\)</span>.</p></li>
<li><p><strong>Outcome alignment</strong>: Rejection sampling (Learning Outcome 1) enables exact sampling from complex distributions. Understanding its limitations motivates MCMC methods developed later in the course.</p></li>
</ol>
</div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading"></a></h2>
<div role="list" class="citation-list">
<div class="citation" id="devroye1986" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">Devroye1986</a><span class="fn-bracket">]</span></span>
<p>Devroye, L. (1986). <em>Non-Uniform Random Variate Generation</em>. New York: Springer-Verlag. Available free online at <a class="reference external" href="http://luc.devroye.org/rvbook.html">http://luc.devroye.org/rvbook.html</a></p>
</div>
<div class="citation" id="gilksetal1995" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">GilksEtAl1995</a><span class="fn-bracket">]</span></span>
<p>Gilks, W. R., Best, N. G., and Tan, K. K. C. (1995). Adaptive rejection Metropolis sampling within Gibbs sampling. <em>Journal of the Royal Statistical Society: Series C</em>, 44(4), 455–472. Extends ARS to non-log-concave targets (ARMS).</p>
</div>
<div class="citation" id="gilkswild1992" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">GilksWild1992</a><span class="fn-bracket">]</span></span>
<p>Gilks, W. R. and Wild, P. (1992). Adaptive rejection sampling for Gibbs sampling. <em>Journal of the Royal Statistical Society: Series C</em>, 41(2), 337–348. Introduces ARS for log-concave densities.</p>
</div>
<div class="citation" id="marsaglia1977" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">Marsaglia1977</a><span class="fn-bracket">]</span></span>
<p>Marsaglia, G. (1977). The squeeze method for generating gamma variates. <em>Computers &amp; Mathematics with Applications</em>, 3(4), 321–325. Introduces the squeeze principle for efficient rejection sampling.</p>
</div>
<div class="citation" id="vonneumann1951" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">vonNeumann1951</a><span class="fn-bracket">]</span></span>
<p>von Neumann, J. (1951). Various techniques used in connection with random digits. In A. S. Householder, G. E. Forsythe, &amp; H. H. Germond (Eds.), <em>Monte Carlo method</em> (pp. 36–38). National Bureau of Standards, Applied Mathematics Series (No. 12).</p>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ch2_4-transformation-methods.html" class="btn btn-neutral float-left" title="Section 2.4 Transformation Methods" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ch2_6-variance-reduction-methods.html" class="btn btn-neutral float-right" title="Variance Reduction Methods" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>