.. _chapter4:

Chapter 4: Resampling Methods
===============================

.. contents:: Chapter Contents
   :local:
   :depth: 2

This chapter covers resampling methods—computational techniques that use the data itself to quantify uncertainty, estimate sampling distributions, and validate models. Resampling methods are fundamental tools in modern data science because they make minimal parametric assumptions and work effectively even when theoretical distributions are unknown or intractable.

We explore two major families of resampling techniques: the bootstrap (sampling with replacement to estimate sampling distributions) and cross-validation (systematic data partitioning to assess predictive performance). These methods transform the classical problem of statistical inference—where we have one sample and want to understand what would happen with many samples—into a computational problem we can solve through simulation.

The chapter begins with the jackknife (a precursor to the bootstrap), then develops nonparametric and parametric bootstrap methods for constructing confidence intervals and correcting bias. We then turn to cross-validation techniques (leave-one-out and k-fold) for model selection and predictive evaluation, showing how resampling provides honest assessments of model performance.

**Learning Objectives:** Upon completion of this chapter, students will be able to:

* Understand the jackknife as a resampling method for bias estimation and variance approximation
* Implement and apply the nonparametric bootstrap for constructing sampling distributions
* Distinguish between parametric and nonparametric bootstrap and choose appropriately
* Construct bootstrap confidence intervals using percentile, BCa, and other methods
* Apply bootstrap methods for bias correction of estimators
* Understand when bootstrap methods fail (e.g., extreme order statistics, heavy-tailed distributions)
* Implement leave-one-out cross-validation (LOOCV) for model assessment
* Apply k-fold cross-validation and understand bias-variance tradeoffs in fold choice
* Use cross-validation for model selection and hyperparameter tuning
* Diagnose overfitting and assess predictive performance using resampling
* Implement computational optimizations for resampling (parallel processing, efficient algorithms)

.. toctree::
   :maxdepth: 2
   :caption: Sections

   jackknife_introduction
   bootstrap_fundamentals
   nonparametric_bootstrap
   parametric_bootstrap
   confidence_intervals
   bias_correction
   cross_validation_loo
   cross_validation_k_fold
   model_selection