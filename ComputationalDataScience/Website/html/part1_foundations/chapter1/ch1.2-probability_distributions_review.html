

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>1.1.2. Probability Distributions: Theory and Computation &mdash; STAT 418</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=5af2d4ad" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT418/Website/part1_foundations/chapter1/ch1.2-probability_distributions_review.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=d2113767"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="1.1.3. Python Random Generation" href="ch1.3-python_random_generation.html" />
    <link rel="prev" title="1.1.1. Paradigms of Probability and Statistical Inference" href="ch1.1-probability-and-inference-paradigms.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Course Content</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">1. Part I: Foundations of Probability and Computation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">1.1. Chapter 1: Statistical Paradigms and Core Concepts</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ch1.1-probability-and-inference-paradigms.html">1.1.1. Paradigms of Probability and Statistical Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch1.1-probability-and-inference-paradigms.html#the-mathematical-foundation-kolmogorov-s-axioms">The Mathematical Foundation: Kolmogorov‚Äôs Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.1-probability-and-inference-paradigms.html#interpretations-of-probability">Interpretations of Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.1-probability-and-inference-paradigms.html#statistical-inference-paradigms">Statistical Inference Paradigms</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.1-probability-and-inference-paradigms.html#historical-and-philosophical-debates">Historical and Philosophical Debates</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.1-probability-and-inference-paradigms.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.1-probability-and-inference-paradigms.html#looking-ahead-our-course-focus">Looking Ahead: Our Course Focus</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.1-probability-and-inference-paradigms.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">1.1.2. Probability Distributions: Theory and Computation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#from-abstract-foundations-to-concrete-tools">From Abstract Foundations to Concrete Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-python-ecosystem-for-probability">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="#introduction-why-probability-distributions-matter">Introduction: Why Probability Distributions Matter</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#continuous-distributions">Continuous Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#additional-important-distributions">Additional Important Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary-and-practical-guidelines">Summary and Practical Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch1.3-python_random_generation.html">1.1.3. Python Random Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch1.3-python_random_generation.html#from-mathematical-distributions-to-computational-samples">From Mathematical Distributions to Computational Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.3-python_random_generation.html#the-python-ecosystem-at-a-glance">The Python Ecosystem at a Glance</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.3-python_random_generation.html#understanding-pseudo-random-number-generation">Understanding Pseudo-Random Number Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.3-python_random_generation.html#the-standard-library-random-module">The Standard Library: <code class="docutils literal notranslate"><span class="pre">random</span></code> Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.3-python_random_generation.html#numpy-fast-vectorized-random-sampling">NumPy: Fast Vectorized Random Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.3-python_random_generation.html#scipy-stats-the-complete-statistical-toolkit">SciPy Stats: The Complete Statistical Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.3-python_random_generation.html#bringing-it-all-together-library-selection-guide">Bringing It All Together: Library Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1.3-python_random_generation.html#looking-ahead-from-random-numbers-to-monte-carlo-methods">Looking Ahead: From Random Numbers to Monte Carlo Methods</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part2_simulation/index.html">Part II: Simulation-Based Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part2_simulation/chapter2/index.html">1. Chapter 2: Monte Carlo Simulation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html">1.1. Monte Carlo Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#the-historical-development-of-monte-carlo-methods">1.1.1. The Historical Development of Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#the-core-principle-expectation-as-integration">1.1.2. The Core Principle: Expectation as Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#theoretical-foundations">1.1.3. Theoretical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#variance-estimation-and-confidence-intervals">1.1.4. Variance Estimation and Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#worked-examples">1.1.5. Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#comparison-with-deterministic-methods">1.1.6. Comparison with Deterministic Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#sample-size-determination">1.1.7. Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#convergence-diagnostics-and-monitoring">1.1.8. Convergence Diagnostics and Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#practical-considerations">1.1.9. Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#bringing-it-all-together">1.1.10. Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.1-monte-carlo-fundamentals.html#transition-to-what-follows">1.1.11. Transition to What Follows</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html">1.2. Uniform Random Variates</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#the-probability-integral-transform">1.2.1. The Probability Integral Transform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#the-paradox-of-computational-randomness">1.2.2. The Paradox of Computational Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#chaotic-dynamical-systems-an-instructive-failure">1.2.3. Chaotic Dynamical Systems: An Instructive Failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#linear-congruential-generators">1.2.4. Linear Congruential Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#shift-register-generators">1.2.5. Shift-Register Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#the-kiss-generator-combining-strategies">1.2.6. The KISS Generator: Combining Strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#modern-generators-mersenne-twister-and-pcg">1.2.7. Modern Generators: Mersenne Twister and PCG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#statistical-testing-of-random-number-generators">1.2.8. Statistical Testing of Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#practical-considerations">1.2.9. Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#bringing-it-all-together">1.2.10. Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.2-uniform-random-variates.html#transition-to-what-follows">1.2.11. Transition to What Follows</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.3-inverse-cdf-method.html">1.3. Inverse CDF Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.3-inverse-cdf-method.html#mathematical-foundations">1.3.1. Mathematical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.3-inverse-cdf-method.html#continuous-distributions-with-closed-form-inverses">1.3.2. Continuous Distributions with Closed-Form Inverses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.3-inverse-cdf-method.html#numerical-inversion">1.3.3. Numerical Inversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.3-inverse-cdf-method.html#discrete-distributions">1.3.4. Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.3-inverse-cdf-method.html#mixed-distributions">1.3.5. Mixed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.3-inverse-cdf-method.html#practical-considerations">1.3.6. Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.3-inverse-cdf-method.html#bringing-it-all-together">1.3.7. Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter2/ch2.3-inverse-cdf-method.html#transition-to-what-follows">1.3.8. Transition to What Follows</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../part2_simulation/chapter3/index.html">2. Chapter 3: Frequentist Statistical Inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter3/sampling_variability.html">2.1. Sampling Variability</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/sampling_variability.html#introduction">2.1.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/sampling_variability.html#key-concepts">2.1.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/sampling_variability.html#mathematical-framework">2.1.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/sampling_variability.html#python-implementation">2.1.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/sampling_variability.html#examples">2.1.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/sampling_variability.html#summary">2.1.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter3/statistical_estimators.html">2.2. Statistical Estimators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/statistical_estimators.html#introduction">2.2.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/statistical_estimators.html#key-concepts">2.2.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/statistical_estimators.html#mathematical-framework">2.2.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/statistical_estimators.html#python-implementation">2.2.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/statistical_estimators.html#examples">2.2.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/statistical_estimators.html#summary">2.2.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter3/plugin_methods.html">2.3. Plugin Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/plugin_methods.html#introduction">2.3.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/plugin_methods.html#key-concepts">2.3.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/plugin_methods.html#mathematical-framework">2.3.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/plugin_methods.html#python-implementation">2.3.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/plugin_methods.html#examples">2.3.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/plugin_methods.html#summary">2.3.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter3/parametric_inference.html">2.4. Parametric Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/parametric_inference.html#introduction">2.4.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/parametric_inference.html#key-concepts">2.4.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/parametric_inference.html#mathematical-framework">2.4.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/parametric_inference.html#python-implementation">2.4.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/parametric_inference.html#examples">2.4.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/parametric_inference.html#summary">2.4.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter3/exponential_families.html">2.5. Exponential Families</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/exponential_families.html#introduction">2.5.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/exponential_families.html#key-concepts">2.5.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/exponential_families.html#mathematical-framework">2.5.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/exponential_families.html#python-implementation">2.5.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/exponential_families.html#examples">2.5.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/exponential_families.html#summary">2.5.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter3/maximum_likelihood.html">2.6. Maximum Likelihood</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/maximum_likelihood.html#introduction">2.6.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/maximum_likelihood.html#key-concepts">2.6.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/maximum_likelihood.html#mathematical-framework">2.6.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/maximum_likelihood.html#python-implementation">2.6.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/maximum_likelihood.html#examples">2.6.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/maximum_likelihood.html#summary">2.6.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter3/linear_models.html">2.7. Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/linear_models.html#introduction">2.7.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/linear_models.html#key-concepts">2.7.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/linear_models.html#mathematical-framework">2.7.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/linear_models.html#python-implementation">2.7.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/linear_models.html#examples">2.7.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/linear_models.html#summary">2.7.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter3/generalized_linear_models.html">2.8. Generalized Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/generalized_linear_models.html#introduction">2.8.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/generalized_linear_models.html#key-concepts">2.8.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/generalized_linear_models.html#mathematical-framework">2.8.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/generalized_linear_models.html#python-implementation">2.8.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/generalized_linear_models.html#examples">2.8.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter3/generalized_linear_models.html#summary">2.8.6. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../part2_simulation/chapter4/index.html">3. Chapter 4: Resampling Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter4/jackknife_introduction.html">3.1. Jackknife Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/jackknife_introduction.html#introduction">3.1.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/jackknife_introduction.html#key-concepts">3.1.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/jackknife_introduction.html#mathematical-framework">3.1.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/jackknife_introduction.html#python-implementation">3.1.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/jackknife_introduction.html#examples">3.1.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/jackknife_introduction.html#summary">3.1.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter4/bootstrap_fundamentals.html">3.2. Bootstrap Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bootstrap_fundamentals.html#introduction">3.2.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bootstrap_fundamentals.html#key-concepts">3.2.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bootstrap_fundamentals.html#mathematical-framework">3.2.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bootstrap_fundamentals.html#python-implementation">3.2.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bootstrap_fundamentals.html#examples">3.2.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bootstrap_fundamentals.html#summary">3.2.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter4/nonparametric_bootstrap.html">3.3. Nonparametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/nonparametric_bootstrap.html#introduction">3.3.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/nonparametric_bootstrap.html#key-concepts">3.3.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/nonparametric_bootstrap.html#mathematical-framework">3.3.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/nonparametric_bootstrap.html#python-implementation">3.3.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/nonparametric_bootstrap.html#examples">3.3.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/nonparametric_bootstrap.html#summary">3.3.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter4/parametric_bootstrap.html">3.4. Parametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/parametric_bootstrap.html#introduction">3.4.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/parametric_bootstrap.html#key-concepts">3.4.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/parametric_bootstrap.html#mathematical-framework">3.4.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/parametric_bootstrap.html#python-implementation">3.4.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/parametric_bootstrap.html#examples">3.4.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/parametric_bootstrap.html#summary">3.4.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter4/confidence_intervals.html">3.5. Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/confidence_intervals.html#introduction">3.5.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/confidence_intervals.html#key-concepts">3.5.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/confidence_intervals.html#mathematical-framework">3.5.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/confidence_intervals.html#python-implementation">3.5.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/confidence_intervals.html#examples">3.5.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/confidence_intervals.html#summary">3.5.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter4/bias_correction.html">3.6. Bias Correction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bias_correction.html#introduction">3.6.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bias_correction.html#key-concepts">3.6.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bias_correction.html#mathematical-framework">3.6.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bias_correction.html#python-implementation">3.6.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bias_correction.html#examples">3.6.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/bias_correction.html#summary">3.6.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_loo.html">3.7. Cross Validation Loo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_loo.html#introduction">3.7.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_loo.html#key-concepts">3.7.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_loo.html#mathematical-framework">3.7.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_loo.html#python-implementation">3.7.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_loo.html#examples">3.7.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_loo.html#summary">3.7.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_k_fold.html">3.8. Cross Validation K Fold</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_k_fold.html#introduction">3.8.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_k_fold.html#key-concepts">3.8.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_k_fold.html#mathematical-framework">3.8.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_k_fold.html#python-implementation">3.8.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_k_fold.html#examples">3.8.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/cross_validation_k_fold.html#summary">3.8.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_simulation/chapter4/model_selection.html">3.9. Model Selection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/model_selection.html#introduction">3.9.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/model_selection.html#key-concepts">3.9.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/model_selection.html#mathematical-framework">3.9.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/model_selection.html#python-implementation">3.9.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/model_selection.html#examples">3.9.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_simulation/chapter4/model_selection.html#summary">3.9.6. Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part3_bayesian/index.html">2. Part III: Bayesian Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part3_bayesian/index.html#overview">2.1. Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html">2.1.1. Bayesian Philosophy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">1. </span>Part I: Foundations of Probability and Computation</a></li>
          <li class="breadcrumb-item"><a href="index.html"><span class="section-number">1.1. </span>Chapter 1: Statistical Paradigms and Core Concepts</a></li>
      <li class="breadcrumb-item active"><span class="section-number">1.1.2. </span>Probability Distributions: Theory and Computation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/part1_foundations/chapter1/ch1.2-probability_distributions_review.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="probability-distributions-theory-and-computation">
<span id="ch1-2-probability-distributions-review"></span><h1><span class="section-number">1.1.2. </span>Probability Distributions: Theory and Computation<a class="headerlink" href="#probability-distributions-theory-and-computation" title="Link to this heading">ÔÉÅ</a></h1>
<section id="from-abstract-foundations-to-concrete-tools">
<h2>From Abstract Foundations to Concrete Tools<a class="headerlink" href="#from-abstract-foundations-to-concrete-tools" title="Link to this heading">ÔÉÅ</a></h2>
<p>In Chapter 1.1, we established probability‚Äôs mathematical foundation through Kolmogorov‚Äôs axioms and explored what probability <em>means</em>‚Äîwhether as long-run frequencies, physical propensities, or degrees of belief. We worked with probability spaces abstractly: sample spaces <span class="math notranslate nohighlight">\(\Omega\)</span>, events as subsets, and probability measures <span class="math notranslate nohighlight">\(P\)</span> satisfying three elegant axioms. We defined random variables as functions mapping outcomes to numbers and explored how they‚Äôre described through probability mass functions (PMFs), probability density functions (PDFs), and cumulative distribution functions (CDFs).</p>
<p>But abstract foundations alone don‚Äôt solve data science problems. When analyzing real data, we don‚Äôt start from first principles each time, defining custom probability functions for every new dataset. Instead, we recognize patterns: customer arrivals follow one distribution, equipment failures another, measurement errors yet another. These recurring patterns are captured by <strong>families of probability distributions</strong>‚Äîparametric models that have been studied, catalogued, and implemented because they arise naturally from common data-generating processes.</p>
<p>This chapter bridges the abstract and the concrete. We‚Äôll explore the major probability distributions used throughout data science, understanding both <em>why</em> they arise (mathematical foundations, limit theorems, relationships) and <em>how</em> to use them (Python implementation, computational properties, practical applications). Every distribution we study serves dual purposes: as a theoretical object with provable properties and as a computational tool for modeling real phenomena.</p>
<section id="the-moment-of-discovery-de-moivre-s-insight">
<h3>The Moment of Discovery: De Moivre‚Äôs Insight<a class="headerlink" href="#the-moment-of-discovery-de-moivre-s-insight" title="Link to this heading">ÔÉÅ</a></h3>
<p>Our story begins in early 18th century London. Abraham de Moivre, a French mathematician who fled religious persecution, made his living tutoring and consulting for gamblers. While studying the binomial distribution‚Äîthe pattern emerging from repeated coin flips‚Äîde Moivre noticed something extraordinary. As the number of flips increased, the jagged discrete histogram began to resemble a smooth, continuous bell-shaped curve.</p>
<p>In his 1733 work <em>‚ÄúThe Doctrine of Chances,‚Äù</em> de Moivre derived the mathematical form of this limiting curve‚Äîwhat we now call the normal distribution. Though it would take another century for the full significance to emerge (formalized by Laplace and Gauss), de Moivre had discovered one of nature‚Äôs fundamental patterns: when many small, independent factors contribute to an outcome, the result follows a predictable bell curve.</p>
<p>This wasn‚Äôt mere mathematical curiosity. De Moivre had uncovered a deep truth: nature exhibits regular patterns in randomness. Today, probability distributions are indispensable tools throughout data science:</p>
<ol class="arabic simple">
<li><p><strong>Modeling uncertainty</strong>: Mathematical frameworks for random phenomena‚Äîfrom radioactive decay to customer behavior</p></li>
<li><p><strong>Statistical inference</strong>: Foundations for making statements about populations from samples</p></li>
<li><p><strong>Predictive modeling</strong>: Building blocks of machine learning algorithms and generative models</p></li>
<li><p><strong>Risk quantification</strong>: Tools for decision-making under uncertainty in finance, medicine, and engineering</p></li>
<li><p><strong>Simulation and validation</strong>: Engines for generating synthetic data to test methods and validate systems</p></li>
</ol>
<div class="important admonition">
<p class="admonition-title">Road Map üß≠</p>
<p><strong>Understand</strong>: The major probability distributions, their properties, and when they arise naturally</p>
<p><strong>Develop</strong>: Ability to prove key relationships and derive distribution properties from first principles</p>
<p><strong>Implement</strong>: Proficiency in Python for generating samples, computing probabilities, and visualizing distributions</p>
<p><strong>Evaluate</strong>: Skill in choosing the appropriate distribution for your data and application</p>
</div>
</section>
<section id="this-chapter-s-philosophy-theory-meets-computation">
<h3>This Chapter‚Äôs Philosophy: Theory Meets Computation<a class="headerlink" href="#this-chapter-s-philosophy-theory-meets-computation" title="Link to this heading">ÔÉÅ</a></h3>
<p>This chapter embodies the course‚Äôs dual emphasis on <strong>rigorous mathematics</strong> and <strong>practical implementation</strong>. For each distribution, we:</p>
<ul class="simple">
<li><p><strong>Derive properties mathematically</strong>: Prove means, variances, memoryless properties, and limit theorems from first principles</p></li>
<li><p><strong>Implement computationally</strong>: Generate samples, evaluate probabilities, and visualize using Python‚Äôs scientific stack</p></li>
<li><p><strong>Demonstrate relationships</strong>: Show how distributions connect through limit theorems, transformations, and special cases</p></li>
<li><p><strong>Apply to real problems</strong>: Illustrate when and why each distribution appears in practice</p></li>
</ul>
<p>We‚Äôll prove the De Moivre-Laplace theorem showing binomial convergence to normal, demonstrate the exponential distribution‚Äôs memoryless property, construct the t-distribution as a ratio of normal and chi-square variables, and show the Beta distribution emerging from order statistics of uniform random variables‚Äîall with both rigorous proofs and computational demonstrations.</p>
<p>This approach prepares you for:</p>
<ul class="simple">
<li><p><strong>Chapter 2</strong> (Simulation): Using distribution theory to <em>generate</em> random samples via inverse CDF, rejection sampling, and Box-Muller transformation</p></li>
<li><p><strong>Chapters 3-4</strong> (Inference &amp; Resampling): Using distributions for <em>inference</em>‚Äîestimation, hypothesis testing, bootstrap, cross-validation</p></li>
<li><p><strong>Chapter 5</strong> (Bayesian Methods): Using distributions as <em>priors and posteriors</em> in Bayesian models, implementing MCMC</p></li>
</ul>
<p>Probability distributions are the common language across all statistical paradigms and computational methods. The CDFs and quantile functions you learn here become essential for simulation. The limit theorems justify asymptotic inference. The conjugate relationships enable efficient Bayesian computation.</p>
</section>
<section id="structure-of-this-chapter">
<h3>Structure of This Chapter<a class="headerlink" href="#structure-of-this-chapter" title="Link to this heading">ÔÉÅ</a></h3>
<p>We begin with Python‚Äôs ecosystem for probability‚Äîunderstanding when to use built-in <cite>random</cite>, vectorized NumPy, or comprehensive SciPy. Then we explore:</p>
<p><strong>Discrete Distributions</strong>: Bernoulli, Binomial, Poisson, Geometric, Negative Binomial‚Äîfor modeling counts, trials, and discrete events</p>
<p><strong>Continuous Distributions</strong>: Uniform, Normal, Exponential, Gamma, Beta‚Äîfor modeling measurements, durations, and proportions</p>
<p><strong>Inference Distributions</strong>: Student‚Äôs t, Chi-squared, F‚Äîarising in statistical inference from normal populations</p>
<p>For each distribution, we provide:</p>
<ul class="simple">
<li><p><strong>Definition and parameterization</strong> (noting different conventions)</p></li>
<li><p><strong>Historical context</strong> explaining why it was discovered and matters</p></li>
<li><p><strong>Mathematical properties</strong> with rigorous derivations</p></li>
<li><p><strong>Computational implementation</strong> with complete Python examples</p></li>
<li><p><strong>Relationships to other distributions</strong> through theorems and proofs</p></li>
<li><p><strong>Practical applications</strong> showing when to use it</p></li>
</ul>
<p>By chapter‚Äôs end, you‚Äôll have both deep theoretical understanding and practical fluency with the probability distributions that form data science‚Äôs foundation. Let‚Äôs begin.</p>
<div class="tip admonition">
<p class="admonition-title">Prerequisites Check ‚úì</p>
<p>Before proceeding, ensure you‚Äôre comfortable with:</p>
<ul class="simple">
<li><p>Random variables (defined in Chapter 1.1)</p></li>
<li><p>PMFs, PDFs, and CDFs (covered in Chapter 1.1)</p></li>
<li><p>Basic calculus (derivatives, integrals, Taylor series)</p></li>
<li><p>Limit notation and convergence concepts</p></li>
<li><p>Python basics and NumPy arrays</p></li>
</ul>
<p>If any of these feel shaky, review Chapter 1.1‚Äôs ‚ÄúMathematical Preliminaries‚Äù section.</p>
</div>
</section>
</section>
<section id="the-python-ecosystem-for-probability">
<h2>The Python Ecosystem for Probability<a class="headerlink" href="#the-python-ecosystem-for-probability" title="Link to this heading">ÔÉÅ</a></h2>
<p>SciPy provides a unified interface for all distributions through <cite>scipy.stats</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Example: Normal distribution</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># N(0, 1)</span>

<span class="c1"># PDF/PMF evaluation</span>
<span class="n">x</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">pdf_value</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># For continuous</span>
<span class="c1"># pmf_value = dist.pmf(x)  # For discrete</span>

<span class="c1"># CDF evaluation</span>
<span class="n">cdf_value</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># P(X ‚â§ x)</span>

<span class="c1"># Quantile function (inverse CDF)</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">quantile</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>  <span class="c1"># Find x such that P(X ‚â§ x) = 0.95</span>

<span class="c1"># Survival function (complement of CDF)</span>
<span class="n">sf_value</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># P(X &gt; x) = 1 - F(x)</span>

<span class="c1"># Random sampling</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Moments</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">variance</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PDF at </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">pdf_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CDF at </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">cdf_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;95th percentile: </span><span class="si">{</span><span class="n">quantile</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean: </span><span class="si">{</span><span class="n">mean</span><span class="si">}</span><span class="s2">, Variance: </span><span class="si">{</span><span class="n">variance</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="tip admonition">
<p class="admonition-title">Computational Best Practices üíª</p>
<p><strong>For discrete distributions:</strong></p>
<ul class="simple">
<li><p>Use <cite>.pmf(x)</cite> for probabilities</p></li>
<li><p>CDF is right-continuous step function</p></li>
<li><p>Quantile function may have flat regions</p></li>
</ul>
<p><strong>For continuous distributions:</strong></p>
<ul class="simple">
<li><p>Use <cite>.pdf(x)</cite> for density (not probability!)</p></li>
<li><p>Remember <span class="math notranslate nohighlight">\(P(X = x) = 0\)</span> for any specific <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p>Compute interval probabilities: <cite>cdf(b) - cdf(a)</cite></p></li>
</ul>
<p><strong>Numerical considerations:</strong></p>
<ul class="simple">
<li><p>For extreme quantiles (p near 0 or 1), use log-scale functions when available</p></li>
<li><p>Be aware of numerical precision limits in tail probabilities</p></li>
<li><p>For simulation, always set <cite>random_state</cite> for reproducibility</p></li>
</ul>
</div>
<section id="practical-example-complete-distribution-analysis">
<h3>Practical Example: Complete Distribution Analysis<a class="headerlink" href="#practical-example-complete-distribution-analysis" title="Link to this heading">ÔÉÅ</a></h3>
<p>Let‚Äôs bring everything together with a complete analysis:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">analyze_distribution</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">x_range</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Complete distribution analysis: PMF/PDF, CDF, quantiles.&quot;&quot;&quot;</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">),</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="c1"># Determine if discrete or continuous</span>
    <span class="n">is_discrete</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="s1">&#39;pmf&#39;</span><span class="p">)</span>

    <span class="c1"># 1. PMF/PDF</span>
    <span class="k">if</span> <span class="n">is_discrete</span><span class="p">:</span>
        <span class="n">x_discrete</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">x_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">x_range</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">pmf</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x_discrete</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">x_discrete</span><span class="p">,</span> <span class="n">pmf</span><span class="p">,</span> <span class="n">basefmt</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;P(X = x)&#39;</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;PMF of </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pdf</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;f(x)&#39;</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;PDF of </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># 2. CDF</span>
    <span class="n">cdf</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">cdf</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;F(x) = P(X ‚â§ x)&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;CDF of </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)</span>

    <span class="c1"># Mark quartiles</span>
    <span class="n">quartiles</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">quartiles</span><span class="p">:</span>
        <span class="n">x_q</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">x_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">x_q</span> <span class="o">&lt;=</span> <span class="n">x_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x_q</span><span class="p">,</span> <span class="n">x_q</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">q</span><span class="p">],</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
            <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_q</span><span class="p">],</span> <span class="p">[</span><span class="n">q</span><span class="p">,</span> <span class="n">q</span><span class="p">],</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
            <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_q</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

    <span class="c1"># 3. Quantile function</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">quantiles</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">quantiles</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Probability (p)&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;F‚Åª¬π(p)&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Quantile Function of </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Mark same quartiles</span>
    <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]:</span>
        <span class="n">x_q</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
        <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">x_q</span><span class="p">,</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

    <span class="c1"># 4. Random samples and histogram</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sample histogram&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_discrete</span><span class="p">:</span>
        <span class="n">x_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="nb">int</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">max</span><span class="p">())</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x_plot</span><span class="p">),</span> <span class="s1">&#39;ro-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True PMF&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">samples</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">200</span><span class="p">)</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_plot</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True PDF&#39;</span><span class="p">)</span>

    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density/Probability&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Sample Distribution (n=10,000)&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># Print summary statistics</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> Summary Statistics:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean: </span><span class="si">{</span><span class="n">dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Variance: </span><span class="si">{</span><span class="n">dist</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Std Dev: </span><span class="si">{</span><span class="n">dist</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Median (50th percentile): </span><span class="si">{</span><span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Q1 (25th percentile): </span><span class="si">{</span><span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Q3 (75th percentile): </span><span class="si">{</span><span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;IQR: </span><span class="si">{</span><span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Example 1: Continuous distribution</span>
<span class="n">normal_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">analyze_distribution</span><span class="p">(</span><span class="n">normal_dist</span><span class="p">,</span> <span class="s2">&quot;Normal(5, 2¬≤)&quot;</span><span class="p">,</span> <span class="n">x_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># Example 2: Discrete distribution</span>
<span class="n">poisson_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">analyze_distribution</span><span class="p">(</span><span class="n">poisson_dist</span><span class="p">,</span> <span class="s2">&quot;Poisson(4)&quot;</span><span class="p">,</span> <span class="n">x_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="why-study-named-distributions">
<h3>Why Study Named Distributions?<a class="headerlink" href="#why-study-named-distributions" title="Link to this heading">ÔÉÅ</a></h3>
<p>Rather than define a new probability function for every problem, we use <strong>families of distributions</strong> characterized by parameters. This is practical for several reasons:</p>
<ol class="arabic simple">
<li><p><strong>Parsimony</strong>: A few parameters (e.g., <span class="math notranslate nohighlight">\(\mu, \sigma\)</span> for Normal) capture complex behavior</p></li>
<li><p><strong>Theory</strong>: Well-understood properties (mean, variance, limit theorems)</p></li>
<li><p><strong>Relationships</strong>: Distributions connect to each other in elegant ways</p></li>
<li><p><strong>Software</strong>: Pre-implemented in libraries like SciPy</p></li>
<li><p><strong>Communication</strong>: ‚ÄúNormal(100, 15¬≤)‚Äù conveys complete information compactly</p></li>
</ol>
<p>The distributions we study aren‚Äôt arbitrary‚Äîthey arise naturally from common data-generating processes and satisfy important theoretical properties.</p>
</section>
<section id="course-context-and-computational-focus">
<h3>Course Context and Computational Focus<a class="headerlink" href="#course-context-and-computational-focus" title="Link to this heading">ÔÉÅ</a></h3>
<p>This chapter emphasizes <strong>computational implementation alongside theory</strong>. For each distribution, we:</p>
<ul class="simple">
<li><p>Derive key properties mathematically (PMF/PDF, CDF, moments)</p></li>
<li><p>Implement generation and computation in Python</p></li>
<li><p>Visualize behavior and relationships</p></li>
<li><p>Connect to real applications</p></li>
</ul>
<p>This dual focus‚Äîrigorous mathematics and practical code‚Äîprepares you for both statistical inference (Chapters 3-4) and computational simulation (Chapter 2). The distributions learned here are the building blocks for Monte Carlo methods, resampling techniques, and Bayesian analysis throughout the course.</p>
<div class="important admonition">
<p class="admonition-title">Connection to Course Trajectory üó∫Ô∏è</p>
<ul class="simple">
<li><p><strong>This chapter</strong>: Probability distributions as computational/theoretical tools (PMFs, PDFs, CDFs)</p></li>
<li><p><strong>Chapter 2</strong>: Using distributions to <em>generate</em> random samples (inverse CDF, rejection sampling, Box-Muller)</p></li>
<li><p><strong>Chapters 3-4</strong>: Using distributions for <em>inference</em> (estimation, hypothesis testing, bootstrap)</p></li>
<li><p><strong>Chapter 5</strong>: Using distributions in <em>Bayesian models</em> (priors, posteriors, MCMC)</p></li>
</ul>
<p>Distributions are the common language across all paradigms and methods in computational data science. The CDF and quantile functions you‚Äôve learned here are especially crucial for simulation methods in Chapter 2.</p>
</div>
<div class="chapter-intro">
   <p>Now that we understand how distributions are described mathematically (PMF, PDF, CDF) and computationally (Python/SciPy), we explore the major probability distributions used in data science. We'll see their theoretical properties, computational implementation, and practical applications‚Äîall building on the foundation of distribution functions established above.</p>
</div></section>
</section>
<section id="introduction-why-probability-distributions-matter">
<h2>Introduction: Why Probability Distributions Matter<a class="headerlink" href="#introduction-why-probability-distributions-matter" title="Link to this heading">ÔÉÅ</a></h2>
<p>[Continue with the existing de Moivre historical introduction‚Ä¶]</p>
<p>In the early 18th century, Abraham de Moivre made a discovery that would revolutionize mathematics and science. While helping gamblers calculate their odds, he was studying the binomial distribution‚Äîthe pattern that emerges when you flip a coin many times and count the heads. De Moivre noticed something remarkable: as the number of flips increased, the jagged discrete distribution began to resemble a smooth, bell-shaped curve. In his 1733 work ‚ÄúThe Doctrine of Chances,‚Äù he derived what we now call the normal distribution, though it would take another century for its full significance to be appreciated.</p>
<p>This discovery was more than a mathematical curiosity. It revealed a deep truth about nature: many phenomena, when influenced by numerous small, independent factors, follow predictable patterns. Today, probability distributions are essential tools in data science for several reasons:</p>
<ol class="arabic simple">
<li><p><strong>Modeling uncertainty</strong>: They provide mathematical models for random phenomena</p></li>
<li><p><strong>Statistical inference</strong>: They enable us to make statements about populations based on samples</p></li>
<li><p><strong>Predictive modeling</strong>: They form the basis for many machine learning algorithms</p></li>
<li><p><strong>Risk assessment</strong>: They help quantify and manage uncertainty in decision-making</p></li>
<li><p><strong>Simulation</strong>: They allow us to generate synthetic data for testing and validation</p></li>
</ol>
<p>In this chapter, we‚Äôll explore the major probability distributions, their properties, relationships, and applications. We‚Äôll implement each distribution using Python, demonstrating both theoretical concepts and practical usage. We‚Äôll derive key properties, prove important relationships, and build a comprehensive understanding of how these distributions connect to form a unified framework.</p>
<div class="learning-objectives admonition">
<p class="admonition-title">Learning Objectives</p>
<p>By the end of this chapter, you will be able to:</p>
<ul class="simple">
<li><p>Understand the key properties and applications of major probability distributions</p></li>
<li><p>Generate random samples from various distributions using Python</p></li>
<li><p>Compute probabilities, quantiles, and other distribution properties</p></li>
<li><p>Prove and understand relationships between different distributions</p></li>
<li><p>Derive important properties like memorylessness from first principles</p></li>
<li><p>Choose the appropriate Python library and distribution for your problem</p></li>
</ul>
</div>
</section>
<section id="id1">
<h2>The Python Ecosystem for Probability<a class="headerlink" href="#id1" title="Link to this heading">ÔÉÅ</a></h2>
<p>Before diving into specific distributions, let‚Äôs understand the tools at our disposal. Python offers multiple libraries for working with probability distributions, each with its own strengths:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>              <span class="c1"># Python&#39;s built-in module</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>        <span class="c1"># Fast array operations</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>   <span class="c1"># Statistical functions</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statistics</span>        <span class="c1"># Basic statistical operations</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>

<span class="c1"># Set seeds for reproducibility</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>When to use each library:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">random</span></code>: Built into Python, no dependencies needed. Perfect for simple sampling and teaching.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">numpy.random</span></code>: Vectorized operations, much faster for large datasets. Your go-to for simulations.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code>: The full statistical toolkit‚ÄîPDFs, CDFs, quantiles, and parameter fitting.</p></li>
</ul>
<p>Let‚Äôs see the performance difference:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>  <span class="c1"># number of samples to generate</span>

<span class="c1"># Using Python&#39;s random module (scalar operations)</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">python_randoms</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">python_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="c1"># Using NumPy (vectorized operations)</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">numpy_randoms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">numpy_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Python random: </span><span class="si">{</span><span class="n">python_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NumPy random: </span><span class="si">{</span><span class="n">numpy_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NumPy is </span><span class="si">{</span><span class="n">python_time</span><span class="o">/</span><span class="n">numpy_time</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">x faster!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="discrete-distributions">
<h2>Discrete Distributions<a class="headerlink" href="#discrete-distributions" title="Link to this heading">ÔÉÅ</a></h2>
<p>Discrete probability distributions model random variables that can take on a countable number of distinct values. These distributions are fundamental for modeling count data, categorical outcomes, and discrete events.</p>
<section id="bernoulli-distribution">
<h3>Bernoulli Distribution<a class="headerlink" href="#bernoulli-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Bernoulli distribution</strong> models a single binary trial with two possible outcomes: success (1) with probability <span class="math notranslate nohighlight">\(p\)</span> and failure (0) with probability <span class="math notranslate nohighlight">\(1-p\)</span>.</p>
<p>A random variable <span class="math notranslate nohighlight">\(X \sim \text{Bernoulli}(p)\)</span> has probability mass function:</p>
<div class="math notranslate nohighlight">
\[P(X = k) = p^k (1-p)^{1-k} \quad \text{for } k \in \{0, 1\}\]</div>
</div>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_bernoulli.png"><img alt="Bar chart showing Bernoulli PMF for p=0.2, 0.5, and 0.7, with two bars each at x=0 (failure) and x=1 (success)" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_bernoulli.png" style="width: 70%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.8 </span><span class="caption-text">The Bernoulli distribution is the simplest discrete distribution, modeling a single binary trial. As <span class="math notranslate nohighlight">\(p\)</span> increases, probability mass shifts from failure (0) to success (1).</span><a class="headerlink" href="#id2" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Historical Context</strong>:</p>
<p>The Bernoulli distribution is named after Jacob Bernoulli (1654-1705), a Swiss mathematician from the famous Bernoulli family of scientists. His groundbreaking work ‚ÄúArs Conjectandi‚Äù (The Art of Conjecturing), published posthumously in 1713, established probability theory as a mathematical discipline. In this work, Bernoulli proved the first version of the law of large numbers, showing that as the number of trials increases, the observed frequency of success converges to the true probability. This was revolutionary‚Äîit provided a mathematical bridge between theoretical probability and observed frequencies, laying the foundation for statistical inference.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = p\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = p(1-p)\)</span></p></li>
<li><p><strong>Moment Generating Function</strong>: <span class="math notranslate nohighlight">\(M_X(t) = (1-p) + pe^t\)</span></p></li>
<li><p><strong>Support</strong>: <span class="math notranslate nohighlight">\(\{0, 1\}\)</span></p></li>
</ul>
<div class="proof admonition">
<p class="admonition-title">Derivation: Mean and Variance</p>
<p><strong>Mean</strong>:</p>
<div class="math notranslate nohighlight">
\[E[X] = \sum_{k=0}^{1} k \cdot P(X = k) = 0 \cdot (1-p) + 1 \cdot p = p\]</div>
<p><strong>Variance</strong>:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}E[X^2] = \sum_{k=0}^{1} k^2 \cdot P(X = k) = 0^2 \cdot (1-p) + 1^2 \cdot p = p\\\text{Var}(X) = E[X^2] - (E[X])^2 = p - p^2 = p(1-p)\end{aligned}\end{align} \]</div>
</div>
<p>Let‚Äôs explore this distribution computationally:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">bernoulli_exploration</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Explore Bernoulli distribution through multiple methods.&quot;&quot;&quot;</span>

    <span class="c1"># Method 1: Using random module</span>
    <span class="n">successes_random</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_trials</span><span class="p">)</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">)</span>

    <span class="c1"># Method 2: Using NumPy (vectorized)</span>
    <span class="n">successes_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n_trials</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">)</span>

    <span class="c1"># Method 3: Using NumPy&#39;s binomial with n=1</span>
    <span class="n">successes_binom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">n_trials</span><span class="p">))</span>

    <span class="c1"># Method 4: Using SciPy for exact probabilities</span>
    <span class="n">bernoulli_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bernoulli Distribution with p = </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical mean: </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical variance: </span><span class="si">{</span><span class="n">p</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Simulated mean (random): </span><span class="si">{</span><span class="n">successes_random</span><span class="o">/</span><span class="n">n_trials</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Simulated mean (numpy): </span><span class="si">{</span><span class="n">successes_numpy</span><span class="o">/</span><span class="n">n_trials</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Exact probabilities:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(X=0) = </span><span class="si">{</span><span class="n">bernoulli_dist</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(X=1) = </span><span class="si">{</span><span class="n">bernoulli_dist</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Run the exploration</span>
<span class="n">bernoulli_exploration</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
<p>Now let‚Äôs visualize the convergence to the true probability:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize convergence - Law of Large Numbers</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_bernoulli_convergence</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># Generate a sequence of trials</span>
    <span class="n">trials</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">n_trials</span><span class="p">)</span>

    <span class="c1"># Running mean</span>
    <span class="n">running_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">trials</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_trials</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">running_mean</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;True mean = </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of trials&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Running mean&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Law of Large Numbers: Bernoulli Distribution&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_bernoulli_convergence</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="binomial-distribution">
<h3>Binomial Distribution<a class="headerlink" href="#binomial-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Binomial distribution</strong> models the number of successes in <span class="math notranslate nohighlight">\(n\)</span> independent Bernoulli trials, each with success probability <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p><strong>Parameterization</strong>: Binomial(n = number of trials, p = success probability)</p>
<p>A random variable <span class="math notranslate nohighlight">\(X \sim \text{Binomial}(n, p)\)</span> has probability mass function:</p>
<div class="math notranslate nohighlight">
\[P(X = k) = \binom{n}{k} p^k (1-p)^{n-k} \quad \text{for } k = 0, 1, ..., n\]</div>
</div>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_binomial.png"><img alt="Three-panel figure showing Binomial distributions with different n and p values, demonstrating symmetric, right-skewed, and approximately normal shapes" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_binomial.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.9 </span><span class="caption-text"><strong>Binomial distribution shapes.</strong> <em>Left:</em> Binomial(10, 0.5) is symmetric around the mean <span class="math notranslate nohighlight">\(np = 5\)</span>. <em>Center:</em> Binomial(10, 0.2) is right-skewed when <span class="math notranslate nohighlight">\(p &lt; 0.5\)</span>. <em>Right:</em> Binomial(50, 0.3) approaches a normal distribution as <span class="math notranslate nohighlight">\(n\)</span> grows large (CLT).</span><a class="headerlink" href="#id3" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Historical Context</strong>:</p>
<p>The binomial distribution‚Äôs history is intertwined with the development of probability theory itself. Jacob Bernoulli studied it extensively in the late 1600s, but it was Abraham de Moivre who made the breakthrough connection to the normal distribution. In 1733, de Moivre showed that for large n, the binomial distribution could be approximated by what we now call the normal distribution. This was one of the first limit theorems in probability, predating the formal central limit theorem by nearly two centuries. The approximation was crucial for practical calculations in an era before computers‚Äîcomputing binomial probabilities for large n was computationally intractable.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = np\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = np(1-p)\)</span></p></li>
<li><p><strong>Moment Generating Function</strong>: <span class="math notranslate nohighlight">\(M_X(t) = [(1-p) + pe^t]^n\)</span></p></li>
<li><p><strong>Support</strong>: <span class="math notranslate nohighlight">\(\{0, 1, 2, ..., n\}\)</span></p></li>
</ul>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Sum of Bernoulli Trials</p>
<p>If <span class="math notranslate nohighlight">\(X_1, X_2, ..., X_n\)</span> are independent <span class="math notranslate nohighlight">\(\text{Bernoulli}(p)\)</span> random variables, then:</p>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^n X_i \sim \text{Binomial}(n, p)\]</div>
<p><strong>Proof</strong>: Using moment generating functions:</p>
<div class="math notranslate nohighlight">
\[M_{\sum X_i}(t) = \prod_{i=1}^n M_{X_i}(t) = \prod_{i=1}^n [(1-p) + pe^t] = [(1-p) + pe^t]^n\]</div>
<p>This is the MGF of <span class="math notranslate nohighlight">\(\text{Binomial}(n, p)\)</span>, proving the result.</p>
</div>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Normal Approximation (De Moivre-Laplace)</p>
<p>For <span class="math notranslate nohighlight">\(X \sim \text{Binomial}(n, p)\)</span>, as <span class="math notranslate nohighlight">\(n \to \infty\)</span>:</p>
<div class="math notranslate nohighlight">
\[\frac{X - np}{\sqrt{np(1-p)}} \xrightarrow{d} \mathcal{N}(0, 1)\]</div>
<p><strong>Proof</strong>:</p>
<ol class="arabic">
<li><p>Write <span class="math notranslate nohighlight">\(X = \sum_{i=1}^n X_i\)</span> where <span class="math notranslate nohighlight">\(X_i \sim \text{Bernoulli}(p)\)</span></p></li>
<li><p>Each <span class="math notranslate nohighlight">\(X_i\)</span> has mean <span class="math notranslate nohighlight">\(\mu = p\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2 = p(1-p)\)</span></p></li>
<li><p>By the Central Limit Theorem:</p>
<div class="math notranslate nohighlight">
\[\frac{\sum_{i=1}^n X_i - n\mu}{\sigma\sqrt{n}} = \frac{X - np}{\sqrt{np(1-p)}} \xrightarrow{d} \mathcal{N}(0, 1)\]</div>
</li>
</ol>
</div>
<p>The binomial distribution implementation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">binomial_calculations</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate binomial distribution calculations.&quot;&quot;&quot;</span>

    <span class="c1"># Generate samples</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>

    <span class="c1"># Theoretical moments</span>
    <span class="n">mean_theory</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">p</span>
    <span class="n">var_theory</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Binomial(</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">) Properties:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical mean: </span><span class="si">{</span><span class="n">mean_theory</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical variance: </span><span class="si">{</span><span class="n">var_theory</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Calculate some probabilities</span>
    <span class="n">k_values</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pmf_values</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k_values</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="c1"># Find mode</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span> <span class="o">==</span> <span class="n">mode</span><span class="p">:</span>  <span class="c1"># Check if there are two modes</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Modes: </span><span class="si">{</span><span class="n">mode</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mode: </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">pmf_values</span>

<span class="n">samples</span><span class="p">,</span> <span class="n">pmf_values</span> <span class="o">=</span> <span class="n">binomial_calculations</span><span class="p">()</span>
</pre></div>
</div>
<p>Visualizing the normal approximation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_normal_approximation</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate the De Moivre-Laplace theorem.&quot;&quot;&quot;</span>

    <span class="c1"># Binomial distribution</span>
    <span class="n">x_binom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pmf_binom</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x_binom</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="c1"># Normal approximation parameters</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">p</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">))</span>

    <span class="c1"># For continuous approximation</span>
    <span class="n">x_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">pdf_norm</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="c1"># Subplot 1: Direct comparison</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_binom</span><span class="p">,</span> <span class="n">pmf_binom</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Binomial&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_norm</span><span class="p">,</span> <span class="n">pdf_norm</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Normal approximation&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of successes&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability/Density&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Binomial(</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s1">) vs Normal(</span><span class="si">{</span><span class="n">mu</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">sigma</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">¬≤)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="mi">4</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">sigma</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Subplot 2: Standardized comparison</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">x_standard</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_binom</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_standard</span><span class="p">,</span> <span class="n">pmf_binom</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Standardized Binomial&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">sigma</span><span class="p">)</span>

    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Standard Normal&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Standardized value&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Standardized Comparison&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_normal_approximation</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="poisson-distribution">
<h3>Poisson Distribution<a class="headerlink" href="#poisson-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Poisson distribution</strong> models the number of events occurring in a fixed interval of time or space, given a constant average rate <span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
<p><strong>Parameterization</strong>: Poisson(Œª = average rate of events)</p>
<p>A random variable <span class="math notranslate nohighlight">\(X \sim \text{Poisson}(\lambda)\)</span> has probability mass function:</p>
<div class="math notranslate nohighlight">
\[P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!} \quad \text{for } k = 0, 1, 2, ...\]</div>
</div>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_poisson.png"><img alt="Three-panel figure showing Poisson distributions for lambda=1, 5, and 15, demonstrating increasing symmetry as lambda grows" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_poisson.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.10 </span><span class="caption-text"><strong>Poisson distribution for different rates.</strong> As <span class="math notranslate nohighlight">\(\lambda\)</span> increases, the distribution shifts rightward and becomes more symmetric. Note that <span class="math notranslate nohighlight">\(E[X] = Var(X) = \lambda\)</span>‚Äîa defining characteristic used to identify Poisson-distributed count data.</span><a class="headerlink" href="#id4" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Historical Context</strong>:</p>
<p>Sim√©on Denis Poisson introduced this distribution in 1837 while studying the probability of wrongful convictions in French courts. He was interested in modeling rare events‚Äîspecifically, the chance that a given jury would convict an innocent person. The distribution gained practical prominence through Ladislaus Bortkiewicz‚Äôs famous 1898 analysis of deaths by horse kicks in the Prussian cavalry. Over 20 years, 10 cavalry corps experienced 196 deaths, averaging 0.61 per corps per year. Bortkiewicz showed that the number of deaths per corps per year followed a Poisson distribution almost perfectly, demonstrating the distribution‚Äôs utility for modeling rare, random events.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = \lambda\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = \lambda\)</span> (mean equals variance!)</p></li>
<li><p><strong>Moment Generating Function</strong>: <span class="math notranslate nohighlight">\(M_X(t) = e^{\lambda(e^t - 1)}\)</span></p></li>
<li><p><strong>Support</strong>: <span class="math notranslate nohighlight">\(\{0, 1, 2, ...\}\)</span></p></li>
</ul>
<div class="proof admonition">
<p class="admonition-title">Derivation: Mean Equals Variance Property</p>
<p><strong>Mean</strong>:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}E[X] = \sum_{k=0}^{\infty} k \cdot \frac{\lambda^k e^{-\lambda}}{k!} = e^{-\lambda} \sum_{k=1}^{\infty} \frac{\lambda^k}{(k-1)!}\\= \lambda e^{-\lambda} \sum_{j=0}^{\infty} \frac{\lambda^j}{j!} = \lambda e^{-\lambda} \cdot e^{\lambda} = \lambda\end{aligned}\end{align} \]</div>
<p><strong>Second Moment</strong>:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}E[X(X-1)] = \sum_{k=0}^{\infty} k(k-1) \cdot \frac{\lambda^k e^{-\lambda}}{k!} = \lambda^2 e^{-\lambda} \sum_{j=0}^{\infty} \frac{\lambda^j}{j!} = \lambda^2\\E[X^2] = E[X(X-1)] + E[X] = \lambda^2 + \lambda\\\text{Var}(X) = E[X^2] - (E[X])^2 = \lambda^2 + \lambda - \lambda^2 = \lambda\end{aligned}\end{align} \]</div>
</div>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Poisson Limit Theorem</p>
<p>Let <span class="math notranslate nohighlight">\(X_n \sim \text{Binomial}(n, p_n)\)</span> where <span class="math notranslate nohighlight">\(p_n = \lambda/n\)</span> for fixed <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span>.
Then as <span class="math notranslate nohighlight">\(n \to \infty\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(X_n = k) \to \frac{\lambda^k e^{-\lambda}}{k!}\]</div>
<p><strong>Proof</strong>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(X_n = k) &amp;= \binom{n}{k} p_n^k (1-p_n)^{n-k} \\
&amp;= \frac{n!}{k!(n-k)!} \left(\frac{\lambda}{n}\right)^k \left(1-\frac{\lambda}{n}\right)^{n-k} \\
&amp;= \frac{n(n-1)...(n-k+1)}{n^k} \cdot \frac{\lambda^k}{k!} \cdot \left(1-\frac{\lambda}{n}\right)^n \cdot \left(1-\frac{\lambda}{n}\right)^{-k}\end{split}\]</div>
<p>As <span class="math notranslate nohighlight">\(n \to \infty\)</span>:
- <span class="math notranslate nohighlight">\(\frac{n(n-1)...(n-k+1)}{n^k} \to 1\)</span>
- <span class="math notranslate nohighlight">\(\left(1-\frac{\lambda}{n}\right)^n \to e^{-\lambda}\)</span>
- <span class="math notranslate nohighlight">\(\left(1-\frac{\lambda}{n}\right)^{-k} \to 1\)</span></p>
<p>Therefore: <span class="math notranslate nohighlight">\(P(X_n = k) \to \frac{\lambda^k e^{-\lambda}}{k!}\)</span>, which is the probability mass function of Poisson(<span class="math notranslate nohighlight">\(\lambda\)</span>).</p>
</div>
<p>Let‚Äôs explore the Poisson distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">poisson_mean_variance_property</span><span class="p">(</span><span class="n">lambda_param</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate that mean equals variance for Poisson.&quot;&quot;&quot;</span>

    <span class="c1"># Generate samples</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">lambda_param</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Poisson(</span><span class="si">{</span><span class="n">lambda_param</span><span class="si">}</span><span class="s2">) Mean = Variance Property:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical mean = variance = </span><span class="si">{</span><span class="n">lambda_param</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ratio variance/mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Calculate index of dispersion</span>
    <span class="n">dispersion</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Index of dispersion: </span><span class="si">{</span><span class="n">dispersion</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (should be ‚âà 1)&quot;</span><span class="p">)</span>

<span class="n">poisson_mean_variance_property</span><span class="p">()</span>
</pre></div>
</div>
<p>Demonstrating the Poisson limit theorem:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_poisson_limit_theorem</span><span class="p">(</span><span class="n">lam</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show how Binomial converges to Poisson for rare events.&quot;&quot;&quot;</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="c1"># Poisson distribution</span>
    <span class="n">poisson_pmf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lam</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">poisson_pmf</span><span class="p">,</span> <span class="s1">&#39;ko-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Poisson(</span><span class="si">{</span><span class="n">lam</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="c1"># Binomial approximations with increasing n</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">]:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">lam</span> <span class="o">/</span> <span class="n">n</span>
        <span class="n">binom_pmf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">binom_pmf</span><span class="p">,</span> <span class="s1">&#39;o--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Binomial(</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;P(X=k)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Poisson Limit Theorem: Binomial ‚Üí Poisson as n‚Üí‚àû, p‚Üí0, np‚ÜíŒª&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_poisson_limit_theorem</span><span class="p">()</span>
</pre></div>
</div>
<p>Connection to exponential distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_poisson_exponential_connection</span><span class="p">(</span><span class="n">lambda_rate</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show connection between Poisson counts and exponential waiting times.&quot;&quot;&quot;</span>

    <span class="c1"># Generate a Poisson process</span>
    <span class="n">n_events</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">lambda_rate</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span>

    <span class="c1"># Method 1: Uniform arrival times</span>
    <span class="n">arrival_times</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">n_events</span><span class="p">))</span>

    <span class="c1"># Calculate inter-arrival times</span>
    <span class="n">inter_arrivals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="n">arrival_times</span><span class="p">]))</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="c1"># Plot 1: The process</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">eventplot</span><span class="p">(</span><span class="n">arrival_times</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Poisson Process (Œª=</span><span class="si">{</span><span class="n">lambda_rate</span><span class="si">}</span><span class="s1"> events/time unit)&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Plot 2: Inter-arrival distribution</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">inter_arrivals</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Inter-arrival times&#39;</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">inter_arrivals</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lambda_rate</span> <span class="o">*</span> <span class="n">x</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Exponential(Œª=</span><span class="si">{</span><span class="n">lambda_rate</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time between events&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Inter-arrival Times are Exponential&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_poisson_exponential_connection</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="geometric-distribution">
<h3>Geometric Distribution<a class="headerlink" href="#geometric-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Geometric distribution</strong> models the number of trials needed to get the first success in a sequence of independent Bernoulli trials.</p>
<p><strong>Parameterization</strong>: Geometric(p = probability of success per trial)</p>
<p><strong>Important</strong>: Different sources use different conventions:</p>
<ul class="simple">
<li><p><strong>SciPy convention</strong> (used throughout this chapter): X = number of trials until first success, support {1, 2, 3, ‚Ä¶}</p></li>
<li><p><strong>Alternative convention</strong>: X = number of failures before first success, support {0, 1, 2, ‚Ä¶}</p></li>
</ul>
<p>Using SciPy‚Äôs convention, <span class="math notranslate nohighlight">\(X \sim \text{Geometric}(p)\)</span> has probability mass function:</p>
<div class="math notranslate nohighlight">
\[P(X = k) = (1-p)^{k-1} p \quad \text{for } k = 1, 2, 3, ...\]</div>
</div>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = \frac{1}{p}\)</span> (average number of trials until success)</p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = \frac{1-p}{p^2}\)</span></p></li>
<li><p><strong>Moment Generating Function</strong>: <span class="math notranslate nohighlight">\(M_X(t) = \frac{pe^t}{1-(1-p)e^t}\)</span> for <span class="math notranslate nohighlight">\(t &lt; -\ln(1-p)\)</span></p></li>
<li><p><strong>Memoryless property</strong>: <span class="math notranslate nohighlight">\(P(X &gt; s+t | X &gt; s) = P(X &gt; t)\)</span></p></li>
</ul>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Memoryless Property</p>
<p>The geometric distribution is the only discrete distribution with the memoryless property:</p>
<div class="math notranslate nohighlight">
\[P(X &gt; s+t | X &gt; s) = P(X &gt; t) \quad \text{for all } s, t \in \mathbb{N}\]</div>
<p><strong>Proof</strong>:</p>
<p>First, note that <span class="math notranslate nohighlight">\(P(X &gt; k) = (1-p)^k\)</span> for <span class="math notranslate nohighlight">\(k \geq 0\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(X &gt; s+t | X &gt; s) &amp;= \frac{P(X &gt; s+t \cap X &gt; s)}{P(X &gt; s)} \\
&amp;= \frac{P(X &gt; s+t)}{P(X &gt; s)} \\
&amp;= \frac{(1-p)^{s+t}}{(1-p)^s} \\
&amp;= (1-p)^t \\
&amp;= P(X &gt; t)\end{split}\]</div>
</div>
<div class="proof admonition">
<p class="admonition-title">Derivation: Mean and Variance</p>
<p><strong>Mean</strong>: Using the fact that <span class="math notranslate nohighlight">\(\sum_{k=1}^{\infty} k x^{k-1} = \frac{1}{(1-x)^2}\)</span> for <span class="math notranslate nohighlight">\(|x| &lt; 1\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}E[X] &amp;= \sum_{k=1}^{\infty} k (1-p)^{k-1} p \\
&amp;= p \sum_{k=1}^{\infty} k (1-p)^{k-1} \\
&amp;= p \cdot \frac{1}{(1-(1-p))^2} \\
&amp;= \frac{p}{p^2} = \frac{1}{p}\end{split}\]</div>
<p><strong>Variance</strong>: First compute <span class="math notranslate nohighlight">\(E[X^2]\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}E[X(X-1)] &amp;= \sum_{k=1}^{\infty} k(k-1) (1-p)^{k-1} p \\
&amp;= p(1-p) \sum_{k=2}^{\infty} k(k-1) (1-p)^{k-2} \\
&amp;= p(1-p) \cdot \frac{2}{p^3} = \frac{2(1-p)}{p^2}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[E[X^2] = E[X(X-1)] + E[X] = \frac{2(1-p)}{p^2} + \frac{1}{p} = \frac{2-p}{p^2}\]</div>
<div class="math notranslate nohighlight">
\[\text{Var}(X) = E[X^2] - (E[X])^2 = \frac{2-p}{p^2} - \frac{1}{p^2} = \frac{1-p}{p^2}\]</div>
</div>
<p>Demonstrating the memoryless property:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_memoryless_property</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show the memoryless property of geometric distribution.&quot;&quot;&quot;</span>

    <span class="n">n_simulations</span> <span class="o">=</span> <span class="mi">100000</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">geometric</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">n_simulations</span><span class="p">)</span>

    <span class="c1"># Test memoryless property: P(X &gt; s+t | X &gt; s) = P(X &gt; t)</span>
    <span class="n">s</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span>

    <span class="c1"># P(X &gt; t)</span>
    <span class="n">prob_greater_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span> <span class="o">&gt;</span> <span class="n">t</span><span class="p">)</span>

    <span class="c1"># P(X &gt; s+t | X &gt; s)</span>
    <span class="n">samples_greater_s</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="n">samples</span> <span class="o">&gt;</span> <span class="n">s</span><span class="p">]</span>
    <span class="n">prob_conditional</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples_greater_s</span> <span class="o">&gt;</span> <span class="n">s</span> <span class="o">+</span> <span class="n">t</span><span class="p">)</span>

    <span class="c1"># Theoretical value</span>
    <span class="n">theoretical</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">**</span> <span class="n">t</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Memoryless Property Test (p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(X &gt; </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">prob_greater_t</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(X &gt; </span><span class="si">{</span><span class="n">s</span><span class="o">+</span><span class="n">t</span><span class="si">}</span><span class="s2"> | X &gt; </span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">prob_conditional</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical value: </span><span class="si">{</span><span class="n">theoretical</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Interpretation: Past failures don&#39;t affect future probability!&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Having already waited </span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s2"> trials doesn&#39;t change the probability&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;of waiting </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2"> more trials.&quot;</span><span class="p">)</span>

<span class="n">demonstrate_memoryless_property</span><span class="p">()</span>
</pre></div>
</div>
<p>Expected waiting time visualization:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_geometric_analysis</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Comprehensive analysis of geometric distribution.&quot;&quot;&quot;</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">),</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># PMF for different p values</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p_val</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]:</span>
        <span class="n">pmf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">geom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p_val</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pmf</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;p=</span><span class="si">{</span><span class="n">p_val</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of trials until first success&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Geometric Distribution PMF&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Survival function (log scale)</span>
    <span class="n">x_surv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p_val</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]:</span>
        <span class="n">survival</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p_val</span><span class="p">)</span> <span class="o">**</span> <span class="n">x_surv</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">x_surv</span><span class="p">,</span> <span class="n">survival</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;p=</span><span class="si">{</span><span class="n">p_val</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;P(X &gt; k)&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Survival Function (Log Scale)&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Convergence to expected value</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">geometric</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="n">running_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">running_mean</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">p</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Expected value = 1/p = </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">p</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of experiments&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Average trials until first success&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Convergence to Expected Waiting Time (p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Memoryless property visualization</span>
    <span class="n">trials</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">paths</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">paths</span><span class="p">):</span>
        <span class="n">wait_times</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">current_pos</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">current_pos</span> <span class="o">&lt;</span> <span class="n">trials</span><span class="p">:</span>
            <span class="n">wait</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">geometric</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">current_pos</span> <span class="o">+=</span> <span class="n">wait</span>
            <span class="n">wait_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_pos</span><span class="p">)</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">wait_times</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">wait_times</span><span class="p">)),</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Trial number&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of successes&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Sample Paths (p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_geometric_analysis</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="negative-binomial-distribution">
<h3>Negative Binomial Distribution<a class="headerlink" href="#negative-binomial-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Negative Binomial distribution</strong> models the number of failures before the <span class="math notranslate nohighlight">\(r\)</span>-th success in a sequence of independent Bernoulli trials.</p>
<p><strong>Parameterization</strong>: NegativeBinomial(r = target number of successes, p = success probability per trial)</p>
<p><strong>Output</strong>: Number of failures before achieving r successes</p>
<p>A random variable <span class="math notranslate nohighlight">\(X \sim \text{NegBinomial}(r, p)\)</span> has probability mass function:</p>
<div class="math notranslate nohighlight">
\[P(X = k) = \binom{k + r - 1}{k} p^r (1-p)^k \quad \text{for } k = 0, 1, 2, ...\]</div>
</div>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_negative_binomial.png"><img alt="Line plot showing Negative Binomial PMF for three different (r, p) parameter combinations" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_negative_binomial.png" style="width: 75%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.11 </span><span class="caption-text"><strong>Negative Binomial distribution</strong> models the number of failures before <span class="math notranslate nohighlight">\(r\)</span> successes. Increasing <span class="math notranslate nohighlight">\(r\)</span> shifts and spreads the distribution; decreasing <span class="math notranslate nohighlight">\(p\)</span> increases the expected number of failures.</span><a class="headerlink" href="#id5" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Alternative Interpretation</strong>: The Negative Binomial can also be viewed as a Poisson distribution where the rate parameter itself follows a Gamma distribution (Gamma-Poisson mixture). This makes it excellent for modeling overdispersed count data.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = \frac{r(1-p)}{p}\)</span> (average number of failures before r successes)</p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = \frac{r(1-p)}{p^2}\)</span></p></li>
<li><p><strong>Moment Generating Function</strong>: <span class="math notranslate nohighlight">\(M_X(t) = \left(\frac{p}{1-(1-p)e^t}\right)^r\)</span> for <span class="math notranslate nohighlight">\(t &lt; -\ln(1-p)\)</span></p></li>
<li><p><strong>Overdispersion</strong>: Variance &gt; Mean (unlike Poisson where Variance = Mean)</p></li>
</ul>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Sum of Geometric Random Variables</p>
<p>If <span class="math notranslate nohighlight">\(Y_1, Y_2, ..., Y_r\)</span> are independent <span class="math notranslate nohighlight">\(\text{Geometric}(p)\)</span> random variables (number of trials until success, SciPy convention), then:</p>
<div class="math notranslate nohighlight">
\[X = \sum_{i=1}^r Y_i - r \sim \text{NegBinomial}(r, p)\]</div>
<p>where <span class="math notranslate nohighlight">\(X\)</span> represents the number of failures before the <span class="math notranslate nohighlight">\(r\)</span>-th success.</p>
<p><strong>Proof</strong>: The <span class="math notranslate nohighlight">\(r\)</span>-th success occurs after <span class="math notranslate nohighlight">\(\sum Y_i\)</span> total trials, which includes <span class="math notranslate nohighlight">\(r\)</span> successes and <span class="math notranslate nohighlight">\(X = \sum Y_i - r\)</span> failures.</p>
<p><strong>Note</strong>: With SciPy‚Äôs convention, if <span class="math notranslate nohighlight">\(Y \sim \text{Geometric}(p)\)</span> and <span class="math notranslate nohighlight">\(X \sim \text{NegBinomial}(1, p)\)</span>, then <span class="math notranslate nohighlight">\(Y = X + 1\)</span> (since Geometric counts trials, NegBinomial counts failures).</p>
</div>
<div class="theorem admonition">
<p class="admonition-title">Relationship: Gamma-Poisson Mixture</p>
<p>If <span class="math notranslate nohighlight">\(\Lambda \sim \text{Gamma}(\alpha, \beta)\)</span> and <span class="math notranslate nohighlight">\(X|\Lambda \sim \text{Poisson}(\Lambda)\)</span>, then marginally:</p>
<div class="math notranslate nohighlight">
\[X \sim \text{NegBinomial}\left(r = \alpha, p = \frac{\beta}{1+\beta}\right)\]</div>
<p>This explains why the negative binomial models overdispersed count data.</p>
</div>
<p>Let‚Äôs explore the negative binomial:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_overdispersion</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compare Poisson and Negative Binomial for overdispersed data.&quot;&quot;&quot;</span>

    <span class="n">mean_val</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="c1"># Poisson with same mean</span>
    <span class="n">poisson_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">mean_val</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>

    <span class="c1"># Negative Binomial with same mean but higher variance</span>
    <span class="n">r</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">r</span> <span class="o">/</span> <span class="p">(</span><span class="n">r</span> <span class="o">+</span> <span class="n">mean_val</span><span class="p">)</span>  <span class="c1"># This gives mean = r(1-p)/p = 10</span>
    <span class="n">nbinom_samples</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">nbinom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Overdispersion Comparison:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target mean: </span><span class="si">{</span><span class="n">mean_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Poisson (mean = variance):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">poisson_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">poisson_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Variance/Mean ratio: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">poisson_samples</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">poisson_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Negative Binomial (overdispersed):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">nbinom_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">nbinom_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Variance/Mean ratio: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">nbinom_samples</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">nbinom_samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Theoretical variance for negative binomial</span>
    <span class="n">var_theory</span> <span class="o">=</span> <span class="n">r</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">/</span> <span class="n">p</span><span class="o">**</span><span class="mi">2</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">  Theoretical variance: </span><span class="si">{</span><span class="n">var_theory</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">demonstrate_overdispersion</span><span class="p">()</span>
</pre></div>
</div>
<p>Demonstrating the sum of geometrics relationship:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">show_nbinom_as_sum_of_geometric</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show that Negative Binomial is sum of Geometric random variables.&quot;&quot;&quot;</span>

    <span class="n">r</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># number of successes</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mf">0.3</span>  <span class="c1"># success probability</span>
    <span class="n">n_simulations</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Method 1: Sum of geometric distributions</span>
    <span class="n">failures_from_geometric</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_simulations</span><span class="p">):</span>
        <span class="n">total_trials</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">geometric</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
        <span class="n">failures</span> <span class="o">=</span> <span class="n">total_trials</span> <span class="o">-</span> <span class="n">r</span>
        <span class="n">failures_from_geometric</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">failures</span><span class="p">)</span>

    <span class="c1"># Method 2: Direct negative binomial</span>
    <span class="n">nbinom_direct</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">nbinom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_simulations</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="c1"># Histogram comparison</span>
    <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">failures_from_geometric</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">nbinom_direct</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">failures_from_geometric</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sum of Geometric - r&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">nbinom_direct</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Direct Negative Binomial&#39;</span><span class="p">)</span>

    <span class="c1"># Theoretical PMF</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">40</span><span class="p">)</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">nbinom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pmf</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theoretical PMF&#39;</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of failures before r successes&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Negative Binomial as Sum of Geometric (r=</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s1">, p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># QQ plot</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">probplot</span>
    <span class="n">probplot</span><span class="p">(</span><span class="n">failures_from_geometric</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">nbinom</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">plot</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Q-Q Plot: Sum of Geometric vs NegBinom Theory&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">show_nbinom_as_sum_of_geometric</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="continuous-distributions">
<h2>Continuous Distributions<a class="headerlink" href="#continuous-distributions" title="Link to this heading">ÔÉÅ</a></h2>
<p>Continuous probability distributions model random variables that can take any value within a continuous range. These distributions are fundamental for modeling measurements, time intervals, and other continuous phenomena.</p>
<section id="uniform-distribution">
<h3>Uniform Distribution<a class="headerlink" href="#uniform-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Uniform distribution</strong> assigns equal probability to all values in an interval [a, b].</p>
<p><strong>Parameterization</strong>: Uniform(a = lower bound, b = upper bound)</p>
<p>A random variable <span class="math notranslate nohighlight">\(X \sim \text{Uniform}(a, b)\)</span> has probability density function:</p>
<div class="math notranslate nohighlight">
\[f(x) = \frac{1}{b-a} \quad \text{for } a \leq x \leq b\]</div>
</div>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_uniform.png"><img alt="Two-panel figure showing discrete uniform PMF for fair die on left and continuous uniform PDF on right with shaded probability region" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_uniform.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.12 </span><span class="caption-text"><strong>Uniform distributions.</strong> <em>Left:</em> Discrete uniform on {1, 2, 3, 4, 5, 6} (fair die)‚Äîeach outcome has equal probability 1/6. <em>Right:</em> Continuous Uniform(2, 7) with constant density <span class="math notranslate nohighlight">\(f(x) = 0.2\)</span>; the shaded region shows <span class="math notranslate nohighlight">\(P(3 \leq X \leq 5) = 0.4\)</span>.</span><a class="headerlink" href="#id6" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Historical Context</strong>:</p>
<p>The uniform distribution is perhaps the most intuitive probability distribution, representing complete ignorance within known bounds. Its theoretical importance was recognized by Pierre-Simon Laplace, who used it as the foundation for his ‚Äúprinciple of insufficient reason‚Äù (later called the principle of indifference): when we have no information favoring one outcome over another, we should assign equal probabilities. This principle, while philosophically controversial, makes the uniform distribution the starting point for many analyses. The principle of indifference can be traced back to Jacob Bernoulli‚Äôs ‚ÄúArs Conjectandi‚Äù (1713), though Laplace formalized and popularized it. The uniform distribution also serves as the foundation for random number generation‚Äîmost pseudo-random number generators produce uniform(0,1) values that are then transformed to other distributions.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = \frac{a+b}{2}\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = \frac{(b-a)^2}{12}\)</span></p></li>
<li><p><strong>Moment Generating Function</strong>: <span class="math notranslate nohighlight">\(M_X(t) = \frac{e^{tb} - e^{ta}}{t(b-a)}\)</span> for <span class="math notranslate nohighlight">\(t \neq 0\)</span></p></li>
<li><p><strong>Standard uniform</strong>: When <span class="math notranslate nohighlight">\(a = 0, b = 1\)</span>, used for random number generation</p></li>
</ul>
<div class="proof admonition">
<p class="admonition-title">Derivation: Mean and Variance</p>
<p><strong>Mean</strong>:</p>
<div class="math notranslate nohighlight">
\[E[X] = \int_a^b x \cdot \frac{1}{b-a} dx = \frac{1}{b-a} \cdot \frac{x^2}{2} \bigg|_a^b = \frac{b^2 - a^2}{2(b-a)} = \frac{a+b}{2}\]</div>
<p><strong>Variance</strong>:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}E[X^2] = \int_a^b x^2 \cdot \frac{1}{b-a} dx = \frac{1}{b-a} \cdot \frac{x^3}{3} \bigg|_a^b = \frac{b^3 - a^3}{3(b-a)}\\= \frac{(b-a)(a^2 + ab + b^2)}{3(b-a)} = \frac{a^2 + ab + b^2}{3}\\\text{Var}(X) = E[X^2] - (E[X])^2 = \frac{a^2 + ab + b^2}{3} - \frac{(a+b)^2}{4} = \frac{(b-a)^2}{12}\end{aligned}\end{align} \]</div>
</div>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Probability Integral Transform</p>
<p>If <span class="math notranslate nohighlight">\(X\)</span> is a continuous random variable with CDF <span class="math notranslate nohighlight">\(F_X\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[U = F_X(X) \sim \text{Uniform}(0, 1)\]</div>
<p>Conversely, if <span class="math notranslate nohighlight">\(U \sim \text{Uniform}(0, 1)\)</span> and <span class="math notranslate nohighlight">\(F\)</span> is a CDF, then:</p>
<div class="math notranslate nohighlight">
\[X = F^{-1}(U) \text{ has CDF } F\]</div>
<p><strong>Proof of first part</strong>: For <span class="math notranslate nohighlight">\(u \in [0, 1]\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(U \leq u) = P(F_X(X) \leq u) = P(X \leq F_X^{-1}(u)) = F_X(F_X^{-1}(u)) = u\]</div>
<p>This is the CDF of Uniform(0, 1).</p>
</div>
<p>Let‚Äôs explore the uniform distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">explore_uniform_properties</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Comprehensive exploration of uniform distribution.&quot;&quot;&quot;</span>

    <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Generate samples</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="c1"># Theoretical values</span>
    <span class="n">theo_mean</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">theo_var</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">12</span>
    <span class="n">theo_median</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Uniform(</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s2">) Properties:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical mean: </span><span class="si">{</span><span class="n">theo_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical variance: </span><span class="si">{</span><span class="n">theo_var</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical variance: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical median: </span><span class="si">{</span><span class="n">theo_median</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical median: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Test uniformity</span>
    <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">counts</span><span class="p">,</span> <span class="n">edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
    <span class="n">expected_count</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="n">bins</span>
    <span class="n">chi2_stat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">counts</span> <span class="o">-</span> <span class="n">expected_count</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">expected_count</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Uniformity test (Chi-square):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Chi-square statistic: </span><span class="si">{</span><span class="n">chi2_stat</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Critical value (Œ±=0.05, df=</span><span class="si">{</span><span class="n">bins</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">bins</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">explore_uniform_properties</span><span class="p">()</span>
</pre></div>
</div>
<p>Demonstrating the probability integral transform:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_probability_integral_transform</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show the probability integral transform in action.&quot;&quot;&quot;</span>

    <span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Start with exponential random variables</span>
    <span class="n">lambda_param</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">exp_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">lambda_param</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="c1"># Apply the CDF to get uniform</span>
    <span class="n">uniform_transformed</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lambda_param</span> <span class="o">*</span> <span class="n">exp_samples</span><span class="p">)</span>

    <span class="c1"># Generate uniform and transform to exponential</span>
    <span class="n">uniform_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">exp_transformed</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">uniform_samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">lambda_param</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">),</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># Original exponential</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">exp_samples</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Original Exponential&#39;</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">exp_samples</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_param</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lambda_param</span> <span class="o">*</span> <span class="n">x</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theory&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Exponential Distribution&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Transformed to uniform</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">uniform_transformed</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;F(X) where X ~ Exp&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Uniform(0,1)&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;CDF Transform ‚Üí Uniform&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Original uniform</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">uniform_samples</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Original Uniform&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theory&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original Uniform Distribution&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Transformed to exponential</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">exp_transformed</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;F‚Åª¬π(U) where U ~ Unif&#39;</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">exp_transformed</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_param</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lambda_param</span> <span class="o">*</span> <span class="n">x</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Exponential&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Inverse CDF Transform ‚Üí Exponential&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">demonstrate_probability_integral_transform</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="normal-gaussian-distribution">
<h3>Normal (Gaussian) Distribution<a class="headerlink" href="#normal-gaussian-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Normal distribution</strong> is characterized by its bell-shaped curve and is defined by two parameters.</p>
<p><strong>Parameterization</strong>: Normal(Œº = mean, œÉ¬≤ = variance) or Normal(Œº = mean, œÉ = standard deviation)</p>
<p>A random variable <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(\mu, \sigma^2)\)</span> has probability density function:</p>
<div class="math notranslate nohighlight">
\[f(x) = \frac{1}{\sigma\sqrt{2\pi}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)\]</div>
</div>
<figure class="align-center" id="id7">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_normal.png"><img alt="Two-panel figure showing effect of mean (shifting location) and standard deviation (changing spread) on normal distribution shape" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_normal.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.13 </span><span class="caption-text"><strong>Normal distribution parameter effects.</strong> <em>Left:</em> Changing <span class="math notranslate nohighlight">\(\mu\)</span> shifts the distribution along the x-axis without affecting shape. <em>Right:</em> Changing <span class="math notranslate nohighlight">\(\sigma\)</span> controls spread‚Äîsmaller <span class="math notranslate nohighlight">\(\sigma\)</span> produces a taller, narrower curve; larger <span class="math notranslate nohighlight">\(\sigma\)</span> produces a flatter, wider curve.</span><a class="headerlink" href="#id7" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Historical Context</strong>:</p>
<p>The normal distribution has a rich history involving multiple independent discoveries. Abraham de Moivre first derived it in 1733 as an approximation to the binomial distribution. Pierre-Simon Laplace extended this work, developing what we now call the Central Limit Theorem. However, the distribution bears Carl Friedrich Gauss‚Äôs name because of his 1809 work on astronomical measurement errors. Gauss showed that if errors are due to many small, independent causes, they follow this distribution‚Äîhence ‚ÄúGaussian distribution.‚Äù The term ‚Äúnormal‚Äù was popularized by Francis Galton, who viewed it as the natural state of variation. Today, we know the normal distribution emerges whenever many independent factors contribute additively to an outcome, making it ubiquitous in nature and statistics.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = \mu\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = \sigma^2\)</span></p></li>
<li><p><strong>Moment Generating Function</strong>: <span class="math notranslate nohighlight">\(M_X(t) = \exp(\mu t + \frac{\sigma^2 t^2}{2})\)</span></p></li>
<li><p><strong>Support</strong>: <span class="math notranslate nohighlight">\((-\infty, \infty)\)</span></p></li>
<li><p><strong>Symmetry</strong>: Symmetric about the mean</p></li>
<li><p><strong>68-95-99.7 Rule</strong>: Approximately 68%, 95%, and 99.7% of values lie within 1, 2, and 3 standard deviations of the mean</p></li>
</ul>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Central Limit Theorem</p>
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, ..., X_n\)</span> be independent and identically distributed random variables with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2 &lt; \infty\)</span>. Then:</p>
<div class="math notranslate nohighlight">
\[\frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} \xrightarrow{d} \mathcal{N}(0, 1) \quad \text{as } n \to \infty\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i\)</span> is the sample mean.</p>
<p><strong>Proof Sketch</strong> (using characteristic functions):</p>
<ol class="arabic simple">
<li><p>Let <span class="math notranslate nohighlight">\(Y_i = \frac{X_i - \mu}{\sigma}\)</span> (standardized)</p></li>
<li><p>The characteristic function of <span class="math notranslate nohighlight">\(Y_i\)</span> is <span class="math notranslate nohighlight">\(\phi_Y(t) = 1 - \frac{t^2}{2} + o(t^2)\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(S_n = \frac{\sum Y_i}{\sqrt{n}}\)</span>, we have <span class="math notranslate nohighlight">\(\phi_{S_n}(t) = \left[\phi_Y(t/\sqrt{n})\right]^n\)</span></p></li>
<li><p>As <span class="math notranslate nohighlight">\(n \to \infty\)</span>: <span class="math notranslate nohighlight">\(\phi_{S_n}(t) \to e^{-t^2/2}\)</span>, which is the characteristic function of <span class="math notranslate nohighlight">\(\mathcal{N}(0,1)\)</span></p></li>
</ol>
</div>
<div class="proof admonition">
<p class="admonition-title">Derivation: 68-95-99.7 Rule</p>
<p>For <span class="math notranslate nohighlight">\(Z \sim \mathcal{N}(0, 1)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(-1 \leq Z \leq 1) &amp;= \Phi(1) - \Phi(-1) = 2\Phi(1) - 1 \approx 0.6827 \\
P(-2 \leq Z \leq 2) &amp;= \Phi(2) - \Phi(-2) = 2\Phi(2) - 1 \approx 0.9545 \\
P(-3 \leq Z \leq 3) &amp;= \Phi(3) - \Phi(-3) = 2\Phi(3) - 1 \approx 0.9973\end{split}\]</div>
<p>For general <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(\mu, \sigma^2)\)</span>, use <span class="math notranslate nohighlight">\(Z = (X - \mu)/\sigma\)</span>.</p>
</div>
<p>Let‚Äôs explore the normal distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">explore_normal_properties</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Comprehensive exploration of normal distribution.&quot;&quot;&quot;</span>

    <span class="c1"># Generate samples</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">100000</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Normal(</span><span class="si">{</span><span class="n">mu</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">sigma</span><span class="si">}</span><span class="s2">¬≤) Properties:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical mean: </span><span class="si">{</span><span class="n">mu</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical std: </span><span class="si">{</span><span class="n">sigma</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical std: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Check 68-95-99.7 rule</span>
    <span class="n">within_1sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">samples</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">sigma</span><span class="p">)</span>
    <span class="n">within_2sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">samples</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="p">)</span>
    <span class="n">within_3sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">samples</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">68-95-99.7 Rule:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Within 1œÉ: </span><span class="si">{</span><span class="n">within_1sigma</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> (theory: 68.3%)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Within 2œÉ: </span><span class="si">{</span><span class="n">within_2sigma</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> (theory: 95.4%)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Within 3œÉ: </span><span class="si">{</span><span class="n">within_3sigma</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2"> (theory: 99.7%)&quot;</span><span class="p">)</span>

    <span class="c1"># Compute higher moments</span>
    <span class="n">standardized</span> <span class="o">=</span> <span class="p">(</span><span class="n">samples</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span>
    <span class="n">skewness</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">standardized</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">standardized</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Higher moments (standardized):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Skewness: </span><span class="si">{</span><span class="n">skewness</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: 0)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Excess kurtosis: </span><span class="si">{</span><span class="n">kurtosis</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">3</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: 0)&quot;</span><span class="p">)</span>

<span class="n">explore_normal_properties</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
<p>Demonstrating the Central Limit Theorem:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_clt</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show CLT with various starting distributions.&quot;&quot;&quot;</span>

    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">sample_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># Different starting distributions</span>
    <span class="n">distributions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;Exponential&#39;</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Uniform&#39;</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">12</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Chi-square&#39;</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">chisquare</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Beta&#39;</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="mi">2</span><span class="o">/</span><span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="o">/</span><span class="mi">343</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">true_mean</span><span class="p">,</span> <span class="n">true_var</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">distributions</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">idx</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">idx</span> <span class="o">%</span> <span class="mi">2</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">sample_sizes</span><span class="p">:</span>
            <span class="c1"># Generate sample means</span>
            <span class="n">sample_means</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
                <span class="n">sample_means</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample</span><span class="p">))</span>

            <span class="c1"># Standardize</span>
            <span class="n">sample_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sample_means</span><span class="p">)</span>
            <span class="n">standardized</span> <span class="o">=</span> <span class="p">(</span><span class="n">sample_means</span> <span class="o">-</span> <span class="n">true_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">true_var</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>

            <span class="c1"># Plot histogram</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">standardized</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="c1"># Overlay standard normal</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;N(0,1)&#39;</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Standardized Sample Mean&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;CLT: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1"> Distribution&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Central Limit Theorem with Different Starting Distributions&#39;</span><span class="p">,</span>
                 <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">demonstrate_clt</span><span class="p">()</span>
</pre></div>
</div>
<p>Sum of normal random variables:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_normal_sum_property</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show that sum of independent normals is normal.&quot;&quot;&quot;</span>

    <span class="c1"># Parameters</span>
    <span class="n">mu1</span><span class="p">,</span> <span class="n">sigma1</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span>
    <span class="n">mu2</span><span class="p">,</span> <span class="n">sigma2</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Generate independent normals</span>
    <span class="n">X1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu1</span><span class="p">,</span> <span class="n">sigma1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu2</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="c1"># Sum</span>
    <span class="n">X_sum</span> <span class="o">=</span> <span class="n">X1</span> <span class="o">+</span> <span class="n">X2</span>

    <span class="c1"># Theoretical parameters of sum</span>
    <span class="n">mu_sum</span> <span class="o">=</span> <span class="n">mu1</span> <span class="o">+</span> <span class="n">mu2</span>
    <span class="n">sigma_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma1</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">sigma2</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="c1"># Plot empirical distribution</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_sum</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;X‚ÇÅ + X‚ÇÇ (empirical)&#39;</span><span class="p">)</span>

    <span class="c1"># Plot theoretical distribution</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu_sum</span> <span class="o">-</span> <span class="mi">4</span><span class="o">*</span><span class="n">sigma_sum</span><span class="p">,</span> <span class="n">mu_sum</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">sigma_sum</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu_sum</span><span class="p">,</span> <span class="n">sigma_sum</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;N(</span><span class="si">{</span><span class="n">mu_sum</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">sigma_sum</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">¬≤) (theory)&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sum of Independent Normal Random Variables&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;X‚ÇÅ ~ N(</span><span class="si">{</span><span class="n">mu1</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">sigma1</span><span class="si">}</span><span class="s2">¬≤), X‚ÇÇ ~ N(</span><span class="si">{</span><span class="n">mu2</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">sigma2</span><span class="si">}</span><span class="s2">¬≤)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;X‚ÇÅ + X‚ÇÇ ~ N(</span><span class="si">{</span><span class="n">mu_sum</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">sigma_sum</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">¬≤)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X_sum</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical std: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X_sum</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">demonstrate_normal_sum_property</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="exponential-distribution">
<h3>Exponential Distribution<a class="headerlink" href="#exponential-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Exponential distribution</strong> models the time between events in a Poisson process, characterized by a constant hazard rate.</p>
<p><strong>Parameterization</strong>:
- <strong>Rate parameterization</strong>: Exponential(Œª = rate), where Œª &gt; 0
- <strong>Scale parameterization</strong>: Exponential(scale = 1/Œª)</p>
<p><strong>Note</strong>: NumPy uses scale parameterization, SciPy supports both.</p>
<p>Using rate parameterization, <span class="math notranslate nohighlight">\(X \sim \text{Exp}(\lambda)\)</span> has probability density function:</p>
<div class="math notranslate nohighlight">
\[f(x) = \lambda e^{-\lambda x} \quad \text{for } x \geq 0\]</div>
</div>
<figure class="align-center" id="id8">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_exponential.png"><img alt="Two-panel figure showing Exponential PDF for different rate parameters on left and memoryless property survival function on right" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_exponential.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.14 </span><span class="caption-text"><strong>Exponential distribution.</strong> <em>Left:</em> Higher rate <span class="math notranslate nohighlight">\(\lambda\)</span> means shorter expected waiting time (<span class="math notranslate nohighlight">\(E[X] = 1/\lambda\)</span>). <em>Right:</em> The memoryless property: <span class="math notranslate nohighlight">\(P(X &gt; s+t \mid X &gt; s) = P(X &gt; t)\)</span>. The conditional probability of surviving another <span class="math notranslate nohighlight">\(t\)</span> units is independent of how long you‚Äôve already waited.</span><a class="headerlink" href="#id8" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Historical Context</strong>:</p>
<p>The exponential distribution naturally arises from the Poisson process and was studied extensively in queueing theory by Agner Krarup Erlang in the early 1900s. Working for the Copenhagen Telephone Company, Erlang needed to determine how many telephone circuits were needed to provide acceptable service. He discovered that call durations followed an exponential distribution, and the time between calls also followed an exponential distribution. This work laid the foundation for queueing theory and operations research. The exponential distribution‚Äôs memoryless property made calculations tractable in an era before computers.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = \frac{1}{\lambda}\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = \frac{1}{\lambda^2}\)</span></p></li>
<li><p><strong>Moment Generating Function</strong>: <span class="math notranslate nohighlight">\(M_X(t) = \frac{\lambda}{\lambda - t}\)</span> for <span class="math notranslate nohighlight">\(t &lt; \lambda\)</span></p></li>
<li><p><strong>Memoryless property</strong>: <span class="math notranslate nohighlight">\(P(X &gt; s + t | X &gt; s) = P(X &gt; t)\)</span></p></li>
<li><p><strong>Relationship to Poisson</strong>: Inter-arrival times in a Poisson process</p></li>
<li><p><strong>Minimum of exponentials</strong>: If <span class="math notranslate nohighlight">\(X_i \sim \text{Exp}(\lambda_i)\)</span>, then <span class="math notranslate nohighlight">\(\min(X_1, ..., X_n) \sim \text{Exp}(\sum \lambda_i)\)</span></p></li>
</ul>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Memoryless Property</p>
<p>The exponential distribution is the only continuous distribution with the memoryless property:</p>
<div class="math notranslate nohighlight">
\[P(X &gt; s + t | X &gt; s) = P(X &gt; t) \quad \text{for all } s, t &gt; 0\]</div>
<p><strong>Proof</strong>:</p>
<p>For <span class="math notranslate nohighlight">\(X \sim \text{Exp}(\lambda)\)</span>, we have <span class="math notranslate nohighlight">\(P(X &gt; x) = e^{-\lambda x}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(X &gt; s + t | X &gt; s) &amp;= \frac{P(X &gt; s + t)}{P(X &gt; s)} \\
&amp;= \frac{e^{-\lambda(s+t)}}{e^{-\lambda s}} \\
&amp;= e^{-\lambda t} \\
&amp;= P(X &gt; t)\end{split}\]</div>
<p><strong>Converse</strong>: If <span class="math notranslate nohighlight">\(P(X &gt; s + t) = P(X &gt; s)P(X &gt; t)\)</span> for all <span class="math notranslate nohighlight">\(s, t &gt; 0\)</span>, then setting <span class="math notranslate nohighlight">\(g(x) = P(X &gt; x)\)</span>:</p>
<div class="math notranslate nohighlight">
\[g(s + t) = g(s)g(t)\]</div>
<p>This functional equation has solution <span class="math notranslate nohighlight">\(g(x) = e^{-\lambda x}\)</span>, proving exponential is unique.</p>
</div>
<div class="proof admonition">
<p class="admonition-title">Derivation: Mean and Variance</p>
<p><strong>Mean</strong> (using integration by parts):</p>
<div class="math notranslate nohighlight">
\[\begin{split}E[X] &amp;= \int_0^{\infty} x \lambda e^{-\lambda x} dx \\
&amp;= \lambda \left[-\frac{x}{\lambda} e^{-\lambda x}\bigg|_0^{\infty} + \int_0^{\infty} \frac{1}{\lambda} e^{-\lambda x} dx\right] \\
&amp;= 0 + \frac{1}{\lambda} \int_0^{\infty} e^{-\lambda x} dx \\
&amp;= \frac{1}{\lambda} \cdot \frac{1}{\lambda} = \frac{1}{\lambda}\end{split}\]</div>
<p><strong>Second Moment</strong> (using Gamma function):</p>
<div class="math notranslate nohighlight">
\[\begin{split}E[X^2] &amp;= \int_0^{\infty} x^2 \lambda e^{-\lambda x} dx \\
&amp;= \lambda \int_0^{\infty} x^2 e^{-\lambda x} dx \\
&amp;= \lambda \cdot \frac{\Gamma(3)}{\lambda^3} = \lambda \cdot \frac{2!}{\lambda^3} = \frac{2}{\lambda^2}\end{split}\]</div>
<p><strong>Variance</strong>:</p>
<div class="math notranslate nohighlight">
\[\text{Var}(X) = E[X^2] - (E[X])^2 = \frac{2}{\lambda^2} - \frac{1}{\lambda^2} = \frac{1}{\lambda^2}\]</div>
</div>
<p>Let‚Äôs explore the exponential distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">explore_exponential_basics</span><span class="p">(</span><span class="n">lam</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Basic properties of exponential distribution.&quot;&quot;&quot;</span>

    <span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Note: NumPy uses scale parameter (1/Œª), not rate</span>
    <span class="n">samples_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="c1"># Using SciPy (which can use either parameterization)</span>
    <span class="n">exp_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">expon</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">)</span>
    <span class="n">samples_scipy</span> <span class="o">=</span> <span class="n">exp_dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Exponential(</span><span class="si">{</span><span class="n">lam</span><span class="si">}</span><span class="s2">) Properties:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Note: Using rate parameterization (Œª=</span><span class="si">{</span><span class="n">lam</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NumPy uses scale=1/Œª=</span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Theoretical mean: </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples_numpy</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical std: </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical std: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">samples_numpy</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Verify variance = mean¬≤</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Mean¬≤ = </span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Variance = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samples_numpy</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">explore_exponential_basics</span><span class="p">()</span>
</pre></div>
</div>
<p>Demonstrating the memoryless property:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_exponential_memoryless</span><span class="p">(</span><span class="n">lam</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show the memoryless property of exponential distribution.&quot;&quot;&quot;</span>

    <span class="n">n</span> <span class="o">=</span> <span class="mi">100000</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

    <span class="c1"># Test memoryless property at different values</span>
    <span class="n">test_cases</span> <span class="o">=</span> <span class="p">[(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Memoryless Property Test (Œª=</span><span class="si">{</span><span class="n">lam</span><span class="si">}</span><span class="s2">):&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">test_cases</span><span class="p">:</span>
        <span class="c1"># P(X &gt; t)</span>
        <span class="n">prob_greater_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span> <span class="o">&gt;</span> <span class="n">t</span><span class="p">)</span>

        <span class="c1"># P(X &gt; s+t | X &gt; s)</span>
        <span class="n">samples_greater_s</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="n">samples</span> <span class="o">&gt;</span> <span class="n">s</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples_greater_s</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">prob_conditional</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples_greater_s</span> <span class="o">&gt;</span> <span class="n">s</span> <span class="o">+</span> <span class="n">t</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prob_conditional</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Theoretical value</span>
        <span class="n">theoretical</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lam</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;s=</span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s2">, t=</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  P(X &gt; </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">prob_greater_t</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  P(X &gt; </span><span class="si">{</span><span class="n">s</span><span class="o">+</span><span class="n">t</span><span class="si">}</span><span class="s2"> | X &gt; </span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">prob_conditional</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Theoretical value: </span><span class="si">{</span><span class="n">theoretical</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">()</span>

<span class="n">demonstrate_exponential_memoryless</span><span class="p">()</span>
</pre></div>
</div>
<p>Relationship between exponential and Poisson:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_exponential_poisson_relationship</span><span class="p">(</span><span class="n">lam</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show how exponential relates to Poisson process.&quot;&quot;&quot;</span>

    <span class="c1"># Generate exponential inter-arrival times</span>
    <span class="n">inter_arrivals</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_time</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">current_time</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
        <span class="n">inter_arrival</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">)</span>
        <span class="n">current_time</span> <span class="o">+=</span> <span class="n">inter_arrival</span>
        <span class="k">if</span> <span class="n">current_time</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
            <span class="n">inter_arrivals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inter_arrival</span><span class="p">)</span>

    <span class="n">arrival_times</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">inter_arrivals</span><span class="p">)</span>
    <span class="n">n_events</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">arrival_times</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">),</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># Plot 1: The Poisson process</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">eventplot</span><span class="p">(</span><span class="n">arrival_times</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Poisson Process (Œª=</span><span class="si">{</span><span class="n">lam</span><span class="si">}</span><span class="s1"> events/unit)&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;Total events: </span><span class="si">{</span><span class="n">n_events</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
             <span class="n">transform</span><span class="o">=</span><span class="n">ax1</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;top&#39;</span><span class="p">)</span>

    <span class="c1"># Plot 2: Inter-arrival distribution</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">inter_arrivals</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed inter-arrivals&#39;</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">inter_arrivals</span><span class="p">)</span> <span class="k">if</span> <span class="n">inter_arrivals</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lam</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lam</span> <span class="o">*</span> <span class="n">x</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Exponential(Œª=</span><span class="si">{</span><span class="n">lam</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time between events&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Inter-arrival Times&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Plot 3: Counting process</span>
    <span class="n">count_times</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">arrival_times</span> <span class="o">&lt;=</span> <span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">count_times</span><span class="p">]</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">count_times</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;N(t)&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">count_times</span><span class="p">,</span> <span class="n">lam</span> <span class="o">*</span> <span class="n">count_times</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;E[N(t)] = Œªt&#39;</span><span class="p">)</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of events&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Counting Process N(t)&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Plot 4: Test Poisson distribution at fixed time</span>
    <span class="n">n_sim</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="n">counts_at_T</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sim</span><span class="p">):</span>
        <span class="n">times</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
                <span class="n">times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="n">counts_at_T</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">times</span><span class="p">))</span>

    <span class="n">k_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">counts_at_T</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">observed_freq</span> <span class="o">=</span> <span class="p">[</span><span class="n">counts_at_T</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_sim</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_values</span><span class="p">]</span>
    <span class="n">theoretical_pmf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k_values</span><span class="p">,</span> <span class="n">lam</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span>

    <span class="n">ax4</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">k_values</span> <span class="o">-</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">observed_freq</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">k_values</span> <span class="o">+</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">theoretical_pmf</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Poisson(</span><span class="si">{</span><span class="n">lam</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">T</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Number of events in [0, </span><span class="si">{</span><span class="n">T</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribution of N(T)&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">demonstrate_exponential_poisson_relationship</span><span class="p">()</span>
</pre></div>
</div>
<p>Minimum of exponentials property:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_minimum_exponentials</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show that minimum of exponentials is exponential.&quot;&quot;&quot;</span>

    <span class="c1"># System with multiple components</span>
    <span class="n">component_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]</span>  <span class="c1"># Different failure rates</span>
    <span class="n">n_sim</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Simulate system failures</span>
    <span class="n">min_times</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">first_component</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_sim</span><span class="p">):</span>
        <span class="n">component_times</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">rate</span><span class="p">)</span>
                          <span class="k">for</span> <span class="n">rate</span> <span class="ow">in</span> <span class="n">component_rates</span><span class="p">]</span>
        <span class="n">min_time</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">component_times</span><span class="p">)</span>
        <span class="n">min_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">min_time</span><span class="p">)</span>
        <span class="n">first_component</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">component_times</span><span class="p">))</span>

    <span class="c1"># Theoretical: min ~ Exp(sum of rates)</span>
    <span class="n">total_rate</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">component_rates</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="c1"># Distribution of minimum</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">min_times</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Simulated minimum&#39;</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">total_rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">total_rate</span> <span class="o">*</span> <span class="n">x</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Exponential(Œª=</span><span class="si">{</span><span class="n">total_rate</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time to first failure&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Minimum of Independent Exponentials&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Which component fails first</span>
    <span class="n">component_labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;Component </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="se">\n</span><span class="s1">(Œª=</span><span class="si">{</span><span class="n">rate</span><span class="si">}</span><span class="s1">)&#39;</span>
                       <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">rate</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">component_rates</span><span class="p">)]</span>
    <span class="n">failure_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">component_rates</span><span class="p">)</span> <span class="o">/</span> <span class="n">total_rate</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">component_rates</span><span class="p">)),</span>
            <span class="p">[</span><span class="n">first_component</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">/</span><span class="n">n_sim</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">component_rates</span><span class="p">))],</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">component_rates</span><span class="p">)),</span> <span class="n">failure_probs</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theoretical&#39;</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Component&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability of failing first&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Which Component Fails First?&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">component_rates</span><span class="p">)))</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">component_labels</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Component rates: </span><span class="si">{</span><span class="n">component_rates</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sum of rates: </span><span class="si">{</span><span class="n">total_rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical mean time to first failure: </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">total_rate</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Observed mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">min_times</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Probability each component fails first:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">rate</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">component_rates</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Component </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">rate</span><span class="o">/</span><span class="n">total_rate</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (theoretical)&quot;</span><span class="p">)</span>

<span class="n">demonstrate_minimum_exponentials</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="gamma-distribution">
<h3>Gamma Distribution<a class="headerlink" href="#gamma-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Gamma distribution</strong> is a two-parameter family of continuous distributions that generalizes the exponential distribution.</p>
<p><strong>Parameterization</strong>:
- <strong>Shape-Rate</strong>: Gamma(Œ± = shape, Œ≤ = rate)
- <strong>Shape-Scale</strong>: Gamma(Œ± = shape, scale = 1/Œ≤)</p>
<p><strong>Important</strong>: SciPy uses shape-scale parameterization (scale = 1/Œ≤)</p>
<p>Using shape-rate parameterization, <span class="math notranslate nohighlight">\(X \sim \text{Gamma}(\alpha, \beta)\)</span> has probability density function:</p>
<div class="math notranslate nohighlight">
\[f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x} \quad \text{for } x &gt; 0\]</div>
<p>where <span class="math notranslate nohighlight">\(\Gamma(\alpha)\)</span> is the gamma function.</p>
</div>
<figure class="align-center" id="id9">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_gamma.png"><img alt="Two-panel figure showing Gamma distribution with varying shape parameter on left and varying scale parameter on right" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_gamma.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.15 </span><span class="caption-text"><strong>Gamma distribution parameter effects.</strong> <em>Left:</em> Increasing shape <span class="math notranslate nohighlight">\(k\)</span> shifts the mode away from zero and makes the distribution more symmetric. When <span class="math notranslate nohighlight">\(k = 1\)</span>, Gamma reduces to Exponential. <em>Right:</em> Increasing scale <span class="math notranslate nohighlight">\(\theta\)</span> stretches the distribution horizontally, increasing both mean and variance.</span><a class="headerlink" href="#id9" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Historical Context</strong>:</p>
<p>The Gamma distribution emerged from studying the gamma function, introduced by Leonhard Euler in 1729. The distribution gained practical importance through Karl Pearson‚Äôs work on skewed distributions in the 1890s. It became fundamental in queueing theory through Erlang‚Äôs work‚Äîthe special case with integer shape parameter is called the Erlang distribution. The gamma distribution‚Äôs flexibility in modeling positive, skewed data made it invaluable in fields from hydrology to finance.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = \frac{\alpha}{\beta}\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = \frac{\alpha}{\beta^2}\)</span></p></li>
<li><p><strong>Mode</strong>: <span class="math notranslate nohighlight">\(\frac{\alpha-1}{\beta}\)</span> for <span class="math notranslate nohighlight">\(\alpha &gt; 1\)</span></p></li>
<li><p><strong>Moment Generating Function</strong>: <span class="math notranslate nohighlight">\(M_X(t) = \left(\frac{\beta}{\beta - t}\right)^\alpha\)</span> for <span class="math notranslate nohighlight">\(t &lt; \beta\)</span></p></li>
<li><p><strong>Special cases</strong>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\alpha = 1\)</span>: Exponential(Œ≤)</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha = n/2, \beta = 1/2\)</span>: Chi-squared with n degrees of freedom</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha = k\)</span> where <span class="math notranslate nohighlight">\(k \in \mathbb{N}\)</span>: Erlang distribution (integer shape parameter)</p></li>
</ul>
</li>
</ul>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Sum of Exponentials</p>
<p>If <span class="math notranslate nohighlight">\(X_1, ..., X_n\)</span> are independent <span class="math notranslate nohighlight">\(\text{Exp}(\beta)\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^n X_i \sim \text{Gamma}(n, \beta)\]</div>
<p><strong>Proof</strong> (using MGFs):</p>
<div class="math notranslate nohighlight">
\[M_{\sum X_i}(t) = \prod_{i=1}^n M_{X_i}(t) = \prod_{i=1}^n \frac{\beta}{\beta - t} = \left(\frac{\beta}{\beta - t}\right)^n\]</div>
<p>This is the MGF of <span class="math notranslate nohighlight">\(\text{Gamma}(n, \beta)\)</span>.</p>
</div>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Relationship to Chi-Squared</p>
<p>The chi-squared distribution is a special case of the gamma distribution:</p>
<div class="math notranslate nohighlight">
\[\chi^2(k) = \text{Gamma}\left(\frac{k}{2}, \frac{1}{2}\right)\]</div>
<p><strong>Proof</strong>: If <span class="math notranslate nohighlight">\(Z_1, ..., Z_k\)</span> are independent <span class="math notranslate nohighlight">\(\mathcal{N}(0,1)\)</span>, then <span class="math notranslate nohighlight">\(\sum Z_i^2 \sim \chi^2(k)\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(Z^2 \sim \text{Gamma}(1/2, 1/2)\)</span> (can be shown via transformation), the sum follows <span class="math notranslate nohighlight">\(\text{Gamma}(k/2, 1/2)\)</span>.</p>
</div>
<p>Let‚Äôs explore the gamma distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">explore_gamma_distribution</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Comprehensive exploration of gamma distribution.&quot;&quot;&quot;</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">),</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># Shape parameter effects</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># Fix rate</span>

    <span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]:</span>
        <span class="c1"># Note: SciPy uses scale parameterization, so scale = 1/beta</span>
        <span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">beta</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Œ±=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="k">if</span> <span class="n">alpha</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">+=</span> <span class="s1">&#39; (Exponential)&#39;</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Gamma PDFs with Œ≤=</span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s1"> (varying shape)&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>

    <span class="c1"># Rate parameter effects</span>
    <span class="n">alpha_fixed</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="k">for</span> <span class="n">beta</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
        <span class="c1"># Note: SciPy uses scale parameterization, so scale = 1/beta</span>
        <span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha_fixed</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">beta</span><span class="p">)</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Œ≤=</span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Gamma PDFs with Œ±=</span><span class="si">{</span><span class="n">alpha_fixed</span><span class="si">}</span><span class="s1"> (varying rate)&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Sum of exponentials</span>
    <span class="n">n_exp</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">lam</span> <span class="o">=</span> <span class="mf">2.0</span>
    <span class="n">n_sim</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Sum of exponentials</span>
    <span class="c1"># Note: NumPy exponential uses scale parameterization</span>
    <span class="n">exp_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">,</span> <span class="n">n_sim</span><span class="p">)</span>
                     <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_exp</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Direct gamma - SciPy uses scale = 1/rate</span>
    <span class="n">gamma_samples</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">n_exp</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_sim</span><span class="p">)</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">exp_sum</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Sum of </span><span class="si">{</span><span class="n">n_exp</span><span class="si">}</span><span class="s1"> Exp(</span><span class="si">{</span><span class="n">lam</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">gamma_samples</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Gamma(</span><span class="si">{</span><span class="n">n_exp</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">lam</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="c1"># Theoretical PDF</span>
    <span class="n">x_theory</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">exp_sum</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">gamma_samples</span><span class="o">.</span><span class="n">max</span><span class="p">()),</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">pdf_theory</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">n_exp</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">pdf_theory</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theory&#39;</span><span class="p">)</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Gamma as Sum of Exponentials&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Chi-squared connection</span>
    <span class="n">x_chi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]:</span>
        <span class="c1"># Chi-squared is Gamma(df/2, 1/2)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">df</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.5</span>

        <span class="c1"># Plot both to show they&#39;re identical</span>
        <span class="n">chi2_pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_chi</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
        <span class="c1"># Note: SciPy gamma uses scale = 1/beta</span>
        <span class="n">gamma_pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_chi</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">beta</span><span class="p">)</span>

        <span class="n">ax4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_chi</span><span class="p">,</span> <span class="n">chi2_pdf</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;œá¬≤(</span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_chi</span><span class="p">[::</span><span class="mi">20</span><span class="p">],</span> <span class="n">gamma_pdf</span><span class="p">[::</span><span class="mi">20</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Chi-squared as Gamma: œá¬≤(k) = Gamma(k/2, 1/2)&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">explore_gamma_distribution</span><span class="p">()</span>
</pre></div>
</div>
<p>Gamma function and factorial relationship:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">explore_gamma_function</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show gamma function properties and relation to factorial.&quot;&quot;&quot;</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.special</span><span class="w"> </span><span class="kn">import</span> <span class="n">gamma</span>

    <span class="c1"># For integers, Œì(n) = (n-1)!</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gamma function for integers:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">):</span>
        <span class="n">gamma_val</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">factorial_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">factorial</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Œì(</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">gamma_val</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s2">! = </span><span class="si">{</span><span class="n">factorial_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Plot gamma function</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Œì(x)&#39;</span><span class="p">)</span>

    <span class="c1"># Mark factorial points</span>
    <span class="n">n_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">factorial_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">gamma</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">n_vals</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_vals</span><span class="p">,</span> <span class="n">factorial_vals</span><span class="p">,</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;(n-1)! points&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Œì(x)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;The Gamma Function&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># Special values</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Special values:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Œì(1/2) = ‚àöœÄ = </span><span class="si">{</span><span class="n">gamma</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Œì(3/2) = ‚àöœÄ/2 = </span><span class="si">{</span><span class="n">gamma</span><span class="p">(</span><span class="mf">1.5</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">explore_gamma_function</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="beta-distribution">
<h3>Beta Distribution<a class="headerlink" href="#beta-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Beta distribution</strong> is a continuous distribution on the interval [0, 1], making it ideal for modeling proportions and probabilities.</p>
<p><strong>Parameterization</strong>: Beta(Œ± = shape1, Œ≤ = shape2)</p>
<p>A random variable <span class="math notranslate nohighlight">\(X \sim \text{Beta}(\alpha, \beta)\)</span> has probability density function:</p>
<div class="math notranslate nohighlight">
\[f(x) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha-1} (1-x)^{\beta-1} \quad \text{for } 0 \leq x \leq 1\]</div>
</div>
<p><strong>Historical Context</strong>:</p>
<p>The Beta distribution was first studied by Euler and Legendre in connection with the Beta function in the 1730s. It gained statistical prominence through Karl Pearson‚Äôs work on the Pearson system of distributions. The Beta distribution‚Äôs bounded support makes it natural for modeling proportions, while its flexibility allows it to take many shapes‚Äîuniform, U-shaped, bell-shaped, or skewed.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = \frac{\alpha}{\alpha + \beta}\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\)</span></p></li>
<li><p><strong>Mode</strong>: <span class="math notranslate nohighlight">\(\frac{\alpha-1}{\alpha+\beta-2}\)</span> for <span class="math notranslate nohighlight">\(\alpha, \beta &gt; 1\)</span></p></li>
<li><p><strong>Moment Generating Function</strong>: No closed form, but moments can be computed</p></li>
<li><p><strong>Special cases</strong>:
- <span class="math notranslate nohighlight">\(\alpha = \beta = 1\)</span>: Uniform(0, 1)
- <span class="math notranslate nohighlight">\(\alpha = \beta\)</span>: Symmetric about 0.5
- <span class="math notranslate nohighlight">\(\alpha = \beta = 0.5\)</span>: Arcsine distribution (U-shaped)</p></li>
</ul>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Order Statistics of Uniform</p>
<p>If <span class="math notranslate nohighlight">\(U_1, ..., U_n\)</span> are independent <span class="math notranslate nohighlight">\(\text{Uniform}(0,1)\)</span> and <span class="math notranslate nohighlight">\(U_{(k)}\)</span> is the <span class="math notranslate nohighlight">\(k\)</span>-th order statistic, then:</p>
<div class="math notranslate nohighlight">
\[U_{(k)} \sim \text{Beta}(k, n-k+1)\]</div>
<p><strong>Proof</strong>: The CDF of <span class="math notranslate nohighlight">\(U_{(k)}\)</span> is:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}F_{U_{(k)}}(x) = P(U_{(k)} \leq x) = P(\text{at least } k \text{ of the } U_i \leq x)\\= \sum_{j=k}^n \binom{n}{j} x^j (1-x)^{n-j}\end{aligned}\end{align} \]</div>
<p>Taking the derivative:</p>
<div class="math notranslate nohighlight">
\[f_{U_{(k)}}(x) = \frac{n!}{(k-1)!(n-k)!} x^{k-1} (1-x)^{n-k} = \text{Beta}(k, n-k+1)\]</div>
</div>
<div class="theorem admonition">
<p class="admonition-title">Relationship: Beta and Gamma</p>
<p>If <span class="math notranslate nohighlight">\(X \sim \text{Gamma}(\alpha, \lambda)\)</span> and <span class="math notranslate nohighlight">\(Y \sim \text{Gamma}(\beta, \lambda)\)</span> are independent, then:</p>
<div class="math notranslate nohighlight">
\[\frac{X}{X+Y} \sim \text{Beta}(\alpha, \beta)\]</div>
<p>This relationship is fundamental in many applications.</p>
</div>
<p>Let‚Äôs explore the beta distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">explore_beta_shapes</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Explore how Œ± and Œ≤ affect the Beta distribution shape.&quot;&quot;&quot;</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">),</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># Different shape combinations</span>
    <span class="n">params_groups</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1"># U-shaped and uniform</span>
        <span class="p">[(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;U-shaped&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Uniform&#39;</span><span class="p">)],</span>
        <span class="c1"># Symmetric shapes</span>
        <span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Bell&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;Concentrated&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;Highly concentrated&#39;</span><span class="p">)],</span>
        <span class="c1"># Skewed shapes</span>
        <span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;Left skewed&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Right skewed&#39;</span><span class="p">)],</span>
        <span class="c1"># Extreme shapes</span>
        <span class="p">[(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;J-shaped&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;Reverse J&#39;</span><span class="p">)]</span>
    <span class="p">]</span>

    <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">]</span>
    <span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;U-shaped and Uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;Symmetric Shapes&#39;</span><span class="p">,</span>
              <span class="s1">&#39;Skewed Shapes&#39;</span><span class="p">,</span> <span class="s1">&#39;Extreme Shapes&#39;</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">params_groups</span><span class="p">,</span> <span class="n">titles</span><span class="p">):</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">desc</span><span class="p">)</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Œ±=</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s1">, Œ≤=</span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">desc</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">explore_beta_shapes</span><span class="p">()</span>
</pre></div>
</div>
<p>Order statistics demonstration:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_beta_order_statistics</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show that order statistics of Uniform(0,1) follow Beta.&quot;&quot;&quot;</span>

    <span class="n">n</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># Sample size</span>
    <span class="n">k</span> <span class="o">=</span> <span class="mi">3</span>   <span class="c1"># We want the k-th smallest</span>
    <span class="n">n_simulations</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Simulate k-th order statistic</span>
    <span class="n">order_stats</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_simulations</span><span class="p">):</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        <span class="n">sorted_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
        <span class="n">order_stats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sorted_sample</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># k-th smallest</span>

    <span class="c1"># Theoretical: k-th order statistic ~ Beta(k, n-k+1)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">k</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="c1"># Histogram vs theory</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">order_stats</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-th order statistic&#39;</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Beta(</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-th Order Statistic of </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1"> Uniform(0,1) Variables&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># QQ plot</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">probplot</span>
    <span class="n">probplot</span><span class="p">(</span><span class="n">order_stats</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">),</span> <span class="n">plot</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Q-Q Plot vs Beta Distribution&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># Expected value and quantiles</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Order statistic: </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">-th out of </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Distribution: Beta(</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical mean: </span><span class="si">{</span><span class="n">alpha</span><span class="o">/</span><span class="p">(</span><span class="n">alpha</span><span class="o">+</span><span class="n">beta</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">order_stats</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical median: </span><span class="si">{</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empirical median: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">order_stats</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">demonstrate_beta_order_statistics</span><span class="p">()</span>
</pre></div>
</div>
<p>Beta-Gamma relationship:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_beta_gamma_relationship</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show Beta arises from ratio of Gamma variables.&quot;&quot;&quot;</span>

    <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span>
    <span class="n">lambda_param</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Same rate for both Gammas</span>
    <span class="n">n_sim</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Generate independent Gammas</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">lambda_param</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_sim</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">lambda_param</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_sim</span><span class="p">)</span>

    <span class="c1"># Form ratio</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="p">(</span><span class="n">X</span> <span class="o">+</span> <span class="n">Y</span><span class="p">)</span>

    <span class="c1"># Theoretical Beta</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">beta_pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;X/(X+Y) where X~Œì(Œ±,Œª), Y~Œì(Œ≤,Œª)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">beta_pdf</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Beta(</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Beta Distribution from Gamma Ratio&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;X ~ Gamma(</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">lambda_param</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Y ~ Gamma(</span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">lambda_param</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;X/(X+Y) ~ Beta(</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Empirical mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theoretical mean: </span><span class="si">{</span><span class="n">alpha</span><span class="o">/</span><span class="p">(</span><span class="n">alpha</span><span class="o">+</span><span class="n">beta</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">demonstrate_beta_gamma_relationship</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="additional-important-distributions">
<h2>Additional Important Distributions<a class="headerlink" href="#additional-important-distributions" title="Link to this heading">ÔÉÅ</a></h2>
<section id="student-s-t-distribution">
<h3>Student‚Äôs t-Distribution<a class="headerlink" href="#student-s-t-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Student‚Äôs t-distribution</strong> arises when estimating the mean of a normally distributed population when the sample size is small and population variance is unknown.</p>
<p><strong>Parameterization</strong>: t(ŒΩ = degrees of freedom)</p>
<p>A random variable <span class="math notranslate nohighlight">\(T \sim t(\nu)\)</span> has probability density function:</p>
<div class="math notranslate nohighlight">
\[f(t) = \frac{\Gamma(\frac{\nu+1}{2})}{\sqrt{\nu\pi}\Gamma(\frac{\nu}{2})} \left(1 + \frac{t^2}{\nu}\right)^{-\frac{\nu+1}{2}}\]</div>
</div>
<figure class="align-center" id="id10">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_student_t.png"><img alt="Comparison of Student's t-distributions with various degrees of freedom against standard normal, showing heavier tails for low df" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_student_t.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.16 </span><span class="caption-text"><strong>Student‚Äôs t-distribution vs Normal.</strong> With low degrees of freedom, the t-distribution has heavier tails than the normal (dashed), accommodating more extreme observations. As <span class="math notranslate nohighlight">\(df \to \infty\)</span>, the t-distribution converges to <span class="math notranslate nohighlight">\(N(0, 1)\)</span>. The t-distribution with <span class="math notranslate nohighlight">\(df = 1\)</span> is the Cauchy distribution.</span><a class="headerlink" href="#id10" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Historical Context</strong>:</p>
<p>The t-distribution was discovered by William Sealy Gosset around 1905-1906 while working as a chemist at the Guinness brewery in Dublin. Guinness was using statistics to improve beer quality but prohibited employees from publishing trade secrets. Gosset published his findings in <em>Biometrika</em> in 1908 under the pseudonym ‚ÄúStudent,‚Äù giving us the ‚ÄúStudent‚Äôs t-distribution.‚Äù His specific problem involved small samples‚Äîtesting beer quality with only 4-5 samples. The normal distribution gave too-narrow confidence intervals for small samples, leading to wrong decisions. The t-distribution corrected this by accounting for the extra uncertainty from estimating variance. This work revolutionized small-sample statistics and remains fundamental to experimental science.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[T] = 0\)</span> for <span class="math notranslate nohighlight">\(\nu &gt; 1\)</span> (undefined for <span class="math notranslate nohighlight">\(\nu = 1\)</span>)</p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(T) = \frac{\nu}{\nu-2}\)</span> for <span class="math notranslate nohighlight">\(\nu &gt; 2\)</span> (undefined for <span class="math notranslate nohighlight">\(1 &lt; \nu \leq 2\)</span>)</p></li>
<li><p><strong>Heavy tails</strong>: Heavier tails than normal distribution</p></li>
<li><p><strong>Convergence</strong>: As <span class="math notranslate nohighlight">\(\nu \to \infty\)</span>, <span class="math notranslate nohighlight">\(t(\nu) \to \mathcal{N}(0,1)\)</span></p></li>
</ul>
<div class="theorem admonition">
<p class="admonition-title">Theorem: t-Distribution from Normal and Chi-Square</p>
<p>If <span class="math notranslate nohighlight">\(Z \sim \mathcal{N}(0,1)\)</span> and <span class="math notranslate nohighlight">\(V \sim \chi^2(\nu)\)</span> are independent, then:</p>
<div class="math notranslate nohighlight">
\[T = \frac{Z}{\sqrt{V/\nu}} \sim t(\nu)\]</div>
<p><strong>Proof</strong>: This follows from the ratio of a standard normal to the square root of a scaled chi-square.</p>
<p>In the context of sample means: if <span class="math notranslate nohighlight">\(\bar{X}\)</span> is the sample mean and <span class="math notranslate nohighlight">\(S^2\)</span> is the sample variance from a normal population, then:</p>
<div class="math notranslate nohighlight">
\[T = \frac{\bar{X} - \mu}{S/\sqrt{n}} \sim t(n-1)\]</div>
</div>
<div class="proof admonition">
<p class="admonition-title">Proof: Convergence to Normal</p>
<p>As <span class="math notranslate nohighlight">\(\nu \to \infty\)</span>, the t-distribution converges to <span class="math notranslate nohighlight">\(\mathcal{N}(0,1)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\lim_{\nu \to \infty} \left(1 + \frac{t^2}{\nu}\right)^{-\frac{\nu+1}{2}} = e^{-t^2/2}\]</div>
<p>Using the fact that <span class="math notranslate nohighlight">\(\lim_{n \to \infty} (1 + x/n)^n = e^x\)</span>.</p>
</div>
<p>Let‚Äôs explore the t-distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">explore_t_distribution</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Comprehensive exploration of the t-distribution.&quot;&quot;&quot;</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">),</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># PDF comparison with normal</span>
    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">30</span><span class="p">]:</span>
        <span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;t(</span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Add normal for comparison</span>
    <span class="n">normal_pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">normal_pdf</span><span class="p">,</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;N(0,1)&#39;</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Student&#39;s t-Distribution PDFs&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Heavy tails (log scale)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">),</span>
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;t(3)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]),</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;N(0,1)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density (log scale)&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Heavy Tails of t-Distribution&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Variance as function of df</span>
    <span class="n">df_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">31</span><span class="p">)</span>
    <span class="n">variances</span> <span class="o">=</span> <span class="p">[</span><span class="n">df</span><span class="o">/</span><span class="p">(</span><span class="n">df</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">df_values</span><span class="p">]</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_values</span><span class="p">,</span> <span class="n">variances</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="s1">&#39;N(0,1) variance = 1&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Degrees of freedom&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Variance&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;t-Distribution Variance&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Demonstrate construction from Z and chi-square</span>
    <span class="n">df</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">n_sim</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Generate t as ratio</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_sim</span><span class="p">)</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">chisquare</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">n_sim</span><span class="p">)</span>
    <span class="n">T_constructed</span> <span class="o">=</span> <span class="n">Z</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">V</span> <span class="o">/</span> <span class="n">df</span><span class="p">)</span>

    <span class="c1"># Direct t samples</span>
    <span class="n">T_direct</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_sim</span><span class="p">)</span>

    <span class="n">ax4</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">T_constructed</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Z/‚àö(V/ŒΩ)&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">T_direct</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Direct t(</span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">x_theory</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">df</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span>
             <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theory&#39;</span><span class="p">)</span>

    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;t-Distribution as Ratio&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">explore_t_distribution</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="chi-square-distribution">
<h3>Chi-Square Distribution<a class="headerlink" href="#chi-square-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>Chi-square distribution</strong> with <span class="math notranslate nohighlight">\(k\)</span> degrees of freedom is the distribution of the sum of squares of <span class="math notranslate nohighlight">\(k\)</span> independent standard normal random variables.</p>
<p><strong>Parameterization</strong>: œá¬≤(k = degrees of freedom)</p>
<p>If <span class="math notranslate nohighlight">\(Z_1, ..., Z_k\)</span> are independent <span class="math notranslate nohighlight">\(\mathcal{N}(0,1)\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[X = \sum_{i=1}^k Z_i^2 \sim \chi^2(k)\]</div>
<p>Probability density function:</p>
<div class="math notranslate nohighlight">
\[f(x) = \frac{1}{2^{k/2}\Gamma(k/2)} x^{k/2-1} e^{-x/2} \quad \text{for } x &gt; 0\]</div>
</div>
<figure class="align-center" id="id11">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_chi_square.png"><img alt="Chi-square distribution PDFs for degrees of freedom 1, 2, 5, 10, and 15, showing progression from highly skewed to more symmetric" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_chi_square.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.17 </span><span class="caption-text"><strong>Chi-square distribution.</strong> Defined as the sum of <span class="math notranslate nohighlight">\(k\)</span> squared standard normals, <span class="math notranslate nohighlight">\(\chi^2_k\)</span> is right-skewed for small <span class="math notranslate nohighlight">\(k\)</span> and becomes more symmetric as <span class="math notranslate nohighlight">\(k\)</span> increases. The mean equals <span class="math notranslate nohighlight">\(k\)</span> and variance equals <span class="math notranslate nohighlight">\(2k\)</span>. Used extensively in hypothesis testing and variance estimation.</span><a class="headerlink" href="#id11" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[X] = k\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) = 2k\)</span></p></li>
<li><p><strong>Mode</strong>: <span class="math notranslate nohighlight">\(\max(k-2, 0)\)</span></p></li>
<li><p><strong>Moment Generating Function</strong>: <span class="math notranslate nohighlight">\(M_X(t) = (1-2t)^{-k/2}\)</span> for <span class="math notranslate nohighlight">\(t &lt; 1/2\)</span></p></li>
<li><p><strong>Relationship to Gamma</strong>: <span class="math notranslate nohighlight">\(\chi^2(k) = \text{Gamma}(k/2, 1/2)\)</span></p></li>
<li><p><strong>Additivity</strong>: If <span class="math notranslate nohighlight">\(X_i \sim \chi^2(k_i)\)</span> independent, then <span class="math notranslate nohighlight">\(\sum X_i \sim \chi^2(\sum k_i)\)</span></p></li>
</ul>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Additivity of Chi-Square</p>
<p>If <span class="math notranslate nohighlight">\(X_1 \sim \chi^2(k_1)\)</span> and <span class="math notranslate nohighlight">\(X_2 \sim \chi^2(k_2)\)</span> are independent, then:</p>
<div class="math notranslate nohighlight">
\[X_1 + X_2 \sim \chi^2(k_1 + k_2)\]</div>
<p><strong>Proof</strong>: Using the Gamma representation and MGFs:</p>
<div class="math notranslate nohighlight">
\[M_{X_1+X_2}(t) = M_{X_1}(t) \cdot M_{X_2}(t) = (1-2t)^{-k_1/2} \cdot (1-2t)^{-k_2/2} = (1-2t)^{-(k_1+k_2)/2}\]</div>
</div>
<p>Let‚Äôs explore the chi-square distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">explore_chi_square</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Comprehensive exploration of chi-square distribution.&quot;&quot;&quot;</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">),</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># PDF for different degrees of freedom</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]:</span>
        <span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;k=</span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="k">if</span> <span class="n">df</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">+=</span> <span class="s1">&#39; (Exponential(1/2))&#39;</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Chi-Square Distribution PDFs&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

    <span class="c1"># Connection to squared normals</span>
    <span class="n">df</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">n_sim</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Sum of squared standard normals</span>
    <span class="n">squared_normals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">n_sim</span><span class="p">,</span> <span class="n">df</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">squared_normals</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Sum of </span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="s1"> squared N(0,1)&#39;</span><span class="p">)</span>

    <span class="n">x_theory</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">squared_normals</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">pdf_theory</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">pdf_theory</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;œá¬≤(</span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;œá¬≤ as Sum of Squared Standard Normals&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Additivity property</span>
    <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span>
    <span class="n">X1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">k1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_sim</span><span class="p">)</span>
    <span class="n">X2</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_sim</span><span class="p">)</span>
    <span class="n">X_sum</span> <span class="o">=</span> <span class="n">X1</span> <span class="o">+</span> <span class="n">X2</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X_sum</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;œá¬≤(</span><span class="si">{</span><span class="n">k1</span><span class="si">}</span><span class="s1">) + œá¬≤(</span><span class="si">{</span><span class="n">k2</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">x_theory</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">X_sum</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">pdf_theory</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">k1</span> <span class="o">+</span> <span class="n">k2</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">pdf_theory</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;œá¬≤(</span><span class="si">{</span><span class="n">k1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k2</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Additivity of Chi-Square&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="c1"># Mean and variance relationship</span>
    <span class="n">df_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>

    <span class="n">ax4</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_values</span><span class="p">,</span> <span class="n">df_values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Mean = k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df_values</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">df_values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Variance = 2k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_values</span><span class="p">,</span> <span class="n">df_values</span><span class="p">,</span> <span class="s1">&#39;b--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df_values</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">df_values</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Degrees of freedom (k)&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Chi-Square Mean and Variance&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">explore_chi_square</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="f-distribution">
<h3>F-Distribution<a class="headerlink" href="#f-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="definition admonition">
<p class="admonition-title">Definition</p>
<p>The <strong>F-distribution</strong> arises as the ratio of two independent chi-square random variables divided by their respective degrees of freedom.</p>
<p><strong>Parameterization</strong>: F(d‚ÇÅ = numerator df, d‚ÇÇ = denominator df)</p>
<p>If <span class="math notranslate nohighlight">\(X_1 \sim \chi^2(d_1)\)</span> and <span class="math notranslate nohighlight">\(X_2 \sim \chi^2(d_2)\)</span> are independent, then:</p>
<div class="math notranslate nohighlight">
\[F = \frac{X_1/d_1}{X_2/d_2} \sim F(d_1, d_2)\]</div>
</div>
<figure class="align-center" id="id12">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_f_distribution.png"><img alt="F-distribution PDFs for various combinations of numerator and denominator degrees of freedom" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_f_distribution.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.18 </span><span class="caption-text"><strong>F-distribution</strong> arises as the ratio of two scaled chi-square random variables. It is always right-skewed and positive. Used in ANOVA and regression for comparing variances. The shape depends on both <span class="math notranslate nohighlight">\(d_1\)</span> (numerator df) and <span class="math notranslate nohighlight">\(d_2\)</span> (denominator df).</span><a class="headerlink" href="#id12" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Historical Context</strong>:</p>
<p>The F-distribution is named after Sir Ronald Fisher, though George Snedecor first tabulated it, leading some to call it the Fisher-Snedecor distribution. Fisher developed it in the 1920s for analysis of variance (ANOVA), revolutionizing agricultural research at Rothamsted Experimental Station. The key insight: to test if several groups have equal means, compare variation between groups to variation within groups. If groups truly have equal means, this ratio follows an F-distribution. This enabled testing multiple treatments simultaneously, dramatically improving experimental efficiency.</p>
<p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Mean</strong>: <span class="math notranslate nohighlight">\(E[F] = \frac{d_2}{d_2-2}\)</span> for <span class="math notranslate nohighlight">\(d_2 &gt; 2\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(F) = \frac{2d_2^2(d_1+d_2-2)}{d_1(d_2-2)^2(d_2-4)}\)</span> for <span class="math notranslate nohighlight">\(d_2 &gt; 4\)</span></p></li>
<li><p><strong>Mode</strong>: <span class="math notranslate nohighlight">\(\frac{d_1-2}{d_1} \cdot \frac{d_2}{d_2+2}\)</span> for <span class="math notranslate nohighlight">\(d_1 &gt; 2\)</span></p></li>
<li><p><strong>Relationship to t</strong>: <span class="math notranslate nohighlight">\(t^2(d) = F(1, d)\)</span></p></li>
</ul>
<div class="theorem admonition">
<p class="admonition-title">Theorem: Relationship to t-Distribution</p>
<p>If <span class="math notranslate nohighlight">\(T \sim t(d)\)</span>, then <span class="math notranslate nohighlight">\(T^2 \sim F(1, d)\)</span></p>
<p><strong>Proof</strong>: From the construction of t-distribution:</p>
<div class="math notranslate nohighlight">
\[T = \frac{Z}{\sqrt{V/d}} \text{ where } Z \sim \mathcal{N}(0,1), V \sim \chi^2(d)\]</div>
<p>Therefore:</p>
<div class="math notranslate nohighlight">
\[T^2 = \frac{Z^2}{V/d} = \frac{Z^2/1}{V/d}\]</div>
<p>Since <span class="math notranslate nohighlight">\(Z^2 \sim \chi^2(1)\)</span>, this is the ratio defining <span class="math notranslate nohighlight">\(F(1, d)\)</span>.</p>
</div>
<p>Let‚Äôs explore the F-distribution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">explore_f_distribution</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Comprehensive exploration of F-distribution.&quot;&quot;&quot;</span>

    <span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">),</span> <span class="p">(</span><span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># PDF for different parameters</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="n">params</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)]</span>

    <span class="k">for</span> <span class="n">d1</span><span class="p">,</span> <span class="n">d2</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
        <span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;F(</span><span class="si">{</span><span class="n">d1</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">d2</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;F-Distribution PDFs&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Connection to ratio of chi-squares</span>
    <span class="n">d1</span><span class="p">,</span> <span class="n">d2</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span>
    <span class="n">n_sim</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># Generate F as ratio of chi-squares</span>
    <span class="n">chi2_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">chisquare</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">n_sim</span><span class="p">)</span>
    <span class="n">chi2_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">chisquare</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">n_sim</span><span class="p">)</span>
    <span class="n">f_ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">chi2_1</span> <span class="o">/</span> <span class="n">d1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">chi2_2</span> <span class="o">/</span> <span class="n">d2</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">f_ratio</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s1">&#39;(œá¬≤‚ÇÅ/d‚ÇÅ)/(œá¬≤‚ÇÇ/d‚ÇÇ)&#39;</span><span class="p">)</span>

    <span class="n">x_theory</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">pdf_theory</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">pdf_theory</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;F(</span><span class="si">{</span><span class="n">d1</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">d2</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;F as Ratio of Scaled Chi-Squares&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

    <span class="c1"># Relationship to t-distribution</span>
    <span class="n">df</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">n_sim</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="c1"># t¬≤ equals F(1, df)</span>
    <span class="n">t_samples</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_sim</span><span class="p">)</span>
    <span class="n">t_squared</span> <span class="o">=</span> <span class="n">t_samples</span><span class="o">**</span><span class="mi">2</span>

    <span class="n">f_samples</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_sim</span><span class="p">)</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">t_squared</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;t¬≤(</span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">f_samples</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;F(1, </span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">x_theory</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">pdf_theory</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_theory</span><span class="p">,</span> <span class="n">pdf_theory</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theory&#39;</span><span class="p">)</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Relationship: t¬≤ = F(1, df)&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="c1"># Effect of degrees of freedom on shape</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">d2_fixed</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="k">for</span> <span class="n">d1</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]:</span>
        <span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d1</span><span class="p">,</span> <span class="n">d2_fixed</span><span class="p">)</span>
        <span class="n">ax4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;d‚ÇÅ=</span><span class="si">{</span><span class="n">d1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;F-Distribution with d‚ÇÇ=</span><span class="si">{</span><span class="n">d2_fixed</span><span class="si">}</span><span class="s1"> (varying d‚ÇÅ)&#39;</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">ax4</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">explore_f_distribution</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="summary-and-practical-guidelines">
<h2>Summary and Practical Guidelines<a class="headerlink" href="#summary-and-practical-guidelines" title="Link to this heading">ÔÉÅ</a></h2>
<section id="choosing-the-right-distribution">
<h3>Choosing the Right Distribution<a class="headerlink" href="#choosing-the-right-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<div class="important admonition">
<p class="admonition-title">Distribution Selection Guide</p>
<p><strong>For Count Data:</strong></p>
<ul class="simple">
<li><p><strong>Binomial</strong>: Fixed number of trials, constant probability</p></li>
<li><p><strong>Poisson</strong>: Rare events, no upper limit, mean = variance</p></li>
<li><p><strong>Negative Binomial</strong>: Overdispersed count data (variance &gt; mean)</p></li>
<li><p><strong>Geometric</strong>: Time until first success, memoryless property</p></li>
</ul>
<p><strong>For Continuous Data:</strong></p>
<ul class="simple">
<li><p><strong>Normal</strong>: Symmetric data, sums of many factors, measurement errors</p></li>
<li><p><strong>Exponential</strong>: Time between events, constant hazard rate</p></li>
<li><p><strong>Gamma</strong>: Waiting times, positive skewed data, sum of exponentials</p></li>
<li><p><strong>Beta</strong>: Proportions, probabilities, bounded data [0,1]</p></li>
<li><p><strong>Uniform</strong>: Complete uncertainty within bounds, basis for simulation</p></li>
</ul>
<p><strong>For Statistical Inference:</strong></p>
<ul class="simple">
<li><p><strong>t-distribution</strong>: Small sample means, unknown variance</p></li>
<li><p><strong>Chi-square</strong>: Variance estimation, goodness-of-fit tests</p></li>
<li><p><strong>F-distribution</strong>: Comparing variances, ANOVA, regression significance</p></li>
</ul>
</div>
</section>
<section id="key-relationships-between-distributions">
<h3>Key Relationships Between Distributions<a class="headerlink" href="#key-relationships-between-distributions" title="Link to this heading">ÔÉÅ</a></h3>
<figure class="align-center" id="id13">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_distribution_relationships.png"><img alt="Diagram showing relationships between probability distributions with arrows indicating transformations like sums, limits, and special cases" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/ch1_2_distribution_relationships.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 1.19 </span><span class="caption-text"><strong>Relationships between distributions.</strong> Arrows indicate how distributions connect: sums of Bernoullis give Binomial; Binomial with <span class="math notranslate nohighlight">\(n \to \infty\)</span> approaches Poisson; Normal arises from the CLT; <span class="math notranslate nohighlight">\(-\ln(U)\)</span> transforms Uniform to Exponential; sums of Exponentials give Gamma; squared Normals give Chi-square; and ratios of Chi-squares give F. Color coding: pink = discrete counts, blue = discrete trials, green = continuous basic, yellow = continuous derived, purple = inference distributions.</span><a class="headerlink" href="#id13" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<div class="theorem admonition">
<p class="admonition-title">Comprehensive Distribution Relationships</p>
<p><strong>1. Limiting Relationships:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\text{Binomial}(n, p) \xrightarrow{n \to \infty} \mathcal{N}(np, np(1-p))\)</span> (De Moivre-Laplace)</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Binomial}(n, p) \xrightarrow{p \to 0, np \to \lambda} \text{Poisson}(\lambda)\)</span> (Poisson limit)</p></li>
<li><p><span class="math notranslate nohighlight">\(t(\nu) \xrightarrow{\nu \to \infty} \mathcal{N}(0, 1)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Gamma}(\alpha, \beta) \xrightarrow{\alpha \to \infty} \mathcal{N}(\alpha/\beta, \alpha/\beta^2)\)</span> (by CLT)</p></li>
</ul>
<p><strong>2. Special Cases:</strong></p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(X \sim \text{Bernoulli}(p)\)</span>, then <span class="math notranslate nohighlight">\(X \sim \text{Binomial}(1, p)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(X \sim \text{Exponential}(\lambda)\)</span>, then <span class="math notranslate nohighlight">\(X \sim \text{Gamma}(1, \lambda)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(X \sim \chi^2(k)\)</span>, then <span class="math notranslate nohighlight">\(X \sim \text{Gamma}(k/2, 1/2)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(X \sim \text{Beta}(1, 1)\)</span>, then <span class="math notranslate nohighlight">\(X \sim \text{Uniform}(0, 1)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(Y \sim \text{Geometric}(p)\)</span> and <span class="math notranslate nohighlight">\(X \sim \text{NegBinomial}(1, p)\)</span>, then <span class="math notranslate nohighlight">\(Y = X + 1\)</span> (SciPy convention)</p></li>
</ul>
<p><strong>3. Sums and Convolutions:</strong></p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(X_i \sim \text{Bernoulli}(p)\)</span> independent, then <span class="math notranslate nohighlight">\(\sum_{i=1}^n X_i \sim \text{Binomial}(n, p)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(X_i \sim \text{Exponential}(\lambda)\)</span> independent, then <span class="math notranslate nohighlight">\(\sum_{i=1}^n X_i \sim \text{Gamma}(n, \lambda)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(Y_i \sim \text{Geometric}(p)\)</span> independent, then <span class="math notranslate nohighlight">\(\sum_{i=1}^n Y_i - n \sim \text{NegBinomial}(n, p)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(X_i \sim \mathcal{N}(\mu_i, \sigma_i^2)\)</span> independent, then <span class="math notranslate nohighlight">\(\sum_{i=1}^n X_i \sim \mathcal{N}(\sum \mu_i, \sum \sigma_i^2)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(X_i \sim \chi^2(k_i)\)</span> independent, then <span class="math notranslate nohighlight">\(\sum_{i=1}^n X_i \sim \chi^2(\sum k_i)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(X_i \sim \text{Gamma}(\alpha_i, \beta)\)</span> independent with same <span class="math notranslate nohighlight">\(\beta\)</span>, then <span class="math notranslate nohighlight">\(\sum_{i=1}^n X_i \sim \text{Gamma}(\sum \alpha_i, \beta)\)</span></p></li>
</ul>
<p><strong>4. Transformations:</strong></p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(0, 1)\)</span>, then <span class="math notranslate nohighlight">\(X^2 \sim \chi^2(1)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(U \sim \text{Uniform}(0, 1)\)</span>, then <span class="math notranslate nohighlight">\(-\ln(U)/\lambda \sim \text{Exponential}(\lambda)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(T \sim t(\nu)\)</span>, then <span class="math notranslate nohighlight">\(T^2 \sim F(1, \nu)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(X \sim \text{Gamma}(\alpha, \lambda)\)</span> and <span class="math notranslate nohighlight">\(Y \sim \text{Gamma}(\beta, \lambda)\)</span>, then <span class="math notranslate nohighlight">\(\frac{X}{X+Y} \sim \text{Beta}(\alpha, \beta)\)</span></p></li>
</ul>
<p><strong>5. Constructions:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\frac{Z}{\sqrt{V/\nu}} \sim t(\nu)\)</span> where <span class="math notranslate nohighlight">\(Z \sim \mathcal{N}(0,1)\)</span>, <span class="math notranslate nohighlight">\(V \sim \chi^2(\nu)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\frac{U/d_1}{V/d_2} \sim F(d_1, d_2)\)</span> where <span class="math notranslate nohighlight">\(U \sim \chi^2(d_1)\)</span>, <span class="math notranslate nohighlight">\(V \sim \chi^2(d_2)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\min(X_1, ..., X_n) \sim \text{Exponential}(\sum \lambda_i)\)</span> where <span class="math notranslate nohighlight">\(X_i \sim \text{Exponential}(\lambda_i)\)</span></p></li>
</ul>
</div>
</section>
<section id="python-tools-summary">
<h3>Python Tools Summary<a class="headerlink" href="#python-tools-summary" title="Link to this heading">ÔÉÅ</a></h3>
<div class="code-summary admonition">
<p class="admonition-title">Essential Python Functions</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Basic operations for any distribution in scipy.stats</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># For distribution &#39;dist&#39; with parameters</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># example with normal</span>

<span class="c1"># PDF/PMF</span>
<span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>    <span class="c1"># Probability density function</span>
<span class="n">dist</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>    <span class="c1"># Probability mass function (discrete)</span>

<span class="c1"># CDF and inverse CDF</span>
<span class="n">dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>    <span class="c1"># Cumulative distribution function</span>
<span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>    <span class="c1"># Percent point function (inverse CDF/quantile)</span>

<span class="c1"># Random sampling</span>
<span class="n">dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>    <span class="c1"># Random variates</span>

<span class="c1"># Moments</span>
<span class="n">dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>    <span class="c1"># Mean</span>
<span class="n">dist</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>     <span class="c1"># Variance</span>
<span class="n">dist</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>     <span class="c1"># Standard deviation</span>
<span class="n">dist</span><span class="o">.</span><span class="n">moment</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="c1"># n-th moment</span>

<span class="c1"># Fitting</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># Maximum likelihood estimation</span>

<span class="c1"># Support</span>
<span class="n">dist</span><span class="o">.</span><span class="n">support</span><span class="p">()</span> <span class="c1"># Valid range of values</span>
</pre></div>
</div>
</div>
</section>
<section id="parameterization-notes">
<h3>Parameterization Notes<a class="headerlink" href="#parameterization-notes" title="Link to this heading">ÔÉÅ</a></h3>
<div class="warning admonition">
<p class="admonition-title">Important Parameterization Differences</p>
<p>Different libraries and sources use different parameterizations:</p>
<p><strong>Exponential Distribution:</strong>
- Rate parameterization: <span class="math notranslate nohighlight">\(f(x) = \lambda e^{-\lambda x}\)</span> (used in formulas)
- Scale parameterization: <span class="math notranslate nohighlight">\(f(x) = \frac{1}{\theta} e^{-x/\theta}\)</span> where <span class="math notranslate nohighlight">\(\theta = 1/\lambda\)</span>
- NumPy uses scale, so use <cite>np.random.exponential(scale=1/lambda)</cite></p>
<p><strong>Gamma Distribution:</strong>
- Shape-Rate: Gamma(Œ±, Œ≤) with mean Œ±/Œ≤
- Shape-Scale: Gamma(Œ±, Œ∏) with mean Œ±Œ∏ where Œ∏ = 1/Œ≤
- SciPy uses shape-scale: <cite>stats.gamma(a=alpha, scale=1/beta)</cite></p>
<p><strong>Geometric Distribution:</strong>
- SciPy: Number of trials until first success, support {1, 2, 3, ‚Ä¶}
- Alternative: Number of failures before first success, support {0, 1, 2, ‚Ä¶}</p>
<p>Always check documentation for the specific parameterization used!</p>
</div>
</section>
<section id="common-pitfalls-and-best-practices">
<h3>Common Pitfalls and Best Practices<a class="headerlink" href="#common-pitfalls-and-best-practices" title="Link to this heading">ÔÉÅ</a></h3>
<div class="tip admonition">
<p class="admonition-title">Best Practices</p>
<ol class="arabic simple">
<li><p><strong>Always visualize your data</strong> before choosing a distribution</p></li>
<li><p><strong>Check assumptions</strong>: Many tests assume normality or equal variances</p></li>
<li><p><strong>Use appropriate parameterizations</strong>: Verify whether using rate or scale</p></li>
<li><p><strong>Consider sample size</strong>: Small samples need t, not normal</p></li>
<li><p><strong>Test goodness-of-fit</strong>: Don‚Äôt assume, verify with chi-square or K-S tests</p></li>
<li><p><strong>Handle edge cases</strong>: What happens at boundaries? (e.g., p=0 or p=1)</p></li>
<li><p><strong>Use vectorized operations</strong>: NumPy is much faster than loops</p></li>
<li><p><strong>Set random seeds</strong>: For reproducible research</p></li>
<li><p><strong>Consider transformations</strong>: Log-normal data? Take logs first</p></li>
<li><p><strong>Don‚Äôt ignore overdispersion</strong>: Real count data often has variance &gt; mean</p></li>
</ol>
</div>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">ÔÉÅ</a></h2>
<p>Probability distributions are the fundamental language for describing uncertainty in data science. Through this chapter, we‚Äôve explored:</p>
<ol class="arabic simple">
<li><p><strong>The computational tools</strong>: From Python‚Äôs built-in <code class="docutils literal notranslate"><span class="pre">random</span></code> module to NumPy‚Äôs vectorized operations and SciPy‚Äôs comprehensive statistical functions</p></li>
<li><p><strong>Key distributions</strong>: Each with its own story, properties, and applications‚Äîfrom the humble Bernoulli to the sophisticated F-distribution</p></li>
<li><p><strong>Mathematical foundations</strong>: Rigorous proofs of limit theorems, derivations of properties like memorylessness, and relationships between distributions</p></li>
<li><p><strong>Practical implementation</strong>: How to generate samples, compute probabilities, and visualize distributions in Python</p></li>
<li><p><strong>Historical context</strong>: Understanding how these distributions were discovered helps appreciate their significance</p></li>
<li><p><strong>Real-world applications</strong>: Each distribution solves specific problems in various fields</p></li>
</ol>
<p>The ability to work fluently with these distributions‚Äîunderstanding their properties, proving their relationships, and implementing them computationally‚Äîforms the foundation for statistical inference, machine learning, and data analysis. As you continue your journey in computational data science, these distributions will appear repeatedly in different contexts, from hypothesis testing to time series analysis to stochastic processes.</p>
<p>Remember: probability distributions are not just mathematical abstractions but practical tools for understanding and quantifying uncertainty in the real world. Master them, and you master a fundamental aspect of data science.</p>
<div class="next-steps admonition">
<p class="admonition-title">Next Steps</p>
<p>In the following chapters, we‚Äôll build on this foundation to explore:</p>
<ul class="simple">
<li><p><strong>Statistical Inference</strong>: Using distributions for hypothesis testing and confidence intervals</p></li>
<li><p><strong>Time Series Analysis</strong>: Distributions evolving over time</p></li>
<li><p><strong>Machine Learning</strong>: Distributions in generative models and uncertainty quantification</p></li>
<li><p><strong>Stochastic Processes</strong>: Systems where randomness evolves dynamically</p></li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ch1.1-probability-and-inference-paradigms.html" class="btn btn-neutral float-left" title="1.1.1. Paradigms of Probability and Statistical Inference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ch1.3-python_random_generation.html" class="btn btn-neutral float-right" title="1.1.3. Python Random Generation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>