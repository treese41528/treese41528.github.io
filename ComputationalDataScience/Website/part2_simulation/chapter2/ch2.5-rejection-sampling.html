

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Rejection Sampling &mdash; STAT 418</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=054f5d2c" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT418/Website/part2_simulation/chapter2/ch2.5-rejection-sampling.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Show solution';</script>
      <script>let toggleHintHide = 'Hide solution';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=df457b14"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Course Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../part1_foundations/index.html">1. Part I: Foundations of Probability and Computation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part1_foundations/chapter1/index.html">1.1. Chapter 1: Statistical Paradigms and Core Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html">1.1.1. Paradigms of Probability and Statistical Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#the-mathematical-foundation-kolmogorov-s-axioms">The Mathematical Foundation: Kolmogorov‚Äôs Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#interpretations-of-probability">Interpretations of Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#statistical-inference-paradigms">Statistical Inference Paradigms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#historical-and-philosophical-debates">Historical and Philosophical Debates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#looking-ahead-our-course-focus">Looking Ahead: Our Course Focus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html">1.1.2. Probability Distributions: Theory and Computation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#from-abstract-foundations-to-concrete-tools">From Abstract Foundations to Concrete Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#the-python-ecosystem-for-probability">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#introduction-why-probability-distributions-matter">Introduction: Why Probability Distributions Matter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#id1">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#continuous-distributions">Continuous Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#additional-important-distributions">Additional Important Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#summary-and-practical-guidelines">Summary and Practical Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html">1.1.3. Python Random Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#from-mathematical-distributions-to-computational-samples">From Mathematical Distributions to Computational Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#the-python-ecosystem-at-a-glance">The Python Ecosystem at a Glance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#understanding-pseudo-random-number-generation">Understanding Pseudo-Random Number Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#the-standard-library-random-module">The Standard Library: <code class="docutils literal notranslate"><span class="pre">random</span></code> Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#numpy-fast-vectorized-random-sampling">NumPy: Fast Vectorized Random Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#scipy-stats-the-complete-statistical-toolkit">SciPy Stats: The Complete Statistical Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#bringing-it-all-together-library-selection-guide">Bringing It All Together: Library Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#looking-ahead-from-random-numbers-to-monte-carlo-methods">Looking Ahead: From Random Numbers to Monte Carlo Methods</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.4-chapter-summary.html">1.1.4. Chapter 1 Summary: Foundations in Place</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.4-chapter-summary.html#the-three-pillars-of-chapter-1">The Three Pillars of Chapter 1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.4-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.4-chapter-summary.html#what-lies-ahead-the-road-to-simulation">What Lies Ahead: The Road to Simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.4-chapter-summary.html#chapter-1-exercises-synthesis-problems">Chapter 1 Exercises: Synthesis Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.4-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">2. Part II: Simulation-Based Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html">2.1. Chapter 2: Monte Carlo Simulation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html">2.1.1. Monte Carlo Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#the-historical-development-of-monte-carlo-methods">The Historical Development of Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#the-core-principle-expectation-as-integration">The Core Principle: Expectation as Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#theoretical-foundations">Theoretical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#variance-estimation-and-confidence-intervals">Variance Estimation and Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#comparison-with-deterministic-methods">Comparison with Deterministic Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#sample-size-determination">Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#convergence-diagnostics-and-monitoring">Convergence Diagnostics and Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_1-monte-carlo-fundamentals.html#transition-to-what-follows">Transition to What Follows</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2_2-uniform-random-variates.html">2.1.2. Uniform Random Variates</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#why-uniform-the-universal-currency-of-randomness">Why Uniform? The Universal Currency of Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#the-paradox-of-computational-randomness">The Paradox of Computational Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#chaotic-dynamical-systems-an-instructive-failure">Chaotic Dynamical Systems: An Instructive Failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#linear-congruential-generators">Linear Congruential Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#shift-register-generators">Shift-Register Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#the-kiss-generator-combining-strategies">The KISS Generator: Combining Strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#modern-generators-mersenne-twister-and-pcg">Modern Generators: Mersenne Twister and PCG</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#statistical-testing-of-random-number-generators">Statistical Testing of Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_2-uniform-random-variates.html#transition-to-what-follows">Transition to What Follows</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2_3-inverse-cdf-method.html">2.1.3. Inverse CDF Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#mathematical-foundations">Mathematical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#continuous-distributions-with-closed-form-inverses">Continuous Distributions with Closed-Form Inverses</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#numerical-inversion">Numerical Inversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#mixed-distributions">Mixed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_3-inverse-cdf-method.html#transition-to-what-follows">Transition to What Follows</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2_4-transformation-methods.html">2.1.4. Transformation Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#why-transformation-methods">Why Transformation Methods?</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#the-boxmuller-transform">The Box‚ÄìMuller Transform</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#the-polar-marsaglia-method">The Polar (Marsaglia) Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#the-ziggurat-algorithm">The Ziggurat Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#the-clt-approximation-historical">The CLT Approximation (Historical)</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#distributions-derived-from-the-normal">Distributions Derived from the Normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#multivariate-normal-generation">Multivariate Normal Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2_4-transformation-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../chapter3/index.html">2.2. Chapter 3: Frequentist Statistical Inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/sampling_variability.html">2.2.1. Sampling Variability</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/statistical_estimators.html">2.2.2. Statistical Estimators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/plugin_methods.html">2.2.3. Plugin Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/parametric_inference.html">2.2.4. Parametric Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/exponential_families.html">2.2.5. Exponential Families</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/maximum_likelihood.html">2.2.6. Maximum Likelihood</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/linear_models.html">2.2.7. Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/generalized_linear_models.html">2.2.8. Generalized Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../chapter4/index.html">2.3. Chapter 4: Resampling Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/jackknife_introduction.html">2.3.1. Jackknife Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html">2.3.2. Bootstrap Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html">2.3.3. Nonparametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/parametric_bootstrap.html">2.3.4. Parametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/confidence_intervals.html">2.3.5. Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/bias_correction.html">2.3.6. Bias Correction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/cross_validation_loo.html">2.3.7. Cross Validation Loo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html">2.3.8. Cross Validation K Fold</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/model_selection.html">2.3.9. Model Selection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part3_bayesian/index.html">3. Part III: Bayesian Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part3_bayesian/index.html#overview">3.1. Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html">3.1.1. Bayesian Philosophy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Rejection Sampling</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/part2_simulation/chapter2/ch2.5-rejection-sampling.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="rejection-sampling">
<span id="ch2-5-rejection-sampling"></span><h1>Rejection Sampling<a class="headerlink" href="#rejection-sampling" title="Link to this heading">ÔÉÅ</a></h1>
<p>The transformation methods of <a class="reference internal" href="ch2_4-transformation-methods.html#ch2-4-transformation-methods"><span class="std std-ref">Transformation Methods</span></a> exploit mathematical structure: Box‚ÄìMuller converts uniforms to normals through polar coordinates; chi-squared emerges as a sum of squared normals; the t-distribution arises from a carefully constructed ratio. These methods are elegant and efficient‚Äîwhen they exist. But what happens when we need samples from a distribution with no known transformation from simple variates?</p>
<p>Consider the Beta distribution with general parameters <span class="math notranslate nohighlight">\(\alpha, \beta\)</span>. No closed-form inverse CDF exists, and there is no simple transformation from uniforms or normals (except for special cases like <span class="math notranslate nohighlight">\(\text{Beta}(1,1) = \text{Uniform}(0,1)\)</span>). What about a posterior distribution in Bayesian inference, known only up to a normalizing constant? Or a custom density defined by a complex formula arising from domain expertise?</p>
<p><strong>Rejection sampling</strong> (also called the accept-reject method) provides a universal solution. The idea, formalized by John von Neumann in 1951 in his notes ‚ÄúVarious techniques used in connection with random digits,‚Äù is surprisingly intuitive: if we can envelope the target density with a scaled version of a simpler ‚Äúproposal‚Äù density, we can generate candidates from the proposal and probabilistically accept or reject them. The accepted samples follow exactly the target distribution‚Äîno approximation, no asymptotic convergence, just exact sampling.</p>
<p>The conceptual roots trace back even further‚Äîto Buffon‚Äôs needle experiment (1777), one of the earliest uses of random sampling to solve a mathematical problem (estimating <span class="math notranslate nohighlight">\(\pi\)</span>). Von Neumann‚Äôs contribution was to generalize and formalize this intuition into a systematic method for arbitrary distributions, making it foundational to computational statistics.</p>
<p>The method‚Äôs power lies in its generality: rejection sampling works for <em>any</em> target density we can evaluate pointwise, even if the normalization constant is unknown. This makes it indispensable for Bayesian computation, where posterior densities are typically known only up to proportionality. The cost is efficiency‚Äîwhen the envelope fits poorly, we reject many candidates before accepting one.</p>
<p>This section develops rejection sampling from first principles. We begin with geometric intuition via the ‚Äúdartboard‚Äù interpretation, then formalize the algorithm and prove its correctness. We analyze efficiency through acceptance rates and explore strategies for choosing good proposal distributions. Worked examples demonstrate the method for Beta distributions, truncated normals, and custom densities. We conclude by examining the method‚Äôs limitations in high dimensions, setting the stage for the Markov Chain Monte Carlo methods of later chapters.</p>
<div class="important admonition">
<p class="admonition-title">Road Map üß≠</p>
<ul class="simple">
<li><p><strong>Understand</strong>: The geometric intuition behind rejection sampling‚Äîpoints uniformly distributed under a curve</p></li>
<li><p><strong>Prove</strong>: Why accepted samples follow the target distribution, even with unknown normalization</p></li>
<li><p><strong>Analyze</strong>: Acceptance probability as <span class="math notranslate nohighlight">\(1/M\)</span> and computational cost implications</p></li>
<li><p><strong>Design</strong>: Strategies for choosing proposal distributions and computing the envelope constant</p></li>
<li><p><strong>Implement</strong>: Efficient rejection samplers in Python with proper numerical safeguards</p></li>
<li><p><strong>Recognize</strong>: When rejection sampling fails and alternatives are needed</p></li>
</ul>
</div>
<section id="the-dartboard-intuition">
<h2>The Dartboard Intuition<a class="headerlink" href="#the-dartboard-intuition" title="Link to this heading">ÔÉÅ</a></h2>
<p>Before diving into formulas, let‚Äôs build geometric intuition for why rejection sampling works.</p>
<section id="the-fundamental-theorem-of-simulation">
<h3>The Fundamental Theorem of Simulation<a class="headerlink" href="#the-fundamental-theorem-of-simulation" title="Link to this heading">ÔÉÅ</a></h3>
<p>The theoretical foundation rests on a beautiful identity. For any probability density <span class="math notranslate nohighlight">\(f(x)\)</span>:</p>
<div class="math notranslate nohighlight">
\[f(x) = \int_0^{f(x)} du\]</div>
<p>This seemingly trivial observation has profound implications: the density <span class="math notranslate nohighlight">\(f(x)\)</span> is the marginal of a uniform distribution over the region under its curve. Formally:</p>
<div class="math notranslate nohighlight">
\[(X, U) \sim \text{Uniform}\{(x, u) : 0 &lt; u &lt; f(x)\} \quad \Longrightarrow \quad X \sim f\]</div>
<p><strong>Key insight</strong>: If we can sample uniformly from the region under a density curve, the <span class="math notranslate nohighlight">\(x\)</span>-coordinates follow that density exactly. Rejection sampling operationalizes this observation.</p>
</section>
<section id="points-under-a-curve">
<h3>Points Under a Curve<a class="headerlink" href="#points-under-a-curve" title="Link to this heading">ÔÉÅ</a></h3>
<p>Imagine plotting the probability density function <span class="math notranslate nohighlight">\(f(x)\)</span> of our target distribution on a coordinate plane. The area under this curve equals 1 (for a proper density). Now suppose we could somehow generate points <span class="math notranslate nohighlight">\((x, y)\)</span> uniformly distributed over the region under the curve‚Äîthat is, uniformly over the set <span class="math notranslate nohighlight">\(\{(x, y) : 0 \le y \le f(x)\}\)</span>.</p>
<p>What distribution would the <span class="math notranslate nohighlight">\(x\)</span>-coordinates of these points follow?</p>
<p>The answer is <span class="math notranslate nohighlight">\(f(x)\)</span> itself. To see why, consider any interval <span class="math notranslate nohighlight">\([a, b]\)</span>. The probability that a uniformly distributed point has <span class="math notranslate nohighlight">\(x \in [a, b]\)</span> is proportional to the area of the region under <span class="math notranslate nohighlight">\(f(x)\)</span> between <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>‚Äîwhich is exactly <span class="math notranslate nohighlight">\(\int_a^b f(x)\,dx\)</span>. This matches the definition of drawing from <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>This observation suggests a sampling strategy: if we can generate points uniformly under <span class="math notranslate nohighlight">\(f(x)\)</span>, we can extract their <span class="math notranslate nohighlight">\(x\)</span>-coordinates as samples from <span class="math notranslate nohighlight">\(f\)</span>. But generating uniform points under an arbitrary curve is itself a non-trivial problem. Rejection sampling solves this by embedding the target region inside a larger, simpler region.</p>
</section>
<section id="the-envelope-strategy">
<h3>The Envelope Strategy<a class="headerlink" href="#the-envelope-strategy" title="Link to this heading">ÔÉÅ</a></h3>
<p>Suppose we have a <strong>proposal density</strong> <span class="math notranslate nohighlight">\(g(x)\)</span> from which we can easily sample (e.g., uniform, normal, exponential). We require that <span class="math notranslate nohighlight">\(g(x) &gt; 0\)</span> wherever <span class="math notranslate nohighlight">\(f(x) &gt; 0\)</span>‚Äîthe proposal must ‚Äúcover‚Äù the target. Furthermore, suppose we can find a constant <span class="math notranslate nohighlight">\(M \ge 1\)</span> such that:</p>
<div class="math notranslate nohighlight">
\[f(x) \le M \cdot g(x) \quad \text{for all } x\]</div>
<p>The function <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span> is called an <strong>envelope</strong> or <strong>hat function</strong> because it lies above <span class="math notranslate nohighlight">\(f(x)\)</span> everywhere. The region under <span class="math notranslate nohighlight">\(f(x)\)</span> is contained within the region under <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span>.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_5_fig01_envelope_concept.png"><img alt="Target density f(x) enclosed by envelope Mg(x), with accepted region shaded" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_5_fig01_envelope_concept.png" style="width: 85%;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>The Envelope Concept.</strong> The target density <span class="math notranslate nohighlight">\(f(x)\)</span> (blue) is everywhere dominated by the envelope <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span> (red dashed). Points uniformly distributed under the envelope will, when filtered to those under <span class="math notranslate nohighlight">\(f(x)\)</span>, yield <span class="math notranslate nohighlight">\(x\)</span>-coordinates distributed according to <span class="math notranslate nohighlight">\(f\)</span>.</span><a class="headerlink" href="#id1" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p>Now here‚Äôs the key insight. We can easily generate points uniformly under <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span>:</p>
<ol class="arabic simple">
<li><p>Sample <span class="math notranslate nohighlight">\(X \sim g(x)\)</span> (a draw from the proposal distribution)</p></li>
<li><p>Sample <span class="math notranslate nohighlight">\(Y \sim \text{Uniform}(0, M \cdot g(X))\)</span> (a height uniformly distributed up to the envelope)</p></li>
</ol>
<p>The pair <span class="math notranslate nohighlight">\((X, Y)\)</span> is uniformly distributed over the region under <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span>. If we now keep only those points with <span class="math notranslate nohighlight">\(Y \le f(X)\)</span>‚Äîthose falling under the target density‚Äîthe remaining points are uniformly distributed under <span class="math notranslate nohighlight">\(f(x)\)</span>, and their <span class="math notranslate nohighlight">\(x\)</span>-coordinates follow <span class="math notranslate nohighlight">\(f\)</span>.</p>
</section>
</section>
<section id="the-accept-reject-algorithm">
<h2>The Accept-Reject Algorithm<a class="headerlink" href="#the-accept-reject-algorithm" title="Link to this heading">ÔÉÅ</a></h2>
<p>We now formalize the geometric intuition into a precise algorithm.</p>
<section id="algorithm-statement">
<h3>Algorithm Statement<a class="headerlink" href="#algorithm-statement" title="Link to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>Given:</dt><dd><ul class="simple">
<li><p>Target density <span class="math notranslate nohighlight">\(f(x)\)</span>, possibly known only up to a normalizing constant</p></li>
<li><p>Proposal density <span class="math notranslate nohighlight">\(g(x)\)</span> from which we can sample directly</p></li>
<li><p>Envelope constant <span class="math notranslate nohighlight">\(M\)</span> such that <span class="math notranslate nohighlight">\(f(x) \le M \cdot g(x)\)</span> for all <span class="math notranslate nohighlight">\(x\)</span></p></li>
</ul>
</dd>
</dl>
<p><strong>Algorithm (Accept-Reject Method)</strong></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>To generate one sample from f(x):

1. REPEAT:
   a. Draw X ~ g(x)                              [sample from proposal]
   b. Draw U ~ Uniform(0, 1)                     [independent uniform]
   c. Compute acceptance probability:
      Œ±(X) = f(X) / [M ¬∑ g(X)]
   d. IF U ‚â§ Œ±(X):
      ACCEPT X and RETURN X
      ELSE:
      REJECT X and continue to next iteration

2. The returned X is an exact draw from f(x)
</pre></div>
</div>
<p>The key observation is that we don‚Äôt actually need to generate <span class="math notranslate nohighlight">\(Y = U \cdot M \cdot g(X)\)</span> explicitly. The condition <span class="math notranslate nohighlight">\(Y \le f(X)\)</span> is equivalent to <span class="math notranslate nohighlight">\(U \cdot M \cdot g(X) \le f(X)\)</span>, which simplifies to <span class="math notranslate nohighlight">\(U \le f(X) / [M \cdot g(X)] = \alpha(X)\)</span>.</p>
</section>
<section id="proof-of-correctness">
<h3>Proof of Correctness<a class="headerlink" href="#proof-of-correctness" title="Link to this heading">ÔÉÅ</a></h3>
<p>We now prove that accepted samples follow the target distribution <span class="math notranslate nohighlight">\(f(x)\)</span>.</p>
<p><strong>Theorem (Correctness of Accept-Reject).</strong> If <span class="math notranslate nohighlight">\(f(x) \le M \cdot g(x)\)</span> for all <span class="math notranslate nohighlight">\(x\)</span>, then the accepted value <span class="math notranslate nohighlight">\(X\)</span> from the accept-reject algorithm has density <span class="math notranslate nohighlight">\(f(x) / \int f(t)\,dt\)</span>.</p>
<p><strong>Proof.</strong> Consider a single iteration. We generate <span class="math notranslate nohighlight">\(X \sim g(x)\)</span> and <span class="math notranslate nohighlight">\(U \sim \text{Uniform}(0,1)\)</span>, accepting if <span class="math notranslate nohighlight">\(U \le f(X)/[M \cdot g(X)]\)</span>.</p>
<p>For any measurable set <span class="math notranslate nohighlight">\(A\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(X \in A \text{ and accepted}) &amp;= \int_A P\left(U \le \frac{f(x)}{M g(x)} \,\Big|\, X = x\right) g(x)\,dx \\
&amp;= \int_A \frac{f(x)}{M g(x)} \cdot g(x)\,dx \\
&amp;= \frac{1}{M} \int_A f(x)\,dx\end{split}\]</div>
<p>The overall probability of acceptance is:</p>
<div class="math notranslate nohighlight">
\[P(\text{accepted}) = \frac{1}{M} \int_{-\infty}^{\infty} f(x)\,dx = \frac{C}{M}\]</div>
<p>where <span class="math notranslate nohighlight">\(C = \int f(x)\,dx\)</span> is the normalizing constant of <span class="math notranslate nohighlight">\(f\)</span> (which equals 1 if <span class="math notranslate nohighlight">\(f\)</span> is already normalized).</p>
<p>By Bayes‚Äô theorem:</p>
<div class="math notranslate nohighlight">
\[P(X \in A \mid \text{accepted}) = \frac{P(X \in A \text{ and accepted})}{P(\text{accepted})} = \frac{\frac{1}{M}\int_A f(x)\,dx}{\frac{C}{M}} = \frac{\int_A f(x)\,dx}{C}\]</div>
<p>This is exactly the probability that a random variable with density <span class="math notranslate nohighlight">\(f(x)/C\)</span> lies in <span class="math notranslate nohighlight">\(A\)</span>. ‚àé</p>
<p><strong>Key insight</strong>: The normalization constant <span class="math notranslate nohighlight">\(C\)</span> cancels in the acceptance ratio. We never need to compute <span class="math notranslate nohighlight">\(\int f(x)\,dx\)</span>‚Äîrejection sampling works even when <span class="math notranslate nohighlight">\(f\)</span> is known only up to proportionality.</p>
</section>
</section>
<section id="efficiency-analysis">
<h2>Efficiency Analysis<a class="headerlink" href="#efficiency-analysis" title="Link to this heading">ÔÉÅ</a></h2>
<p>Not every proposed sample is accepted. Understanding the acceptance rate is crucial for assessing computational cost.</p>
<section id="acceptance-probability">
<h3>Acceptance Probability<a class="headerlink" href="#acceptance-probability" title="Link to this heading">ÔÉÅ</a></h3>
<p>From the proof above, the probability of accepting a single proposal is:</p>
<div class="math notranslate nohighlight" id="equation-acceptance-rate">
<span class="eqno">()<a class="headerlink" href="#equation-acceptance-rate" title="Link to this equation">ÔÉÅ</a></span>\[P(\text{accept}) = \frac{C}{M} = \frac{\int f(x)\,dx}{M}\]</div>
<p>If <span class="math notranslate nohighlight">\(f(x)\)</span> is already normalized (<span class="math notranslate nohighlight">\(C = 1\)</span>), the acceptance probability is simply <span class="math notranslate nohighlight">\(1/M\)</span>. The larger <span class="math notranslate nohighlight">\(M\)</span> is, the lower the acceptance rate.</p>
<p><strong>Geometric interpretation</strong>: The acceptance probability equals the ratio of the area under <span class="math notranslate nohighlight">\(f(x)\)</span> to the area under <span class="math notranslate nohighlight">\(M \cdot g(x)\)</span>. A tighter envelope (smaller <span class="math notranslate nohighlight">\(M\)</span>) means less wasted area and higher efficiency.</p>
</section>
<section id="expected-number-of-iterations">
<h3>Expected Number of Iterations<a class="headerlink" href="#expected-number-of-iterations" title="Link to this heading">ÔÉÅ</a></h3>
<p>Since each iteration has acceptance probability <span class="math notranslate nohighlight">\(1/M\)</span> (for normalized <span class="math notranslate nohighlight">\(f\)</span>), the number of iterations until acceptance follows a Geometric distribution:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\text{iterations}] = M\]</div>
<p>If <span class="math notranslate nohighlight">\(M = 2\)</span>, we expect 2 proposals per accepted sample (50% acceptance). If <span class="math notranslate nohighlight">\(M = 10\)</span>, we expect 10 proposals per accepted sample (10% acceptance). For <span class="math notranslate nohighlight">\(M = 100\)</span>, rejection sampling becomes painfully slow.</p>
</section>
<section id="the-optimal-envelope-constant">
<h3>The Optimal Envelope Constant<a class="headerlink" href="#the-optimal-envelope-constant" title="Link to this heading">ÔÉÅ</a></h3>
<p>Given a proposal <span class="math notranslate nohighlight">\(g(x)\)</span>, the smallest valid <span class="math notranslate nohighlight">\(M\)</span> is:</p>
<div class="math notranslate nohighlight" id="equation-optimal-m">
<span class="eqno">()<a class="headerlink" href="#equation-optimal-m" title="Link to this equation">ÔÉÅ</a></span>\[M^* = \sup_x \frac{f(x)}{g(x)}\]</div>
<p>Using <span class="math notranslate nohighlight">\(M^*\)</span> maximizes acceptance probability. Any <span class="math notranslate nohighlight">\(M &gt; M^*\)</span> is valid but wasteful; any <span class="math notranslate nohighlight">\(M &lt; M^*\)</span> violates the envelope condition and produces incorrect samples.</p>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ‚ö†Ô∏è</p>
<p><strong>Using M that‚Äôs too small</strong>: If <span class="math notranslate nohighlight">\(M \cdot g(x) &lt; f(x)\)</span> for some <span class="math notranslate nohighlight">\(x\)</span>, samples from the region where the envelope dips below the target are underrepresented. This is a <strong>silent error</strong>‚Äîthe algorithm runs but produces biased samples. Always verify that your envelope truly dominates the target, especially in tail regions.</p>
</div>
</section>
</section>
<section id="choosing-the-proposal-distribution">
<h2>Choosing the Proposal Distribution<a class="headerlink" href="#choosing-the-proposal-distribution" title="Link to this heading">ÔÉÅ</a></h2>
<p>The efficiency of rejection sampling hinges on choosing a proposal <span class="math notranslate nohighlight">\(g(x)\)</span> that closely approximates the target <span class="math notranslate nohighlight">\(f(x)\)</span> while remaining easy to sample.</p>
<section id="desiderata-for-proposals">
<h3>Desiderata for Proposals<a class="headerlink" href="#desiderata-for-proposals" title="Link to this heading">ÔÉÅ</a></h3>
<p>A good proposal distribution should satisfy:</p>
<ol class="arabic simple">
<li><p><strong>Easy to sample</strong>: We need fast, direct sampling from <span class="math notranslate nohighlight">\(g(x)\)</span>. Good choices include uniform, exponential, normal, Cauchy, and mixtures of these.</p></li>
<li><p><strong>Support covers target</strong>: Wherever <span class="math notranslate nohighlight">\(f(x) &gt; 0\)</span>, we need <span class="math notranslate nohighlight">\(g(x) &gt; 0\)</span>. Otherwise, some regions of the target receive zero probability mass.</p></li>
<li><p><strong>Shape matches target</strong>: Ideally, the ratio <span class="math notranslate nohighlight">\(f(x)/g(x)\)</span> should be nearly constant. Large variations in this ratio force <span class="math notranslate nohighlight">\(M\)</span> to be large, reducing efficiency.</p></li>
<li><p><strong>Tail behavior matches or exceeds</strong>: If <span class="math notranslate nohighlight">\(f(x)\)</span> has heavy tails, <span class="math notranslate nohighlight">\(g(x)\)</span> must have at least as heavy tails. A light-tailed proposal for a heavy-tailed target leads to <span class="math notranslate nohighlight">\(M = \infty\)</span>.</p></li>
</ol>
</section>
<section id="finding-the-envelope-constant">
<h3>Finding the Envelope Constant<a class="headerlink" href="#finding-the-envelope-constant" title="Link to this heading">ÔÉÅ</a></h3>
<p>Given <span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(g\)</span>, we must compute <span class="math notranslate nohighlight">\(M^* = \sup_x f(x)/g(x)\)</span>. Several approaches are available:</p>
<p><strong>Analytical optimization</strong>: For well-behaved functions, calculus yields the maximum. Set the derivative of <span class="math notranslate nohighlight">\(f(x)/g(x)\)</span> to zero and solve.</p>
<p><strong>Numerical optimization</strong>: Use <code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize_scalar</span></code> to find the maximum of <span class="math notranslate nohighlight">\(f(x)/g(x)\)</span>.</p>
<p><strong>Grid search</strong>: Evaluate the ratio on a fine grid covering the support, then take the maximum plus a small safety margin.</p>
<p><strong>Bounding arguments</strong>: Sometimes theoretical bounds are available. For instance, if <span class="math notranslate nohighlight">\(f\)</span> is a product of terms each bounded by a constant, those bounds can be combined.</p>
<div class="note admonition">
<p class="admonition-title">Example üí° Finding M for Beta(2.5, 6) with Uniform Proposal</p>
<p><strong>Target</strong>: <span class="math notranslate nohighlight">\(f(x) \propto x^{1.5}(1-x)^5\)</span> on <span class="math notranslate nohighlight">\([0, 1]\)</span></p>
<p><strong>Proposal</strong>: <span class="math notranslate nohighlight">\(g(x) = 1\)</span> (uniform on <span class="math notranslate nohighlight">\([0, 1]\)</span>)</p>
<p><strong>Find M</strong>: We need <span class="math notranslate nohighlight">\(M \ge \sup_{x \in [0,1]} x^{1.5}(1-x)^5\)</span>. Taking the derivative:</p>
<div class="math notranslate nohighlight">
\[\frac{d}{dx}\left[x^{1.5}(1-x)^5\right] = x^{0.5}(1-x)^4\left[1.5(1-x) - 5x\right] = 0\]</div>
<p>This gives <span class="math notranslate nohighlight">\(x^* = 1.5/6.5 \approx 0.231\)</span>. Evaluating:</p>
<div class="math notranslate nohighlight">
\[M^* = (0.231)^{1.5}(0.769)^5 \approx 0.0297\]</div>
<p>Wait‚Äîthis is less than 1! That‚Äôs because <span class="math notranslate nohighlight">\(f(x)\)</span> is unnormalized. The normalized Beta(2.5, 6) density has maximum approximately 2.53 at <span class="math notranslate nohighlight">\(x^* = 0.231\)</span>. So <span class="math notranslate nohighlight">\(M^* \approx 2.53\)</span> for the normalized target.</p>
</div>
</section>
<section id="strategies-for-different-scenarios">
<h3>Strategies for Different Scenarios<a class="headerlink" href="#strategies-for-different-scenarios" title="Link to this heading">ÔÉÅ</a></h3>
<table class="docutils align-default" id="id2">
<caption><span class="caption-text">Proposal Selection Strategies</span><a class="headerlink" href="#id2" title="Link to this table">ÔÉÅ</a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 35.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Target Characteristic</p></th>
<th class="head"><p>Recommended Proposal</p></th>
<th class="head"><p>Rationale</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Bounded support <span class="math notranslate nohighlight">\([a, b]\)</span></p></td>
<td><p>Uniform on <span class="math notranslate nohighlight">\([a, b]\)</span></p></td>
<td><p>Simple; <span class="math notranslate nohighlight">\(M\)</span> equals max of <span class="math notranslate nohighlight">\(f\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Unimodal, symmetric</p></td>
<td><p>Normal centered at mode</p></td>
<td><p>Good shape match; adjust <span class="math notranslate nohighlight">\(\sigma\)</span> to cover tails</p></td>
</tr>
<tr class="row-even"><td><p>Skewed, positive support</p></td>
<td><p>Exponential or Gamma</p></td>
<td><p>Matches asymmetry and tail decay</p></td>
</tr>
<tr class="row-odd"><td><p>Heavy tails</p></td>
<td><p>Cauchy or Student-t</p></td>
<td><p>Polynomial tail decay prevents <span class="math notranslate nohighlight">\(M = \infty\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Multiple modes</p></td>
<td><p>Mixture of normals</p></td>
<td><p>Each component covers one mode</p></td>
</tr>
<tr class="row-odd"><td><p>Log-concave density</p></td>
<td><p>Adaptive rejection (ARS)</p></td>
<td><p>Automatically constructs piecewise envelope</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="python-implementation">
<h2>Python Implementation<a class="headerlink" href="#python-implementation" title="Link to this heading">ÔÉÅ</a></h2>
<p>Let‚Äôs implement rejection sampling and apply it to several distributions.</p>
<section id="basic-implementation">
<h3>Basic Implementation<a class="headerlink" href="#basic-implementation" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">rejection_sample</span><span class="p">(</span><span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_sampler</span><span class="p">,</span> <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                     <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate samples from target using rejection sampling.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target_pdf : callable</span>
<span class="sd">        Function computing f(x), possibly unnormalized.</span>
<span class="sd">    proposal_sampler : callable</span>
<span class="sd">        Function that returns one sample from g(x).</span>
<span class="sd">    proposal_pdf : callable</span>
<span class="sd">        Function computing g(x).</span>
<span class="sd">    M : float</span>
<span class="sd">        Envelope constant such that f(x) &lt;= M * g(x) for all x.</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        Number of samples to generate.</span>
<span class="sd">    seed : int, optional</span>
<span class="sd">        Random seed for reproducibility.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    samples : ndarray</span>
<span class="sd">        Array of n_samples draws from the target distribution.</span>
<span class="sd">    acceptance_rate : float</span>
<span class="sd">        Fraction of proposals that were accepted.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="c1"># Step 1: Draw from proposal</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">proposal_sampler</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Step 2: Draw uniform for acceptance test</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>

        <span class="c1"># Step 3: Accept or reject</span>
        <span class="n">acceptance_prob</span> <span class="o">=</span> <span class="n">target_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">proposal_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">acceptance_prob</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_proposals</span>
</pre></div>
</div>
<div class="note admonition">
<p class="admonition-title">Example üí° Sampling from Beta(2.5, 6)</p>
<p><strong>Given</strong>: Target is Beta(2.5, 6); proposal is Uniform(0, 1)</p>
<p><strong>Find</strong>: 10,000 samples and verify against theoretical distribution</p>
<p><strong>Implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Target: Beta(2.5, 6) - use unnormalized kernel</span>
<span class="n">alpha</span><span class="p">,</span> <span class="n">beta_param</span> <span class="o">=</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">6.0</span>
<span class="k">def</span><span class="w"> </span><span class="nf">target_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">beta_param</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Proposal: Uniform(0, 1)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">proposal_sampler</span><span class="p">(</span><span class="n">rng</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">proposal_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="k">else</span> <span class="mf">0.0</span>

<span class="c1"># Find M: maximum of unnormalized Beta density</span>
<span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">f_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">target_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_grid</span><span class="p">]</span>
<span class="n">M</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">f_vals</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.01</span>  <span class="c1"># 1% safety margin</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Envelope constant M = </span><span class="si">{</span><span class="n">M</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected acceptance rate = </span><span class="si">{</span><span class="mi">1</span><span class="o">/</span><span class="n">M</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Generate samples</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">rejection_sample</span><span class="p">(</span>
    <span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_sampler</span><span class="p">,</span> <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Actual acceptance rate = </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample mean = </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="n">alpha</span><span class="o">/</span><span class="p">(</span><span class="n">alpha</span><span class="o">+</span><span class="n">beta_param</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Envelope</span> <span class="n">constant</span> <span class="n">M</span> <span class="o">=</span> <span class="mf">2.5561</span>
<span class="n">Expected</span> <span class="n">acceptance</span> <span class="n">rate</span> <span class="o">=</span> <span class="mf">39.1</span><span class="o">%</span>
<span class="n">Actual</span> <span class="n">acceptance</span> <span class="n">rate</span> <span class="o">=</span> <span class="mf">39.3</span><span class="o">%</span>
<span class="n">Sample</span> <span class="n">mean</span> <span class="o">=</span> <span class="mf">0.2937</span> <span class="p">(</span><span class="n">theory</span><span class="p">:</span> <span class="mf">0.2941</span><span class="p">)</span>
</pre></div>
</div>
<p>The acceptance rate matches the theoretical <span class="math notranslate nohighlight">\(1/M \approx 39\%\)</span>, and the sample mean matches the theoretical Beta mean <span class="math notranslate nohighlight">\(\alpha/(\alpha+\beta)\)</span>.</p>
</div>
</section>
<section id="vectorized-implementation-for-speed">
<h3>Vectorized Implementation for Speed<a class="headerlink" href="#vectorized-implementation-for-speed" title="Link to this heading">ÔÉÅ</a></h3>
<p>The basic implementation loops over individual samples. For better performance, we can generate batches of proposals and filter:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">rejection_sample_vectorized</span><span class="p">(</span><span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_sampler_batch</span><span class="p">,</span>
                                <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Vectorized rejection sampling for improved performance.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    proposal_sampler_batch : callable</span>
<span class="sd">        Function that takes (rng, batch_size) and returns batch_size samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Estimate batch size based on expected acceptance rate</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">M</span> <span class="o">*</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="mi">10</span><span class="p">))</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="c1"># Generate batch of proposals</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="n">proposal_sampler_batch</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">u_batch</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="n">batch_size</span>

        <span class="c1"># Vectorized acceptance test</span>
        <span class="n">f_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">target_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_batch</span><span class="p">])</span>
        <span class="n">g_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">proposal_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_batch</span><span class="p">])</span>
        <span class="n">acceptance_probs</span> <span class="o">=</span> <span class="n">f_vals</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">g_vals</span><span class="p">)</span>

        <span class="c1"># Accept where u &lt;= acceptance probability</span>
        <span class="n">accepted</span> <span class="o">=</span> <span class="n">x_batch</span><span class="p">[</span><span class="n">u_batch</span> <span class="o">&lt;=</span> <span class="n">acceptance_probs</span><span class="p">]</span>
        <span class="n">samples</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">accepted</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]),</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposals</span>
</pre></div>
</div>
</section>
</section>
<section id="the-squeeze-principle">
<h2>The Squeeze Principle<a class="headerlink" href="#the-squeeze-principle" title="Link to this heading">ÔÉÅ</a></h2>
<p>When the target density <span class="math notranslate nohighlight">\(f(x)\)</span> is expensive to evaluate, we can accelerate rejection sampling using a <strong>squeeze function</strong> (also called a lower envelope). The idea, introduced by Marsaglia (1977), is to construct a cheap-to-evaluate function <span class="math notranslate nohighlight">\(\ell(x)\)</span> satisfying:</p>
<div class="math notranslate nohighlight">
\[\ell(x) \le f(x) \le M \cdot g(x) \quad \text{for all } x\]</div>
<p>The modified algorithm becomes:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>To generate one sample from f(x) with squeeze:

1. REPEAT:
   a. Draw X ~ g(x)
   b. Draw U ~ Uniform(0, 1)
   c. IF U ‚â§ ‚Ñì(X) / [M ¬∑ g(X)]:
      ACCEPT X immediately (without evaluating f)
   d. ELSE IF U ‚â§ f(X) / [M ¬∑ g(X)]:
      ACCEPT X (requires evaluating f)
   e. ELSE:
      REJECT X

2. Return accepted X
</pre></div>
</div>
<p>The squeeze function acts as a ‚Äúfast accept‚Äù gate. If the uniform variate falls below <span class="math notranslate nohighlight">\(\ell(X)/[M \cdot g(X)]\)</span>, we accept without ever computing <span class="math notranslate nohighlight">\(f(X)\)</span>. Only when <span class="math notranslate nohighlight">\(U\)</span> falls between the squeeze and the envelope do we need the expensive <span class="math notranslate nohighlight">\(f\)</span> evaluation.</p>
<p><strong>Efficiency gain</strong>: If <span class="math notranslate nohighlight">\(\ell(x)\)</span> is close to <span class="math notranslate nohighlight">\(f(x)\)</span>, most acceptances occur at step (c), avoiding the costly <span class="math notranslate nohighlight">\(f(x)\)</span> evaluation. This is particularly valuable when <span class="math notranslate nohighlight">\(f\)</span> involves special functions, numerical integration, or complex likelihood computations.</p>
<div class="note admonition">
<p class="admonition-title">Example üí° Squeeze for Normal Density</p>
<p>From the Taylor expansion <span class="math notranslate nohighlight">\(e^{-x^2/2} \ge 1 - x^2/2\)</span> for <span class="math notranslate nohighlight">\(|x| \le \sqrt{2}\)</span>, we can use <span class="math notranslate nohighlight">\(\ell(x) = (1 - x^2/2)/\sqrt{2\pi}\)</span> as a squeeze function for the standard normal density within <span class="math notranslate nohighlight">\([-\sqrt{2}, \sqrt{2}]\)</span>. This avoids the exponential evaluation for about 61% of proposals when using a Cauchy envelope.</p>
</div>
</section>
<section id="geometric-example-sampling-from-the-unit-disk">
<h2>Geometric Example: Sampling from the Unit Disk<a class="headerlink" href="#geometric-example-sampling-from-the-unit-disk" title="Link to this heading">ÔÉÅ</a></h2>
<p>A classic application of rejection sampling is generating points uniformly distributed in a geometric region. Consider sampling uniformly from the unit disk <span class="math notranslate nohighlight">\(\{(x, y) : x^2 + y^2 \le 1\}\)</span>.</p>
<p><strong>Target</strong>: Uniform distribution on the disk (density <span class="math notranslate nohighlight">\(f(x,y) = 1/\pi\)</span> inside, 0 outside)</p>
<p><strong>Proposal</strong>: Uniform on the bounding square <span class="math notranslate nohighlight">\([-1, 1]^2\)</span> (density <span class="math notranslate nohighlight">\(g(x,y) = 1/4\)</span>)</p>
<p><strong>Envelope constant</strong>: Inside the disk, <span class="math notranslate nohighlight">\(f(x,y)/g(x,y) = (1/\pi)/(1/4) = 4/\pi\)</span>, so <span class="math notranslate nohighlight">\(M = 4/\pi \approx 1.273\)</span>.</p>
<p><strong>Acceptance rate</strong>: <span class="math notranslate nohighlight">\(1/M = \pi/4 \approx 78.5\%\)</span>, which equals the ratio of areas (disk area <span class="math notranslate nohighlight">\(\pi\)</span> divided by square area 4).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">sample_unit_disk</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample uniformly from the unit disk via rejection.</span>

<span class="sd">    Acceptance rate = œÄ/4 ‚âà 78.5% (area ratio).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="c1"># Propose from uniform square [-1, 1]¬≤</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Accept if inside disk</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="o">*</span><span class="n">y</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposals</span>

<span class="c1"># Generate 10,000 points</span>
<span class="n">points</span><span class="p">,</span> <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">sample_unit_disk</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate: </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">4</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Points shape: </span><span class="si">{</span><span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Acceptance</span> <span class="n">rate</span><span class="p">:</span> <span class="mf">0.785</span> <span class="p">(</span><span class="n">theory</span><span class="p">:</span> <span class="mf">0.785</span><span class="p">)</span>
<span class="n">Points</span> <span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>This ‚Äúhit-and-miss‚Äù approach generalizes to any region where membership can be tested: sample from a bounding box and reject points outside the target region. The efficiency depends on how well the bounding box fits the region.</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_5_fig02_unit_disk.png"><img alt="Rejection sampling for uniform disk: accepted points inside circle, rejected in corners" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_5_fig02_unit_disk.png" style="width: 70%;" />
</a>
<figcaption>
<p><span class="caption-text"><strong>Rejection Sampling for the Unit Disk.</strong> Blue points are accepted (inside disk); red points are rejected (in square corners). The acceptance rate equals the area ratio <span class="math notranslate nohighlight">\(\pi/4 \approx 78.5\%\)</span>.</span><a class="headerlink" href="#id3" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
</section>
<section id="worked-examples">
<h2>Worked Examples<a class="headerlink" href="#worked-examples" title="Link to this heading">ÔÉÅ</a></h2>
<p>We now apply rejection sampling to several important scenarios.</p>
<section id="example-1-truncated-normal-distribution">
<h3>Example 1: Truncated Normal Distribution<a class="headerlink" href="#example-1-truncated-normal-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<p>A truncated normal distribution restricts the standard normal to an interval <span class="math notranslate nohighlight">\([a, b]\)</span>. When <span class="math notranslate nohighlight">\([a, b]\)</span> lies in the tails, inversion methods become numerically unstable, but rejection sampling offers a simple solution.</p>
<p><strong>Target</strong>: <span class="math notranslate nohighlight">\(f(x) \propto \phi(x)\)</span> for <span class="math notranslate nohighlight">\(x \in [a, b]\)</span></p>
<p><strong>Proposal</strong>: The untruncated normal <span class="math notranslate nohighlight">\(g(x) = \phi(x)\)</span></p>
<p><strong>Envelope</strong>: Since <span class="math notranslate nohighlight">\(f(x) = \phi(x)\)</span> when <span class="math notranslate nohighlight">\(x \in [a, b]\)</span> and 0 otherwise, we have <span class="math notranslate nohighlight">\(f(x) \le g(x)\)</span>, so <span class="math notranslate nohighlight">\(M = 1\)</span>.</p>
<p><strong>Acceptance criterion</strong>: Accept <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(0, 1)\)</span> if <span class="math notranslate nohighlight">\(a \le X \le b\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">truncated_normal</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample from N(0,1) truncated to [a, b] via rejection.</span>

<span class="sd">    Acceptance rate = Œ¶(b) - Œ¶(a).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">()</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;=</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">b</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">theoretical_rate</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">actual_rate</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_proposals</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">actual_rate</span><span class="p">,</span> <span class="n">theoretical_rate</span>

<span class="c1"># Example: truncate to [1, 3] (right tail)</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">theory</span> <span class="o">=</span> <span class="n">truncated_normal</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Truncated N(0,1) to [1, 3]:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Theoretical acceptance rate: </span><span class="si">{</span><span class="n">theory</span><span class="si">:</span><span class="s2">.3%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Actual acceptance rate: </span><span class="si">{</span><span class="n">actual</span><span class="si">:</span><span class="s2">.3%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample mean: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Truncated</span> <span class="n">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="n">to</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]:</span>
  <span class="n">Theoretical</span> <span class="n">acceptance</span> <span class="n">rate</span><span class="p">:</span> <span class="mf">15.7</span><span class="o">%</span>
  <span class="n">Actual</span> <span class="n">acceptance</span> <span class="n">rate</span><span class="p">:</span> <span class="mf">15.8</span><span class="o">%</span>
  <span class="n">Sample</span> <span class="n">mean</span><span class="p">:</span> <span class="mf">1.5239</span>
</pre></div>
</div>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ‚ö†Ô∏è</p>
<p><strong>Extreme truncation</strong>: If <span class="math notranslate nohighlight">\([a, b]\)</span> lies far in the tail (e.g., <span class="math notranslate nohighlight">\([4, 6]\)</span>), the acceptance rate becomes tiny: <span class="math notranslate nohighlight">\(\Phi(6) - \Phi(4) \approx 0.003\%\)</span>. For extreme truncation, use specialized algorithms like Robert‚Äôs exponential tilting method or inverse CDF with careful numerical handling.</p>
</div>
</section>
<section id="example-2-gamma-distribution">
<h3>Example 2: Gamma Distribution<a class="headerlink" href="#example-2-gamma-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<p>The Gamma distribution with non-integer shape parameter has no simple transformation from uniforms. Rejection sampling provides an efficient solution.</p>
<p><strong>Target</strong>: <span class="math notranslate nohighlight">\(\text{Gamma}(\alpha, 1)\)</span> with <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span></p>
<p>For <span class="math notranslate nohighlight">\(\alpha \ge 1\)</span>, Ahrens-Dieter and other algorithms use rejection with carefully chosen envelopes. Here‚Äôs a simplified version using an exponential proposal for <span class="math notranslate nohighlight">\(\alpha \ge 1\)</span>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">gamma_rejection</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample Gamma(alpha, 1) using rejection with exponential envelope.</span>

<span class="sd">    Uses the fact that for alpha &gt;= 1, we can bound the Gamma density</span>
<span class="sd">    with a scaled exponential.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">alpha</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Use transformation: Gamma(alpha) = Gamma(alpha+1) * U^(1/alpha)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">gamma_rejection</span><span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span> <span class="o">*</span> <span class="n">u</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">alpha</span><span class="p">)</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="c1"># For alpha &gt;= 1, use exponential(1/alpha) as proposal</span>
    <span class="c1"># Envelope constant derived from ratio at mode</span>
    <span class="n">rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">alpha</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># M = f(mode) / g(mode) where g is Exp(rate)</span>
    <span class="n">f_mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">**</span><span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">mode</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">g_mode</span> <span class="o">=</span> <span class="n">rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rate</span> <span class="o">*</span> <span class="n">mode</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">f_mode</span> <span class="o">/</span> <span class="n">g_mode</span> <span class="o">*</span> <span class="mf">1.01</span>  <span class="c1"># safety margin</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">rate</span><span class="p">)</span>  <span class="c1"># Exp(rate) sample</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Gamma(alpha, 1) pdf (up to constant)</span>
        <span class="n">f_x</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="p">(</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Exp(rate) pdf</span>
        <span class="n">g_x</span> <span class="o">=</span> <span class="n">rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rate</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">f_x</span> <span class="o">/</span> <span class="p">(</span><span class="n">M</span> <span class="o">*</span> <span class="n">g_x</span><span class="p">):</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gamma(</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">): acceptance rate = </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">/</span><span class="n">n_proposals</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

<span class="c1"># Test</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">gamma_rejection</span><span class="p">(</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample mean: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (theory: 2.5)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample var:  </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (theory: 2.5)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="example-3-custom-posterior-distribution">
<h3>Example 3: Custom Posterior Distribution<a class="headerlink" href="#example-3-custom-posterior-distribution" title="Link to this heading">ÔÉÅ</a></h3>
<p>Rejection sampling shines in Bayesian inference where posteriors are known only up to proportionality.</p>
<p><strong>Scenario</strong>: Binomial likelihood with Beta prior yields Beta posterior, but suppose we want to apply rejection sampling without recognizing the conjugate form.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">bayesian_posterior_rejection</span><span class="p">(</span><span class="n">n_successes</span><span class="p">,</span> <span class="n">n_trials</span><span class="p">,</span> <span class="n">prior_alpha</span><span class="p">,</span> <span class="n">prior_beta</span><span class="p">,</span>
                                 <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample from posterior of Binomial parameter Œ∏.</span>

<span class="sd">    Prior: Œ∏ ~ Beta(prior_alpha, prior_beta)</span>
<span class="sd">    Likelihood: X | Œ∏ ~ Binomial(n_trials, Œ∏)</span>
<span class="sd">    Posterior: Œ∏ | X ‚àù Œ∏^(Œ± + x - 1) (1-Œ∏)^(Œ≤ + n - x - 1)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Posterior kernel (unnormalized)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">posterior_kernel</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">theta</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">theta</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">theta</span><span class="o">**</span><span class="p">(</span><span class="n">prior_alpha</span> <span class="o">+</span> <span class="n">n_successes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span>
                <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">prior_beta</span> <span class="o">+</span> <span class="n">n_trials</span> <span class="o">-</span> <span class="n">n_successes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Use uniform proposal on [0, 1]</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">kernel_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">posterior_kernel</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_grid</span><span class="p">]</span>
    <span class="n">M</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">kernel_vals</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.01</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">n_proposals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>  <span class="c1"># Uniform(0, 1)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">n_proposals</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">posterior_kernel</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">/</span> <span class="n">M</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="n">n_proposals</span>

<span class="c1"># Example: 7 successes in 10 trials, uniform prior</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">acc_rate</span> <span class="o">=</span> <span class="n">bayesian_posterior_rejection</span><span class="p">(</span>
    <span class="n">n_successes</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">prior_alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">prior_beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># uniform prior</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># True posterior is Beta(8, 4)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Posterior mean: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> (theory: </span><span class="si">{</span><span class="mi">8</span><span class="o">/</span><span class="mi">12</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acceptance rate: </span><span class="si">{</span><span class="n">acc_rate</span><span class="si">:</span><span class="s2">.1%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="limitations-and-the-curse-of-dimensionality">
<h2>Limitations and the Curse of Dimensionality<a class="headerlink" href="#limitations-and-the-curse-of-dimensionality" title="Link to this heading">ÔÉÅ</a></h2>
<p>Rejection sampling is elegant and exact, but it has fundamental limitations.</p>
<section id="the-high-dimensional-problem">
<h3>The High-Dimensional Problem<a class="headerlink" href="#the-high-dimensional-problem" title="Link to this heading">ÔÉÅ</a></h3>
<p>In <span class="math notranslate nohighlight">\(d\)</span> dimensions, the envelope condition becomes:</p>
<div class="math notranslate nohighlight">
\[f(\mathbf{x}) \le M \cdot g(\mathbf{x}) \quad \text{for all } \mathbf{x} \in \mathbb{R}^d\]</div>
<p>The acceptance probability is still <span class="math notranslate nohighlight">\(1/M\)</span>, but now <span class="math notranslate nohighlight">\(M\)</span> often grows exponentially with dimension.</p>
<p><strong>Example</strong>: Target is <span class="math notranslate nohighlight">\(\mathcal{N}(\mathbf{0}, \mathbf{I}_d)\)</span> and proposal is <span class="math notranslate nohighlight">\(\mathcal{N}(\mathbf{0}, \sigma^2 \mathbf{I}_d)\)</span> with <span class="math notranslate nohighlight">\(\sigma &gt; 1\)</span>. The ratio <span class="math notranslate nohighlight">\(f(\mathbf{x})/g(\mathbf{x})\)</span> involves:</p>
<div class="math notranslate nohighlight">
\[\frac{f(\mathbf{x})}{g(\mathbf{x})} = \sigma^d \exp\left[-\frac{\|\mathbf{x}\|^2}{2}\left(1 - \frac{1}{\sigma^2}\right)\right]\]</div>
<p>The maximum occurs at <span class="math notranslate nohighlight">\(\mathbf{x} = \mathbf{0}\)</span>, giving <span class="math notranslate nohighlight">\(M = \sigma^d\)</span>. For <span class="math notranslate nohighlight">\(\sigma = 1.5\)</span> and <span class="math notranslate nohighlight">\(d = 20\)</span>, this is <span class="math notranslate nohighlight">\(1.5^{20} \approx 3,300\)</span>‚Äîa 0.03% acceptance rate!</p>
</section>
<section id="when-rejection-sampling-fails">
<h3>When Rejection Sampling Fails<a class="headerlink" href="#when-rejection-sampling-fails" title="Link to this heading">ÔÉÅ</a></h3>
<p>Rejection sampling becomes impractical when:</p>
<ol class="arabic simple">
<li><p><strong>High dimensions</strong>: The curse of dimensionality makes finding a tight envelope nearly impossible.</p></li>
<li><p><strong>Multimodal targets</strong>: A single proposal struggles to cover well-separated modes without huge <span class="math notranslate nohighlight">\(M\)</span>.</p></li>
<li><p><strong>Heavy tails with light-tailed proposals</strong>: If <span class="math notranslate nohighlight">\(f(x)/g(x) \to \infty\)</span> as <span class="math notranslate nohighlight">\(|x| \to \infty\)</span>, no finite <span class="math notranslate nohighlight">\(M\)</span> exists.</p></li>
<li><p><strong>Unknown mode location</strong>: Without knowing where the target is concentrated, any proposal is a guess.</p></li>
</ol>
<p><strong>Practical guideline</strong>: Rejection sampling works well for <span class="math notranslate nohighlight">\(d \le 5\)</span> or so. For higher dimensions, consider Markov Chain Monte Carlo (Metropolis-Hastings, Gibbs sampling) which we develop in later chapters.</p>
</section>
</section>
<section id="connections-to-other-methods">
<h2>Connections to Other Methods<a class="headerlink" href="#connections-to-other-methods" title="Link to this heading">ÔÉÅ</a></h2>
<p>Rejection sampling is the ancestor of several more sophisticated techniques.</p>
<section id="importance-sampling">
<h3>Importance Sampling<a class="headerlink" href="#importance-sampling" title="Link to this heading">ÔÉÅ</a></h3>
<p>Where rejection sampling discards proposals that don‚Äôt pass the acceptance test, <strong>importance sampling</strong> keeps all proposals but assigns them weights:</p>
<div class="math notranslate nohighlight">
\[w(x) = \frac{f(x)}{g(x)}\]</div>
<p>Expectations are then computed as weighted averages. Importance sampling avoids discarding samples but requires careful handling of weight variability. We develop this in detail in <span class="xref std std-ref">ch2.6-variance-reduction</span>.</p>
</section>
<section id="markov-chain-monte-carlo">
<h3>Markov Chain Monte Carlo<a class="headerlink" href="#markov-chain-monte-carlo" title="Link to this heading">ÔÉÅ</a></h3>
<p>The Metropolis-Hastings algorithm generalizes rejection sampling to create a Markov chain whose stationary distribution is the target. Instead of independent proposals, it uses sequential proposals from a transition kernel. Rejected proposals don‚Äôt disappear‚Äîthe chain stays at its current position. This modification allows MCMC to work efficiently in high dimensions where direct rejection sampling fails. See Chapter 5 for full development.</p>
</section>
<section id="adaptive-rejection-sampling">
<h3>Adaptive Rejection Sampling<a class="headerlink" href="#adaptive-rejection-sampling" title="Link to this heading">ÔÉÅ</a></h3>
<p>For <strong>log-concave</strong> densities (densities <span class="math notranslate nohighlight">\(f(x)\)</span> where <span class="math notranslate nohighlight">\(\log f(x)\)</span> is concave), the ARS algorithm of Gilks and Wild (1992) constructs an envelope <em>adaptively</em> during sampling. The key insight is that tangent lines to a concave function lie above the function, while secant lines lie below.</p>
<p><strong>Log-concave examples</strong>: Many important distributions are log-concave:</p>
<ul class="simple">
<li><p>Normal: <span class="math notranslate nohighlight">\(\log \phi(x) \propto -x^2/2\)</span> (concave parabola)</p></li>
<li><p>Exponential: <span class="math notranslate nohighlight">\(\log(\lambda e^{-\lambda x}) \propto -\lambda x\)</span> (linear, hence concave)</p></li>
<li><p>Gamma with <span class="math notranslate nohighlight">\(\alpha \ge 1\)</span>: <span class="math notranslate nohighlight">\(\log f(x) \propto (\alpha-1)\log x - x\)</span> (concave for <span class="math notranslate nohighlight">\(\alpha \ge 1\)</span>)</p></li>
<li><p>Beta with <span class="math notranslate nohighlight">\(\alpha, \beta \ge 1\)</span>: log-concave on <span class="math notranslate nohighlight">\((0, 1)\)</span></p></li>
<li><p>Logistic, log-normal truncated appropriately</p></li>
</ul>
<p><strong>The ARS algorithm</strong>:</p>
<ol class="arabic simple">
<li><p>Initialize with a few points <span class="math notranslate nohighlight">\(S_n = \{x_0, x_1, \ldots, x_n\}\)</span> where <span class="math notranslate nohighlight">\(\log f(x_i)\)</span> is known.</p></li>
<li><p>Construct <strong>upper envelope</strong> <span class="math notranslate nohighlight">\(\bar{h}_n(x)\)</span>: piecewise linear, connecting tangent lines at <span class="math notranslate nohighlight">\(x_i\)</span>. By concavity, this lies above <span class="math notranslate nohighlight">\(\log f(x)\)</span>.</p></li>
<li><p>Construct <strong>lower envelope</strong> <span class="math notranslate nohighlight">\(\underline{h}_n(x)\)</span>: piecewise linear through <span class="math notranslate nohighlight">\((x_i, \log f(x_i))\)</span>. By concavity, this lies below <span class="math notranslate nohighlight">\(\log f(x)\)</span>.</p></li>
<li><p>Sample from <span class="math notranslate nohighlight">\(g_n(x) \propto \exp(\bar{h}_n(x))\)</span> (piecewise exponential, easy to sample).</p></li>
<li><p><strong>Squeeze test</strong>: If <span class="math notranslate nohighlight">\(U \le \exp(\underline{h}_n(X) - \bar{h}_n(X))\)</span>, accept immediately.</p></li>
<li><p><strong>Full test</strong>: Otherwise, evaluate <span class="math notranslate nohighlight">\(f(X)\)</span> and accept if <span class="math notranslate nohighlight">\(U \le f(X)/g_n(X)\)</span>.</p></li>
<li><p><strong>Adapt</strong>: If rejected (or if <span class="math notranslate nohighlight">\(f(X)\)</span> was evaluated), add <span class="math notranslate nohighlight">\(X\)</span> to <span class="math notranslate nohighlight">\(S_n\)</span>, tightening future envelopes.</p></li>
</ol>
<p>The adaptive nature means efficiency improves as sampling progresses‚Äîearly rejections contribute information that speeds later sampling. ARS is particularly valuable within Gibbs samplers where full conditionals are often log-concave.</p>
<p><strong>Limitation</strong>: ARS requires log-concavity. For non-log-concave targets (e.g., mixture distributions, heavy-tailed posteriors), the algorithm fails. The ARMS extension (Adaptive Rejection Metropolis Sampling) handles non-log-concave targets by adding a Metropolis-Hastings correction step.</p>
</section>
</section>
<section id="practical-considerations">
<h2>Practical Considerations<a class="headerlink" href="#practical-considerations" title="Link to this heading">ÔÉÅ</a></h2>
<section id="numerical-stability">
<h3>Numerical Stability<a class="headerlink" href="#numerical-stability" title="Link to this heading">ÔÉÅ</a></h3>
<p>Several numerical issues can arise:</p>
<ol class="arabic simple">
<li><p><strong>Underflow in density ratios</strong>: When <span class="math notranslate nohighlight">\(f(x)\)</span> is very small, <span class="math notranslate nohighlight">\(f(x)/[M \cdot g(x)]\)</span> may underflow to zero. Work with log-densities: accept if <span class="math notranslate nohighlight">\(\log U \le \log f(x) - \log M - \log g(x)\)</span>.</p></li>
<li><p><strong>Overflow in unnormalized densities</strong>: Large exponents can overflow. Again, log-densities help.</p></li>
<li><p><strong>Zero proposal density</strong>: If <span class="math notranslate nohighlight">\(g(x) = 0\)</span> at a point where <span class="math notranslate nohighlight">\(f(x) &gt; 0\)</span>, the ratio is undefined. Ensure proposal support covers target support.</p></li>
</ol>
<p><strong>Log-space implementation</strong> for numerical stability:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">rejection_sample_log</span><span class="p">(</span><span class="n">log_target</span><span class="p">,</span> <span class="n">log_proposal</span><span class="p">,</span> <span class="n">proposal_sampler</span><span class="p">,</span>
                         <span class="n">log_M</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rejection sampling using log-densities for numerical stability.</span>

<span class="sd">    Accept if log(U) &lt;= log_target(x) - log_M - log_proposal(x)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">proposal_sampler</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">log_u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>  <span class="c1"># log(U) where U ~ Uniform(0,1)</span>

        <span class="n">log_accept_prob</span> <span class="o">=</span> <span class="n">log_target</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_M</span> <span class="o">-</span> <span class="n">log_proposal</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">log_u</span> <span class="o">&lt;=</span> <span class="n">log_accept_prob</span><span class="p">:</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<p>This approach handles densities that would otherwise cause overflow or underflow in direct computation.</p>
</section>
<section id="verifying-correctness">
<h3>Verifying Correctness<a class="headerlink" href="#verifying-correctness" title="Link to this heading">ÔÉÅ</a></h3>
<p>Always verify your rejection sampler:</p>
<ol class="arabic simple">
<li><p><strong>Check acceptance rate</strong>: Compare actual rate to theoretical <span class="math notranslate nohighlight">\(1/M\)</span>.</p></li>
<li><p><strong>Compare moments</strong>: Sample mean and variance should match theoretical values.</p></li>
<li><p><strong>Visual comparison</strong>: Histogram of samples should match theoretical density.</p></li>
<li><p><strong>Kolmogorov-Smirnov test</strong>: Statistical test for distribution match.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">verify_rejection_sampler</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">true_dist</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify rejection samples against known distribution.&quot;&quot;&quot;</span>
    <span class="c1"># Moments</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> verification:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample mean: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Theory: </span><span class="si">{</span><span class="n">true_dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sample std:  </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Theory: </span><span class="si">{</span><span class="n">true_dist</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># KS test</span>
    <span class="n">ks_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">true_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  KS statistic: </span><span class="si">{</span><span class="n">ks_stat</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  WARNING: KS test suggests samples may not match target!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="production-diagnostics">
<h3>Production Diagnostics<a class="headerlink" href="#production-diagnostics" title="Link to this heading">ÔÉÅ</a></h3>
<p>For production use, a sampler with built-in monitoring helps detect issues:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RejectionSamplerWithDiagnostics</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Rejection sampler with performance monitoring.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_pdf</span><span class="p">,</span> <span class="n">proposal_sampler</span><span class="p">,</span> <span class="n">proposal_pdf</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_pdf</span> <span class="o">=</span> <span class="n">target_pdf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proposal_sampler</span> <span class="o">=</span> <span class="n">proposal_sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proposal_pdf</span> <span class="o">=</span> <span class="n">proposal_pdf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="n">M</span>

        <span class="c1"># Diagnostics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_proposed</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_accepted</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acceptance_history</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample with batch monitoring.&quot;&quot;&quot;</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">:</span>
            <span class="n">batch_accepted</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">+</span> <span class="mi">100</span><span class="p">)):</span>
                <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proposal_sampler</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_proposed</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="n">u</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
                <span class="n">accept_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_pdf</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">proposal_pdf</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

                <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;=</span> <span class="n">accept_prob</span><span class="p">:</span>
                    <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n_accepted</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">batch_accepted</span> <span class="o">+=</span> <span class="mi">1</span>

                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">size</span><span class="p">:</span>
                        <span class="k">break</span>

            <span class="c1"># Record batch acceptance rate</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">acceptance_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_accepted</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">[:</span><span class="n">size</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_diagnostics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return sampling diagnostics.&quot;&quot;&quot;</span>
        <span class="n">actual_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_accepted</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_proposed</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_proposed</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;n_proposed&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_proposed</span><span class="p">,</span>
            <span class="s1">&#39;n_accepted&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_accepted</span><span class="p">,</span>
            <span class="s1">&#39;actual_acceptance_rate&#39;</span><span class="p">:</span> <span class="n">actual_rate</span><span class="p">,</span>
            <span class="s1">&#39;theoretical_rate&#39;</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">,</span>
            <span class="s1">&#39;efficiency&#39;</span><span class="p">:</span> <span class="n">actual_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">,</span>  <span class="c1"># Should be ‚âà 1</span>
            <span class="s1">&#39;acceptance_history&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">acceptance_history</span>
        <span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">efficiency</span></code> metric should be close to 1.0; significant deviations indicate either an incorrect <span class="math notranslate nohighlight">\(M\)</span> or implementation bugs.</p>
<div class="tip admonition">
<p class="admonition-title">Try It Yourself üñ•Ô∏è</p>
<p><strong>Exercise 1: Semicircle Distribution</strong></p>
<p>The semicircle distribution has density <span class="math notranslate nohighlight">\(f(x) = \frac{2}{\pi}\sqrt{1 - x^2}\)</span> for <span class="math notranslate nohighlight">\(x \in [-1, 1]\)</span>. Implement rejection sampling with a uniform proposal. What is the theoretical acceptance rate? Verify your implementation by comparing sample moments to the theoretical mean (0) and variance (<span class="math notranslate nohighlight">\(1/4\)</span>).</p>
<p><strong>Exercise 2: Optimal Proposal for Gamma</strong></p>
<p>For <span class="math notranslate nohighlight">\(\text{Gamma}(\alpha, 1)\)</span> with <span class="math notranslate nohighlight">\(\alpha = 0.5\)</span>, try both (a) an exponential proposal and (b) a Weibull proposal. Which achieves a higher acceptance rate? Hint: For small <span class="math notranslate nohighlight">\(\alpha\)</span>, the Gamma density has a singularity at 0.</p>
<p><strong>Exercise 3: Bivariate Rejection</strong></p>
<p>Implement rejection sampling for the bivariate distribution with density proportional to <span class="math notranslate nohighlight">\(\exp(-(x^2 + y^2 + xy))\)</span> using a bivariate normal proposal. Estimate <span class="math notranslate nohighlight">\(M\)</span> numerically and compare theoretical vs. actual acceptance rates.</p>
<p><strong>Exercise 4: Envelope Violation Detection</strong></p>
<p>Write a diagnostic function that detects when <span class="math notranslate nohighlight">\(M\)</span> is too small (envelope violation). The function should sample points and flag any where <span class="math notranslate nohighlight">\(f(x) &gt; M \cdot g(x)\)</span>. Test it on Beta(0.5, 0.5) with a uniform proposal and varying <span class="math notranslate nohighlight">\(M\)</span>.</p>
<p><strong>Exercise 5: von Mises (Circular Normal) Distribution</strong></p>
<p>The von Mises distribution has PDF <span class="math notranslate nohighlight">\(f(\theta) = \frac{e^{\kappa \cos(\theta - \mu)}}{2\pi I_0(\kappa)}\)</span> for <span class="math notranslate nohighlight">\(\theta \in [0, 2\pi)\)</span>, where <span class="math notranslate nohighlight">\(I_0\)</span> is the modified Bessel function. Implement rejection sampling using a Uniform <span class="math notranslate nohighlight">\([0, 2\pi)\)</span> proposal. Plot acceptance rate as a function of concentration parameter <span class="math notranslate nohighlight">\(\kappa\)</span> for <span class="math notranslate nohighlight">\(\kappa \in \{0.5, 1, 2, 5, 10\}\)</span>. Why does efficiency degrade as <span class="math notranslate nohighlight">\(\kappa\)</span> increases?</p>
</div>
</section>
</section>
<section id="bringing-it-all-together">
<h2>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading">ÔÉÅ</a></h2>
<p>Rejection sampling provides a universal method for generating random samples from any distribution whose density we can evaluate pointwise. The key insights are:</p>
<ol class="arabic simple">
<li><p><strong>Geometric foundation</strong>: Points uniformly distributed under a density curve have <span class="math notranslate nohighlight">\(x\)</span>-coordinates following that density. Rejection sampling implements this by filtering proposals.</p></li>
<li><p><strong>Envelope requirement</strong>: We need <span class="math notranslate nohighlight">\(f(x) \le M \cdot g(x)\)</span> everywhere. The constant <span class="math notranslate nohighlight">\(M\)</span> determines efficiency through acceptance rate <span class="math notranslate nohighlight">\(1/M\)</span>.</p></li>
<li><p><strong>Normalization not required</strong>: The algorithm works even when <span class="math notranslate nohighlight">\(f(x)\)</span> is known only up to a constant‚Äîessential for Bayesian posterior sampling.</p></li>
<li><p><strong>Proposal design matters</strong>: Good proposals have similar shape to the target. Tail behavior is critical: light-tailed proposals for heavy-tailed targets fail.</p></li>
<li><p><strong>Dimensional limitations</strong>: Acceptance rates degrade exponentially with dimension. For <span class="math notranslate nohighlight">\(d \gtrsim 5\)</span>, consider MCMC alternatives.</p></li>
<li><p><strong>Foundation for advanced methods</strong>: Rejection sampling‚Äôs ideas appear in importance sampling, Metropolis-Hastings, and adaptive rejection sampling.</p></li>
</ol>
<section id="looking-ahead">
<h3>Looking Ahead<a class="headerlink" href="#looking-ahead" title="Link to this heading">ÔÉÅ</a></h3>
<p>The next section introduces <strong>variance reduction techniques</strong> that improve Monte Carlo efficiency. Some, like importance sampling, can be viewed as alternatives to rejection sampling that use all proposals rather than discarding rejects. Others, like antithetic variates and control variates, reduce estimator variance through clever correlation structures.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaways üìù</p>
<ol class="arabic simple">
<li><p><strong>The algorithm</strong>: Propose from <span class="math notranslate nohighlight">\(g(x)\)</span>, accept with probability <span class="math notranslate nohighlight">\(f(x)/[M \cdot g(x)]\)</span>. Accepted samples are exact draws from <span class="math notranslate nohighlight">\(f\)</span>.</p></li>
<li><p><strong>Envelope condition</strong>: Must have <span class="math notranslate nohighlight">\(f(x) \le M \cdot g(x)\)</span> for all <span class="math notranslate nohighlight">\(x\)</span>. Violation produces biased samples‚Äîa silent error.</p></li>
<li><p><strong>Efficiency = 1/M</strong>: Expected proposals per accepted sample equals <span class="math notranslate nohighlight">\(M\)</span>. Tight envelopes (small <span class="math notranslate nohighlight">\(M\)</span>) are crucial for efficiency.</p></li>
<li><p><strong>Normalization not needed</strong>: The algorithm works for unnormalized densities‚Äîessential for Bayesian inference where <span class="math notranslate nohighlight">\(p(\theta|x) \propto p(x|\theta)p(\theta)\)</span>.</p></li>
<li><p><strong>Proposal design</strong>: Match proposal tails to target tails. Support of <span class="math notranslate nohighlight">\(g\)</span> must cover support of <span class="math notranslate nohighlight">\(f\)</span>. For bounded support, uniform proposals often suffice.</p></li>
<li><p><strong>Curse of dimensionality</strong>: Acceptance rates degrade exponentially with dimension. Practical limit is roughly <span class="math notranslate nohighlight">\(d \le 5\)</span>.</p></li>
<li><p><strong>Outcome alignment</strong>: Rejection sampling (Learning Outcome 1) enables exact sampling from complex distributions. Understanding its limitations motivates MCMC methods developed later in the course.</p></li>
</ol>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>