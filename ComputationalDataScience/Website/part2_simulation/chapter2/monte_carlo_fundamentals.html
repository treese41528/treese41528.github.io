

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Monte Carlo Fundamentals &mdash; STAT 418</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=6826d573" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT418/Website/part2_simulation/chapter2/monte_carlo_fundamentals.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=d2113767"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Course Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../part1_foundations/index.html">1. Part I: Foundations of Probability and Computation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part1_foundations/chapter1/index.html">1.1. Chapter 1: Statistical Paradigms and Core Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html">1.1.1. Paradigms of Probability and Statistical Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#the-mathematical-foundation-kolmogorov-s-axioms">The Mathematical Foundation: Kolmogorov‚Äôs Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#interpretations-of-probability">Interpretations of Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#statistical-inference-paradigms">Statistical Inference Paradigms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#historical-and-philosophical-debates">Historical and Philosophical Debates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#looking-ahead-our-course-focus">Looking Ahead: Our Course Focus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html">1.1.2. Probability Distributions: Theory and Computation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#from-abstract-foundations-to-concrete-tools">From Abstract Foundations to Concrete Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#the-python-ecosystem-for-probability">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#introduction-why-probability-distributions-matter">Introduction: Why Probability Distributions Matter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#id1">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#continuous-distributions">Continuous Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#additional-important-distributions">Additional Important Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#summary-and-practical-guidelines">Summary and Practical Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html">1.1.3. Python Random Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#from-mathematical-distributions-to-computational-samples">From Mathematical Distributions to Computational Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#the-python-ecosystem-at-a-glance">The Python Ecosystem at a Glance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#understanding-pseudo-random-number-generation">Understanding Pseudo-Random Number Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#the-standard-library-random-module">The Standard Library: <code class="docutils literal notranslate"><span class="pre">random</span></code> Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#numpy-fast-vectorized-random-sampling">NumPy: Fast Vectorized Random Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#scipy-stats-the-complete-statistical-toolkit">SciPy Stats: The Complete Statistical Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#bringing-it-all-together-library-selection-guide">Bringing It All Together: Library Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#looking-ahead-from-random-numbers-to-monte-carlo-methods">Looking Ahead: From Random Numbers to Monte Carlo Methods</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Part II: Simulation-Based Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html">1. Chapter 2: Monte Carlo Simulation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html">1.1. Monte Carlo Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#the-historical-development-of-monte-carlo-methods">1.1.1. The Historical Development of Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#the-core-principle-expectation-as-integration">1.1.2. The Core Principle: Expectation as Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#theoretical-foundations">1.1.3. Theoretical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#variance-estimation-and-confidence-intervals">1.1.4. Variance Estimation and Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#worked-examples">1.1.5. Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#comparison-with-deterministic-methods">1.1.6. Comparison with Deterministic Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#sample-size-determination">1.1.7. Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#convergence-diagnostics-and-monitoring">1.1.8. Convergence Diagnostics and Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#practical-considerations">1.1.9. Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#bringing-it-all-together">1.1.10. Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#transition-to-what-follows">1.1.11. Transition to What Follows</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2.2-uniform-random-variates.html">1.2. Uniform Random Variates</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#the-probability-integral-transform">1.2.1. The Probability Integral Transform</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#the-paradox-of-computational-randomness">1.2.2. The Paradox of Computational Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#chaotic-dynamical-systems-an-instructive-failure">1.2.3. Chaotic Dynamical Systems: An Instructive Failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#linear-congruential-generators">1.2.4. Linear Congruential Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#shift-register-generators">1.2.5. Shift-Register Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#the-kiss-generator-combining-strategies">1.2.6. The KISS Generator: Combining Strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#modern-generators-mersenne-twister-and-pcg">1.2.7. Modern Generators: Mersenne Twister and PCG</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#statistical-testing-of-random-number-generators">1.2.8. Statistical Testing of Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#practical-considerations">1.2.9. Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#bringing-it-all-together">1.2.10. Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.2-uniform-random-variates.html#transition-to-what-follows">1.2.11. Transition to What Follows</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2.3-inverse-cdf-method.html">1.3. Inverse CDF Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#mathematical-foundations">1.3.1. Mathematical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#continuous-distributions-with-closed-form-inverses">1.3.2. Continuous Distributions with Closed-Form Inverses</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#numerical-inversion">1.3.3. Numerical Inversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#discrete-distributions">1.3.4. Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#mixed-distributions">1.3.5. Mixed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#practical-considerations">1.3.6. Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#bringing-it-all-together">1.3.7. Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#transition-to-what-follows">1.3.8. Transition to What Follows</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../chapter3/index.html">2. Chapter 3: Frequentist Statistical Inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/sampling_variability.html">2.1. Sampling Variability</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#introduction">2.1.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#key-concepts">2.1.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#mathematical-framework">2.1.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#python-implementation">2.1.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#examples">2.1.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#summary">2.1.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/statistical_estimators.html">2.2. Statistical Estimators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#introduction">2.2.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#key-concepts">2.2.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#mathematical-framework">2.2.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#python-implementation">2.2.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#examples">2.2.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#summary">2.2.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/plugin_methods.html">2.3. Plugin Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#introduction">2.3.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#key-concepts">2.3.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#mathematical-framework">2.3.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#python-implementation">2.3.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#examples">2.3.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#summary">2.3.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/parametric_inference.html">2.4. Parametric Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#introduction">2.4.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#key-concepts">2.4.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#mathematical-framework">2.4.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#python-implementation">2.4.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#examples">2.4.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#summary">2.4.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/exponential_families.html">2.5. Exponential Families</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#introduction">2.5.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#key-concepts">2.5.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#mathematical-framework">2.5.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#python-implementation">2.5.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#examples">2.5.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#summary">2.5.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/maximum_likelihood.html">2.6. Maximum Likelihood</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#introduction">2.6.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#key-concepts">2.6.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#mathematical-framework">2.6.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#python-implementation">2.6.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#examples">2.6.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#summary">2.6.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/linear_models.html">2.7. Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#introduction">2.7.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#key-concepts">2.7.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#mathematical-framework">2.7.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#python-implementation">2.7.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#examples">2.7.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#summary">2.7.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/generalized_linear_models.html">2.8. Generalized Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#introduction">2.8.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#key-concepts">2.8.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#mathematical-framework">2.8.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#python-implementation">2.8.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#examples">2.8.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#summary">2.8.6. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../chapter4/index.html">3. Chapter 4: Resampling Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/jackknife_introduction.html">3.1. Jackknife Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#introduction">3.1.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#key-concepts">3.1.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#mathematical-framework">3.1.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#python-implementation">3.1.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#examples">3.1.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#summary">3.1.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html">3.2. Bootstrap Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#introduction">3.2.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#key-concepts">3.2.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#mathematical-framework">3.2.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#python-implementation">3.2.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#examples">3.2.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#summary">3.2.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html">3.3. Nonparametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#introduction">3.3.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#key-concepts">3.3.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#mathematical-framework">3.3.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#python-implementation">3.3.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#examples">3.3.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#summary">3.3.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/parametric_bootstrap.html">3.4. Parametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#introduction">3.4.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#key-concepts">3.4.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#mathematical-framework">3.4.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#python-implementation">3.4.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#examples">3.4.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#summary">3.4.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/confidence_intervals.html">3.5. Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#introduction">3.5.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#key-concepts">3.5.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#mathematical-framework">3.5.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#python-implementation">3.5.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#examples">3.5.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#summary">3.5.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/bias_correction.html">3.6. Bias Correction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#introduction">3.6.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#key-concepts">3.6.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#mathematical-framework">3.6.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#python-implementation">3.6.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#examples">3.6.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#summary">3.6.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/cross_validation_loo.html">3.7. Cross Validation Loo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#introduction">3.7.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#key-concepts">3.7.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#mathematical-framework">3.7.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#python-implementation">3.7.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#examples">3.7.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#summary">3.7.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html">3.8. Cross Validation K Fold</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#introduction">3.8.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#key-concepts">3.8.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#mathematical-framework">3.8.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#python-implementation">3.8.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#examples">3.8.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#summary">3.8.6. Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/model_selection.html">3.9. Model Selection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#introduction">3.9.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#key-concepts">3.9.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#mathematical-framework">3.9.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#python-implementation">3.9.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#examples">3.9.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#summary">3.9.6. Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part3_bayesian/index.html">Part III: Bayesian Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part3_bayesian/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html">1. Bayesian Philosophy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#introduction">1.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#key-concepts">1.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#mathematical-framework">1.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#python-implementation">1.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#examples">1.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#summary">1.6. Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Monte Carlo Fundamentals</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/part2_simulation/chapter2/monte_carlo_fundamentals.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="monte-carlo-fundamentals">
<span id="id1"></span><h1>Monte Carlo Fundamentals<a class="headerlink" href="#monte-carlo-fundamentals" title="Link to this heading">ÔÉÅ</a></h1>
<p>Monte Carlo methods transform intractable analytical problems into computational experiments, using randomness as a fundamental tool for numerical calculation. Named after the famous casino in Monaco, these methods leverage the law of large numbers to solve problems ranging from multidimensional integration to optimization, revolutionizing fields from physics to finance.</p>
<p>At their core, Monte Carlo methods represent quantities of interest as expectations with respect to probability distributions, then approximate these expectations through repeated random sampling. This probabilistic approach often succeeds where deterministic methods fail, particularly in high-dimensional spaces where the curse of dimensionality renders traditional numerical methods impractical.</p>
<div class="important admonition">
<p class="admonition-title">Road Map üß≠</p>
<ul class="simple">
<li><p><strong>Understand</strong> the mathematical foundations of Monte Carlo methods and their convergence properties</p></li>
<li><p><strong>Master</strong> the fundamental Monte Carlo estimator and its statistical properties</p></li>
<li><p><strong>Apply</strong> Monte Carlo integration to compute probabilities and expectations</p></li>
<li><p><strong>Analyze</strong> convergence rates and error bounds using the Central Limit Theorem</p></li>
</ul>
</div>
<section id="what-are-monte-carlo-methods">
<h2>What Are Monte Carlo Methods?<a class="headerlink" href="#what-are-monte-carlo-methods" title="Link to this heading">ÔÉÅ</a></h2>
<p>A Monte Carlo method is any computational technique that uses random sampling to solve mathematical problems that might be deterministic in nature.</p>
<section id="formal-definition">
<h3>Formal Definition<a class="headerlink" href="#formal-definition" title="Link to this heading">ÔÉÅ</a></h3>
<p><strong>Definition</strong>: A Monte Carlo method is any computational technique that represents a quantity of interest as an expectation with respect to a specified probability law and then approximates that quantity using repeated pseudo-random draws from that law, with guarantees supplied by probabilistic limit theorems.</p>
<p>Mathematically, if the quantity of interest can be expressed as:</p>
<div class="math notranslate nohighlight">
\[I = E[h(X)] = \int h(x) f_X(x) dx\]</div>
<p>where f_X is a probability density, then a Monte Carlo estimator with n samples x_1, x_2, ‚Ä¶, x_n drawn i.i.d. from F_X is:</p>
<div class="math notranslate nohighlight">
\[\hat{I}_n = \frac{1}{n} \sum_{i=1}^{n} h(x_i)\]</div>
<p><strong>Convergence</strong>: By the Strong Law of Large Numbers:</p>
<div class="math notranslate nohighlight">
\[\hat{I}_n \xrightarrow{a.s.} I \quad \text{as } n \to \infty\]</div>
<p><strong>Error Analysis</strong>: By the Central Limit Theorem, if Var[h(X)] &lt; ‚àû:</p>
<div class="math notranslate nohighlight">
\[\sqrt{n}(\hat{I}_n - I) \xrightarrow{d} N(0, \sigma^2)\]</div>
<p>where œÉ¬≤ = Var[h(X)].</p>
</section>
<section id="python-implementation">
<h3>Python Implementation<a class="headerlink" href="#python-implementation" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MonteCarloEstimator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generic Monte Carlo estimator with convergence diagnostics.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h_func</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">true_value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        h_func : callable</span>
<span class="sd">            Function h in E[h(X)]</span>
<span class="sd">        sampler : callable</span>
<span class="sd">            Function that returns samples from distribution of X</span>
<span class="sd">        true_value : float, optional</span>
<span class="sd">            True value of E[h(X)] if known</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">h_func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">sampler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">true_value</span> <span class="o">=</span> <span class="n">true_value</span>

        <span class="c1"># Storage for convergence analysis</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std_errors</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">estimate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute Monte Carlo estimate with batch updates.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples : int</span>
<span class="sd">            Total number of samples</span>
<span class="sd">        batch_size : int</span>
<span class="sd">            Size of batches for updating estimates</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        estimate : float</span>
<span class="sd">            Final Monte Carlo estimate</span>
<span class="sd">        std_error : float</span>
<span class="sd">            Standard error of estimate</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_batches</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="n">batch_size</span>
        <span class="n">current_sum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">current_sum_sq</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">):</span>
            <span class="c1"># Generate batch of samples</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)])</span>
            <span class="n">h_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">])</span>

            <span class="c1"># Update running sums</span>
            <span class="n">current_sum</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">h_values</span><span class="p">)</span>
            <span class="n">current_sum_sq</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">h_values</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

            <span class="c1"># Current estimates</span>
            <span class="n">n_current</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span>
            <span class="n">current_mean</span> <span class="o">=</span> <span class="n">current_sum</span> <span class="o">/</span> <span class="n">n_current</span>
            <span class="n">current_var</span> <span class="o">=</span> <span class="p">(</span><span class="n">current_sum_sq</span> <span class="o">/</span> <span class="n">n_current</span><span class="p">)</span> <span class="o">-</span> <span class="n">current_mean</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">current_se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">current_var</span> <span class="o">/</span> <span class="n">n_current</span><span class="p">)</span>

            <span class="c1"># Store for convergence analysis</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">estimates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_mean</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_current</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">std_errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_se</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">current_mean</span><span class="p">,</span> <span class="n">current_se</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">plot_convergence</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Visualize convergence of Monte Carlo estimates.&quot;&quot;&quot;</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

        <span class="c1"># Left: Estimate vs sample size</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimates</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">true_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">true_value</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span>
                           <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True value&#39;</span><span class="p">)</span>

        <span class="c1"># Add confidence bands</span>
        <span class="n">estimates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimates</span><span class="p">)</span>
        <span class="n">std_errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">std_errors</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">,</span>
                             <span class="n">estimates</span> <span class="o">-</span> <span class="mf">1.96</span><span class="o">*</span><span class="n">std_errors</span><span class="p">,</span>
                             <span class="n">estimates</span> <span class="o">+</span> <span class="mf">1.96</span><span class="o">*</span><span class="n">std_errors</span><span class="p">,</span>
                             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;95% CI&#39;</span><span class="p">)</span>

        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of samples&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Estimate&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Monte Carlo Convergence&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

        <span class="c1"># Right: Standard error vs sample size</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">,</span> <span class="n">std_errors</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

        <span class="c1"># Theoretical 1/‚àön rate</span>
        <span class="n">n_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_sizes</span><span class="p">)</span>
        <span class="n">theoretical_se</span> <span class="o">=</span> <span class="n">std_errors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_array</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">n_array</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">n_array</span><span class="p">,</span> <span class="n">theoretical_se</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span>
                      <span class="n">label</span><span class="o">=</span><span class="s1">&#39;1/‚àön rate&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of samples&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Standard error&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Standard Error Decay&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="historical-context">
<h3>Historical Context<a class="headerlink" href="#historical-context" title="Link to this heading">ÔÉÅ</a></h3>
<p>Monte Carlo methods emerged from the Manhattan Project in the 1940s, where Stanislaw Ulam, John von Neumann, and Nicholas Metropolis developed these techniques to study neutron diffusion. The evolution includes:</p>
<ul class="simple">
<li><p><strong>1777</strong>: Buffon‚Äôs Needle - earliest documented use of randomness for œÄ estimation</p></li>
<li><p><strong>1940s</strong>: Modern Monte Carlo born at Los Alamos</p></li>
<li><p><strong>1953</strong>: Metropolis Algorithm - foundation of MCMC</p></li>
<li><p><strong>1970s</strong>: Development of variance reduction techniques</p></li>
<li><p><strong>1990s</strong>: Sequential Monte Carlo (particle filters)</p></li>
<li><p><strong>2000s</strong>: Quantum Monte Carlo advances</p></li>
<li><p><strong>2020s</strong>: Neural network-enhanced Monte Carlo methods</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title">Example üí°: Buffon‚Äôs Needle Problem</p>
<p><strong>Given</strong>: Parallel lines distance d apart, needle of length l &lt; d</p>
<p><strong>Find</strong>: Probability needle crosses a line when dropped randomly</p>
<p><strong>Solution</strong>:</p>
<p>Mathematical analysis yields:</p>
<div class="math notranslate nohighlight">
\[P(\text{crosses}) = \frac{2l}{\pi d}\]</div>
<p>Monte Carlo simulation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">buffon_needle_simulation</span><span class="p">(</span><span class="n">l</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">n_drops</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate œÄ using Buffon&#39;s needle.&quot;&quot;&quot;</span>
    <span class="n">crosses</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_drops</span><span class="p">):</span>
        <span class="c1"># Random position of needle center</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Random angle of needle</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>

        <span class="c1"># Check if needle crosses line</span>
        <span class="k">if</span> <span class="n">y</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="n">l</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
            <span class="n">crosses</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># Estimate œÄ from crossing probability</span>
    <span class="n">p_cross</span> <span class="o">=</span> <span class="n">crosses</span> <span class="o">/</span> <span class="n">n_drops</span>
    <span class="n">pi_estimate</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">l</span> <span class="o">/</span> <span class="p">(</span><span class="n">d</span> <span class="o">*</span> <span class="n">p_cross</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_cross</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

    <span class="k">return</span> <span class="n">pi_estimate</span><span class="p">,</span> <span class="n">p_cross</span>

<span class="c1"># Run simulation</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">pi_est</span><span class="p">,</span> <span class="n">p_cross</span> <span class="o">=</span> <span class="n">buffon_needle_simulation</span><span class="p">(</span><span class="n">n_drops</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;œÄ estimate: </span><span class="si">{</span><span class="n">pi_est</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True œÄ: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="nb">abs</span><span class="p">(</span><span class="n">pi_est</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Result</strong>: Monte Carlo recovers œÄ ‚âà 3.14159 from purely geometric random experiments.</p>
</div>
</section>
</section>
<section id="computing-probabilities-as-expectations">
<h2>Computing Probabilities as Expectations<a class="headerlink" href="#computing-probabilities-as-expectations" title="Link to this heading">ÔÉÅ</a></h2>
<p>Any probability can be expressed as an expectation using indicator functions, making Monte Carlo methods universally applicable for probability estimation.</p>
<section id="indicator-function-approach">
<h3>Indicator Function Approach<a class="headerlink" href="#indicator-function-approach" title="Link to this heading">ÔÉÅ</a></h3>
<p>For any event A:</p>
<div class="math notranslate nohighlight">
\[P(A) = E[1_A(X)] = \int 1_A(x) f_X(x) dx\]</div>
<p>where 1_A is the indicator function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">monte_carlo_probability</span><span class="p">(</span><span class="n">event_func</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimate probability using Monte Carlo.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    event_func : callable</span>
<span class="sd">        Function that returns True if event occurs</span>
<span class="sd">    sampler : callable</span>
<span class="sd">        Function that generates samples from distribution</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        Number of Monte Carlo samples</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    p_estimate : float</span>
<span class="sd">        Estimated probability</span>
<span class="sd">    std_error : float</span>
<span class="sd">        Standard error of estimate</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">indicators</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">event_func</span><span class="p">(</span><span class="n">sampler</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)])</span>
    <span class="n">p_estimate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">indicators</span><span class="p">)</span>

    <span class="c1"># Standard error for Bernoulli</span>
    <span class="n">std_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p_estimate</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p_estimate</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_samples</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">p_estimate</span><span class="p">,</span> <span class="n">std_error</span>

<span class="c1"># Example: P(X + Y &gt; 1) where X, Y ~ Uniform(0, 1)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sampler_xy</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">event_sum_greater_one</span><span class="p">(</span><span class="n">xy</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span>

<span class="n">p_est</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">monte_carlo_probability</span><span class="p">(</span><span class="n">event_sum_greater_one</span><span class="p">,</span> <span class="n">sampler_xy</span><span class="p">,</span> <span class="mi">50000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(X + Y &gt; 1) ‚âà </span><span class="si">{</span><span class="n">p_est</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ¬± </span><span class="si">{</span><span class="mf">1.96</span><span class="o">*</span><span class="n">se</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True value: 0.5000&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="monte-carlo-integration">
<h2>Monte Carlo Integration<a class="headerlink" href="#monte-carlo-integration" title="Link to this heading">ÔÉÅ</a></h2>
<p>Monte Carlo integration excels where traditional quadrature fails: high dimensions and complex integration regions.</p>
<section id="basic-monte-carlo-integration">
<h3>Basic Monte Carlo Integration<a class="headerlink" href="#basic-monte-carlo-integration" title="Link to this heading">ÔÉÅ</a></h3>
<p>To compute:</p>
<div class="math notranslate nohighlight">
\[I = \int_a^b g(x) dx\]</div>
<p>we can write:</p>
<div class="math notranslate nohighlight">
\[I = (b - a) \int_a^b g(x) \frac{1}{b-a} dx = (b - a) \cdot E[g(U)]\]</div>
<p>where U ~ Uniform(a, b).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">monte_carlo_integrate</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Monte Carlo integration over [a, b].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : callable</span>
<span class="sd">        Function to integrate</span>
<span class="sd">    a, b : float</span>
<span class="sd">        Integration bounds</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        Number of samples</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    integral : float</span>
<span class="sd">        Estimated integral</span>
<span class="sd">    std_error : float</span>
<span class="sd">        Standard error</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Sample uniformly from [a, b]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>

    <span class="c1"># Evaluate function</span>
    <span class="n">g_values</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Monte Carlo estimate</span>
    <span class="n">integral</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">g_values</span><span class="p">)</span>

    <span class="c1"># Standard error</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">g_values</span><span class="p">)</span>
    <span class="n">std_error</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">/</span> <span class="n">n_samples</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">integral</span><span class="p">,</span> <span class="n">std_error</span>
</pre></div>
</div>
</section>
<section id="multidimensional-integration">
<h3>Multidimensional Integration<a class="headerlink" href="#multidimensional-integration" title="Link to this heading">ÔÉÅ</a></h3>
<p>Monte Carlo shines in high dimensions where the curse of dimensionality cripples deterministic methods.</p>
<p><strong>Key Insight</strong>: Monte Carlo error is O(1/‚àön) independent of dimension, while deterministic quadrature is O(n^(-k/d)) where k depends on smoothness and d is dimension.</p>
<div class="note admonition">
<p class="admonition-title">Example üí°: Volume of High-Dimensional Sphere</p>
<p><strong>Given</strong>: Unit sphere in d dimensions</p>
<p><strong>Find</strong>: Volume using Monte Carlo</p>
<p><strong>Solution</strong>:</p>
<p>The volume is the integral of the indicator function over the hypercube:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sphere_volume_monte_carlo</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate volume of unit sphere in d dimensions.&quot;&quot;&quot;</span>

    <span class="c1"># Generate points in [-1, 1]^d hypercube</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>

    <span class="c1"># Check which points are inside unit sphere</span>
    <span class="n">distances_squared</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">points</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">inside_sphere</span> <span class="o">=</span> <span class="n">distances_squared</span> <span class="o">&lt;=</span> <span class="mi">1</span>

    <span class="c1"># Volume = volume of hypercube √ó fraction inside</span>
    <span class="n">hypercube_volume</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="n">d</span>
    <span class="n">fraction_inside</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">inside_sphere</span><span class="p">)</span>
    <span class="n">volume_estimate</span> <span class="o">=</span> <span class="n">hypercube_volume</span> <span class="o">*</span> <span class="n">fraction_inside</span>

    <span class="c1"># Standard error</span>
    <span class="n">std_error</span> <span class="o">=</span> <span class="n">hypercube_volume</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="n">fraction_inside</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">fraction_inside</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_samples</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">volume_estimate</span><span class="p">,</span> <span class="n">std_error</span>

<span class="c1"># Compare with analytical formula</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.special</span><span class="w"> </span><span class="kn">import</span> <span class="n">gamma</span>

<span class="k">def</span><span class="w"> </span><span class="nf">true_sphere_volume</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">**</span><span class="p">(</span><span class="n">d</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">(</span><span class="n">d</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Test for various dimensions</span>
<span class="n">dimensions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dimensions</span><span class="p">:</span>
    <span class="n">est</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">sphere_volume_monte_carlo</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>
    <span class="n">true_val</span> <span class="o">=</span> <span class="n">true_sphere_volume</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">rel_error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">est</span> <span class="o">-</span> <span class="n">true_val</span><span class="p">)</span> <span class="o">/</span> <span class="n">true_val</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;d=</span><span class="si">{</span><span class="n">d</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Est=</span><span class="si">{</span><span class="n">est</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ¬± </span><span class="si">{</span><span class="n">se</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;True=</span><span class="si">{</span><span class="n">true_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, RelErr=</span><span class="si">{</span><span class="n">rel_error</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Result</strong>: Monte Carlo maintains similar relative error across dimensions, unlike grid-based methods.</p>
</div>
</section>
<section id="importance-sampling-integration">
<h3>Importance Sampling Integration<a class="headerlink" href="#importance-sampling-integration" title="Link to this heading">ÔÉÅ</a></h3>
<p>When the integrand has high variance, importance sampling can dramatically improve efficiency:</p>
<div class="math notranslate nohighlight">
\[I = \int g(x) dx = \int \frac{g(x)}{q(x)} q(x) dx = E_q\left[\frac{g(X)}{q(X)}\right]\]</div>
<p>where q is the importance distribution.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">importance_sampling_integrate</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">importance_sampler</span><span class="p">,</span> <span class="n">importance_pdf</span><span class="p">,</span>
                                 <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Monte Carlo integration using importance sampling.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    g : callable</span>
<span class="sd">        Function to integrate</span>
<span class="sd">    importance_sampler : callable</span>
<span class="sd">        Generates samples from importance distribution</span>
<span class="sd">    importance_pdf : callable</span>
<span class="sd">        PDF of importance distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">importance_sampler</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)])</span>

    <span class="c1"># Importance weights</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">importance_pdf</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

    <span class="c1"># Handle potential infinities/NaNs</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">weights</span><span class="p">)]</span>

    <span class="n">integral</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">std_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">integral</span><span class="p">,</span> <span class="n">std_error</span>
</pre></div>
</div>
</section>
</section>
<section id="variance-and-convergence-analysis">
<h2>Variance and Convergence Analysis<a class="headerlink" href="#variance-and-convergence-analysis" title="Link to this heading">ÔÉÅ</a></h2>
<p>Understanding the statistical properties of Monte Carlo estimators is crucial for practical applications.</p>
<section id="variance-of-monte-carlo-estimators">
<h3>Variance of Monte Carlo Estimators<a class="headerlink" href="#variance-of-monte-carlo-estimators" title="Link to this heading">ÔÉÅ</a></h3>
<p>For the basic estimator:</p>
<div class="math notranslate nohighlight">
\[\text{Var}[\hat{I}_n] = \frac{1}{n} \text{Var}[h(X)] = \frac{\sigma^2}{n}\]</div>
<p>The root mean square error (RMSE) decreases as O(1/‚àön):</p>
<div class="math notranslate nohighlight">
\[\text{RMSE} = \sqrt{E[(\hat{I}_n - I)^2]} = \frac{\sigma}{\sqrt{n}}\]</div>
</section>
<section id="confidence-intervals">
<h3>Confidence Intervals<a class="headerlink" href="#confidence-intervals" title="Link to this heading">ÔÉÅ</a></h3>
<p>Using the CLT, approximate confidence intervals are:</p>
<div class="math notranslate nohighlight">
\[\hat{I}_n \pm z_{\alpha/2} \cdot \frac{\hat{\sigma}}{\sqrt{n}}\]</div>
<p>where ·∫ë_{Œ±/2} is the standard normal quantile and œÉÃÇ is the sample standard deviation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">monte_carlo_with_confidence</span><span class="p">(</span><span class="n">h_func</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                               <span class="n">confidence</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Monte Carlo estimation with confidence intervals.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Estimate, standard error, and confidence interval</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

    <span class="c1"># Generate samples and evaluate</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">h_func</span><span class="p">(</span><span class="n">sampler</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)])</span>

    <span class="c1"># Point estimate</span>
    <span class="n">estimate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

    <span class="c1"># Standard error</span>
    <span class="n">std_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

    <span class="c1"># Confidence interval</span>
    <span class="n">z_score</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="n">confidence</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">margin_error</span> <span class="o">=</span> <span class="n">z_score</span> <span class="o">*</span> <span class="n">std_error</span>
    <span class="n">ci_lower</span> <span class="o">=</span> <span class="n">estimate</span> <span class="o">-</span> <span class="n">margin_error</span>
    <span class="n">ci_upper</span> <span class="o">=</span> <span class="n">estimate</span> <span class="o">+</span> <span class="n">margin_error</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;estimate&#39;</span><span class="p">:</span> <span class="n">estimate</span><span class="p">,</span>
        <span class="s1">&#39;std_error&#39;</span><span class="p">:</span> <span class="n">std_error</span><span class="p">,</span>
        <span class="s1">&#39;confidence_interval&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">ci_lower</span><span class="p">,</span> <span class="n">ci_upper</span><span class="p">),</span>
        <span class="s1">&#39;margin_of_error&#39;</span><span class="p">:</span> <span class="n">margin_error</span><span class="p">,</span>
        <span class="s1">&#39;effective_sample_size&#39;</span><span class="p">:</span> <span class="n">n_samples</span>
    <span class="p">}</span>
</pre></div>
</div>
</section>
<section id="effective-sample-size">
<h3>Effective Sample Size<a class="headerlink" href="#effective-sample-size" title="Link to this heading">ÔÉÅ</a></h3>
<p>When samples are correlated (e.g., from MCMC), the effective sample size is:</p>
<div class="math notranslate nohighlight">
\[n_{\text{eff}} = \frac{n}{1 + 2\sum_{k=1}^{\infty} \rho_k}\]</div>
<p>where œÅ_k is the autocorrelation at lag k.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">effective_sample_size</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">max_lag</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute effective sample size for correlated samples.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : array</span>
<span class="sd">        Sample values (possibly correlated)</span>
<span class="sd">    max_lag : int</span>
<span class="sd">        Maximum lag for autocorrelation calculation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_lag</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_lag</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">4</span><span class="p">),</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="c1"># Compute autocorrelations</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">c0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">samples</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">sum_autocorr</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_lag</span><span class="p">):</span>
        <span class="n">ck</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">samples</span><span class="p">[:</span><span class="o">-</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">k</span><span class="p">:]</span> <span class="o">-</span> <span class="n">mean</span><span class="p">))</span>
        <span class="n">rho_k</span> <span class="o">=</span> <span class="n">ck</span> <span class="o">/</span> <span class="n">c0</span>

        <span class="c1"># Stop when autocorrelation becomes negligible</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">rho_k</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="n">sum_autocorr</span> <span class="o">+=</span> <span class="n">rho_k</span>

    <span class="c1"># Effective sample size</span>
    <span class="n">n_eff</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sum_autocorr</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">n_eff</span>
</pre></div>
</div>
</section>
</section>
<section id="practical-considerations">
<h2>Practical Considerations<a class="headerlink" href="#practical-considerations" title="Link to this heading">ÔÉÅ</a></h2>
<p>Implementing Monte Carlo methods in production requires attention to reproducibility, parallelization, and numerical stability.</p>
<section id="random-seed-management">
<h3>Random Seed Management<a class="headerlink" href="#random-seed-management" title="Link to this heading">ÔÉÅ</a></h3>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ‚ö†Ô∏è</p>
<p>Using global random seeds can lead to non-reproducible results in parallel computing environments.</p>
<p><strong>Solution</strong>: Use independent random number generators:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MonteCarloRunner</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_seed</span> <span class="o">=</span> <span class="n">base_seed</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">32</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run_parallel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">n_jobs</span><span class="p">,</span> <span class="n">n_samples_per_job</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run Monte Carlo in parallel with reproducible seeds.&quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">joblib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">worker</span><span class="p">(</span><span class="n">job_id</span><span class="p">):</span>
            <span class="c1"># Create independent RNG for this job</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_seed</span> <span class="o">+</span> <span class="n">job_id</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">n_samples_per_job</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">)(</span>
            <span class="n">delayed</span><span class="p">(</span><span class="n">worker</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_jobs</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">combine_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="adaptive-sample-size-determination">
<h3>Adaptive Sample Size Determination<a class="headerlink" href="#adaptive-sample-size-determination" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">adaptive_monte_carlo</span><span class="p">(</span><span class="n">h_func</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">target_error</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                        <span class="n">initial_n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="mi">7</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adaptively determine sample size to achieve target error.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">current_n</span> <span class="o">=</span> <span class="n">initial_n</span>
    <span class="n">all_samples</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span> <span class="n">current_n</span> <span class="o">&lt;=</span> <span class="n">max_n</span><span class="p">:</span>
        <span class="c1"># Generate new batch</span>
        <span class="n">new_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">h_func</span><span class="p">(</span><span class="n">sampler</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">initial_n</span><span class="p">)]</span>
        <span class="n">all_samples</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">new_samples</span><span class="p">)</span>

        <span class="c1"># Current estimate and error</span>
        <span class="n">estimate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_samples</span><span class="p">)</span>
        <span class="n">std_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">all_samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_samples</span><span class="p">))</span>

        <span class="c1"># Check if target accuracy achieved</span>
        <span class="k">if</span> <span class="n">std_error</span> <span class="o">&lt;</span> <span class="n">target_error</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">estimate</span><span class="p">,</span> <span class="n">std_error</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_samples</span><span class="p">)</span>

        <span class="n">current_n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_samples</span><span class="p">)</span>

    <span class="c1"># Max samples reached</span>
    <span class="k">return</span> <span class="n">estimate</span><span class="p">,</span> <span class="n">std_error</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_samples</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="bringing-it-all-together">
<h2>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading">ÔÉÅ</a></h2>
<p>Monte Carlo methods provide a universal computational framework for solving problems involving uncertainty, integration, and optimization. Their power lies in transforming deterministic problems into stochastic simulations where the law of large numbers guarantees convergence.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaways üìù</p>
<ol class="arabic simple">
<li><p><strong>Core concept</strong>: Represent any quantity as an expectation E[h(X)] and approximate via sampling</p></li>
<li><p><strong>Computational insight</strong>: Error decreases as O(1/‚àön) independent of dimension</p></li>
<li><p><strong>Practical application</strong>: Essential for high-dimensional problems where deterministic methods fail</p></li>
<li><p><strong>Connection</strong>: Foundation for all simulation-based methods including MCMC and particle filters</p></li>
</ol>
</div>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">ÔÉÅ</a></h3>
<ol class="arabic">
<li><p><strong>Conceptual Understanding</strong>: Prove that the Monte Carlo estimator is unbiased and derive its variance. Show that the variance of the sample variance estimator is O(1/n).</p></li>
<li><p><strong>Implementation</strong>: Implement Monte Carlo integration for the Gaussian integral:</p>
<div class="math notranslate nohighlight">
\[I = \int_{-\infty}^{\infty} e^{-x^2/2} dx = \sqrt{2\pi}\]</div>
<p>Use importance sampling with a Cauchy distribution and compare with naive sampling. Plot the convergence for both methods.</p>
</li>
<li><p><strong>Analysis</strong>: The Genz test functions are standard benchmarks for multidimensional integration. Implement Monte Carlo integration for the oscillatory Genz function:</p>
<div class="math notranslate nohighlight">
\[f(x) = \cos\left(2\pi u_1 + \sum_{i=1}^d a_i x_i\right)\]</div>
<p>over [0,1]^d. Study how the variance depends on dimension d and frequency parameters a_i.</p>
</li>
<li><p><strong>Extension</strong>: Implement a quasi-Monte Carlo method using Sobol sequences instead of pseudo-random numbers. Compare convergence rates with standard Monte Carlo for:
a) Integration over the unit cube in various dimensions
b) Option pricing using the Black-Scholes model</p>
<p>Explain when quasi-Monte Carlo outperforms standard Monte Carlo.</p>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>