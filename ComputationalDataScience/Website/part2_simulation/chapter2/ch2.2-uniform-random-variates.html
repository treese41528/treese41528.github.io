

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>2.1.2. Uniform Random Variates &mdash; STAT 418</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=6826d573" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT418/Website/part2_simulation/chapter2/ch2.2-uniform-random-variates.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=d2113767"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2.1.3. Inverse CDF Method" href="ch2.3-inverse-cdf-method.html" />
    <link rel="prev" title="2.1.1. Monte Carlo Fundamentals" href="ch2.1-monte-carlo-fundamentals.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Course Content</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../part1_foundations/index.html">1. Part I: Foundations of Probability and Computation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part1_foundations/chapter1/index.html">1.1. Chapter 1: Statistical Paradigms and Core Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html">1.1.1. Paradigms of Probability and Statistical Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#the-mathematical-foundation-kolmogorov-s-axioms">The Mathematical Foundation: Kolmogorov‚Äôs Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#interpretations-of-probability">Interpretations of Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#statistical-inference-paradigms">Statistical Inference Paradigms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#historical-and-philosophical-debates">Historical and Philosophical Debates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#looking-ahead-our-course-focus">Looking Ahead: Our Course Focus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html">1.1.2. Probability Distributions: Theory and Computation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#from-abstract-foundations-to-concrete-tools">From Abstract Foundations to Concrete Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#the-python-ecosystem-for-probability">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#introduction-why-probability-distributions-matter">Introduction: Why Probability Distributions Matter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#id1">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#continuous-distributions">Continuous Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#additional-important-distributions">Additional Important Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#summary-and-practical-guidelines">Summary and Practical Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html">1.1.3. Python Random Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#from-mathematical-distributions-to-computational-samples">From Mathematical Distributions to Computational Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#the-python-ecosystem-at-a-glance">The Python Ecosystem at a Glance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#understanding-pseudo-random-number-generation">Understanding Pseudo-Random Number Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#the-standard-library-random-module">The Standard Library: <code class="docutils literal notranslate"><span class="pre">random</span></code> Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#numpy-fast-vectorized-random-sampling">NumPy: Fast Vectorized Random Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#scipy-stats-the-complete-statistical-toolkit">SciPy Stats: The Complete Statistical Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#bringing-it-all-together-library-selection-guide">Bringing It All Together: Library Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part1_foundations/chapter1/ch1.3-python_random_generation.html#looking-ahead-from-random-numbers-to-monte-carlo-methods">Looking Ahead: From Random Numbers to Monte Carlo Methods</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">2. Part II: Simulation-Based Methods</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">2.1. Chapter 2: Monte Carlo Simulation</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html">2.1.1. Monte Carlo Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#the-historical-development-of-monte-carlo-methods">The Historical Development of Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#the-core-principle-expectation-as-integration">The Core Principle: Expectation as Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#theoretical-foundations">Theoretical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#variance-estimation-and-confidence-intervals">Variance Estimation and Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#comparison-with-deterministic-methods">Comparison with Deterministic Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#sample-size-determination">Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#convergence-diagnostics-and-monitoring">Convergence Diagnostics and Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.1-monte-carlo-fundamentals.html#transition-to-what-follows">Transition to What Follows</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">2.1.2. Uniform Random Variates</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#why-uniform-the-universal-currency-of-randomness">Why Uniform? The Universal Currency of Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-paradox-of-computational-randomness">The Paradox of Computational Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="#chaotic-dynamical-systems-an-instructive-failure">Chaotic Dynamical Systems: An Instructive Failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="#linear-congruential-generators">Linear Congruential Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="#shift-register-generators">Shift-Register Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-kiss-generator-combining-strategies">The KISS Generator: Combining Strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="#modern-generators-mersenne-twister-and-pcg">Modern Generators: Mersenne Twister and PCG</a></li>
<li class="toctree-l4"><a class="reference internal" href="#statistical-testing-of-random-number-generators">Statistical Testing of Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transition-to-what-follows">Transition to What Follows</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch2.3-inverse-cdf-method.html">2.1.3. Inverse CDF Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#mathematical-foundations">Mathematical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#continuous-distributions-with-closed-form-inverses">Continuous Distributions with Closed-Form Inverses</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#numerical-inversion">Numerical Inversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#mixed-distributions">Mixed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch2.3-inverse-cdf-method.html#transition-to-what-follows">Transition to What Follows</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../chapter3/index.html">2.2. Chapter 3: Frequentist Statistical Inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/sampling_variability.html">2.2.1. Sampling Variability</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/sampling_variability.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/statistical_estimators.html">2.2.2. Statistical Estimators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/statistical_estimators.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/plugin_methods.html">2.2.3. Plugin Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/plugin_methods.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/parametric_inference.html">2.2.4. Parametric Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/parametric_inference.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/exponential_families.html">2.2.5. Exponential Families</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/exponential_families.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/maximum_likelihood.html">2.2.6. Maximum Likelihood</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/maximum_likelihood.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/linear_models.html">2.2.7. Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/linear_models.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter3/generalized_linear_models.html">2.2.8. Generalized Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter3/generalized_linear_models.html#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../chapter4/index.html">2.3. Chapter 4: Resampling Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/jackknife_introduction.html">2.3.1. Jackknife Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/jackknife_introduction.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html">2.3.2. Bootstrap Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bootstrap_fundamentals.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html">2.3.3. Nonparametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/nonparametric_bootstrap.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/parametric_bootstrap.html">2.3.4. Parametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/parametric_bootstrap.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/confidence_intervals.html">2.3.5. Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/confidence_intervals.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/bias_correction.html">2.3.6. Bias Correction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/bias_correction.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/cross_validation_loo.html">2.3.7. Cross Validation Loo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_loo.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html">2.3.8. Cross Validation K Fold</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/cross_validation_k_fold.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../chapter4/model_selection.html">2.3.9. Model Selection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../chapter4/model_selection.html#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part3_bayesian/index.html">2. Part III: Bayesian Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part3_bayesian/index.html#overview">2.1. Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html">1. Bayesian Philosophy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#introduction">1.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#key-concepts">1.2. Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#mathematical-framework">1.3. Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#python-implementation">1.4. Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#examples">1.5. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part3_bayesian/chapter5/bayesian_philosophy.html#summary">1.6. Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">2. </span>Part II: Simulation-Based Methods</a></li>
          <li class="breadcrumb-item"><a href="index.html"><span class="section-number">2.1. </span>Chapter 2: Monte Carlo Simulation</a></li>
      <li class="breadcrumb-item active"><span class="section-number">2.1.2. </span>Uniform Random Variates</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/part2_simulation/chapter2/ch2.2-uniform-random-variates.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="uniform-random-variates">
<span id="ch2-2-uniform-random-variates"></span><h1><span class="section-number">2.1.2. </span>Uniform Random Variates<a class="headerlink" href="#uniform-random-variates" title="Link to this heading">ÔÉÅ</a></h1>
<p>Every random number you have ever used in a computer program began as a uniform random variate. When you call <code class="docutils literal notranslate"><span class="pre">np.random.normal()</span></code> to generate Gaussian samples, the library first generates uniform numbers on <span class="math notranslate nohighlight">\([0, 1)\)</span> and then transforms them. When you shuffle a deck of cards, simulate a Markov chain, or train a neural network, uniform variates are the hidden substrate beneath every stochastic operation. The uniform distribution is the computational atom of randomness‚Äîthe irreducible building block from which all other random variables are constructed.</p>
<p>Yet this foundation rests on a paradox. Computers are deterministic machines: given identical inputs, they produce identical outputs. How can a deterministic device generate numbers that behave randomly? The answer is that it cannot‚Äînot truly. What computers produce instead are <em>pseudo-random</em> numbers: sequences generated by deterministic algorithms that, while entirely predictable given the algorithm and starting state, pass stringent statistical tests for randomness. Understanding this distinction, and the remarkable success of pseudo-random methods despite it, is essential for any practitioner of computational statistics.</p>
<p>This section explores the theory and practice of uniform random variate generation. We begin with a brief look at why uniform variates are so fundamental‚Äîthe Probability Integral Transform makes them the universal source for all other distributions‚Äîand then examine the surprisingly deep question of how to generate sequences that <em>behave</em> uniformly even when produced by deterministic algorithms. Along the way, we will encounter chaotic dynamical systems that seem random but fail statistical tests, historical generators whose flaws caused years of corrupted research, and the modern algorithms that power today‚Äôs scientific computing.</p>
<div class="important admonition">
<p class="admonition-title">Road Map üß≠</p>
<ul class="simple">
<li><p><strong>Understand</strong>: Why the uniform distribution is the universal source for all random generation (full details in <a class="reference internal" href="ch2.3-inverse-cdf-method.html#ch2-3-inverse-cdf-method"><span class="std std-ref">Inverse CDF Method</span></a>)</p></li>
<li><p><strong>Explore</strong>: The paradox of computational randomness and what ‚Äúpseudo-random‚Äù really means</p></li>
<li><p><strong>Analyze</strong>: Why some deterministic systems (chaotic maps, naive generators) fail to produce acceptable randomness</p></li>
<li><p><strong>Master</strong>: The mathematical structure of linear congruential and shift-register generators, including their failure modes</p></li>
<li><p><strong>Apply</strong>: Modern generators (Mersenne Twister, PCG64) and best practices for seeds, reproducibility, and parallelism</p></li>
</ul>
</div>
<section id="why-uniform-the-universal-currency-of-randomness">
<h2>Why Uniform? The Universal Currency of Randomness<a class="headerlink" href="#why-uniform-the-universal-currency-of-randomness" title="Link to this heading">ÔÉÅ</a></h2>
<p>Before examining how uniform variates are generated, we must understand <em>why</em> they occupy such a privileged position. The answer lies in a beautiful theoretical result called the <strong>Probability Integral Transform</strong>, which establishes a universal correspondence between the uniform distribution and all other distributions.</p>
<section id="the-core-insight">
<h3>The Core Insight<a class="headerlink" href="#the-core-insight" title="Link to this heading">ÔÉÅ</a></h3>
<p>The key result, which we develop fully in <a class="reference internal" href="ch2.3-inverse-cdf-method.html#ch2-3-inverse-cdf-method"><span class="std std-ref">Inverse CDF Method</span></a>, can be stated simply:</p>
<blockquote>
<div><p><strong>If</strong> <span class="math notranslate nohighlight">\(U \sim \text{Uniform}(0, 1)\)</span> <strong>and</strong> <span class="math notranslate nohighlight">\(F\)</span> <strong>is any CDF, then</strong> <span class="math notranslate nohighlight">\(X = F^{-1}(U)\)</span> <strong>has distribution</strong> <span class="math notranslate nohighlight">\(F\)</span>.</p>
</div></blockquote>
<p>This means that <strong>uniform random numbers can be transformed into any distribution</strong> by applying the appropriate inverse CDF. The uniform distribution is the ‚Äúuniversal currency‚Äù of randomness‚Äîany desired distribution can be ‚Äúpurchased‚Äù by applying the right transformation.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig01_probability_integral_transform.png"><img alt="Six-panel visualization of the Probability Integral Transform showing forward and inverse directions" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig01_probability_integral_transform.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 2.9 </span><span class="caption-text"><strong>The Probability Integral Transform: Universal Currency of Randomness.</strong> Top row (Forward): Starting with <span class="math notranslate nohighlight">\(X \sim \text{Exp}(1)\)</span>, applying the CDF transforms exponential samples into uniform samples. Bottom row (Inverse): Starting with <span class="math notranslate nohighlight">\(U \sim \text{Uniform}(0,1)\)</span>, applying the inverse CDF <span class="math notranslate nohighlight">\(X = -\ln(1-U)\)</span> transforms uniform samples into exponential samples. The geometric construction‚Äîhorizontal and vertical lines on the CDF curve‚Äîshows how the transform works.</span><a class="headerlink" href="#id1" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p>Consider what this means algorithmically:</p>
<ul class="simple">
<li><p>To generate <span class="math notranslate nohighlight">\(\text{Exponential}(\lambda)\)</span>: compute <span class="math notranslate nohighlight">\(-\ln(1-U)/\lambda\)</span></p></li>
<li><p>To generate <span class="math notranslate nohighlight">\(\text{Cauchy}(\mu, \sigma)\)</span>: compute <span class="math notranslate nohighlight">\(\mu + \sigma \tan(\pi(U - 1/2))\)</span></p></li>
<li><p>To generate any continuous distribution with CDF <span class="math notranslate nohighlight">\(F\)</span>: compute <span class="math notranslate nohighlight">\(F^{-1}(U)\)</span></p></li>
</ul>
<p>This universality explains why so much effort has been devoted to generating high-quality uniform variates. Every improvement in uniform generation propagates to every distribution built upon it. Every flaw in uniform generation corrupts every simulation that depends on it.</p>
<p>The full mathematical treatment‚Äîincluding the generalized inverse for discrete distributions, complete proofs, and efficient algorithms‚Äîappears in <a class="reference internal" href="ch2.3-inverse-cdf-method.html#ch2-3-inverse-cdf-method"><span class="std std-ref">Inverse CDF Method</span></a>. For now, what matters is this: <strong>get the uniforms right, and everything else follows</strong>.</p>
</section>
</section>
<section id="the-paradox-of-computational-randomness">
<h2>The Paradox of Computational Randomness<a class="headerlink" href="#the-paradox-of-computational-randomness" title="Link to this heading">ÔÉÅ</a></h2>
<p>With the importance of uniform variates established, we face a fundamental question: how do computers generate them? The honest answer is unsettling‚Äîcomputers cannot generate truly random numbers through algorithmic means. They produce <em>pseudo-random</em> numbers: sequences that are entirely deterministic yet pass statistical tests for randomness.</p>
<section id="von-neumann-s-confession">
<h3>Von Neumann‚Äôs Confession<a class="headerlink" href="#von-neumann-s-confession" title="Link to this heading">ÔÉÅ</a></h3>
<p>John von Neumann, one of the founding figures of both computer science and Monte Carlo methods, captured this paradox memorably:</p>
<blockquote>
<div><p>‚ÄúAnyone who considers arithmetical methods of producing random digits is, of course, in a state of sin. For, as has been pointed out several times, there is no such thing as a random number‚Äîthere are only methods of producing random numbers, and a strict arithmetic procedure of course is not such a method.‚Äù</p>
</div></blockquote>
<p>Yet von Neumann himself used such ‚Äúsinful‚Äù methods extensively in his computational work. The Monte Carlo simulations he developed with Ulam at Los Alamos depended entirely on pseudo-random numbers. How could a method built on a logical contradiction prove so useful?</p>
<p>The resolution lies in recognizing that we do not need <em>true</em> randomness for most purposes‚Äîwe need <em>statistical</em> randomness. A sequence is statistically random if no practical test can distinguish it from genuinely random data. A pseudo-random number generator (PRNG) succeeds if its output, while deterministic, passes every statistical test we can devise.</p>
<p>This is a functional definition: we accept a PRNG if it is not rejected by our tests. The definition is pragmatic rather than philosophical, and it works remarkably well in practice.</p>
</section>
<section id="von-neumann-s-middle-square-method">
<h3>Von Neumann‚Äôs Middle-Square Method<a class="headerlink" href="#von-neumann-s-middle-square-method" title="Link to this heading">ÔÉÅ</a></h3>
<p>Von Neumann proposed one of the earliest PRNGs in 1946: the <strong>middle-square method</strong>. The algorithm is simple:</p>
<ol class="arabic simple">
<li><p>Start with an <span class="math notranslate nohighlight">\(n\)</span>-digit number (the seed)</p></li>
<li><p>Square it to obtain a <span class="math notranslate nohighlight">\(2n\)</span>-digit number</p></li>
<li><p>Extract the middle <span class="math notranslate nohighlight">\(n\)</span> digits as the next number</p></li>
<li><p>Repeat</p></li>
</ol>
<p>For example, with <span class="math notranslate nohighlight">\(n = 4\)</span> and seed 1234:</p>
<div class="math notranslate nohighlight">
\[\begin{split}1234^2 &amp;= 01522756 \to \text{middle 4 digits} = 5227 \\
5227^2 &amp;= 27321529 \to \text{middle 4 digits} = 3215 \\
3215^2 &amp;= 10336225 \to \text{middle 4 digits} = 3362 \\
&amp;\vdots\end{split}\]</div>
<p>The method is elegant but deeply flawed. The sequence can converge to zero (if a middle segment is 0000), fall into short cycles, or exhibit strong correlations. Von Neumann knew these limitations‚Äîhe called the method a ‚Äúvery crude‚Äù approach suitable only for quick calculations. But it established the paradigm: use arithmetic operations to generate sequences that <em>appear</em> random.</p>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig07_middle_square.png"><img alt="Three sequences showing middle-square method behavior: reasonable, degenerating to zero, and falling into cycle" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig07_middle_square.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 2.10 </span><span class="caption-text"><strong>Von Neumann‚Äôs Middle-Square Method: Elegant but Flawed.</strong> Left: With seed 1234, the sequence behaves reasonably for many iterations. Center: With seed 404, the sequence wanders briefly then degenerates to zero and stays there forever. Right: With seed 2100, the sequence immediately falls into a short 4-cycle (2100‚Üí4100‚Üí8100‚Üí6100‚Üí2100‚Ä¶). The method‚Äôs behavior is highly seed-dependent, making it unreliable for serious simulation work.</span><a class="headerlink" href="#id2" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">middle_square</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">n_digits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Von Neumann&#39;s middle-square method (historical; do not use in practice).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    seed : int</span>
<span class="sd">        Starting value (n_digits digits).</span>
<span class="sd">    n_digits : int</span>
<span class="sd">        Number of digits in each generated number.</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        Number of values to generate.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">        Sequence of pseudo-random integers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sequence</span> <span class="o">=</span> <span class="p">[</span><span class="n">seed</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">seed</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">x_squared</span> <span class="o">=</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="c1"># Pad to 2*n_digits, extract middle n_digits</span>
        <span class="n">x_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">x_squared</span><span class="p">)</span><span class="o">.</span><span class="n">zfill</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_digits</span><span class="p">)</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">n_digits</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x_str</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">start</span> <span class="o">+</span> <span class="n">n_digits</span><span class="p">])</span>
        <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Degenerate: will stay at 0</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">sequence</span>

<span class="c1"># Demonstrate the method</span>
<span class="n">seq</span> <span class="o">=</span> <span class="n">middle_square</span><span class="p">(</span><span class="mi">1234</span><span class="p">,</span> <span class="n">n_digits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Middle-square sequence:&quot;</span><span class="p">,</span> <span class="n">seq</span><span class="p">)</span>

<span class="c1"># Show it can degenerate to zero</span>
<span class="n">bad_seq</span> <span class="o">=</span> <span class="n">middle_square</span><span class="p">(</span><span class="mi">404</span><span class="p">,</span> <span class="n">n_digits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Degenerating sequence:&quot;</span><span class="p">,</span> <span class="n">bad_seq</span><span class="p">)</span>

<span class="c1"># Show it can fall into a short cycle</span>
<span class="n">cycle_seq</span> <span class="o">=</span> <span class="n">middle_square</span><span class="p">(</span><span class="mi">2100</span><span class="p">,</span> <span class="n">n_digits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cycling sequence:&quot;</span><span class="p">,</span> <span class="n">cycle_seq</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Middle-square sequence: [1234, 5227, 3215, 3362, 3030, 1809, 2724, 4201, 6484, 424, 1797, 2292, 2532, 4102, 8263]
Degenerating sequence: [404, 1632, 6634, 99, 98, 96, 92, 84, 70, 49, 24, 5, 0]
Cycling sequence: [2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100]
</pre></div>
</div>
<p>Running this code reveals the method‚Äôs instability. Some seeds produce reasonable-looking sequences; others degenerate to zero or fall into short cycles.</p>
</section>
</section>
<section id="chaotic-dynamical-systems-an-instructive-failure">
<h2>Chaotic Dynamical Systems: An Instructive Failure<a class="headerlink" href="#chaotic-dynamical-systems-an-instructive-failure" title="Link to this heading">ÔÉÅ</a></h2>
<p>Given the limitations of simple arithmetic methods, researchers explored whether <em>chaotic dynamical systems</em>‚Äîdeterministic systems exhibiting sensitive dependence on initial conditions‚Äîmight serve as random number generators. The idea is seductive: chaotic systems produce trajectories that appear random, never repeating and highly sensitive to initial conditions. Perhaps chaos could provide the randomness that arithmetic methods lack?</p>
<p>The answer, disappointingly, is no. Chaotic systems fail as PRNGs for subtle but important reasons.</p>
<section id="the-logistic-map">
<h3>The Logistic Map<a class="headerlink" href="#the-logistic-map" title="Link to this heading">ÔÉÅ</a></h3>
<p>The <strong>logistic map</strong> is perhaps the most famous chaotic system:</p>
<div class="math notranslate nohighlight">
\[X_{n+1} = \alpha X_n (1 - X_n)\]</div>
<p>For certain values of <span class="math notranslate nohighlight">\(\alpha\)</span>, particularly <span class="math notranslate nohighlight">\(\alpha = 4\)</span>, this simple recurrence produces chaotic behavior. Starting from almost any <span class="math notranslate nohighlight">\(X_0 \in (0, 1)\)</span>, the sequence <span class="math notranslate nohighlight">\(X_1, X_2, \ldots\)</span> bounces unpredictably around the interval, never settling into a pattern.</p>
<p>Remarkably, for <span class="math notranslate nohighlight">\(\alpha = 4\)</span>, the stationary distribution of the logistic map is known analytically: it is the <strong>arcsine distribution</strong> with density:</p>
<div class="math notranslate nohighlight">
\[f(x) = \frac{1}{\pi\sqrt{x(1-x)}}, \quad 0 &lt; x &lt; 1\]</div>
<p>This density concentrates mass near 0 and 1, not uniformly across <span class="math notranslate nohighlight">\([0, 1]\)</span>. However, applying the probability integral transform <span class="math notranslate nohighlight">\(Y_n = F(X_n) = \frac{1}{2} + \frac{\arcsin(2X_n - 1)}{\pi}\)</span> should yield uniformly distributed <span class="math notranslate nohighlight">\(Y_n\)</span>.</p>
</section>
<section id="the-failure-of-chaos">
<h3>The Failure of Chaos<a class="headerlink" href="#the-failure-of-chaos" title="Link to this heading">ÔÉÅ</a></h3>
<p>The following figure reveals the problem with using chaotic maps as PRNGs.</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig03_logistic_map_failure.png"><img alt="Six-panel comparison showing logistic map marginal distribution looks uniform but lag-1 plot reveals deterministic structure" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig03_logistic_map_failure.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 2.11 </span><span class="caption-text"><strong>Why Chaos ‚â† Randomness: The Logistic Map Failure.</strong> Top row: The raw logistic map output follows an arcsine distribution (left). After transformation, the marginal histogram looks uniform (center). But the lag-1 scatter plot (right) reveals the fatal flaw‚Äîpoints trace a deterministic curve rather than filling the unit square. Bottom row: A good PRNG (PCG64) also has a uniform marginal (left), but its lag-1 plot fills the square uniformly (center). The logistic map‚Äôs lag-100 plot (right) looks better, but achieving independence requires discarding 99 out of every 100 samples‚Äîdefeating the purpose of a fast generator.</span><a class="headerlink" href="#id3" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p>While the marginal histogram of <span class="math notranslate nohighlight">\(Y_n\)</span> looks roughly uniform, the lag-1 scatter plot <span class="math notranslate nohighlight">\((Y_n, Y_{n+1})\)</span> shows strong structure‚Äîthe points do <em>not</em> fill the unit square uniformly. The logistic map introduces correlations between consecutive outputs that persist even after the uniformizing transformation.</p>
<p>The lag-100 plot <span class="math notranslate nohighlight">\((Y_n, Y_{n+100})\)</span> looks better, suggesting that values separated by many iterations are approximately independent. But this comes at an unacceptable cost: to generate <span class="math notranslate nohighlight">\(n\)</span> independent-looking values, we must compute <span class="math notranslate nohighlight">\(100n\)</span> iterations of the map. This defeats the purpose of using a fast deterministic generator.</p>
<p>The deeper issue is that chaotic dynamics and statistical independence are different properties. A chaotic system exhibits <em>sensitive dependence on initial conditions</em>‚Äînearby starting points diverge exponentially over time. But this says nothing about the joint distribution of <span class="math notranslate nohighlight">\((X_n, X_{n+1})\)</span>. The deterministic relationship <span class="math notranslate nohighlight">\(X_{n+1} = 4X_n(1-X_n)\)</span> creates strong dependencies that no transformation can remove.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">logistic_map_generator</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate pseudo-random numbers using the logistic map.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x0 : float</span>
<span class="sd">        Initial value in (0, 1).</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Logistic map parameter (use 4.0 for chaos).</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        Number of samples to generate.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    X : ndarray</span>
<span class="sd">        Raw logistic map values (arcsine distributed).</span>
<span class="sd">    Y : ndarray</span>
<span class="sd">        Transformed values (should be uniform).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">x0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
        <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># Transform to uniform via arcsine CDF</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">arcsin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">X</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>

<span class="c1"># Generate samples</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">logistic_map_generator</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="c1"># Check lag-1 correlation</span>
<span class="n">lag1_corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">Y</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="mi">1</span><span class="p">:])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Lag-1 correlation of transformed logistic map: </span><span class="si">{</span><span class="n">lag1_corr</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(Should be ~0 for a good PRNG, but deterministic structure remains)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Lag-1 correlation of transformed logistic map: -0.0012
(Should be ~0 for a good PRNG, but deterministic structure remains)
</pre></div>
</div>
<p>Note that the correlation coefficient is near zero, yet the scatter plot reveals complete dependence! This illustrates why correlation alone is insufficient‚Äîthe relationship is nonlinear, so Pearson correlation misses it entirely.</p>
</section>
<section id="the-tent-map-another-cautionary-tale">
<h3>The Tent Map: Another Cautionary Tale<a class="headerlink" href="#the-tent-map-another-cautionary-tale" title="Link to this heading">ÔÉÅ</a></h3>
<p>The <strong>tent map</strong> provides another example:</p>
<div class="math notranslate nohighlight">
\[\begin{split}D(x) = \begin{cases} 2x &amp; \text{if } x \leq 1/2 \\ 2(1-x) &amp; \text{if } x &gt; 1/2 \end{cases}\end{split}\]</div>
<p>Theoretically, the tent map preserves the uniform distribution: if <span class="math notranslate nohighlight">\(X_n \sim \text{Uniform}(0,1)\)</span>, then <span class="math notranslate nohighlight">\(X_{n+1} = D(X_n) \sim \text{Uniform}(0,1)\)</span>. This seems ideal for a PRNG.</p>
<p>In practice, the tent map fails catastrophically on computers. The problem is finite-precision arithmetic. Each application of <span class="math notranslate nohighlight">\(D\)</span> effectively shifts the binary representation of <span class="math notranslate nohighlight">\(x\)</span> by one bit‚Äîmultiplying by 2 and taking the fractional part. After <span class="math notranslate nohighlight">\(k\)</span> iterations, the <span class="math notranslate nohighlight">\(k\)</span> least significant bits of the original <span class="math notranslate nohighlight">\(x\)</span> have been shifted away. With 64-bit floating-point numbers, the sequence converges to a fixed point or short cycle within 64 iterations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tent_map</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate tent map degeneration.&quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Fixed point</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="c1"># Watch it degenerate</span>
<span class="n">seq</span> <span class="o">=</span> <span class="n">tent_map</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sequence length before degeneration: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final values: </span><span class="si">{</span><span class="n">seq</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Sequence length before degeneration: 70
Final values: [0.0, 0.0, 0.0, 0.0, 0.0]
</pre></div>
</div>
<p>The lesson is clear: <strong>theoretical properties of continuous dynamical systems do not translate to discrete computer arithmetic</strong>. The finite representation of numbers fundamentally changes the behavior of these systems. Chaotic maps that work beautifully in continuous mathematics become useless or dangerous when implemented on computers.</p>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ‚ö†Ô∏è</p>
<p><strong>Chaotic maps are not PRNGs</strong>: Despite their apparent randomness, chaotic dynamical systems like the logistic map or tent map fail as pseudo-random number generators. They introduce correlations (logistic) or degenerate rapidly (tent) on finite-precision computers. Always use established PRNG algorithms, never improvised chaotic generators.</p>
</div>
</section>
</section>
<section id="linear-congruential-generators">
<h2>Linear Congruential Generators<a class="headerlink" href="#linear-congruential-generators" title="Link to this heading">ÔÉÅ</a></h2>
<p>The first successful class of PRNGs was the <strong>linear congruential generator</strong> (LCG), introduced by D.H. Lehmer in 1948. LCGs dominated random number generation for decades and remain important today for understanding PRNG design‚Äîboth its successes and its pitfalls.</p>
<section id="the-algorithm">
<h3>The Algorithm<a class="headerlink" href="#the-algorithm" title="Link to this heading">ÔÉÅ</a></h3>
<p>An LCG produces integers <span class="math notranslate nohighlight">\(X_0, X_1, X_2, \ldots\)</span> via the recurrence:</p>
<div class="math notranslate nohighlight" id="equation-lcg-recurrence">
<span class="eqno">(2.7)<a class="headerlink" href="#equation-lcg-recurrence" title="Link to this equation">ÔÉÅ</a></span>\[X_{n+1} = (a X_n + c) \mod m\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(m &gt; 0\)</span> is the <strong>modulus</strong> (often <span class="math notranslate nohighlight">\(2^{32}\)</span> or <span class="math notranslate nohighlight">\(2^{64}\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(a\)</span> with <span class="math notranslate nohighlight">\(0 &lt; a &lt; m\)</span> is the <strong>multiplier</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(c\)</span> with <span class="math notranslate nohighlight">\(0 \leq c &lt; m\)</span> is the <strong>increment</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(X_0\)</span> is the <strong>seed</strong> (initial state)</p></li>
</ul>
<p>The output uniform variates are <span class="math notranslate nohighlight">\(U_n = X_n / m \in [0, 1)\)</span>.</p>
<p>The appeal of LCGs is computational efficiency: each iteration requires only a multiplication, addition, and modulo operation. On modern hardware, this executes in a few clock cycles. The entire state fits in a single integer.</p>
</section>
<section id="period-and-the-hull-dobell-theorem">
<h3>Period and the Hull-Dobell Theorem<a class="headerlink" href="#period-and-the-hull-dobell-theorem" title="Link to this heading">ÔÉÅ</a></h3>
<p>A critical property of any PRNG is its <strong>period</strong>‚Äîthe number of values generated before the sequence repeats. Since an LCG has state <span class="math notranslate nohighlight">\(X_n \in \{0, 1, \ldots, m-1\}\)</span>, its period cannot exceed <span class="math notranslate nohighlight">\(m\)</span>. The question is: when does it achieve the maximum period?</p>
<div class="note admonition">
<p class="admonition-title">Theorem: Hull-Dobell (1962)</p>
<p>The LCG with modulus <span class="math notranslate nohighlight">\(m\)</span>, multiplier <span class="math notranslate nohighlight">\(a\)</span>, and increment <span class="math notranslate nohighlight">\(c\)</span> has period <span class="math notranslate nohighlight">\(m\)</span> (the maximum) if and only if:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\gcd(c, m) = 1\)</span> (c and m are coprime)</p></li>
<li><p><span class="math notranslate nohighlight">\(a - 1\)</span> is divisible by all prime factors of <span class="math notranslate nohighlight">\(m\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(m\)</span> is divisible by 4, then <span class="math notranslate nohighlight">\(a - 1\)</span> is divisible by 4</p></li>
</ol>
</div>
<p>For the common choice <span class="math notranslate nohighlight">\(m = 2^{32}\)</span>:</p>
<ul class="simple">
<li><p>Condition 1 requires <span class="math notranslate nohighlight">\(c\)</span> to be odd</p></li>
<li><p>Condition 2 requires <span class="math notranslate nohighlight">\(a \equiv 1 \pmod{2}\)</span>, i.e., <span class="math notranslate nohighlight">\(a\)</span> odd</p></li>
<li><p>Condition 3 requires <span class="math notranslate nohighlight">\(a \equiv 1 \pmod{4}\)</span></p></li>
</ul>
<p>Thus any <span class="math notranslate nohighlight">\(a \equiv 1 \pmod{4}\)</span> with odd <span class="math notranslate nohighlight">\(c\)</span> achieves full period <span class="math notranslate nohighlight">\(2^{32}\)</span>.</p>
</section>
<section id="the-lattice-structure-problem">
<h3>The Lattice Structure Problem<a class="headerlink" href="#the-lattice-structure-problem" title="Link to this heading">ÔÉÅ</a></h3>
<p>Achieving full period is necessary but not sufficient for a good generator. LCGs have a fundamental flaw that limits their usefulness: <strong>outputs fall on a lattice in high-dimensional space</strong>.</p>
<p>Consider plotting consecutive pairs <span class="math notranslate nohighlight">\((U_n, U_{n+1})\)</span>. From the recurrence:</p>
<div class="math notranslate nohighlight">
\[U_{n+1} = \frac{X_{n+1}}{m} = \frac{aX_n + c}{m} \mod 1 = \frac{a}{m} \cdot m U_n + \frac{c}{m} \mod 1\]</div>
<p>The points <span class="math notranslate nohighlight">\((U_n, U_{n+1})\)</span> lie on lines of the form <span class="math notranslate nohighlight">\(y = (a/m) x + c/m \mod 1\)</span>. In fact, all such points fall on at most <span class="math notranslate nohighlight">\(\sqrt{m}\)</span> parallel lines in <span class="math notranslate nohighlight">\([0,1]^2\)</span>. In three dimensions, consecutive triples <span class="math notranslate nohighlight">\((U_n, U_{n+1}, U_{n+2})\)</span> fall on parallel planes; in <span class="math notranslate nohighlight">\(d\)</span> dimensions, on parallel hyperplanes.</p>
<p>This lattice structure is not random at all‚Äîit is a highly regular geometric pattern masquerading as uniform coverage.</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig04_lcg_lattice.png"><img alt="Six-panel comparison showing LCG lattice structure with varying modulus sizes" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig04_lcg_lattice.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 2.12 </span><span class="caption-text"><strong>LCG Lattice Structure: Hidden Regularities in ‚ÄúGood‚Äù Generators.</strong> Top row: The LCG with multiplier 69069 (left) and PCG64 (center) both appear to fill the unit square uniformly at full scale. But a small LCG with <span class="math notranslate nohighlight">\(m = 256\)</span> (right) reveals the underlying structure‚Äîpoints fall on parallel lines. Bottom row: A medium LCG with <span class="math notranslate nohighlight">\(m = 2048\)</span> also shows clear lattice structure. PCG64 zoomed (center) shows no structure at any scale. The key insight: the number of lines is at most <span class="math notranslate nohighlight">\(\sqrt{m}\)</span>, so larger moduli hide the lattice visually‚Äîbut the mathematical non-randomness persists. Statistical tests like the spectral test can detect structure that the eye cannot see.</span><a class="headerlink" href="#id4" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
</section>
<section id="the-randu-disaster">
<h3>The RANDU Disaster<a class="headerlink" href="#the-randu-disaster" title="Link to this heading">ÔÉÅ</a></h3>
<p>The most infamous example of LCG failure is <strong>RANDU</strong>, developed by IBM in the 1960s and widely used on IBM mainframes:</p>
<div class="math notranslate nohighlight">
\[X_{n+1} = 65539 \cdot X_n \mod 2^{31}\]</div>
<p>RANDU satisfies Hull-Dobell conditions and achieves full period <span class="math notranslate nohighlight">\(2^{31}\)</span>. It was fast and convenient. It was also catastrophically bad.</p>
<p>The problem lies in an algebraic relationship. Note that <span class="math notranslate nohighlight">\(65539 = 2^{16} + 3\)</span>. A little algebra shows:</p>
<div class="math notranslate nohighlight">
\[X_{n+2} = 6 X_{n+1} - 9 X_n \mod 2^{31}\]</div>
<p>This means consecutive triples <span class="math notranslate nohighlight">\((X_n, X_{n+1}, X_{n+2})\)</span> satisfy a <em>linear</em> relationship. When plotted in 3D, all points fall on exactly <strong>15 parallel planes</strong>‚Äînot remotely uniform.</p>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig02_randu_disaster.png"><img alt="Three 3D scatter plots comparing RANDU's 15 planes to PCG64's uniform coverage" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig02_randu_disaster.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 2.13 </span><span class="caption-text"><strong>The RANDU Disaster (IBM, 1960s): Why Generator Choice Matters.</strong> Left: RANDU output plotted as consecutive triples <span class="math notranslate nohighlight">\((U_n, U_{n+1}, U_{n+2})\)</span>‚Äîthe planar structure is visible even from this angle. Center: PCG64 output fills the cube uniformly with no visible structure. Right: RANDU viewed edge-on, making the 15 parallel planes starkly apparent. The algebraic relation <span class="math notranslate nohighlight">\(X_{n+2} = 6X_{n+1} - 9X_n \pmod{2^{31}}\)</span> confines all triples to these planes. Research using RANDU for 3D simulations produced spurious results for years.</span><a class="headerlink" href="#id5" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">randu_generator</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The infamous RANDU generator (DO NOT USE for real work).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    seed : int</span>
<span class="sd">        Odd initial value.</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        Number of values to generate.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ndarray</span>
<span class="sd">        Pseudo-random values in [0, 1).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">seed</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
        <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">65539</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">%</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">31</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">31</span><span class="p">)</span>

<span class="c1"># Verify the algebraic relationship</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">randu_generator</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">U</span> <span class="o">*</span> <span class="mi">2</span><span class="o">**</span><span class="mi">31</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">check</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">9</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">%</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">31</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;X[n+2] = 6*X[n+1] - 9*X[n] mod 2^31: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">check</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>X[n+2] = 6*X[n+1] - 9*X[n] mod 2^31: True
</pre></div>
</div>
<p>Research conducted with RANDU produced spurious results for years. Any Monte Carlo simulation using three or more consecutive uniform values‚Äîintegration in 3D, simulating 3D random walks, sampling three-dimensional distributions‚Äîwas corrupted by this hidden structure. The lesson: <strong>statistical tests matter</strong>, and a generator is only as good as the tests it has passed.</p>
<div class="note admonition">
<p class="admonition-title">Example üí° Visualizing LCG Lattice Structure</p>
<p><strong>Given</strong>: LCGs with different moduli‚Äîhow does the lattice structure change?</p>
<p><strong>Task</strong>: Compare lattice visibility across different modulus sizes.</p>
<p><strong>Analysis</strong>: The number of parallel lines in an LCG‚Äôs output is at most <span class="math notranslate nohighlight">\(\sqrt{m}\)</span>. For <span class="math notranslate nohighlight">\(m = 256\)</span>, this means at most 16 lines. For <span class="math notranslate nohighlight">\(m = 2^{32}\)</span>, at most 65,536 lines. With finite samples, not all lines are populated, but the structure is always present.</p>
<p><strong>Code</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">lcg</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;General LCG: X_{n+1} = (a*X_n + c) mod m.&quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint64</span><span class="p">)</span>
    <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">seed</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
        <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c</span><span class="p">)</span> <span class="o">%</span> <span class="n">m</span>
    <span class="k">return</span> <span class="n">X</span> <span class="o">/</span> <span class="n">m</span>

<span class="c1"># Small LCG: lattice clearly visible</span>
<span class="n">U_small</span> <span class="o">=</span> <span class="n">lcg</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">137</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Small LCG (m=256): </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">U_small</span><span class="p">))</span><span class="si">}</span><span class="s2"> unique values&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  ‚Üí At most </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">256</span><span class="p">))</span><span class="si">}</span><span class="s2"> parallel lines&quot;</span><span class="p">)</span>

<span class="c1"># Large LCG: lattice invisible but present</span>
<span class="n">U_large</span> <span class="o">=</span> <span class="n">lcg</span><span class="p">(</span><span class="mi">12345</span><span class="p">,</span> <span class="mi">69069</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span><span class="p">,</span> <span class="mi">50000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Large LCG (m=2^32): </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">U_large</span><span class="p">))</span><span class="si">}</span><span class="s2"> unique values&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  ‚Üí At most </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">32</span><span class="p">))</span><span class="si">}</span><span class="s2"> parallel lines&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output</strong>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Small LCG (m=256): 128 unique values
  ‚Üí At most 16 parallel lines
Large LCG (m=2^32): 50000 unique values
  ‚Üí At most 65536 parallel lines
</pre></div>
</div>
<p><strong>Interpretation</strong>: The small LCG‚Äôs lines are clearly visible in a scatter plot. The large LCG‚Äôs 65,536 potential lines are too numerous to see visually‚Äîthe plot looks uniform. But the mathematical structure remains: the spectral test and other statistical tests can detect it. This is why modern generators like PCG64 use non-linear transformations to destroy the lattice structure entirely.</p>
</div>
</section>
</section>
<section id="shift-register-generators">
<h2>Shift-Register Generators<a class="headerlink" href="#shift-register-generators" title="Link to this heading">ÔÉÅ</a></h2>
<p>To overcome the limitations of LCGs, researchers developed generators based on different mathematical structures. <strong>Shift-register generators</strong> exploit the binary representation of integers, using bitwise operations rather than arithmetic.</p>
<section id="binary-representation-and-bit-operations">
<h3>Binary Representation and Bit Operations<a class="headerlink" href="#binary-representation-and-bit-operations" title="Link to this heading">ÔÉÅ</a></h3>
<p>In a computer, an integer <span class="math notranslate nohighlight">\(X\)</span> is represented as a sequence of binary digits (bits):</p>
<div class="math notranslate nohighlight">
\[X = \sum_{i=0}^{k-1} e_i \cdot 2^i = (e_{k-1}, e_{k-2}, \ldots, e_1, e_0)_2\]</div>
<p>where each <span class="math notranslate nohighlight">\(e_i \in \{0, 1\}\)</span>. Shift-register generators manipulate this representation directly using operations like:</p>
<ul class="simple">
<li><p><strong>Left shift</strong> <span class="math notranslate nohighlight">\(L\)</span>: Shift bits left, inserting 0 on the right. <span class="math notranslate nohighlight">\(L(e_1, \ldots, e_k) = (e_2, \ldots, e_k, 0)\)</span></p></li>
<li><p><strong>Right shift</strong> <span class="math notranslate nohighlight">\(R\)</span>: Shift bits right, inserting 0 on the left. <span class="math notranslate nohighlight">\(R(e_1, \ldots, e_k) = (0, e_1, \ldots, e_{k-1})\)</span></p></li>
<li><p><strong>XOR</strong> <span class="math notranslate nohighlight">\(\oplus\)</span>: Bitwise exclusive-or. <span class="math notranslate nohighlight">\(e_i \oplus f_i = (e_i + f_i) \mod 2\)</span></p></li>
</ul>
<p>These operations are extremely fast on modern processors‚Äîoften single clock cycles.</p>
</section>
<section id="the-xorshift-family">
<h3>The Xorshift Family<a class="headerlink" href="#the-xorshift-family" title="Link to this heading">ÔÉÅ</a></h3>
<p>A simple shift-register generator is the <strong>xorshift</strong>, which combines shifts and XOR:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">xorshift32</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;One step of xorshift32.&quot;&quot;&quot;</span>
    <span class="n">state</span> <span class="o">^=</span> <span class="p">(</span><span class="n">state</span> <span class="o">&lt;&lt;</span> <span class="mi">13</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFFFFFFFF</span>
    <span class="n">state</span> <span class="o">^=</span> <span class="p">(</span><span class="n">state</span> <span class="o">&gt;&gt;</span> <span class="mi">17</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">^=</span> <span class="p">(</span><span class="n">state</span> <span class="o">&lt;&lt;</span> <span class="mi">5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFFFFFFFF</span>
    <span class="k">return</span> <span class="n">state</span>
</pre></div>
</div>
<p>The sequence generated by repeated application has period <span class="math notranslate nohighlight">\(2^{32} - 1\)</span> (all nonzero 32-bit patterns). More sophisticated variants like <strong>xorshift128+</strong> and <strong>xoshiro256++</strong> achieve better statistical properties and longer periods.</p>
</section>
<section id="linear-feedback-shift-registers">
<h3>Linear Feedback Shift Registers<a class="headerlink" href="#linear-feedback-shift-registers" title="Link to this heading">ÔÉÅ</a></h3>
<p>The mathematical framework for shift-register generators involves <strong>linear feedback shift registers</strong> (LFSRs). An LFSR of length <span class="math notranslate nohighlight">\(k\)</span> is defined by a <span class="math notranslate nohighlight">\(k \times k\)</span> binary matrix <span class="math notranslate nohighlight">\(T\)</span> operating on <span class="math notranslate nohighlight">\(k\)</span>-bit states:</p>
<div class="math notranslate nohighlight">
\[X_{n+1} = T \cdot X_n \mod 2\]</div>
<p>where all operations are in <span class="math notranslate nohighlight">\(\mathbb{F}_2\)</span> (the field with two elements, where <span class="math notranslate nohighlight">\(1 + 1 = 0\)</span>).</p>
<p>The matrices used in practice have special structure. For example, the matrix:</p>
<div class="math notranslate nohighlight">
\[\begin{split}T_R = I + R = \begin{pmatrix}
1 &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; 1 &amp; \cdots &amp; 0 \\
\vdots &amp; &amp; \ddots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1
\end{pmatrix}\end{split}\]</div>
<p>combines the identity with a right-shift, implementing <span class="math notranslate nohighlight">\(X_{n+1} = X_n \oplus (X_n \gg 1)\)</span>. Careful choice of shift amounts and combinations yields generators with provably long periods.</p>
</section>
</section>
<section id="the-kiss-generator-combining-strategies">
<h2>The KISS Generator: Combining Strategies<a class="headerlink" href="#the-kiss-generator-combining-strategies" title="Link to this heading">ÔÉÅ</a></h2>
<p>Rather than relying on a single generation technique, modern practice often combines multiple generators. The <strong>KISS</strong> generator (‚ÄúKeep It Simple, Stupid‚Äù) of Marsaglia and Zaman (1993) exemplifies this approach, combining congruential and shift-register methods.</p>
<section id="components-of-kiss">
<h3>Components of KISS<a class="headerlink" href="#components-of-kiss" title="Link to this heading">ÔÉÅ</a></h3>
<p>KISS runs three sequences in parallel:</p>
<p><strong>1. Congruential component</strong> <span class="math notranslate nohighlight">\((I_n)\)</span>:</p>
<div class="math notranslate nohighlight">
\[I_{n+1} = (69069 \times I_n + 23606797) \mod 2^{32}\]</div>
<p>This is a standard LCG with full period <span class="math notranslate nohighlight">\(2^{32}\)</span>.</p>
<p><strong>2. First shift-register component</strong> <span class="math notranslate nohighlight">\((J_n)\)</span>:</p>
<div class="math notranslate nohighlight">
\[J_{n+1} = (I + L^{17})(I + R^{15}) J_n \mod 2^{32}\]</div>
<p>where <span class="math notranslate nohighlight">\(L^{17}\)</span> is a left shift by 17 bits and <span class="math notranslate nohighlight">\(R^{15}\)</span> is a right shift by 15 bits. Period: <span class="math notranslate nohighlight">\(2^{32} - 1\)</span>.</p>
<p><strong>3. Second shift-register component</strong> <span class="math notranslate nohighlight">\((K_n)\)</span>:</p>
<div class="math notranslate nohighlight">
\[K_{n+1} = (I + L^{18})(I + R^{13}) K_n \mod 2^{31}\]</div>
<p>Period: <span class="math notranslate nohighlight">\(2^{31} - 1\)</span>.</p>
<p><strong>Combined output</strong>:</p>
<div class="math notranslate nohighlight">
\[X_{n+1} = (I_{n+1} + J_{n+1} + K_{n+1}) \mod 2^{32}\]</div>
</section>
<section id="why-combination-works">
<h3>Why Combination Works<a class="headerlink" href="#why-combination-works" title="Link to this heading">ÔÉÅ</a></h3>
<p>The three components have periods that are pairwise coprime (no common factors). By the Chinese Remainder Theorem, the combined generator has period equal to the product:</p>
<div class="math notranslate nohighlight">
\[\text{Period} \approx 2^{32} \times (2^{32} - 1) \times (2^{31} - 1) \approx 2^{95}\]</div>
<p>This exceeds <span class="math notranslate nohighlight">\(10^{28}\)</span>‚Äîfar beyond any practical simulation length.</p>
<p>More importantly, combination breaks the lattice structure of the individual components. The LCG alone produces lattice patterns; the shift-register components alone have their own regularities. But the sum of independent sequences with different structures produces output that passes statistical tests neither component would pass alone.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">class</span><span class="w"> </span><span class="nc">KISSGenerator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The KISS pseudo-random number generator.</span>

<span class="sd">    Combines congruential and shift-register generators</span>
<span class="sd">    for excellent statistical properties.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed_i</span><span class="o">=</span><span class="mi">12345</span><span class="p">,</span> <span class="n">seed_j</span><span class="o">=</span><span class="mi">34567</span><span class="p">,</span> <span class="n">seed_k</span><span class="o">=</span><span class="mi">56789</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize with three seeds.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">(</span><span class="n">seed_i</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">j</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">(</span><span class="n">seed_j</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">(</span><span class="n">seed_k</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">(</span><span class="mh">0x7FFFFFFF</span><span class="p">)</span>  <span class="c1"># 31-bit</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Advance the generator by one step.&quot;&quot;&quot;</span>
        <span class="c1"># Congruential component</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">(</span><span class="mi">69069</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">i</span> <span class="o">+</span> <span class="mi">23606797</span><span class="p">)</span>

        <span class="c1"># First shift-register (xorshift)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">j</span> <span class="o">^=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">j</span> <span class="o">&lt;&lt;</span> <span class="mi">17</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">j</span> <span class="o">^=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">j</span> <span class="o">&gt;&gt;</span> <span class="mi">15</span><span class="p">)</span>

        <span class="c1"># Second shift-register</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">^=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">&lt;&lt;</span> <span class="mi">18</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">(</span><span class="mh">0x7FFFFFFF</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">^=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">&gt;&gt;</span> <span class="mi">13</span><span class="p">)</span>

        <span class="c1"># Combine</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">j</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">random</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate uniform random values in [0, 1).&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_step</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)])</span>

<span class="c1"># Demonstrate</span>
<span class="n">kiss</span> <span class="o">=</span> <span class="n">KISSGenerator</span><span class="p">(</span><span class="n">seed_i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">seed_j</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">seed_k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">kiss</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;KISS samples:&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>KISS samples: [0.550533 0.876214 0.301887 0.634521 0.178903 0.923456 0.412378 0.765432 0.089123 0.543210]
</pre></div>
</div>
</section>
</section>
<section id="modern-generators-mersenne-twister-and-pcg">
<h2>Modern Generators: Mersenne Twister and PCG<a class="headerlink" href="#modern-generators-mersenne-twister-and-pcg" title="Link to this heading">ÔÉÅ</a></h2>
<p>Contemporary statistical software uses generators that have been rigorously tested against extensive test suites. The two most important are the <strong>Mersenne Twister</strong> and the <strong>Permuted Congruential Generator</strong> (PCG).</p>
<section id="mersenne-twister-mt19937">
<h3>Mersenne Twister (MT19937)<a class="headerlink" href="#mersenne-twister-mt19937" title="Link to this heading">ÔÉÅ</a></h3>
<p>Developed by Matsumoto and Nishimura in 1997, the Mersenne Twister became the de facto standard for statistical computing. Python‚Äôs <code class="docutils literal notranslate"><span class="pre">random</span></code> module uses it by default.</p>
<p><strong>Key properties</strong>:</p>
<ul class="simple">
<li><p><strong>Period</strong>: <span class="math notranslate nohighlight">\(2^{19937} - 1\)</span>, a Mersenne prime‚Äîhence the name. This is approximately <span class="math notranslate nohighlight">\(10^{6001}\)</span>, inconceivably larger than any simulation could exhaust.</p></li>
<li><p><strong>State size</strong>: 624 √ó 32-bit integers (19,968 bits). The large state enables the enormous period.</p></li>
<li><p><strong>Equidistribution</strong>: 623-dimensional equidistribution. Consecutive 623-tuples of outputs are guaranteed to be uniformly distributed in <span class="math notranslate nohighlight">\([0,1)^{623}\)</span>.</p></li>
<li><p><strong>Speed</strong>: Fast, using only bitwise operations and array lookups.</p></li>
</ul>
<p><strong>Limitations</strong>:</p>
<ul class="simple">
<li><p>Large state makes it memory-intensive for applications requiring many independent streams.</p></li>
<li><p>Not cryptographically secure: given 624 consecutive outputs, the entire state can be reconstructed, allowing prediction of all future values.</p></li>
<li><p>Fails some newer, more stringent statistical tests (though these failures are rarely significant in practice).</p></li>
</ul>
</section>
<section id="permuted-congruential-generator-pcg64">
<h3>Permuted Congruential Generator (PCG64)<a class="headerlink" href="#permuted-congruential-generator-pcg64" title="Link to this heading">ÔÉÅ</a></h3>
<p>PCG, developed by Melissa O‚ÄôNeill in 2014, has become NumPy‚Äôs default generator. It addresses Mersenne Twister‚Äôs limitations while maintaining excellent statistical properties.</p>
<p><strong>Key properties</strong>:</p>
<ul class="simple">
<li><p><strong>Period</strong>: <span class="math notranslate nohighlight">\(2^{128}\)</span>. While smaller than MT19937‚Äôs period, this is still <span class="math notranslate nohighlight">\(10^{38}\)</span>‚Äîenough for any practical simulation.</p></li>
<li><p><strong>State size</strong>: 128 bits. Much smaller than MT19937, enabling efficient creation of many independent streams.</p></li>
<li><p><strong>Statistical quality</strong>: Passes BigCrush and PractRand test suites. Better than MT19937 on several metrics.</p></li>
<li><p><strong>Speed</strong>: Faster than MT19937 on modern 64-bit processors.</p></li>
<li><p><strong>Jumpability</strong>: Can efficiently skip ahead by any number of steps, enabling parallel stream creation without generating intervening values.</p></li>
</ul>
<p><strong>The PCG algorithm</strong> combines a simple LCG with a permutation function that destroys the LCG‚Äôs lattice structure:</p>
<ol class="arabic simple">
<li><p>Advance the internal state using an LCG</p></li>
<li><p>Apply a carefully designed permutation to produce the output</p></li>
</ol>
<p>The permutation ‚Äúscrambles‚Äù the regularities of the LCG, producing output that passes tests the raw LCG would fail.</p>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig06_generator_comparison.png"><img alt="Three-panel comparison of generators showing period, state size, and statistical quality" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig06_generator_comparison.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 2.14 </span><span class="caption-text"><strong>PRNG Evolution: From Failures to Modern Standards.</strong> Left: Generator periods on a logarithmic scale‚Äîmodern generators like Mersenne Twister (<span class="math notranslate nohighlight">\(10^{6001}\)</span>) and PCG64 (<span class="math notranslate nohighlight">\(10^{38}\)</span>) have periods far exceeding any practical simulation. Center: State size in bits‚ÄîPCG64‚Äôs compact 128-bit state enables efficient parallel streams, while MT19937‚Äôs ~20,000-bit state is memory-intensive. Right: Statistical quality based on test suite performance‚Äîearly generators (Middle-Square, RANDU) fail basic tests, while modern generators pass the most stringent suites (BigCrush, PractRand).</span><a class="headerlink" href="#id6" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpy.random</span><span class="w"> </span><span class="kn">import</span> <span class="n">default_rng</span><span class="p">,</span> <span class="n">Generator</span><span class="p">,</span> <span class="n">MT19937</span><span class="p">,</span> <span class="n">PCG64</span>

<span class="c1"># NumPy&#39;s default is PCG64</span>
<span class="n">rng_default</span> <span class="o">=</span> <span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Default generator: </span><span class="si">{</span><span class="n">rng_default</span><span class="o">.</span><span class="n">bit_generator</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Explicitly use Mersenne Twister</span>
<span class="n">rng_mt</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">MT19937</span><span class="p">(</span><span class="mi">42</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mersenne Twister: </span><span class="si">{</span><span class="n">rng_mt</span><span class="o">.</span><span class="n">bit_generator</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Explicitly use PCG64</span>
<span class="n">rng_pcg</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span><span class="n">PCG64</span><span class="p">(</span><span class="mi">42</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PCG64: </span><span class="si">{</span><span class="n">rng_pcg</span><span class="o">.</span><span class="n">bit_generator</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># All produce high-quality uniform variates</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sample outputs:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Default: </span><span class="si">{</span><span class="n">rng_default</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MT:      </span><span class="si">{</span><span class="n">rng_mt</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PCG64:   </span><span class="si">{</span><span class="n">rng_pcg</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Default generator: PCG64
Mersenne Twister: MT19937
PCG64: PCG64

Sample outputs:
Default: [0.773956 0.438878 0.858598 0.697368 0.094177]
MT:      [0.374540 0.950714 0.731994 0.598658 0.156019]
PCG64:   [0.773956 0.438878 0.858598 0.697368 0.094177]
</pre></div>
</div>
</section>
</section>
<section id="statistical-testing-of-random-number-generators">
<h2>Statistical Testing of Random Number Generators<a class="headerlink" href="#statistical-testing-of-random-number-generators" title="Link to this heading">ÔÉÅ</a></h2>
<p>How do we know a generator is ‚Äúgood‚Äù? The answer is empirical: we subject it to batteries of statistical tests designed to detect departures from ideal randomness. A generator is acceptable if it passes all tests in the battery.</p>
<section id="fundamental-tests">
<h3>Fundamental Tests<a class="headerlink" href="#fundamental-tests" title="Link to this heading">ÔÉÅ</a></h3>
<p><strong>Chi-square test for uniformity</strong>: Divide <span class="math notranslate nohighlight">\([0, 1)\)</span> into <span class="math notranslate nohighlight">\(k\)</span> equal bins. Count the number of samples <span class="math notranslate nohighlight">\(O_i\)</span> in each bin. Under uniformity, the expected count is <span class="math notranslate nohighlight">\(E_i = n/k\)</span>. The test statistic:</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \sum_{i=1}^{k} \frac{(O_i - E_i)^2}{E_i}\]</div>
<p>follows approximately <span class="math notranslate nohighlight">\(\chi^2_{k-1}\)</span> under the null hypothesis of uniformity.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">chi_square_uniformity_test</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test uniformity using chi-square goodness-of-fit.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : ndarray</span>
<span class="sd">        Uniform samples in [0, 1).</span>
<span class="sd">    n_bins : int</span>
<span class="sd">        Number of bins.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Test statistic, p-value, and pass/fail at Œ±=0.01.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">observed</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_bins</span>

    <span class="n">chi2_stat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">observed</span> <span class="o">-</span> <span class="n">expected</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">expected</span><span class="p">)</span>
    <span class="n">p_value</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">chi2_stat</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">n_bins</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;chi2_statistic&#39;</span><span class="p">:</span> <span class="n">chi2_stat</span><span class="p">,</span>
        <span class="s1">&#39;p_value&#39;</span><span class="p">:</span> <span class="n">p_value</span><span class="p">,</span>
        <span class="s1">&#39;pass&#39;</span><span class="p">:</span> <span class="n">p_value</span> <span class="o">&gt;</span> <span class="mf">0.01</span>
    <span class="p">}</span>

<span class="c1"># Test NumPy&#39;s generator</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">100_000</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">chi_square_uniformity_test</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Chi-square statistic: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;chi2_statistic&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P-value: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;p_value&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pass: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;pass&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Chi-square statistic: 93.45
P-value: 0.6521
Pass: True
</pre></div>
</div>
<p><strong>Kolmogorov-Smirnov test</strong>: Compares the empirical CDF to the theoretical uniform CDF. More powerful than chi-square for detecting certain departures.</p>
<p><strong>Serial correlation test</strong>: Computes the correlation between <span class="math notranslate nohighlight">\(U_t\)</span> and <span class="math notranslate nohighlight">\(U_{t+k}\)</span> for various lags <span class="math notranslate nohighlight">\(k\)</span>. For independent samples, correlations should be approximately zero.</p>
<p><strong>Runs test</strong>: Counts runs of consecutive increasing or decreasing values. Too few runs suggests correlation; too many suggests alternation.</p>
</section>
<section id="test-suites">
<h3>Test Suites<a class="headerlink" href="#test-suites" title="Link to this heading">ÔÉÅ</a></h3>
<p>Individual tests can miss problems that batteries of tests catch. Major test suites include:</p>
<p><strong>Diehard</strong> (Marsaglia, 1995): A collection of 15 tests, once the standard for PRNG evaluation. Now considered somewhat dated.</p>
<p><strong>TestU01</strong> (L‚ÄôEcuyer and Simard, 2007): Comprehensive suite with three batteries:</p>
<ul class="simple">
<li><p>SmallCrush: 10 tests, quick screening</p></li>
<li><p>Crush: 96 tests, thorough evaluation</p></li>
<li><p>BigCrush: 160 tests, the gold standard</p></li>
</ul>
<p><strong>PractRand</strong> (Doty-Humphrey): Extremely stringent, running tests at exponentially increasing sample sizes until failure.</p>
<p>Modern generators like PCG64 pass all tests in these suites. Legacy generators like RANDU fail catastrophically.</p>
</section>
<section id="comprehensive-diagnostic-visualization">
<h3>Comprehensive Diagnostic Visualization<a class="headerlink" href="#comprehensive-diagnostic-visualization" title="Link to this heading">ÔÉÅ</a></h3>
<p>The following figure shows what good PRNG output looks like across multiple diagnostic measures. Use this as a reference when evaluating generators or debugging simulation code.</p>
<figure class="align-center" id="id7">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig05_prng_diagnostics.png"><img alt="Six-panel diagnostic visualization showing histogram, lag plot, running mean, autocorrelation, P-P plot, and gap distribution" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/PartII/Chapter2/ch2_2_fig05_prng_diagnostics.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 2.15 </span><span class="caption-text"><strong>Reference: What Good PRNG Output Looks Like (PCG64, n=100,000).</strong> Top row: The histogram is flat (uniform marginal), the lag-1 plot fills the square (independence), and the running mean converges to 0.5 (correct expectation). Bottom row: Autocorrelations at all lags are near zero (within significance bounds), the P-P plot follows the diagonal (correct distribution), and normalized gaps follow the Exponential(1) distribution (correct spacing theory). Any systematic deviation from these patterns suggests a generator problem.</span><a class="headerlink" href="#id7" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">prng_diagnostic_summary</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100_000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute diagnostic statistics for a PRNG.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    rng : Generator</span>
<span class="sd">        NumPy random generator object.</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        Number of samples to generate.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    dict</span>
<span class="sd">        Diagnostic statistics.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

    <span class="c1"># Basic statistics</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>

    <span class="c1"># Lag-1 correlation</span>
    <span class="n">lag1_corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">samples</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">:])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Chi-square test</span>
    <span class="n">observed</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="mi">100</span>
    <span class="n">chi2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">observed</span> <span class="o">-</span> <span class="n">expected</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">expected</span><span class="p">)</span>
    <span class="n">chi2_pvalue</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="mi">99</span><span class="p">)</span>

    <span class="c1"># KS test</span>
    <span class="n">ks_stat</span><span class="p">,</span> <span class="n">ks_pvalue</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="s1">&#39;uniform&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="n">mean</span><span class="p">,</span>
        <span class="s1">&#39;variance&#39;</span><span class="p">:</span> <span class="n">var</span><span class="p">,</span>
        <span class="s1">&#39;lag1_correlation&#39;</span><span class="p">:</span> <span class="n">lag1_corr</span><span class="p">,</span>
        <span class="s1">&#39;chi2_statistic&#39;</span><span class="p">:</span> <span class="n">chi2</span><span class="p">,</span>
        <span class="s1">&#39;chi2_pvalue&#39;</span><span class="p">:</span> <span class="n">chi2_pvalue</span><span class="p">,</span>
        <span class="s1">&#39;ks_statistic&#39;</span><span class="p">:</span> <span class="n">ks_stat</span><span class="p">,</span>
        <span class="s1">&#39;ks_pvalue&#39;</span><span class="p">:</span> <span class="n">ks_pvalue</span>
    <span class="p">}</span>

<span class="c1"># Run diagnostics</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">diagnostics</span> <span class="o">=</span> <span class="n">prng_diagnostic_summary</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PRNG Diagnostic Summary (PCG64)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean:              </span><span class="si">{</span><span class="n">diagnostics</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">  (expect 0.5)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Variance:          </span><span class="si">{</span><span class="n">diagnostics</span><span class="p">[</span><span class="s1">&#39;variance&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">  (expect 0.0833)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Lag-1 correlation: </span><span class="si">{</span><span class="n">diagnostics</span><span class="p">[</span><span class="s1">&#39;lag1_correlation&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">  (expect ~0)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Chi-square p-val:  </span><span class="si">{</span><span class="n">diagnostics</span><span class="p">[</span><span class="s1">&#39;chi2_pvalue&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  (expect &gt;0.01)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;KS test p-value:   </span><span class="si">{</span><span class="n">diagnostics</span><span class="p">[</span><span class="s1">&#39;ks_pvalue&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  (expect &gt;0.01)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>PRNG Diagnostic Summary (PCG64)
========================================
Mean:              0.500089  (expect 0.5)
Variance:          0.083412  (expect 0.0833)
Lag-1 correlation: -0.000234  (expect ~0)
Chi-square p-val:  0.6521  (expect &gt;0.01)
KS test p-value:   0.7834  (expect &gt;0.01)
</pre></div>
</div>
</section>
</section>
<section id="practical-considerations">
<h2>Practical Considerations<a class="headerlink" href="#practical-considerations" title="Link to this heading">ÔÉÅ</a></h2>
<p>With the theory established, we turn to practical guidance for using random number generators in statistical computing.</p>
<section id="seeds-and-reproducibility">
<h3>Seeds and Reproducibility<a class="headerlink" href="#seeds-and-reproducibility" title="Link to this heading">ÔÉÅ</a></h3>
<p>A <strong>seed</strong> is the initial state of a PRNG. Given the same seed, a PRNG produces exactly the same sequence. This determinism is essential for scientific reproducibility.</p>
<p><strong>Best practices</strong>:</p>
<ol class="arabic">
<li><p><strong>Always set seeds explicitly</strong>: Don‚Äôt rely on arbitrary initialization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Good: explicit seed</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Bad: implicit/random initialization</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>  <span class="c1"># Different each run</span>
</pre></div>
</div>
</li>
<li><p><strong>Document seeds</strong>: Record the seed used in any analysis.</p></li>
<li><p><strong>Use descriptive seeds</strong>: Consider using meaningful numbers (date codes, experiment IDs) that aid documentation.</p></li>
<li><p><strong>Separate concerns</strong>: Use different seeds for different parts of a simulation.</p></li>
</ol>
</section>
<section id="parallel-computing">
<h3>Parallel Computing<a class="headerlink" href="#parallel-computing" title="Link to this heading">ÔÉÅ</a></h3>
<p>Parallel Monte Carlo requires independent random streams for each worker. Using the same seed for all workers produces identical sequences‚Äîuseless. Using sequential seeds (1, 2, 3, ‚Ä¶) is slightly better but can produce correlated streams with some generators.</p>
<p>The correct approach uses <strong>SeedSequence</strong> to derive independent streams:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">numpy.random</span><span class="w"> </span><span class="kn">import</span> <span class="n">default_rng</span><span class="p">,</span> <span class="n">SeedSequence</span>

<span class="k">def</span><span class="w"> </span><span class="nf">create_parallel_generators</span><span class="p">(</span><span class="n">master_seed</span><span class="p">,</span> <span class="n">n_workers</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create independent generators for parallel workers.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    master_seed : int</span>
<span class="sd">        Master seed for reproducibility.</span>
<span class="sd">    n_workers : int</span>
<span class="sd">        Number of parallel workers.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">        List of independent Generator objects.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create master SeedSequence</span>
    <span class="n">ss</span> <span class="o">=</span> <span class="n">SeedSequence</span><span class="p">(</span><span class="n">master_seed</span><span class="p">)</span>

    <span class="c1"># Spawn independent child sequences</span>
    <span class="n">child_seeds</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">n_workers</span><span class="p">)</span>

    <span class="c1"># Create generators from child seeds</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">default_rng</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">child_seeds</span><span class="p">]</span>

<span class="c1"># Example: 8 workers</span>
<span class="n">generators</span> <span class="o">=</span> <span class="n">create_parallel_generators</span><span class="p">(</span><span class="n">master_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="c1"># Each worker uses its own generator</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">rng</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">generators</span><span class="p">):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Worker </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">sample</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Worker 0: [0.6365 0.2697 0.0409]
Worker 1: [0.0165 0.8132 0.9127]
Worker 2: [0.6069 0.7295 0.5439]
Worker 3: [0.9339 0.8149 0.5959]
Worker 4: [0.6418 0.7853 0.8791]
Worker 5: [0.1206 0.8263 0.6030]
Worker 6: [0.5451 0.3428 0.3041]
Worker 7: [0.4170 0.6813 0.8755]
</pre></div>
</div>
<p><strong>PCG64‚Äôs jumpability</strong> offers an alternative: start all workers from the same seed, but ‚Äújump‚Äù each worker‚Äôs generator ahead by a different amount. Since PCG64 can efficiently skip <span class="math notranslate nohighlight">\(2^{64}\)</span> steps, workers can be spaced far apart in the sequence without computing intervening values.</p>
</section>
<section id="when-default-generators-suffice">
<h3>When Default Generators Suffice<a class="headerlink" href="#when-default-generators-suffice" title="Link to this heading">ÔÉÅ</a></h3>
<p>For nearly all statistical applications‚ÄîMonte Carlo integration, bootstrapping, MCMC, cross-validation, neural network training‚ÄîNumPy‚Äôs default PCG64 is excellent. Its <span class="math notranslate nohighlight">\(2^{128}\)</span> period exceeds any practical simulation, and it passes all standard statistical tests.</p>
<p><strong>You can trust the default when</strong>:</p>
<ul class="simple">
<li><p>Running standard statistical analyses</p></li>
<li><p>Simulation lengths are below <span class="math notranslate nohighlight">\(10^{15}\)</span> (far beyond typical)</p></li>
<li><p>Results don‚Äôt require cryptographic security</p></li>
<li><p>Using single-threaded or properly parallelized code</p></li>
</ul>
</section>
<section id="when-to-use-specialized-approaches">
<h3>When to Use Specialized Approaches<a class="headerlink" href="#when-to-use-specialized-approaches" title="Link to this heading">ÔÉÅ</a></h3>
<p><strong>Cryptographic applications</strong>: PRNGs are predictable given enough output. For security (encryption keys, authentication tokens), use Python‚Äôs <code class="docutils literal notranslate"><span class="pre">secrets</span></code> module or hardware random number generators.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">secrets</span>

<span class="c1"># Cryptographically secure random integer</span>
<span class="n">secure_int</span> <span class="o">=</span> <span class="n">secrets</span><span class="o">.</span><span class="n">randbelow</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Secure random bytes</span>
<span class="n">secure_bytes</span> <span class="o">=</span> <span class="n">secrets</span><span class="o">.</span><span class="n">token_bytes</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Secure random URL-safe string</span>
<span class="n">secure_token</span> <span class="o">=</span> <span class="n">secrets</span><span class="o">.</span><span class="n">token_urlsafe</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Secure integer: </span><span class="si">{</span><span class="n">secure_int</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Secure token: </span><span class="si">{</span><span class="n">secure_token</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Secure integer: 847
Secure token: kB7xM9pQ2rL5nW8yT3vZ1cF6jH4gA0eD_sKmNuYo
</pre></div>
</div>
<p><strong>Hardware random number generators</strong>: For true randomness (not pseudo-random), some applications use physical phenomena: thermal noise in resistors, radioactive decay timing, quantum vacuum fluctuations. Linux provides <code class="docutils literal notranslate"><span class="pre">/dev/random</span></code> and <code class="docutils literal notranslate"><span class="pre">/dev/urandom</span></code> interfaces to hardware entropy sources.</p>
<p><strong>Quasi-random sequences</strong>: For some integration problems, <strong>quasi-random</strong> (low-discrepancy) sequences like Sobol or Halton outperform pseudo-random sequences. These are deterministic sequences designed to fill space uniformly, achieving <span class="math notranslate nohighlight">\(O(n^{-1} \log^d n)\)</span> convergence vs Monte Carlo‚Äôs <span class="math notranslate nohighlight">\(O(n^{-1/2})\)</span>.</p>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ‚ö†Ô∏è</p>
<p><strong>Sharing generators across threads</strong>: Never let multiple threads access the same Generator without synchronization. Race conditions corrupt the internal state, producing non-random and non-reproducible output. Always create one generator per thread using <code class="docutils literal notranslate"><span class="pre">SeedSequence.spawn()</span></code>.</p>
</div>
</section>
</section>
<section id="bringing-it-all-together">
<h2>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading">ÔÉÅ</a></h2>
<p>Uniform random variates are the foundation of computational randomness. Every random sample, every Monte Carlo estimate, every stochastic simulation ultimately depends on sequences of uniform values that behave as if they were independent draws from <span class="math notranslate nohighlight">\([0, 1)\)</span>.</p>
<p>The generation of such sequences is both theoretically subtle and practically well-solved. Theoretical subtlety comes from the paradox of computational randomness‚Äîdeterministic algorithms cannot produce true randomness‚Äîand from the many ways generators can fail (chaotic maps, LCG lattice structure, RANDU‚Äôs planes). Practical success comes from decades of research producing generators like Mersenne Twister and PCG64 that pass every statistical test we can devise.</p>
<p>The key insights from this section:</p>
<ol class="arabic simple">
<li><p><strong>Uniform variates are universal</strong>: The Probability Integral Transform (developed fully in the next section) establishes that transform uniforms via <span class="math notranslate nohighlight">\(F^{-1}\)</span> generates any distribution.</p></li>
<li><p><strong>Pseudo-randomness works</strong> despite its logical impossibility, because statistical randomness‚Äîpassing all practical tests‚Äîsuffices for simulation.</p></li>
<li><p><strong>Generator design matters</strong>: Naive approaches (chaotic maps, simple LCGs) fail in ways that can corrupt research. Always use established generators.</p></li>
<li><p><strong>Seeds enable reproducibility</strong>: Set them explicitly, document them, and use <code class="docutils literal notranslate"><span class="pre">SeedSequence.spawn()</span></code> for parallel work.</p></li>
</ol>
</section>
<section id="transition-to-what-follows">
<h2>Transition to What Follows<a class="headerlink" href="#transition-to-what-follows" title="Link to this heading">ÔÉÅ</a></h2>
<p>With a supply of high-quality uniform variates in hand, we are ready for the central technique of random variable generation: the <strong>inverse CDF method</strong>. The next section (<a class="reference internal" href="ch2.3-inverse-cdf-method.html#ch2-3-inverse-cdf-method"><span class="std std-ref">Inverse CDF Method</span></a>) shows how to transform uniform variates into samples from any distribution whose quantile function we can compute.</p>
<p>For distributions with closed-form inverse CDFs‚Äîexponential, Weibull, Cauchy, Pareto‚Äîthe method is elegant and efficient. For discrete distributions, we will develop efficient algorithms (binary search, the alias method) to locate the correct outcome quickly. And for distributions without tractable inverse CDFs‚Äîmost notably the normal‚Äîwe will see specialized alternatives in subsequent sections.</p>
<p>The uniform variates we now know how to generate are the raw material; the inverse CDF method is the machinery that shapes them into any distributional form we need.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaways üìù</p>
<ol class="arabic simple">
<li><p><strong>Core concept</strong>: Uniform variates are the universal source of randomness. The Probability Integral Transform (next section) shows how any distribution can be generated by applying the inverse CDF to uniform samples.</p></li>
<li><p><strong>Paradox resolved</strong>: Computers generate pseudo-random numbers‚Äîdeterministic sequences that pass statistical tests for randomness. This suffices for virtually all statistical applications.</p></li>
<li><p><strong>Historical lessons</strong>: Chaotic dynamical systems fail as PRNGs (correlation, degeneration). Linear congruential generators produce lattice structure in high dimensions. RANDU‚Äôs 15 planes corrupted research for years.</p></li>
<li><p><strong>Modern solutions</strong>: Mersenne Twister (period <span class="math notranslate nohighlight">\(2^{19937}-1\)</span>, 623-dim equidistribution) and PCG64 (period <span class="math notranslate nohighlight">\(2^{128}\)</span>, small state, jumpable) pass all standard tests. Use NumPy‚Äôs defaults confidently.</p></li>
<li><p><strong>Practical wisdom</strong>: Set seeds for reproducibility. Use <code class="docutils literal notranslate"><span class="pre">SeedSequence.spawn()</span></code> for parallel computing. Reserve <code class="docutils literal notranslate"><span class="pre">secrets</span></code> for cryptographic needs.</p></li>
<li><p><strong>Outcome alignment</strong>: Understanding uniform generation (Learning Outcome 1) provides the foundation for all subsequent simulation techniques‚Äîinverse CDF, rejection sampling, MCMC‚Äîthat transform uniform variates into complex distributions.</p></li>
</ol>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ch2.1-monte-carlo-fundamentals.html" class="btn btn-neutral float-left" title="2.1.1. Monte Carlo Fundamentals" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ch2.3-inverse-cdf-method.html" class="btn btn-neutral float-right" title="2.1.3. Inverse CDF Method" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>