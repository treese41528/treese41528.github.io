

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Part II: Frequentist Inference &mdash; STAT 418</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=3d0abd52" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT418/Website/part2_simulation/index.html" />
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Show solution';</script>
      <script>let toggleHintHide = 'Hide solution';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../_static/custom.js?v=8718e0ab"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Course Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../part1_foundations/index.html">Part I: Foundations of Probability and Computation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../part1_foundations/index.html#the-arc-of-part-i">The Arc of Part I</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part1_foundations/index.html#why-foundations-matter">Why Foundations Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part1_foundations/index.html#connections">Connections</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part1_foundations/index.html#prerequisites">Prerequisites</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../part1_foundations/chapter1/index.html">Chapter 1: Statistical Paradigms and Core Concepts</a><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../part3_bayesian/index.html">Part III: Bayesian Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../part3_bayesian/index.html#the-arc-of-part-iii">The Arc of Part III</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part3_bayesian/index.html#the-challenge-computation">The Challenge: Computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part3_bayesian/index.html#connections">Connections</a></li>
<li class="toctree-l2"><a class="reference internal" href="../part3_bayesian/index.html#prerequisites">Prerequisites</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../part3_bayesian/chapter5/index.html">Chapter 5: Bayesian Inference</a><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Part II: Frequentist Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/part2_simulation/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="part-ii-frequentist-inference">
<span id="part2-frequentist-inference"></span><h1>Part II: Frequentist Inference<a class="headerlink" href="#part-ii-frequentist-inference" title="Link to this heading"></a></h1>
<p><em>What would happen if we repeated this procedure many times?</em> The frequentist paradigm interprets probability as long-run frequency: if we could repeat an experiment infinitely many times under identical conditions, the probability of an event equals the proportion of times it occurs. This deceptively simple idea—that probability lives in the repetition, not in our beliefs—generates a powerful and coherent framework for statistical inference.</p>
<p>The frequentist approach answers inferential questions through hypothetical repetition. A 95% confidence interval isn’t 95% likely to contain the true parameter; rather, the <em>procedure</em> that generated it captures the truth in 95% of repeated applications. A p-value of 0.03 doesn’t mean there’s a 3% chance the null hypothesis is true; it means that if the null were true, we’d see evidence this extreme only 3% of the time. These subtle but crucial distinctions pervade everything that follows.</p>
<p>What makes modern frequentist inference <em>computational</em> is the recognition that we can often <em>simulate</em> the repeated experiments that define our inferential quantities. Rather than deriving sampling distributions analytically—possible only for simple cases—we generate them directly through Monte Carlo simulation, bootstrap resampling, and permutation tests. The computer becomes a laboratory for frequentist thought experiments.</p>
<section id="the-arc-of-part-ii">
<h2>The Arc of Part II<a class="headerlink" href="#the-arc-of-part-ii" title="Link to this heading"></a></h2>
<p><strong>Chapter 2: Monte Carlo Simulation</strong> establishes the computational engine that powers modern frequentist inference. We begin with a philosophical puzzle: how can deterministic algorithms produce “random” numbers? The answer—pseudo-random number generators that create sequences indistinguishable from true randomness—leads us through uniform variate generation, the inverse CDF method for arbitrary distributions, and rejection sampling for cases where inversion fails. The chapter culminates with variance reduction techniques that can improve Monte Carlo efficiency by orders of magnitude.</p>
<p><strong>Chapter 3: Parametric Inference</strong> develops the classical frequentist toolkit for estimation and model building. Exponential families provide the mathematical scaffolding—a unified framework encompassing normal, binomial, Poisson, and most distributions used in practice. Maximum likelihood estimation emerges as the natural way to learn parameters from data, with beautiful asymptotic properties (consistency, efficiency, normality) that justify the confidence intervals and hypothesis tests we construct. Linear models and their generalization to non-normal responses (GLMs) extend these ideas to regression. Throughout, we emphasize both elegant theory and computational reality: Newton-Raphson iteration, Fisher scoring, and numerical optimization.</p>
<p><strong>Chapter 4: Resampling Methods</strong> completes the frequentist toolkit by showing how to estimate sampling variability without parametric assumptions. The jackknife estimates standard errors by systematically leaving out observations. The bootstrap goes further: by treating the observed sample as a stand-in for the population, we can simulate the sampling distribution of virtually any statistic. These methods provide confidence intervals, bias corrections, and hypothesis tests for quantities too complex for analytical treatment. We develop nonparametric and parametric bootstrap, BCa intervals for improved coverage, and permutation tests that achieve exact inference under exchangeability.</p>
</section>
<section id="computational-themes">
<h2>Computational Themes<a class="headerlink" href="#computational-themes" title="Link to this heading"></a></h2>
<p>Several computational motifs recur throughout Part II:</p>
<p><strong>Simulation as inference.</strong> When analytical solutions are intractable, we simulate. Monte Carlo integration replaces calculus with averaging. Bootstrap resampling replaces asymptotic theory with empirical distributions. Permutation tests replace distributional assumptions with combinatorial enumeration.</p>
<p><strong>The bias-variance tradeoff.</strong> Estimators balance accuracy (low bias) against stability (low variance). We see this in shrinkage estimators, cross-validation, and bootstrap bias correction—foreshadowing regularization methods in later chapters.</p>
<p><strong>Numerical stability.</strong> Theoretical formulas often fail computationally. We use log-likelihoods instead of likelihoods, Welford’s algorithm instead of textbook variance formulas, and careful conditioning to avoid catastrophic cancellation.</p>
<p><strong>Vectorization and efficiency.</strong> Python’s NumPy enables fast simulation through vectorized operations. This isn’t premature optimization—it’s the difference between simulations that take seconds and those that take hours.</p>
</section>
<section id="connections">
<h2>Connections<a class="headerlink" href="#connections" title="Link to this heading"></a></h2>
<p><strong>Part I: Foundations</strong> provides the probability distributions, computational tools, and philosophical grounding that Part II builds upon. The frequentist interpretation introduced there becomes the operating framework here.</p>
<p><strong>Part III: Bayesian Inference</strong> offers an alternative paradigm. Monte Carlo simulation underlies Markov chain Monte Carlo. Likelihood functions reappear as components of Bayes’ theorem. The bootstrap and posterior distributions both quantify uncertainty, though from different philosophical foundations. Understanding frequentist methods deeply makes the Bayesian alternative more meaningful—and vice versa.</p>
<p><strong>Part IV: LLMs in Data Science</strong> extends the validation mindset. Cross-validation principles from Chapter 4 apply directly when evaluating LLM performance. The habit of quantifying uncertainty transfers to assessing model reliability.</p>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading"></a></h2>
<p>Part II assumes mastery of Part I material: random variables, probability distributions, expectation, the law of large numbers, and the central limit theorem. We also assume comfort with Python, NumPy, and basic calculus.</p>
<p>By Part II’s end, you’ll command a complete frequentist toolkit—from foundational simulation through sophisticated resampling—ready to tackle inference problems that resist analytical treatment.</p>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="chapter2/index.html">Chapter 2: Monte Carlo Simulation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="chapter2/ch2_1-monte-carlo-fundamentals.html">Monte Carlo Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter2/ch2_2-uniform-random-variates.html">Uniform Random Variates</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter2/ch2_3-inverse-cdf-method.html">Inverse CDF Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter2/ch2_4-transformation-methods.html">Transformation Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter2/ch2_5-rejection-sampling.html">Rejection Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter2/ch2_6-variance-reduction-methods.html">Variance Reduction Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter2/ch2_7-chapter-summary.html">Chapter Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="chapter3/index.html">Chapter 3: Parametric Inference and Likelihood Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="chapter3/ch3_1-exponential-families.html">Exponential Families</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter3/ch3_2-maximum-likelihood-estimation.html">Maximum Likelihood Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter3/ch3_3-sampling-variability.html">Sampling Variability and Variance Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter3/ch3_4-linear-models.html">Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter3/ch3_5-generalized-linear-models.html">Generalized Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter3/ch3_6-chapter-summary.html">Chapter Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="chapter4/index.html">Chapter 4: Resampling Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="chapter4/ch4_1-sampling-distribution-problem.html">The Sampling Distribution Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter4/ch4_2-empirical-distribution-plugin.html">The Empirical Distribution and Plug-in Principle</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter4/ch4_3-nonparametric-bootstrap.html">The Nonparametric Bootstrap</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter4/ch4_4-parametric-bootstrap.html">Section 4.4: The Parametric Bootstrap</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter4/ch4_5-jackknife-methods.html">Section 4.5: Jackknife Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="chapter4/ch4_6-bootstrap-hypothesis-testing.html">Bootstrap Hypothesis Testing and Permutation Tests</a></li>
</ul>
</li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>