

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Homework 1: Distributional Relationships and Computational Foundations &mdash; STAT 418</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=3d0abd52" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT418/Website/Homework/hw1_distributional_relationships.html" />
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Show solution';</script>
      <script>let toggleHintHide = 'Hide solution';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../_static/custom.js?v=8718e0ab"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Part I: Foundations of Probability and Computation" href="../part1_foundations/index.html" />
    <link rel="prev" title="Homework Assignments" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Course Content</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Homework Assignments</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="index.html#assignment-policies">Assignment Policies</a></li>
<li class="toctree-l3"><a class="reference internal" href="index.html#recommended-workflow">Recommended Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="index.html#submission-requirements">Submission Requirements</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#assignments-by-chapter">Assignments by Chapter</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="index.html#part-i-foundations">Part I: Foundations</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">Homework 1: Distributional Relationships and Computational Foundations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#tips-for-success">Tips for Success</a><ul>
<li class="toctree-l3"><a class="reference internal" href="index.html#mathematical-derivations">Mathematical Derivations</a></li>
<li class="toctree-l3"><a class="reference internal" href="index.html#computational-verification">Computational Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="index.html#common-pitfalls">Common Pitfalls</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../part1_foundations/index.html">Part I: Foundations of Probability and Computation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../part1_foundations/chapter1/index.html">Chapter 1: Statistical Paradigms and Core Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html">Paradigms of Probability and Statistical Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#the-mathematical-foundation-kolmogorov-s-axioms">The Mathematical Foundation: Kolmogorov’s Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#interpretations-of-probability">Interpretations of Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#statistical-inference-paradigms">Statistical Inference Paradigms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#historical-and-philosophical-debates">Historical and Philosophical Debates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#looking-ahead-our-course-focus">Looking Ahead: Our Course Focus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.1-probability-and-inference-paradigms.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html">Probability Distributions: Theory and Computation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#from-abstract-foundations-to-concrete-tools">From Abstract Foundations to Concrete Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#the-python-ecosystem-for-probability">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#introduction-why-probability-distributions-matter">Introduction: Why Probability Distributions Matter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#id1">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#continuous-distributions">Continuous Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#additional-important-distributions">Additional Important Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#summary-and-practical-guidelines">Summary and Practical Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#conclusion">Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.2-probability_distributions_review.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part1_foundations/chapter1/ch1.3-python_random_generation.html">Python Random Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.3-python_random_generation.html#from-mathematical-distributions-to-computational-samples">From Mathematical Distributions to Computational Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.3-python_random_generation.html#the-python-ecosystem-at-a-glance">The Python Ecosystem at a Glance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.3-python_random_generation.html#understanding-pseudo-random-number-generation">Understanding Pseudo-Random Number Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.3-python_random_generation.html#the-standard-library-random-module">The Standard Library: <code class="docutils literal notranslate"><span class="pre">random</span></code> Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.3-python_random_generation.html#numpy-fast-vectorized-random-sampling">NumPy: Fast Vectorized Random Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.3-python_random_generation.html#scipy-stats-the-complete-statistical-toolkit">SciPy Stats: The Complete Statistical Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.3-python_random_generation.html#bringing-it-all-together-library-selection-guide">Bringing It All Together: Library Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.3-python_random_generation.html#looking-ahead-from-random-numbers-to-monte-carlo-methods">Looking Ahead: From Random Numbers to Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.3-python_random_generation.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part1_foundations/chapter1/ch1.4-chapter-summary.html">Chapter 1 Summary: Foundations in Place</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.4-chapter-summary.html#the-three-pillars-of-chapter-1">The Three Pillars of Chapter 1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.4-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.4-chapter-summary.html#what-lies-ahead-the-road-to-simulation">What Lies Ahead: The Road to Simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.4-chapter-summary.html#chapter-1-exercises-synthesis-problems">Chapter 1 Exercises: Synthesis Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part1_foundations/chapter1/ch1.4-chapter-summary.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../part2_simulation/index.html">Part II: Simulation-Based Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../part2_simulation/chapter2/index.html">Chapter 2: Monte Carlo Simulation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html">Monte Carlo Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#the-historical-development-of-monte-carlo-methods">The Historical Development of Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#the-core-principle-expectation-as-integration">The Core Principle: Expectation as Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#theoretical-foundations">Theoretical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#variance-estimation-and-confidence-intervals">Variance Estimation and Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#comparison-with-deterministic-methods">Comparison with Deterministic Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#sample-size-determination">Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#convergence-diagnostics-and-monitoring">Convergence Diagnostics and Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#chapter-2-1-exercises-monte-carlo-fundamentals-mastery">Chapter 2.1 Exercises: Monte Carlo Fundamentals Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#id1">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_1-monte-carlo-fundamentals.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html">Uniform Random Variates</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#why-uniform-the-universal-currency-of-randomness">Why Uniform? The Universal Currency of Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#the-paradox-of-computational-randomness">The Paradox of Computational Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#chaotic-dynamical-systems-an-instructive-failure">Chaotic Dynamical Systems: An Instructive Failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#linear-congruential-generators">Linear Congruential Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#shift-register-generators">Shift-Register Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#the-kiss-generator-combining-strategies">The KISS Generator: Combining Strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#modern-generators-mersenne-twister-and-pcg">Modern Generators: Mersenne Twister and PCG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#statistical-testing-of-random-number-generators">Statistical Testing of Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#chapter-2-2-exercises-uniform-random-variates-mastery">Chapter 2.2 Exercises: Uniform Random Variates Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_2-uniform-random-variates.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html">Inverse CDF Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#mathematical-foundations">Mathematical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#continuous-distributions-with-closed-form-inverses">Continuous Distributions with Closed-Form Inverses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#numerical-inversion">Numerical Inversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#mixed-distributions">Mixed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#chapter-2-3-exercises-inverse-cdf-method-mastery">Chapter 2.3 Exercises: Inverse CDF Method Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#id1">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_3-inverse-cdf-method.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html">Transformation Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#why-transformation-methods">Why Transformation Methods?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#the-boxmuller-transform">The Box–Muller Transform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#the-polar-marsaglia-method">The Polar (Marsaglia) Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#method-comparison-boxmuller-vs-polar-vs-ziggurat">Method Comparison: Box–Muller vs Polar vs Ziggurat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#the-ziggurat-algorithm">The Ziggurat Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#the-clt-approximation-historical">The CLT Approximation (Historical)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#distributions-derived-from-the-normal">Distributions Derived from the Normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#multivariate-normal-generation">Multivariate Normal Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#implementation-guidance">Implementation Guidance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#chapter-2-4-exercises-transformation-methods-mastery">Chapter 2.4 Exercises: Transformation Methods Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_4-transformation-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html">Rejection Sampling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#the-dartboard-intuition">The Dartboard Intuition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#the-accept-reject-algorithm">The Accept-Reject Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#efficiency-analysis">Efficiency Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#choosing-the-proposal-distribution">Choosing the Proposal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#the-squeeze-principle">The Squeeze Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#geometric-example-sampling-from-the-unit-disk">Geometric Example: Sampling from the Unit Disk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#limitations-and-the-curse-of-dimensionality">Limitations and the Curse of Dimensionality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#connections-to-other-methods">Connections to Other Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#chapter-2-5-exercises-rejection-sampling-mastery">Chapter 2.5 Exercises: Rejection Sampling Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_5-rejection-sampling.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html">Variance Reduction Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#the-variance-reduction-paradigm">The Variance Reduction Paradigm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#importance-sampling">Importance Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#control-variates">Control Variates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#antithetic-variates">Antithetic Variates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#stratified-sampling">Stratified Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#common-random-numbers">Common Random Numbers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#conditional-monte-carlo-raoblackwellization">Conditional Monte Carlo (Rao–Blackwellization)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#combining-variance-reduction-techniques">Combining Variance Reduction Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#chapter-2-6-exercises-variance-reduction-mastery">Chapter 2.6 Exercises: Variance Reduction Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_6-variance-reduction-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter2/ch2_7-chapter-summary.html">Chapter Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_7-chapter-summary.html#the-complete-monte-carlo-workflow">The Complete Monte Carlo Workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_7-chapter-summary.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_7-chapter-summary.html#quick-reference-tables">Quick Reference Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_7-chapter-summary.html#common-pitfalls-checklist">Common Pitfalls Checklist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_7-chapter-summary.html#connections-to-later-chapters">Connections to Later Chapters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_7-chapter-summary.html#learning-outcomes-checklist">Learning Outcomes Checklist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_7-chapter-summary.html#further-reading-optimization-and-missing-data">Further Reading: Optimization and Missing Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_7-chapter-summary.html#final-perspective">Final Perspective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter2/ch2_7-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../part2_simulation/chapter3/index.html">Chapter 3: Parametric Inference and Likelihood Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html">Exponential Families</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#historical-origins-from-scattered-results-to-unified-theory">Historical Origins: From Scattered Results to Unified Theory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#the-canonical-exponential-family">The Canonical Exponential Family</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#converting-familiar-distributions">Converting Familiar Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#the-log-partition-function-a-moment-generating-machine">The Log-Partition Function: A Moment-Generating Machine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#sufficiency-capturing-all-parameter-information">Sufficiency: Capturing All Parameter Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#minimal-sufficiency-and-completeness">Minimal Sufficiency and Completeness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#conjugate-priors-and-bayesian-inference">Conjugate Priors and Bayesian Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#exponential-dispersion-models-and-glms">Exponential Dispersion Models and GLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#chapter-3-1-exercises-exponential-families-mastery">Chapter 3.1 Exercises: Exponential Families Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_1-exponential-families.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html">Maximum Likelihood Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#the-likelihood-function">The Likelihood Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#the-score-function">The Score Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#fisher-information">Fisher Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#closed-form-maximum-likelihood-estimators">Closed-Form Maximum Likelihood Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#numerical-optimization-for-mle">Numerical Optimization for MLE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#asymptotic-properties-of-mles">Asymptotic Properties of MLEs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#the-cramer-rao-lower-bound">The Cramér-Rao Lower Bound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#the-invariance-property">The Invariance Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#likelihood-based-hypothesis-testing">Likelihood-Based Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#confidence-intervals-from-likelihood">Confidence Intervals from Likelihood</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#connection-to-bayesian-inference">Connection to Bayesian Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#chapter-3-2-exercises-maximum-likelihood-estimation-mastery">Chapter 3.2 Exercises: Maximum Likelihood Estimation Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_2-maximum-likelihood-estimation.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html">Sampling Variability and Variance Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html#statistical-estimators-and-their-properties">Statistical Estimators and Their Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html#sampling-distributions">Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html#the-delta-method">The Delta Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html#the-plug-in-principle">The Plug-in Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html#variance-estimation-methods">Variance Estimation Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html#applications-and-worked-examples">Applications and Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_3-sampling-variability.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html">Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#matrix-calculus-foundations">Matrix Calculus Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#the-linear-model">The Linear Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#ordinary-least-squares-the-calculus-approach">Ordinary Least Squares: The Calculus Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#ordinary-least-squares-the-geometric-approach">Ordinary Least Squares: The Geometric Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#properties-of-the-ols-estimator">Properties of the OLS Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#the-gauss-markov-theorem">The Gauss-Markov Theorem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#estimating-the-error-variance">Estimating the Error Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#distributional-results-under-normality">Distributional Results Under Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#diagnostics-and-model-checking">Diagnostics and Model Checking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#numerical-stability-qr-decomposition">Numerical Stability: QR Decomposition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#model-selection-and-information-criteria">Model Selection and Information Criteria</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#regularization-ridge-and-lasso">Regularization: Ridge and LASSO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#chapter-3-4-exercises-linear-models-mastery">Chapter 3.4 Exercises: Linear Models Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_4-linear-models.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html">Generalized Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#historical-context-unification-of-regression-methods">Historical Context: Unification of Regression Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#the-glm-framework-three-components">The GLM Framework: Three Components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#score-equations-and-fisher-information">Score Equations and Fisher Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#iteratively-reweighted-least-squares">Iteratively Reweighted Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#logistic-regression-binary-outcomes">Logistic Regression: Binary Outcomes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#poisson-regression-count-data">Poisson Regression: Count Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#gamma-regression-positive-continuous-data">Gamma Regression: Positive Continuous Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#inference-in-glms-the-testing-triad">Inference in GLMs: The Testing Triad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#model-diagnostics">Model Diagnostics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#model-comparison-and-selection">Model Comparison and Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#quasi-likelihood-and-robust-inference">Quasi-Likelihood and Robust Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#further-reading">Further Reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#chapter-3-5-exercises-generalized-linear-models-mastery">Chapter 3.5 Exercises: Generalized Linear Models Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_5-generalized-linear-models.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter3/ch3_6-chapter-summary.html">Chapter Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_6-chapter-summary.html#the-parametric-inference-pipeline">The Parametric Inference Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_6-chapter-summary.html#the-five-pillars-of-chapter-3">The Five Pillars of Chapter 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_6-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_6-chapter-summary.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_6-chapter-summary.html#quick-reference-core-formulas">Quick Reference: Core Formulas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_6-chapter-summary.html#connections-to-future-material">Connections to Future Material</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_6-chapter-summary.html#practical-guidance">Practical Guidance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_6-chapter-summary.html#final-perspective">Final Perspective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter3/ch3_6-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../part2_simulation/chapter4/index.html">Chapter 4: Resampling Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html">The Sampling Distribution Problem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html#the-fundamental-target-sampling-distributions">The Fundamental Target: Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html#historical-development-the-quest-for-sampling-distributions">Historical Development: The Quest for Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html#three-routes-to-the-sampling-distribution">Three Routes to the Sampling Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html#when-asymptotics-fail-motivating-the-bootstrap">When Asymptotics Fail: Motivating the Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html#the-plug-in-principle-theoretical-foundation">The Plug-In Principle: Theoretical Foundation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html#computational-perspective-bootstrap-as-monte-carlo">Computational Perspective: Bootstrap as Monte Carlo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html#chapter-4-1-exercises">Chapter 4.1 Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_1-sampling-distribution-problem.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html">The Empirical Distribution and Plug-in Principle</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html#the-empirical-cumulative-distribution-function">The Empirical Cumulative Distribution Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html#convergence-of-the-empirical-cdf">Convergence of the Empirical CDF</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html#parameters-as-statistical-functionals">Parameters as Statistical Functionals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html#the-plug-in-principle">The Plug-in Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html#when-the-plug-in-principle-fails">When the Plug-in Principle Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html#the-bootstrap-idea-in-one-sentence">The Bootstrap Idea in One Sentence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html#computational-implementation">Computational Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html#section-4-2-exercises-ecdf-and-plug-in-mastery">Section 4.2 Exercises: ECDF and Plug-in Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_2-empirical-distribution-plugin.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html">The Nonparametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#the-bootstrap-principle">The Bootstrap Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-standard-errors">Bootstrap Standard Errors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-bias-estimation">Bootstrap Bias Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-confidence-intervals">Bootstrap Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-for-regression">Bootstrap for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-diagnostics">Bootstrap Diagnostics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#when-bootstrap-fails">When Bootstrap Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_3-nonparametric-bootstrap.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html">Section 4.4: The Parametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html#the-parametric-bootstrap-principle">The Parametric Bootstrap Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html#location-scale-families">Location-Scale Families</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html#parametric-bootstrap-for-regression">Parametric Bootstrap for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html#confidence-intervals">Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html#model-checking-and-validation">Model Checking and Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html#when-parametric-bootstrap-fails">When Parametric Bootstrap Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html#parametric-vs-nonparametric-a-decision-framework">Parametric vs. Nonparametric: A Decision Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_4-parametric-bootstrap.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html">Section 4.5: Jackknife Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html#historical-context-and-motivation">Historical Context and Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html#the-delete-1-jackknife">The Delete-1 Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html#jackknife-bias-estimation">Jackknife Bias Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html#the-delete-d-jackknife">The Delete-<span class="math notranslate nohighlight">\(d\)</span> Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html#jackknife-versus-bootstrap">Jackknife versus Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html#the-infinitesimal-jackknife">The Infinitesimal Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part2_simulation/chapter4/ch4_5-jackknife-methods.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../part3_bayesian/index.html">Part III: Bayesian Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../part3_bayesian/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../part3_bayesian/chapter5/bayesian_philosophy.html">Bayesian Philosophy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../part3_bayesian/chapter5/bayesian_philosophy.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part3_bayesian/chapter5/bayesian_philosophy.html#key-concepts">Key Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part3_bayesian/chapter5/bayesian_philosophy.html#mathematical-framework">Mathematical Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part3_bayesian/chapter5/bayesian_philosophy.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part3_bayesian/chapter5/bayesian_philosophy.html#examples">Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../part3_bayesian/chapter5/bayesian_philosophy.html#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Homework Assignments</a></li>
      <li class="breadcrumb-item active">Homework 1: Distributional Relationships and Computational Foundations</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/Homework/hw1_distributional_relationships.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="homework-1-distributional-relationships-and-computational-foundations">
<span id="hw1-distributional-relationships"></span><h1>Homework 1: Distributional Relationships and Computational Foundations<a class="headerlink" href="#homework-1-distributional-relationships-and-computational-foundations" title="Link to this heading"></a></h1>
<dl class="field-list simple">
<dt class="field-odd">Due<span class="colon">:</span></dt>
<dd class="field-odd"><p>[TBD]</p>
</dd>
<dt class="field-even">Submission<span class="colon">:</span></dt>
<dd class="field-even"><p>Upload your written derivations (PDF) and Python verification script (.py or .ipynb) to Gradescope</p>
</dd>
</dl>
<nav class="contents local" id="assignment-contents">
<p class="topic-title">Assignment Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#overview-and-learning-objectives" id="id3">Overview and Learning Objectives</a></p>
<ul>
<li><p><a class="reference internal" href="#assignment-structure" id="id4">Assignment Structure</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#mathematical-preliminaries" id="id5">Mathematical Preliminaries</a></p>
<ul>
<li><p><a class="reference internal" href="#moment-generating-functions" id="id6">Moment Generating Functions</a></p></li>
<li><p><a class="reference internal" href="#when-mgfs-fail-transformation-methods" id="id7">When MGFs Fail: Transformation Methods</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#computational-setup" id="id8">Computational Setup</a></p></li>
<li><p><a class="reference internal" href="#visual-verification-tools" id="id9">Visual Verification Tools</a></p>
<ul>
<li><p><a class="reference internal" href="#visualization-utilities" id="id10">Visualization Utilities</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#part-i-mgf-and-analytic-derivations" id="id11">Part I: MGF and Analytic Derivations</a></p>
<ul>
<li><p><a class="reference internal" href="#problem-1-geometric-to-negative-binomial" id="id12">Problem 1: Geometric to Negative Binomial</a></p></li>
<li><p><a class="reference internal" href="#problem-2-poisson-additivity" id="id13">Problem 2: Poisson Additivity</a></p></li>
<li><p><a class="reference internal" href="#problem-3-binomial-additivity" id="id14">Problem 3: Binomial Additivity</a></p></li>
<li><p><a class="reference internal" href="#problem-4-normal-additivity" id="id15">Problem 4: Normal Additivity</a></p></li>
<li><p><a class="reference internal" href="#problem-5-chi-square-from-normal-squares" id="id16">Problem 5: Chi-Square from Normal Squares</a></p></li>
<li><p><a class="reference internal" href="#problem-6-the-gamma-poisson-negative-binomial-triangle" id="id17">Problem 6: The Gamma-Poisson-Negative Binomial Triangle</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#part-ii-transformation-methods" id="id18">Part II: Transformation Methods</a></p>
<ul>
<li><p><a class="reference internal" href="#problem-7-ratio-of-normals-is-cauchy" id="id19">Problem 7: Ratio of Normals is Cauchy</a></p></li>
<li><p><a class="reference internal" href="#problem-8-student-s-t-from-normal-and-chi-square" id="id20">Problem 8: Student’s t from Normal and Chi-Square</a></p></li>
<li><p><a class="reference internal" href="#problem-9-f-distribution-from-chi-squares" id="id21">Problem 9: F Distribution from Chi-Squares</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#part-iii-computational-foundations" id="id22">Part III: Computational Foundations</a></p>
<ul>
<li><p><a class="reference internal" href="#problem-10-the-central-limit-theorem-in-action" id="id23">Problem 10: The Central Limit Theorem in Action</a></p></li>
<li><p><a class="reference internal" href="#problem-11-reproducibility-and-parallel-streams" id="id24">Problem 11: Reproducibility and Parallel Streams</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="overview-and-learning-objectives">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Overview and Learning Objectives</a><a class="headerlink" href="#overview-and-learning-objectives" title="Link to this heading"></a></h2>
<p>Probability distributions don’t exist in isolation—they form an interconnected family linked through sums, limits, transformations, and special cases. Understanding these relationships is essential for:</p>
<ul class="simple">
<li><p><strong>Simulation</strong>: Generating samples from complex distributions using simpler ones</p></li>
<li><p><strong>Inference</strong>: Deriving sampling distributions of test statistics</p></li>
<li><p><strong>Model selection</strong>: Recognizing when a simpler distribution is appropriate</p></li>
<li><p><strong>Derivation</strong>: Proving properties of one distribution from another</p></li>
</ul>
<p>This assignment develops your ability to <strong>prove</strong> distributional relationships rigorously and <strong>verify</strong> your work computationally. You’ll use moment generating functions (MGFs) where they exist and transformation techniques where they don’t—learning when each tool is appropriate.</p>
<div class="important admonition">
<p class="admonition-title">Learning Outcomes Addressed</p>
<ul class="simple">
<li><p><strong>LO 1</strong>: Apply simulation techniques, including transformation methods for random variable generation</p></li>
<li><p><strong>LO 2</strong>: Compare mathematical frameworks for probabilistic reasoning and inference</p></li>
<li><p><strong>LO 3</strong>: Implement computational methods for verifying theoretical results</p></li>
</ul>
</div>
<section id="assignment-structure">
<h3><a class="toc-backref" href="#id4" role="doc-backlink">Assignment Structure</a><a class="headerlink" href="#assignment-structure" title="Link to this heading"></a></h3>
<p>The assignment has three parts:</p>
<ul class="simple">
<li><p><strong>Part I: MGF and Analytic Derivations</strong> (Problems 1–6): Use MGFs where they exist, plus related analytic techniques (sums, transforms, mixtures) to prove distributional identities</p></li>
<li><p><strong>Part II: Transformation Methods</strong> (Problems 7–9): Use Jacobian transformations for distributions lacking MGFs (Cauchy, t, F)</p></li>
<li><p><strong>Part III: Computational Foundations</strong> (Problems 10–11): Empirically verify the Central Limit Theorem and demonstrate proper use of random number generation</p></li>
</ul>
<p>Each problem in Parts I and II requires <strong>two components</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Mathematical Derivation</strong> (handwritten or typeset): Show all steps, define notation, state assumptions, and justify each equality. This is the primary assessment—your derivation must be complete and correct.</p></li>
<li><p><strong>Computational Verification</strong> (Python): Use the visualization utilities provided to verify your algebra and explore the result numerically. This catches errors and builds intuition.</p></li>
</ol>
<p>Part III problems are primarily computational—you’ll implement simulations and create visualizations that demonstrate key theoretical concepts from Chapter 1.</p>
<p>The computational component is not a shortcut—it verifies work you’ve already done by hand. Start each problem with pencil and paper before touching the keyboard.</p>
</section>
</section>
<section id="mathematical-preliminaries">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Mathematical Preliminaries</a><a class="headerlink" href="#mathematical-preliminaries" title="Link to this heading"></a></h2>
<p>This section provides reference material. You may cite these results without re-deriving them.</p>
<section id="moment-generating-functions">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">Moment Generating Functions</a><a class="headerlink" href="#moment-generating-functions" title="Link to this heading"></a></h3>
<p>For a random variable <span class="math notranslate nohighlight">\(X\)</span>, the <strong>moment generating function</strong> (MGF) is defined as:</p>
<div class="math notranslate nohighlight">
\[M_X(t) = \mathbb{E}[e^{tX}]\]</div>
<p>for all <span class="math notranslate nohighlight">\(t\)</span> in an open interval containing zero where the expectation exists.</p>
<p><strong>Key Property (Independent Sums)</strong>: If <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> are independent and each <span class="math notranslate nohighlight">\(M_{X_i}(t)\)</span> exists in a neighborhood of zero, then:</p>
<div class="math notranslate nohighlight">
\[M_{\sum_{i=1}^n X_i}(t) = \prod_{i=1}^n M_{X_i}(t)\]</div>
<p><strong>Uniqueness</strong>: Under standard regularity conditions, the MGF uniquely determines the distribution. If two random variables have the same MGF in a neighborhood of zero, they have the same distribution.</p>
<section id="reference-common-mgfs">
<h4>Reference: Common MGFs<a class="headerlink" href="#reference-common-mgfs" title="Link to this heading"></a></h4>
<p>The following MGFs may be used without derivation:</p>
<table class="docutils align-default" id="id1">
<caption><span class="caption-number">Table 1 </span><span class="caption-text">Common Moment Generating Functions</span><a class="headerlink" href="#id1" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 35.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Distribution</p></th>
<th class="head"><p>PMF/PDF</p></th>
<th class="head"><p>MGF <span class="math notranslate nohighlight">\(M_X(t)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Geometric(<span class="math notranslate nohighlight">\(p\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(P(X=k) = p(1-p)^{k-1}\)</span>, <span class="math notranslate nohighlight">\(k=1,2,\ldots\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\dfrac{pe^t}{1-(1-p)e^t}\)</span>, <span class="math notranslate nohighlight">\(t &lt; -\ln(1-p)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>NegBinom(<span class="math notranslate nohighlight">\(r, p\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(P(Y=k) = \binom{k-1}{r-1}p^r(1-p)^{k-r}\)</span>, <span class="math notranslate nohighlight">\(k \geq r\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\left(\dfrac{pe^t}{1-(1-p)e^t}\right)^r\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Poisson(<span class="math notranslate nohighlight">\(\lambda\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(P(X=k) = e^{-\lambda}\dfrac{\lambda^k}{k!}\)</span>, <span class="math notranslate nohighlight">\(k=0,1,\ldots\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\exp(\lambda(e^t - 1))\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Binomial(<span class="math notranslate nohighlight">\(n,p\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(P(X=k) = \binom{n}{k}p^k(1-p)^{n-k}\)</span>, <span class="math notranslate nohighlight">\(k=0,\ldots,n\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\((1 - p + pe^t)^n\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Normal(<span class="math notranslate nohighlight">\(\mu, \sigma^2\)</span>)</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\exp\left(\mu t + \frac{\sigma^2 t^2}{2}\right)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\chi^2(\nu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(f(x) = \frac{x^{\nu/2-1}e^{-x/2}}{2^{\nu/2}\Gamma(\nu/2)}\)</span>, <span class="math notranslate nohighlight">\(x &gt; 0\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\((1 - 2t)^{-\nu/2}\)</span>, <span class="math notranslate nohighlight">\(t &lt; 1/2\)</span></p></td>
</tr>
</tbody>
</table>
<p><strong>Important</strong>: The Cauchy, Student’s <span class="math notranslate nohighlight">\(t\)</span>, and <span class="math notranslate nohighlight">\(F\)</span> distributions do <strong>not</strong> have MGFs (the expectation diverges). For these, use transformation/Jacobian methods.</p>
<table class="docutils align-default" id="id2">
<caption><span class="caption-number">Table 2 </span><span class="caption-text">Distributions Without MGFs (for Part II reference)</span><a class="headerlink" href="#id2" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 50.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Distribution</p></th>
<th class="head"><p>PDF</p></th>
<th class="head"><p>Support</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Cauchy (standard)</p></td>
<td><p><span class="math notranslate nohighlight">\(f(x) = \dfrac{1}{\pi(1 + x^2)}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(x \in \mathbb{R}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Student’s <span class="math notranslate nohighlight">\(t(\nu)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(f(x) = \dfrac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu\pi}\,\Gamma\left(\frac{\nu}{2}\right)} \left(1 + \frac{x^2}{\nu}\right)^{-(\nu+1)/2}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(x \in \mathbb{R}\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(F(\nu_1, \nu_2)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(f(x) = \dfrac{1}{B(\nu_1/2, \nu_2/2)} \left(\frac{\nu_1}{\nu_2}\right)^{\nu_1/2} x^{\nu_1/2-1} \left(1 + \frac{\nu_1 x}{\nu_2}\right)^{-(\nu_1+\nu_2)/2}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(x &gt; 0\)</span></p></td>
</tr>
</tbody>
</table>
<p>These distributions arise from ratios and other transformations of normal and chi-square random variables, which is why transformation methods are required.</p>
</section>
</section>
<section id="when-mgfs-fail-transformation-methods">
<h3><a class="toc-backref" href="#id7" role="doc-backlink">When MGFs Fail: Transformation Methods</a><a class="headerlink" href="#when-mgfs-fail-transformation-methods" title="Link to this heading"></a></h3>
<p>When an MGF doesn’t exist, we derive distributions using the <strong>transformation (Jacobian) method</strong>:</p>
<p>For <span class="math notranslate nohighlight">\(Y = g(X)\)</span> where <span class="math notranslate nohighlight">\(g\)</span> is monotonic with inverse <span class="math notranslate nohighlight">\(g^{-1}\)</span>:</p>
<div class="math notranslate nohighlight">
\[f_Y(y) = f_X(g^{-1}(y)) \cdot \left| \frac{d}{dy} g^{-1}(y) \right|\]</div>
<p>For multivariate transformations <span class="math notranslate nohighlight">\((Y_1, Y_2) = g(X_1, X_2)\)</span>:</p>
<div class="math notranslate nohighlight">
\[f_{Y_1, Y_2}(y_1, y_2) = f_{X_1, X_2}(g^{-1}(y_1, y_2)) \cdot |J|\]</div>
<p>where <span class="math notranslate nohighlight">\(|J|\)</span> is the absolute value of the Jacobian determinant.</p>
</section>
</section>
<section id="computational-setup">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">Computational Setup</a><a class="headerlink" href="#computational-setup" title="Link to this heading"></a></h2>
<p>Before starting, set up your Python environment. The code below provides tools for <strong>verifying</strong> your hand derivations—SymPy can check symbolic algebra, and numerical sampling confirms distributional results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Homework 1: Distributional Relationships</span>
<span class="sd">Computational Verification Template</span>

<span class="sd">Instructions:</span>
<span class="sd">1. Complete the hand derivation FIRST (on paper or iPad)</span>
<span class="sd">2. Use this code to verify your algebraic work</span>
<span class="sd">3. Include output and figures in your submission</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sympy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sympy</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">symbols</span><span class="p">,</span> <span class="n">exp</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">simplify</span><span class="p">,</span> <span class="n">expand</span><span class="p">,</span>
                   <span class="n">integrate</span><span class="p">,</span> <span class="n">diff</span><span class="p">,</span> <span class="n">factorial</span><span class="p">,</span> <span class="n">binomial</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">oo</span><span class="p">,</span>
                   <span class="n">Rational</span><span class="p">,</span> <span class="n">latex</span><span class="p">,</span> <span class="n">init_printing</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sympy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">Normal</span><span class="p">,</span> <span class="n">ChiSquared</span><span class="p">,</span> <span class="n">density</span><span class="p">,</span> <span class="n">E</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">init_printing</span><span class="p">()</span>  <span class="c1"># Pretty symbolic output</span>

<span class="c1"># Common symbols (define once, reuse throughout)</span>
<span class="n">t</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;t p r k n m&#39;</span><span class="p">,</span> <span class="n">positive</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">real</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">lam</span><span class="p">,</span> <span class="n">lam1</span><span class="p">,</span> <span class="n">lam2</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;lambda lambda_1 lambda_2&#39;</span><span class="p">,</span> <span class="n">positive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;mu sigma&#39;</span><span class="p">,</span> <span class="n">real</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">nu</span><span class="p">,</span> <span class="n">nu1</span><span class="p">,</span> <span class="n">nu2</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;nu nu_1 nu_2&#39;</span><span class="p">,</span> <span class="n">positive</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">integer</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">z</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;z u x&#39;</span><span class="p">,</span> <span class="n">real</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="visual-verification-tools">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">Visual Verification Tools</a><a class="headerlink" href="#visual-verification-tools" title="Link to this heading"></a></h2>
<p>A key component of this assignment is <strong>visually verifying</strong> your theoretical results. For each distributional relationship, you will:</p>
<ol class="arabic simple">
<li><p><strong>Sample directly</strong> from the target distribution (e.g., Negative Binomial)</p></li>
<li><p><strong>Construct samples</strong> by sampling from the building-block distributions and applying the appropriate transformation (e.g., sum of Geometrics)</p></li>
<li><p><strong>Compare visually</strong> using histograms, kernel density estimates, and Q-Q plots</p></li>
</ol>
<p>If your derivation is correct, the two sampling methods should produce indistinguishable distributions.</p>
<section id="visualization-utilities">
<h3><a class="toc-backref" href="#id10" role="doc-backlink">Visualization Utilities</a><a class="headerlink" href="#visualization-utilities" title="Link to this heading"></a></h3>
<p>Use the following helper functions throughout the assignment:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compare_distributions</span><span class="p">(</span><span class="n">samples_constructed</span><span class="p">,</span> <span class="n">samples_direct</span><span class="p">,</span>
                          <span class="n">title</span><span class="p">,</span> <span class="n">label_constructed</span><span class="p">,</span> <span class="n">label_direct</span><span class="p">,</span>
                          <span class="n">discrete</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">theoretical_pmf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">theoretical_pdf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_range</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Visually compare two sets of samples that should follow the same distribution.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples_constructed : array-like</span>
<span class="sd">        Samples obtained by transforming/combining simpler distributions</span>
<span class="sd">    samples_direct : array-like</span>
<span class="sd">        Samples drawn directly from the target distribution</span>
<span class="sd">    title : str</span>
<span class="sd">        Plot title</span>
<span class="sd">    label_constructed : str</span>
<span class="sd">        Label for constructed samples (e.g., &quot;Sum of Geometrics&quot;)</span>
<span class="sd">    label_direct : str</span>
<span class="sd">        Label for direct samples (e.g., &quot;NegBinom(r,p)&quot;)</span>
<span class="sd">    discrete : bool</span>
<span class="sd">        If True, use bar plots for PMF comparison</span>
<span class="sd">    theoretical_pmf : callable, optional</span>
<span class="sd">        Function computing theoretical PMF at integer values</span>
<span class="sd">    theoretical_pdf : callable, optional</span>
<span class="sd">        Function computing theoretical PDF</span>
<span class="sd">    x_range : tuple, optional</span>
<span class="sd">        (min, max) for x-axis; auto-determined if None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

    <span class="c1"># Panel 1: Histogram/PMF comparison</span>
    <span class="n">ax1</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">discrete</span><span class="p">:</span>
        <span class="c1"># For discrete distributions, use aligned bar plots</span>
        <span class="n">all_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">samples_constructed</span><span class="p">,</span> <span class="n">samples_direct</span><span class="p">])</span>
        <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">all_vals</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">all_vals</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples_constructed</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="n">label_constructed</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;steelblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples_direct</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="n">label_direct</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;coral&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">theoretical_pmf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">all_vals</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span> <span class="nb">int</span><span class="p">(</span><span class="n">all_vals</span><span class="o">.</span><span class="n">max</span><span class="p">())</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="p">[</span><span class="n">theoretical_pmf</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">x_vals</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span>
                     <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theoretical PMF&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># For continuous distributions, use KDE</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples_constructed</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="n">label_constructed</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;steelblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples_direct</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="n">label_direct</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;coral&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">theoretical_pdf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">x_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">x_range</span> <span class="o">=</span> <span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">samples_constructed</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">samples_direct</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span>
                           <span class="nb">max</span><span class="p">(</span><span class="n">samples_constructed</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">samples_direct</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>
            <span class="n">x_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">200</span><span class="p">)</span>
            <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">theoretical_pdf</span><span class="p">(</span><span class="n">x_vals</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                     <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theoretical PDF&#39;</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribution Comparison&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># Panel 2: Q-Q plot (constructed vs direct)</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">quantiles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">q_constructed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">samples_constructed</span><span class="p">,</span> <span class="n">quantiles</span><span class="p">)</span>
    <span class="n">q_direct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">samples_direct</span><span class="p">,</span> <span class="n">quantiles</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">q_direct</span><span class="p">,</span> <span class="n">q_constructed</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;purple&#39;</span><span class="p">)</span>

    <span class="c1"># Add reference line</span>
    <span class="n">lims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">q_direct</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">q_constructed</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span>
            <span class="nb">max</span><span class="p">(</span><span class="n">q_direct</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">q_constructed</span><span class="o">.</span><span class="n">max</span><span class="p">())]</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lims</span><span class="p">,</span> <span class="n">lims</span><span class="p">,</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;y = x&#39;</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Quantiles (</span><span class="si">{</span><span class="n">label_direct</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Quantiles (</span><span class="si">{</span><span class="n">label_constructed</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Q-Q Plot&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>

    <span class="c1"># Panel 3: Empirical CDF comparison</span>
    <span class="n">ax3</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="c1"># Sort samples for ECDF</span>
    <span class="n">x_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">samples_constructed</span><span class="p">)</span>
    <span class="n">y_con</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_con</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_con</span><span class="p">)</span>
    <span class="n">x_dir</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">samples_direct</span><span class="p">)</span>
    <span class="n">y_dir</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_dir</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_dir</span><span class="p">)</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x_con</span><span class="p">,</span> <span class="n">y_con</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_constructed</span><span class="p">,</span>
             <span class="n">color</span><span class="o">=</span><span class="s1">&#39;steelblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x_dir</span><span class="p">,</span> <span class="n">y_dir</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_direct</span><span class="p">,</span>
             <span class="n">color</span><span class="o">=</span><span class="s1">&#39;coral&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

    <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Probability&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Empirical CDF Comparison&#39;</span><span class="p">)</span>
    <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># Print summary statistics</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Summary Statistics:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">label_constructed</span><span class="si">:</span><span class="s2">25s</span><span class="si">}</span><span class="s2"> - Mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples_constructed</span><span class="p">)</span><span class="si">:</span><span class="s2">8.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;Var: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samples_constructed</span><span class="p">)</span><span class="si">:</span><span class="s2">8.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;Median: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">samples_constructed</span><span class="p">)</span><span class="si">:</span><span class="s2">8.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">label_direct</span><span class="si">:</span><span class="s2">25s</span><span class="si">}</span><span class="s2"> - Mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples_direct</span><span class="p">)</span><span class="si">:</span><span class="s2">8.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;Var: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">samples_direct</span><span class="p">)</span><span class="si">:</span><span class="s2">8.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;Median: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">samples_direct</span><span class="p">)</span><span class="si">:</span><span class="s2">8.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Kolmogorov-Smirnov test</span>
    <span class="n">ks_stat</span><span class="p">,</span> <span class="n">ks_pval</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ks_2samp</span><span class="p">(</span><span class="n">samples_constructed</span><span class="p">,</span> <span class="n">samples_direct</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">  Two-sample KS test: statistic = </span><span class="si">{</span><span class="n">ks_stat</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, p-value = </span><span class="si">{</span><span class="n">ks_pval</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ks_pval</span> <span class="o">&gt;</span> <span class="mf">0.05</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  → No significant evidence of difference (p &gt; 0.05)&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  → Evidence of difference detected (p ≤ 0.05)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Note: KS p-values are approximate for discrete distributions&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">qq_plot_theoretical</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">dist_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Q-Q plot comparing samples against a theoretical distribution.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : array-like</span>
<span class="sd">        Empirical samples</span>
<span class="sd">    dist : scipy.stats distribution</span>
<span class="sd">        Frozen scipy distribution (e.g., stats.norm(0, 1))</span>
<span class="sd">    title : str</span>
<span class="sd">        Plot title</span>
<span class="sd">    dist_name : str</span>
<span class="sd">        Name of theoretical distribution for labeling</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="c1"># Compute theoretical and sample quantiles</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">theoretical_quantiles</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">n</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">sample_quantiles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">theoretical_quantiles</span><span class="p">,</span> <span class="n">sample_quantiles</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="c1"># Reference line</span>
    <span class="n">lims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">theoretical_quantiles</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">sample_quantiles</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span>
            <span class="nb">max</span><span class="p">(</span><span class="n">theoretical_quantiles</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">sample_quantiles</span><span class="o">.</span><span class="n">max</span><span class="p">())]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lims</span><span class="p">,</span> <span class="n">lims</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Theoretical Quantiles (</span><span class="si">{</span><span class="n">dist_name</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Sample Quantiles&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="part-i-mgf-and-analytic-derivations">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">Part I: MGF and Analytic Derivations</a><a class="headerlink" href="#part-i-mgf-and-analytic-derivations" title="Link to this heading"></a></h2>
<p>These problems use moment generating functions and related analytic techniques to prove distributional identities. For MGF problems, compute the MGF of the relevant quantity, then identify the resulting distribution by matching to known MGF forms.</p>
<div class="warning admonition">
<p class="admonition-title">Parameterization Conventions ⚠️</p>
<p>Pay careful attention to parameterization differences between mathematical conventions and SciPy:</p>
<ul class="simple">
<li><p><strong>Geometric</strong>: We use support <span class="math notranslate nohighlight">\(\{1, 2, 3, \ldots\}\)</span> (trials until first success). SciPy’s <code class="docutils literal notranslate"><span class="pre">stats.geom(p)</span></code> matches this convention.</p></li>
<li><p><strong>Negative Binomial</strong>: SciPy’s <code class="docutils literal notranslate"><span class="pre">stats.nbinom(n=r,</span> <span class="pre">p=p)</span></code> counts <em>failures before r successes</em> with support <span class="math notranslate nohighlight">\(\{0, 1, 2, \ldots\}\)</span>. To get <em>trials until r successes</em>, add r to SciPy samples.</p></li>
<li><p><strong>Gamma</strong>: We write <span class="math notranslate nohighlight">\(\text{Gamma}(r, \beta)\)</span> with shape <span class="math notranslate nohighlight">\(r\)</span> and <strong>rate</strong> <span class="math notranslate nohighlight">\(\beta\)</span>. SciPy uses <strong>scale</strong> = <span class="math notranslate nohighlight">\(1/\beta\)</span>, so use <code class="docutils literal notranslate"><span class="pre">stats.gamma(a=r,</span> <span class="pre">scale=1/beta)</span></code>.</p></li>
<li><p><strong>Exponential</strong>: We write <span class="math notranslate nohighlight">\(\text{Exp}(\lambda)\)</span> with <strong>rate</strong> <span class="math notranslate nohighlight">\(\lambda\)</span>. SciPy uses <strong>scale</strong> = <span class="math notranslate nohighlight">\(1/\lambda\)</span>, so use <code class="docutils literal notranslate"><span class="pre">stats.expon(scale=1/lambda)</span></code>.</p></li>
</ul>
</div>
<section id="problem-1-geometric-to-negative-binomial">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Problem 1: Geometric to Negative Binomial</a><a class="headerlink" href="#problem-1-geometric-to-negative-binomial" title="Link to this heading"></a></h3>
<p>Let <span class="math notranslate nohighlight">\(X_1, \ldots, X_r\)</span> be independent and identically distributed <span class="math notranslate nohighlight">\(\text{Geometric}(p)\)</span> random variables, where <span class="math notranslate nohighlight">\(X_i\)</span> counts the number of trials until the first success:</p>
<div class="math notranslate nohighlight">
\[P(X_i = k) = p(1-p)^{k-1}, \quad k = 1, 2, 3, \ldots\]</div>
<p>Let <span class="math notranslate nohighlight">\(S_r = \sum_{i=1}^r X_i\)</span> be the total number of trials until <span class="math notranslate nohighlight">\(r\)</span> successes.</p>
<p><strong>(a)</strong> Using the MGF of the Geometric distribution and the multiplication property for independent sums, derive the MGF of <span class="math notranslate nohighlight">\(S_r\)</span>:</p>
<div class="math notranslate nohighlight">
\[M_{S_r}(t) = \left( \frac{pe^t}{1 - (1-p)e^t} \right)^r\]</div>
<p><strong>(b)</strong> Conclude that <span class="math notranslate nohighlight">\(S_r \sim \text{NegativeBinomial}(r, p)\)</span> in the “trials until <span class="math notranslate nohighlight">\(r\)</span>-th success” parameterization, with PMF:</p>
<div class="math notranslate nohighlight">
\[P(S_r = k) = \binom{k-1}{r-1} p^r (1-p)^{k-r}, \quad k = r, r+1, r+2, \ldots\]</div>
<p>Explain the combinatorial interpretation of this PMF (why <span class="math notranslate nohighlight">\(\binom{k-1}{r-1}\)</span>?).</p>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">stats.geom.rvs(p=p_val,</span> <span class="pre">size=(n_samples,</span> <span class="pre">r_val))</span></code> to generate a matrix of Geometric samples, then sum across rows</p></li>
<li><p>For direct Negative Binomial samples, note that SciPy’s <code class="docutils literal notranslate"><span class="pre">nbinom</span></code> uses the “failures before r successes” parameterization — you’ll need to add r to convert to “trials until r successes”</p></li>
<li><p>After deriving the MGFs by hand, use SymPy to check that the product of r identical Geometric MGFs simplifies to the Negative Binomial MGF</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">compare_distributions()</span></code> with <code class="docutils literal notranslate"><span class="pre">discrete=True</span></code> to visualize the PMF comparison</p></li>
</ul>
</section>
<section id="problem-2-poisson-additivity">
<h3><a class="toc-backref" href="#id13" role="doc-backlink">Problem 2: Poisson Additivity</a><a class="headerlink" href="#problem-2-poisson-additivity" title="Link to this heading"></a></h3>
<p>Let <span class="math notranslate nohighlight">\(X_1, \ldots, X_m\)</span> be independent Poisson random variables with possibly <strong>different</strong> rates <span class="math notranslate nohighlight">\(\lambda_1, \ldots, \lambda_m\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(X_i = k) = e^{-\lambda_i} \frac{\lambda_i^k}{k!}, \quad k = 0, 1, 2, \ldots\]</div>
<p>Let <span class="math notranslate nohighlight">\(S = \sum_{i=1}^m X_i\)</span>.</p>
<p><strong>(a)</strong> Prove that <span class="math notranslate nohighlight">\(S \sim \text{Poisson}(\Lambda)\)</span> where <span class="math notranslate nohighlight">\(\Lambda = \sum_{i=1}^m \lambda_i\)</span>.</p>
<p><strong>(b)</strong> The Poisson family is called <strong>closed under convolution</strong> (or “reproducing”). Explain in one sentence what this means and give a real-world example where this property is useful.</p>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p>Define a lambda function for the Poisson MGF: <code class="docutils literal notranslate"><span class="pre">M_pois</span> <span class="pre">=</span> <span class="pre">lambda</span> <span class="pre">lam:</span> <span class="pre">exp(lam</span> <span class="pre">*</span> <span class="pre">(exp(t)</span> <span class="pre">-</span> <span class="pre">1))</span></code></p></li>
<li><p>Multiply MGFs with different rates and use <code class="docutils literal notranslate"><span class="pre">simplify()</span></code> to verify they combine as expected</p></li>
<li><p>Generate samples from multiple Poisson distributions with different λ values and sum them</p></li>
<li><p>Compare against direct samples from <code class="docutils literal notranslate"><span class="pre">stats.poisson.rvs(mu=sum(lambda_vals),</span> <span class="pre">...)</span></code></p></li>
<li><p>For Poisson, mean equals variance — check this holds for both constructed and direct samples</p></li>
</ul>
</section>
<section id="problem-3-binomial-additivity">
<h3><a class="toc-backref" href="#id14" role="doc-backlink">Problem 3: Binomial Additivity</a><a class="headerlink" href="#problem-3-binomial-additivity" title="Link to this heading"></a></h3>
<p>Let <span class="math notranslate nohighlight">\(X_1, \ldots, X_m\)</span> be independent Binomial random variables with <strong>the same success probability</strong> <span class="math notranslate nohighlight">\(p\)</span> but possibly different numbers of trials <span class="math notranslate nohighlight">\(n_1, \ldots, n_m\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(X_i = k) = \binom{n_i}{k} p^k (1-p)^{n_i - k}, \quad k = 0, 1, \ldots, n_i\]</div>
<p>Let <span class="math notranslate nohighlight">\(S = \sum_{i=1}^m X_i\)</span>.</p>
<p><strong>(a)</strong> Prove that <span class="math notranslate nohighlight">\(S \sim \text{Binomial}(N, p)\)</span> where <span class="math notranslate nohighlight">\(N = \sum_{i=1}^m n_i\)</span>.</p>
<p><strong>(b)</strong> What happens if the <span class="math notranslate nohighlight">\(X_i\)</span> have different success probabilities <span class="math notranslate nohighlight">\(p_i\)</span>? Is the sum still Binomial? Justify your answer (a counterexample or brief argument suffices).</p>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p>The Binomial MGF is <span class="math notranslate nohighlight">\((1 - p + pe^t)^n\)</span> — after your hand derivation, use SymPy to check the product simplifies correctly</p></li>
<li><p>Taking logarithms before comparing can simplify the algebra: <code class="docutils literal notranslate"><span class="pre">simplify(log(product)</span> <span class="pre">-</span> <span class="pre">log(combined))</span></code></p></li>
<li><p>Generate Binomial samples with varying n values but the <strong>same</strong> p, then sum</p></li>
<li><p>For part (b), try sampling from Binomials with different p values and observe that the sum’s distribution doesn’t match any Binomial — plot the PMF to see the discrepancy</p></li>
</ul>
</section>
<section id="problem-4-normal-additivity">
<h3><a class="toc-backref" href="#id15" role="doc-backlink">Problem 4: Normal Additivity</a><a class="headerlink" href="#problem-4-normal-additivity" title="Link to this heading"></a></h3>
<p>Let <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> be independent and identically distributed <span class="math notranslate nohighlight">\(\mathcal{N}(\mu, \sigma^2)\)</span> random variables. Let <span class="math notranslate nohighlight">\(S_n = \sum_{i=1}^n X_i\)</span>.</p>
<p><strong>(a)</strong> Prove that <span class="math notranslate nohighlight">\(S_n \sim \mathcal{N}(n\mu, n\sigma^2)\)</span>.</p>
<p><strong>(b)</strong> As a corollary, prove that the sample mean <span class="math notranslate nohighlight">\(\bar{X} = S_n/n\)</span> follows <span class="math notranslate nohighlight">\(\mathcal{N}(\mu, \sigma^2/n)\)</span>. This is the exact (finite-sample) distribution, not an asymptotic approximation.</p>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p>The Normal MGF is <span class="math notranslate nohighlight">\(\exp(\mu t + \sigma^2 t^2/2)\)</span> — after your hand derivation, use SymPy to check that <span class="math notranslate nohighlight">\([M_X(t)]^n\)</span> simplifies to <span class="math notranslate nohighlight">\(M_{S_n}(t)\)</span></p></li>
<li><p>Generate an (n_samples × n) matrix of Normal samples, then use <code class="docutils literal notranslate"><span class="pre">np.sum(...,</span> <span class="pre">axis=1)</span></code> for sums and <code class="docutils literal notranslate"><span class="pre">np.mean(...,</span> <span class="pre">axis=1)</span></code> for means</p></li>
<li><p>Create two visualizations: one for the sum <span class="math notranslate nohighlight">\(S_n \sim N(n\mu, n\sigma^2)\)</span> and one for the mean <span class="math notranslate nohighlight">\(\bar{X} \sim N(\mu, \sigma^2/n)\)</span></p></li>
<li><p>The sample mean distribution is <strong>exact</strong> (not asymptotic) — verify that even small n gives perfect agreement</p></li>
</ul>
</section>
<section id="problem-5-chi-square-from-normal-squares">
<h3><a class="toc-backref" href="#id16" role="doc-backlink">Problem 5: Chi-Square from Normal Squares</a><a class="headerlink" href="#problem-5-chi-square-from-normal-squares" title="Link to this heading"></a></h3>
<p>This problem establishes one of the most important constructions in statistical inference.</p>
<p><strong>(a)</strong> Let <span class="math notranslate nohighlight">\(Z \sim \mathcal{N}(0, 1)\)</span> and define <span class="math notranslate nohighlight">\(Y = Z^2\)</span>. <strong>Derive from first principles</strong> that:</p>
<div class="math notranslate nohighlight">
\[M_Y(t) = \mathbb{E}[e^{tZ^2}] = (1 - 2t)^{-1/2}, \quad t &lt; \frac{1}{2}\]</div>
<p>and conclude that <span class="math notranslate nohighlight">\(Y \sim \chi^2(1)\)</span>.</p>
<p><strong>Hint</strong>: Write the expectation as an integral over the standard normal density, combine exponents, and use the Gaussian integral identity:</p>
<div class="math notranslate nohighlight">
\[\int_{-\infty}^{\infty} e^{-az^2} \, dz = \sqrt{\frac{\pi}{a}}, \quad a &gt; 0\]</div>
<p><strong>(b)</strong> Now let <span class="math notranslate nohighlight">\(Z_1, \ldots, Z_n\)</span> be iid <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span> and define <span class="math notranslate nohighlight">\(Q = \sum_{i=1}^n Z_i^2\)</span>. Prove that <span class="math notranslate nohighlight">\(Q \sim \chi^2(n)\)</span>.</p>
<p><strong>(c)</strong> Explain why this result implies that for a random sample <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> from <span class="math notranslate nohighlight">\(\mathcal{N}(\mu, \sigma^2)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)\]</div>
<p>where <span class="math notranslate nohighlight">\(S^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2\)</span> is the sample variance. (You may state without proof that <span class="math notranslate nohighlight">\(\sum (X_i - \bar{X})^2/\sigma^2\)</span> involves <span class="math notranslate nohighlight">\(n-1\)</span> independent squared standard normals.)</p>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p>For part (a), after deriving the MGF by hand, verify your integral computation using SymPy: <code class="docutils literal notranslate"><span class="pre">integrate(exp(t*z**2)</span> <span class="pre">*</span> <span class="pre">exp(-z**2/2)</span> <span class="pre">/</span> <span class="pre">sqrt(2*pi),</span> <span class="pre">(z,</span> <span class="pre">-oo,</span> <span class="pre">oo),</span> <span class="pre">conds='none')</span></code> should simplify to <span class="math notranslate nohighlight">\((1-2t)^{-1/2}\)</span></p></li>
<li><p>For part (b), square standard normal samples and sum across columns, then compare to <code class="docutils literal notranslate"><span class="pre">stats.chi2.rvs(df=n,</span> <span class="pre">...)</span></code></p></li>
<li><p>The <span class="math notranslate nohighlight">\(\chi^2\)</span> distribution is right-skewed with support <span class="math notranslate nohighlight">\([0, \infty)\)</span> — set appropriate x-axis limits for visualization</p></li>
<li><p>Theoretical moments: <span class="math notranslate nohighlight">\(E[\chi^2_n] = n\)</span>, <span class="math notranslate nohighlight">\(\text{Var}(\chi^2_n) = 2n\)</span></p></li>
</ul>
</section>
<section id="problem-6-the-gamma-poisson-negative-binomial-triangle">
<h3><a class="toc-backref" href="#id17" role="doc-backlink">Problem 6: The Gamma-Poisson-Negative Binomial Triangle</a><a class="headerlink" href="#problem-6-the-gamma-poisson-negative-binomial-triangle" title="Link to this heading"></a></h3>
<p>This problem explores the deep connections between three distributions that arise naturally in count data modeling. The relationships have both theoretical elegance and practical importance—the Negative Binomial emerges as an “overdispersed Poisson” when the Poisson rate is itself random.</p>
<p><strong>Background</strong>: In many applications, count data exhibits more variability than a Poisson model predicts. One explanation: the rate parameter <span class="math notranslate nohighlight">\(\lambda\)</span> varies across observations. If we model this heterogeneity by treating <span class="math notranslate nohighlight">\(\lambda\)</span> as a Gamma-distributed random variable, the resulting marginal distribution is Negative Binomial.</p>
<p><strong>(a) Poisson-Gamma Mixture</strong>: Let <span class="math notranslate nohighlight">\(X \mid \Lambda = \lambda \sim \text{Poisson}(\lambda)\)</span> and let <span class="math notranslate nohighlight">\(\Lambda \sim \text{Gamma}(r, \beta)\)</span> with PDF:</p>
<div class="math notranslate nohighlight">
\[f_\Lambda(\lambda) = \frac{\beta^r}{\Gamma(r)} \lambda^{r-1} e^{-\beta\lambda}, \quad \lambda &gt; 0\]</div>
<p>Show that the marginal distribution of <span class="math notranslate nohighlight">\(X\)</span> (integrating out <span class="math notranslate nohighlight">\(\Lambda\)</span>) is Negative Binomial. Specifically, prove:</p>
<div class="math notranslate nohighlight">
\[P(X = k) = \binom{k + r - 1}{k} \left(\frac{\beta}{1 + \beta}\right)^r \left(\frac{1}{1 + \beta}\right)^k, \quad k = 0, 1, 2, \ldots\]</div>
<p><strong>Hint</strong>: Write <span class="math notranslate nohighlight">\(P(X = k) = \int_0^\infty P(X = k \mid \Lambda = \lambda) f_\Lambda(\lambda) \, d\lambda\)</span>, substitute the Poisson PMF and Gamma PDF, then recognize the resulting integral as a Gamma function.</p>
<p><strong>(b) Identifying the Parameterization</strong>: The result in (a) gives a Negative Binomial in the “number of failures before <span class="math notranslate nohighlight">\(r\)</span> successes” parameterization. Show that if we define <span class="math notranslate nohighlight">\(p = \frac{\beta}{1 + \beta}\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[P(X = k) = \binom{k + r - 1}{k} p^r (1-p)^k\]</div>
<p>Verify that <span class="math notranslate nohighlight">\(\mathbb{E}[X] = \frac{r(1-p)}{p} = \frac{r}{\beta}\)</span> and <span class="math notranslate nohighlight">\(\text{Var}(X) = \frac{r(1-p)}{p^2} = \frac{r(1+\beta)}{\beta^2}\)</span>.</p>
<p><strong>(c) Overdispersion</strong>: For a Poisson distribution, <span class="math notranslate nohighlight">\(\text{Var}(X) = \mathbb{E}[X]\)</span>. Show that for the Negative Binomial from part (b):</p>
<div class="math notranslate nohighlight">
\[\text{Var}(X) = \mathbb{E}[X] + \frac{(\mathbb{E}[X])^2}{r}\]</div>
<p>This demonstrates <strong>overdispersion</strong>: <span class="math notranslate nohighlight">\(\text{Var}(X) &gt; \mathbb{E}[X]\)</span>. Explain intuitively why mixing over the rate parameter increases variability.</p>
<p><strong>(d) Poisson Process Connection</strong>: In a Poisson process with rate <span class="math notranslate nohighlight">\(\mu\)</span>, let <span class="math notranslate nohighlight">\(N(t)\)</span> be the number of events by time <span class="math notranslate nohighlight">\(t\)</span>, and let <span class="math notranslate nohighlight">\(T_r\)</span> be the time of the <span class="math notranslate nohighlight">\(r\)</span>-th event. We have:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N(t) \sim \text{Poisson}(\mu t)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(T_r \sim \text{Gamma}(r, \mu)\)</span> (shape <span class="math notranslate nohighlight">\(r\)</span>, rate <span class="math notranslate nohighlight">\(\mu\)</span>)</p></li>
</ul>
<p>Prove the fundamental equivalence:</p>
<div class="math notranslate nohighlight">
\[P(N(t) \geq r) = P(T_r \leq t)\]</div>
<p><strong>Hint</strong>: The event “at least <span class="math notranslate nohighlight">\(r\)</span> arrivals by time <span class="math notranslate nohighlight">\(t\)</span>” is equivalent to “the <span class="math notranslate nohighlight">\(r\)</span>-th arrival occurred by time <span class="math notranslate nohighlight">\(t\)</span>.”</p>
<p><strong>(e) Exponential-Gamma Additivity</strong>: As a parallel to Problem 1 (Geometric <span class="math notranslate nohighlight">\(\to\)</span> Negative Binomial), prove using MGFs that if <span class="math notranslate nohighlight">\(X_1, \ldots, X_r\)</span> are iid <span class="math notranslate nohighlight">\(\text{Exponential}(\lambda)\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[S_r = \sum_{i=1}^r X_i \sim \text{Gamma}(r, \lambda)\]</div>
<p>This shows that Gamma is to Exponential as Negative Binomial is to Geometric—the waiting time for <span class="math notranslate nohighlight">\(r\)</span> events in continuous vs. discrete time.</p>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p><strong>Part (a/b)</strong>: To construct the Poisson-Gamma mixture, first sample <span class="math notranslate nohighlight">\(\Lambda \sim \text{Gamma}(r, \beta)\)</span> using <code class="docutils literal notranslate"><span class="pre">stats.gamma.rvs(a=r,</span> <span class="pre">scale=1/beta,</span> <span class="pre">...)</span></code>, then sample <span class="math notranslate nohighlight">\(X \mid \Lambda\)</span> from <code class="docutils literal notranslate"><span class="pre">stats.poisson.rvs(mu=lambda_sample)</span></code> for each <span class="math notranslate nohighlight">\(\Lambda\)</span> value</p></li>
<li><p>SciPy’s Negative Binomial uses the “failures before r successes” parameterization with <span class="math notranslate nohighlight">\(p = \beta/(1+\beta)\)</span></p></li>
<li><p><strong>Part (c)</strong>: Compute the theoretical variance using both the direct formula and the overdispersion formula <span class="math notranslate nohighlight">\(\text{Var} = E[X] + E[X]^2/r\)</span> to verify they match</p></li>
<li><p><strong>Part (d)</strong>: Compare <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">-</span> <span class="pre">stats.poisson.cdf(r-1,</span> <span class="pre">mu=mu*t)</span></code> with <code class="docutils literal notranslate"><span class="pre">stats.gamma.cdf(t,</span> <span class="pre">a=r,</span> <span class="pre">scale=1/mu)</span></code> — they should be equal to machine precision</p></li>
<li><p><strong>Part (e)</strong>: Sum Exponential samples and compare to Gamma; note SciPy’s <code class="docutils literal notranslate"><span class="pre">expon</span></code> uses scale = 1/rate, so <code class="docutils literal notranslate"><span class="pre">stats.expon.rvs(scale=1/lambda,</span> <span class="pre">...)</span></code></p></li>
<li><p>Create two visualizations: one for the Poisson-Gamma mixture (discrete) and one for Exponential-to-Gamma (continuous)</p></li>
</ul>
</section>
</section>
<section id="part-ii-transformation-methods">
<h2><a class="toc-backref" href="#id18" role="doc-backlink">Part II: Transformation Methods</a><a class="headerlink" href="#part-ii-transformation-methods" title="Link to this heading"></a></h2>
<p>These distributions lack MGFs, requiring transformation (Jacobian) techniques. Derive the PDFs by hand using change-of-variables, then use numerical sampling to verify your results.</p>
<section id="problem-7-ratio-of-normals-is-cauchy">
<h3><a class="toc-backref" href="#id19" role="doc-backlink">Problem 7: Ratio of Normals is Cauchy</a><a class="headerlink" href="#problem-7-ratio-of-normals-is-cauchy" title="Link to this heading"></a></h3>
<p>Let <span class="math notranslate nohighlight">\(Z_1, Z_2\)</span> be independent <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span> random variables. Define <span class="math notranslate nohighlight">\(V = Z_1 / Z_2\)</span>.</p>
<p><strong>(a)</strong> Prove that <span class="math notranslate nohighlight">\(V\)</span> has the standard Cauchy distribution:</p>
<div class="math notranslate nohighlight">
\[f_V(v) = \frac{1}{\pi(1 + v^2)}, \quad v \in \mathbb{R}\]</div>
<p><strong>Suggested approach</strong>: Use polar coordinates. Define <span class="math notranslate nohighlight">\(R = \sqrt{Z_1^2 + Z_2^2}\)</span> and <span class="math notranslate nohighlight">\(\Theta\)</span> as the angle, where <span class="math notranslate nohighlight">\(\Theta \in (-\pi, \pi]\)</span>. Show that:</p>
<ol class="arabic simple">
<li><p>Under the isotropic bivariate standard normal, <span class="math notranslate nohighlight">\(\Theta\)</span> is uniformly distributed (the angle is independent of radius for spherically symmetric distributions)</p></li>
<li><p><span class="math notranslate nohighlight">\(V = Z_1/Z_2 = \tan(\Theta)\)</span> for <span class="math notranslate nohighlight">\(\Theta \neq \pm\pi/2\)</span></p></li>
<li><p>Use the transformation method to find <span class="math notranslate nohighlight">\(f_V(v)\)</span> from the uniform distribution on <span class="math notranslate nohighlight">\(\Theta\)</span></p></li>
</ol>
<p><em>Note</em>: The set where <span class="math notranslate nohighlight">\(Z_2 = 0\)</span> has probability zero and can be ignored.</p>
<p><strong>(b)</strong> Verify that the Cauchy PDF integrates to 1. Explain why the MGF <span class="math notranslate nohighlight">\(\mathbb{E}[e^{tV}]\)</span> does not exist for any <span class="math notranslate nohighlight">\(t \neq 0\)</span>.</p>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p>After computing the Jacobian by hand for the polar transformation <span class="math notranslate nohighlight">\((z_1, z_2) = (r\cos\theta, r\sin\theta)\)</span>, you can check your result using SymPy’s <code class="docutils literal notranslate"><span class="pre">Matrix([...]).jacobian([r,</span> <span class="pre">theta])</span></code> — it should give <span class="math notranslate nohighlight">\(|J| = r\)</span></p></li>
<li><p>Verify that the Cauchy PDF integrates to 1 using <code class="docutils literal notranslate"><span class="pre">integrate(1/(pi*(1+v**2)),</span> <span class="pre">(v,</span> <span class="pre">-oo,</span> <span class="pre">oo))</span></code></p></li>
<li><p>To construct samples: generate independent <span class="math notranslate nohighlight">\(Z_1, Z_2 \sim N(0,1)\)</span> and compute <span class="math notranslate nohighlight">\(V = Z_1/Z_2\)</span>. Do <strong>not</strong> filter samples for correctness—the probability of <span class="math notranslate nohighlight">\(Z_2\)</span> being exactly zero is zero</p></li>
<li><p><strong>Visualization challenge</strong>: The Cauchy distribution has such heavy tails that histograms are dominated by extreme values. For readability, clip the histogram x-axis to a central range (e.g., <code class="docutils literal notranslate"><span class="pre">[-10,</span> <span class="pre">10]</span></code>), but keep all samples and use full quantile comparisons to verify tail behavior</p></li>
<li><p>Compare quantiles at extreme probabilities (1%, 5%, 95%, 99%) to verify the heavy tails match theory</p></li>
<li><p>The Cauchy has no mean or variance — sample moments will be unstable and meaningless</p></li>
</ul>
</section>
<section id="problem-8-student-s-t-from-normal-and-chi-square">
<h3><a class="toc-backref" href="#id20" role="doc-backlink">Problem 8: Student’s t from Normal and Chi-Square</a><a class="headerlink" href="#problem-8-student-s-t-from-normal-and-chi-square" title="Link to this heading"></a></h3>
<p>Let <span class="math notranslate nohighlight">\(Z \sim \mathcal{N}(0, 1)\)</span> and <span class="math notranslate nohighlight">\(U \sim \chi^2(\nu)\)</span> be <strong>independent</strong>. Define:</p>
<div class="math notranslate nohighlight">
\[T = \frac{Z}{\sqrt{U/\nu}}\]</div>
<p><strong>(a)</strong> Prove that <span class="math notranslate nohighlight">\(T\)</span> has Student’s <span class="math notranslate nohighlight">\(t\)</span> distribution with <span class="math notranslate nohighlight">\(\nu\)</span> degrees of freedom:</p>
<div class="math notranslate nohighlight">
\[f_T(t) = \frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu\pi} \, \Gamma\left(\frac{\nu}{2}\right)} \left(1 + \frac{t^2}{\nu}\right)^{-(\nu+1)/2}, \quad t \in \mathbb{R}\]</div>
<p><strong>Suggested approach</strong>: Use conditioning. Note that <span class="math notranslate nohighlight">\(T \mid U = u \sim \mathcal{N}(0, \nu/u)\)</span>. Then:</p>
<div class="math notranslate nohighlight">
\[f_T(t) = \int_0^\infty f_{T|U}(t \mid u) \cdot f_U(u) \, du\]</div>
<p>Substitute the Normal and Chi-square densities, then evaluate the integral using the Gamma function identity.</p>
<p><strong>(b)</strong> Verify that as <span class="math notranslate nohighlight">\(\nu \to \infty\)</span>, the <span class="math notranslate nohighlight">\(t_\nu\)</span> distribution approaches <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span>. Based on your KS statistic plot, propose a data-driven threshold for <span class="math notranslate nohighlight">\(\nu\)</span> at which the normal approximation becomes adequate (e.g., KS statistic drops below 0.02).</p>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p>Construct <span class="math notranslate nohighlight">\(T = Z / \sqrt{U/\nu}\)</span> where <span class="math notranslate nohighlight">\(Z \sim N(0,1)\)</span> and <span class="math notranslate nohighlight">\(U \sim \chi^2(\nu)\)</span> are independent</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">stats.chi2.rvs(df=nu,</span> <span class="pre">...)</span></code> for chi-squared samples</p></li>
<li><p>Compare against <code class="docutils literal notranslate"><span class="pre">stats.t.rvs(df=nu,</span> <span class="pre">...)</span></code> for direct t-distribution samples</p></li>
<li><p>Theoretical variance: <span class="math notranslate nohighlight">\(\text{Var}(T) = \nu/(\nu-2)\)</span> for <span class="math notranslate nohighlight">\(\nu &gt; 2\)</span>; undefined for <span class="math notranslate nohighlight">\(\nu \leq 2\)</span></p></li>
<li><p><strong>For part (b)</strong>: Create a two-panel figure: (1) t-distribution PDFs for <span class="math notranslate nohighlight">\(\nu \in \{1, 3, 5, 10, 30\}\)</span> overlaid with N(0,1), and (2) KS statistic vs. <span class="math notranslate nohighlight">\(\nu\)</span> for <span class="math notranslate nohighlight">\(\nu \in \{3, 5, 10, 15, 20, 25, 30, 40, 50\}\)</span></p></li>
<li><p>A common rule of thumb states <span class="math notranslate nohighlight">\(t_{30} \approx N(0,1)\)</span> — does your analysis support this?</p></li>
</ul>
</section>
<section id="problem-9-f-distribution-from-chi-squares">
<h3><a class="toc-backref" href="#id21" role="doc-backlink">Problem 9: F Distribution from Chi-Squares</a><a class="headerlink" href="#problem-9-f-distribution-from-chi-squares" title="Link to this heading"></a></h3>
<p>Let <span class="math notranslate nohighlight">\(U \sim \chi^2(\nu_1)\)</span> and <span class="math notranslate nohighlight">\(V \sim \chi^2(\nu_2)\)</span> be <strong>independent</strong>. Define:</p>
<div class="math notranslate nohighlight">
\[F = \frac{U/\nu_1}{V/\nu_2}\]</div>
<p><strong>(a)</strong> Prove that <span class="math notranslate nohighlight">\(F\)</span> has the <span class="math notranslate nohighlight">\(F(\nu_1, \nu_2)\)</span> distribution:</p>
<div class="math notranslate nohighlight">
\[f_F(x) = \frac{1}{B(\nu_1/2, \nu_2/2)} \left(\frac{\nu_1}{\nu_2}\right)^{\nu_1/2} x^{\nu_1/2 - 1} \left(1 + \frac{\nu_1}{\nu_2}x\right)^{-(\nu_1+\nu_2)/2}, \quad x &gt; 0\]</div>
<p>where <span class="math notranslate nohighlight">\(B(a, b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}\)</span> is the Beta function.</p>
<p><strong>Hint</strong>: Use the Gamma representation: <span class="math notranslate nohighlight">\(\chi^2(\nu) = \text{Gamma}(\nu/2, 1/2)\)</span>. Transform <span class="math notranslate nohighlight">\((U, V) \mapsto (F, V)\)</span> and integrate out <span class="math notranslate nohighlight">\(V\)</span>.</p>
<p><strong>(b)</strong> Show that if <span class="math notranslate nohighlight">\(T \sim t(\nu)\)</span>, then <span class="math notranslate nohighlight">\(T^2 \sim F(1, \nu)\)</span>. This connects the <span class="math notranslate nohighlight">\(t\)</span>-test to the <span class="math notranslate nohighlight">\(F\)</span>-test.</p>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p>Construct <span class="math notranslate nohighlight">\(F = (U/\nu_1) / (V/\nu_2)\)</span> where <span class="math notranslate nohighlight">\(U \sim \chi^2(\nu_1)\)</span> and <span class="math notranslate nohighlight">\(V \sim \chi^2(\nu_2)\)</span> are independent</p></li>
<li><p>Compare against <code class="docutils literal notranslate"><span class="pre">stats.f.rvs(dfn=nu1,</span> <span class="pre">dfd=nu2,</span> <span class="pre">...)</span></code> for direct F-distribution samples</p></li>
<li><p>Theoretical mean: <span class="math notranslate nohighlight">\(E[F] = \nu_2/(\nu_2 - 2)\)</span> for <span class="math notranslate nohighlight">\(\nu_2 &gt; 2\)</span> (note: depends only on denominator df)</p></li>
<li><p>The F distribution has support <span class="math notranslate nohighlight">\([0, \infty)\)</span> and is right-skewed — set x-axis limits appropriately</p></li>
<li><p><strong>For part (b)</strong>: Generate <span class="math notranslate nohighlight">\(T \sim t(\nu)\)</span> samples, square them, and compare to <span class="math notranslate nohighlight">\(F(1, \nu)\)</span> samples</p></li>
<li><p>This demonstrates why a two-sided t-test at level <span class="math notranslate nohighlight">\(\alpha\)</span> is equivalent to an F-test at level <span class="math notranslate nohighlight">\(\alpha\)</span>: if <span class="math notranslate nohighlight">\(|T| &gt; t_{\alpha/2, \nu}\)</span>, then <span class="math notranslate nohighlight">\(T^2 &gt; F_{\alpha, 1, \nu}\)</span></p></li>
<li><p>Create two visualizations: one for the general F construction, one for the <span class="math notranslate nohighlight">\(T^2 \sim F(1, \nu)\)</span> relationship</p></li>
</ul>
</section>
</section>
<section id="part-iii-computational-foundations">
<h2><a class="toc-backref" href="#id22" role="doc-backlink">Part III: Computational Foundations</a><a class="headerlink" href="#part-iii-computational-foundations" title="Link to this heading"></a></h2>
<p>This section tests your understanding of the fundamental computational concepts from Chapter 1: the Central Limit Theorem, convergence in distribution, and proper use of Python’s random generation ecosystem.</p>
<section id="problem-10-the-central-limit-theorem-in-action">
<h3><a class="toc-backref" href="#id23" role="doc-backlink">Problem 10: The Central Limit Theorem in Action</a><a class="headerlink" href="#problem-10-the-central-limit-theorem-in-action" title="Link to this heading"></a></h3>
<p>The <strong>Central Limit Theorem (CLT)</strong> states that for iid random variables <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2 &lt; \infty\)</span>:</p>
<div class="math notranslate nohighlight">
\[\frac{\bar{X}_n - \mu}{\sigma / \sqrt{n}} \xrightarrow{d} \mathcal{N}(0, 1) \quad \text{as } n \to \infty\]</div>
<p>This problem explores the CLT empirically across distributions with very different shapes.</p>
<p><strong>(a) CLT Universality</strong>: For each of the following distributions, generate <strong>5,000 samples</strong> of size <span class="math notranslate nohighlight">\(n\)</span> for <span class="math notranslate nohighlight">\(n \in \{1, 2, 5, 10, 30, 100\}\)</span>. For each sample, compute the standardized sample mean:</p>
<div class="math notranslate nohighlight">
\[Z_n = \frac{\bar{X}_n - \mu}{\sigma / \sqrt{n}}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> are the <strong>theoretical</strong> mean and standard deviation.</p>
<p>Test with these distributions (use the theoretical moments given):</p>
<ol class="arabic simple">
<li><p><strong>Exponential(1)</strong>: <span class="math notranslate nohighlight">\(\mu = 1\)</span>, <span class="math notranslate nohighlight">\(\sigma = 1\)</span> (right-skewed)</p></li>
<li><p><strong>Uniform(0, 1)</strong>: <span class="math notranslate nohighlight">\(\mu = 0.5\)</span>, <span class="math notranslate nohighlight">\(\sigma = 1/\sqrt{12}\)</span> (symmetric, bounded)</p></li>
<li><p><strong>Bernoulli(0.1)</strong>: <span class="math notranslate nohighlight">\(\mu = 0.1\)</span>, <span class="math notranslate nohighlight">\(\sigma = \sqrt{0.1 \times 0.9}\)</span> (discrete, highly skewed)</p></li>
<li><p><strong>Beta(0.5, 0.5)</strong>: <span class="math notranslate nohighlight">\(\mu = 0.5\)</span>, <span class="math notranslate nohighlight">\(\sigma = 0.5/\sqrt{2}\)</span> (U-shaped)</p></li>
</ol>
<p>Create a <span class="math notranslate nohighlight">\(4 \times 6\)</span> grid of histograms showing the distribution of <span class="math notranslate nohighlight">\(Z_n\)</span> for each (distribution, n) combination, with the <span class="math notranslate nohighlight">\(N(0,1)\)</span> PDF overlaid. Title each panel with the distribution name and sample size.</p>
<p><strong>(b) Quantifying Convergence with the Kolmogorov-Smirnov Test</strong>: The <strong>Kolmogorov-Smirnov (KS) statistic</strong> measures the maximum vertical distance between two cumulative distribution functions:</p>
<div class="math notranslate nohighlight">
\[D_n = \sup_x |F_n(x) - F(x)|\]</div>
<p>where <span class="math notranslate nohighlight">\(F_n(x)\)</span> is the empirical CDF and <span class="math notranslate nohighlight">\(F(x)\)</span> is the reference CDF. Smaller values indicate better agreement. The one-sample KS test compares a sample against a theoretical distribution; <code class="docutils literal notranslate"><span class="pre">stats.kstest(samples,</span> <span class="pre">'norm')</span></code> returns both the KS statistic and a p-value testing the null hypothesis that the sample came from <span class="math notranslate nohighlight">\(N(0,1)\)</span>.</p>
<p>For each distribution from part (a), compute the KS statistic between your standardized means and <span class="math notranslate nohighlight">\(N(0,1)\)</span> for each value of <span class="math notranslate nohighlight">\(n\)</span>. Create a single plot showing KS statistic vs. <span class="math notranslate nohighlight">\(n\)</span> (use log scale for n) with one line per distribution. Which distribution converges fastest? Slowest? Explain why in terms of the source distribution’s shape (symmetry, boundedness, skewness).</p>
<p><strong>(c) Studentized Statistics</strong>: In practice, we rarely know the true <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>. The <strong>studentized</strong> version of the CLT uses sample estimates:</p>
<div class="math notranslate nohighlight">
\[T_n = \frac{\bar{X}_n - \mu}{S_n / \sqrt{n}}\]</div>
<p>where <span class="math notranslate nohighlight">\(S_n\)</span> is the sample standard deviation. For normal populations, <span class="math notranslate nohighlight">\(T_n \sim t(n-1)\)</span> exactly. For non-normal populations, <span class="math notranslate nohighlight">\(T_n \xrightarrow{d} N(0,1)\)</span> as <span class="math notranslate nohighlight">\(n \to \infty\)</span>, but convergence may be slower.</p>
<p>Repeat part (a) using the studentized statistic <span class="math notranslate nohighlight">\(T_n\)</span> instead of <span class="math notranslate nohighlight">\(Z_n\)</span> (replace <span class="math notranslate nohighlight">\(\sigma\)</span> with <span class="math notranslate nohighlight">\(S_n\)</span> computed from each sample). Create another <span class="math notranslate nohighlight">\(4 \times 6\)</span> grid and compare to your results from part (a). For which distributions and sample sizes does using estimated variance make a noticeable difference?</p>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">np.random.default_rng(seed)</span></code> for reproducibility</p></li>
<li><p>For each (distribution, n) combination, generate a matrix of shape <code class="docutils literal notranslate"><span class="pre">(n_simulations,</span> <span class="pre">n)</span></code> and compute row means using <code class="docutils literal notranslate"><span class="pre">np.mean(...,</span> <span class="pre">axis=1)</span></code></p></li>
<li><p>For part (a), standardize using theoretical moments</p></li>
<li><p>For part (c), compute sample standard deviations with <code class="docutils literal notranslate"><span class="pre">np.std(...,</span> <span class="pre">axis=1,</span> <span class="pre">ddof=1)</span></code> (use <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code> for the unbiased estimator)</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">stats.kstest(samples,</span> <span class="pre">'norm')</span></code> to get the KS statistic—the function returns a named tuple with <code class="docutils literal notranslate"><span class="pre">.statistic</span></code> and <code class="docutils literal notranslate"><span class="pre">.pvalue</span></code> attributes</p></li>
</ul>
</section>
<section id="problem-11-reproducibility-and-parallel-streams">
<h3><a class="toc-backref" href="#id24" role="doc-backlink">Problem 11: Reproducibility and Parallel Streams</a><a class="headerlink" href="#problem-11-reproducibility-and-parallel-streams" title="Link to this heading"></a></h3>
<p>Proper random number generation is critical for reproducible research. This problem tests your understanding of seeds, generator state, and parallel streams.</p>
<p><strong>(a) Seed Sensitivity</strong>: Consider estimating <span class="math notranslate nohighlight">\(E[X^2]\)</span> where <span class="math notranslate nohighlight">\(X \sim N(0, 1)\)</span> (true value = 1) using <span class="math notranslate nohighlight">\(n = 100\)</span> samples.</p>
<ul class="simple">
<li><p>Run this estimation with 10 different seeds (0 through 9)</p></li>
<li><p>Report the 10 estimates and their sample standard deviation</p></li>
<li><p>Now repeat with <span class="math notranslate nohighlight">\(n = 10000\)</span> samples — how does seed sensitivity change?</p></li>
<li><p>Explain the relationship between sample size and seed sensitivity</p></li>
</ul>
<p><strong>(b) Generator State</strong>: Demonstrate that you understand generator state by completing this task:</p>
<ul class="simple">
<li><p>Create a generator with seed 42</p></li>
<li><p>Draw 100 uniform samples and compute their mean (call it <code class="docutils literal notranslate"><span class="pre">mean_a</span></code>)</p></li>
<li><p>Save the generator state using <code class="docutils literal notranslate"><span class="pre">.bit_generator.state</span></code></p></li>
<li><p>Draw 100 more uniform samples and compute their mean (call it <code class="docutils literal notranslate"><span class="pre">mean_b</span></code>)</p></li>
<li><p>Restore the saved state</p></li>
<li><p>Draw 100 uniform samples and verify their mean equals <code class="docutils literal notranslate"><span class="pre">mean_b</span></code></p></li>
</ul>
<p>Report all three means and confirm the state restoration worked.</p>
<p><strong>(c) Parallel Streams</strong>: When running simulations in parallel, each worker needs an independent random stream. Using <code class="docutils literal notranslate"><span class="pre">SeedSequence.spawn()</span></code>:</p>
<ul class="simple">
<li><p>Create a parent <code class="docutils literal notranslate"><span class="pre">SeedSequence</span></code> with entropy 42</p></li>
<li><p>Spawn 4 child sequences</p></li>
<li><p>Create a generator from each child</p></li>
<li><p>From each generator, draw 10000 samples from <span class="math notranslate nohighlight">\(N(0, 1)\)</span> and compute the mean</p></li>
<li><p>Verify the streams are independent by computing pairwise correlations between the raw samples (should be near 0)</p></li>
</ul>
<p>Report the 4 means and the 6 pairwise correlations.</p>
<p><strong>(d) The Birthday Problem Revisited</strong>: Use Monte Carlo simulation to estimate the probability that in a room of <span class="math notranslate nohighlight">\(k\)</span> people, at least two share a birthday (assume 365 equally likely birthdays).</p>
<ul class="simple">
<li><p>Write a function <code class="docutils literal notranslate"><span class="pre">birthday_collision(k,</span> <span class="pre">rng)</span></code> that simulates one room and returns True if there’s a collision</p></li>
<li><p>Estimate the probability for <span class="math notranslate nohighlight">\(k \in \{10, 20, 23, 30, 40, 50\}\)</span> using 100,000 simulations each</p></li>
<li><p>Compare to the exact formula: <span class="math notranslate nohighlight">\(P(\text{collision}) = 1 - \frac{365!}{365^k (365-k)!}\)</span></p></li>
<li><p>Your estimates should be within 0.01 of the exact values</p></li>
</ul>
<p><strong>Computational Verification Tips:</strong></p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">rng.bit_generator.state</span></code> to save/restore state (it’s a dictionary)</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">SeedSequence</span></code>, use <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">numpy.random</span> <span class="pre">import</span> <span class="pre">SeedSequence,</span> <span class="pre">default_rng</span></code></p></li>
<li><p>For parallel streams: <code class="docutils literal notranslate"><span class="pre">children</span> <span class="pre">=</span> <span class="pre">SeedSequence(42).spawn(4)</span></code>, then <code class="docutils literal notranslate"><span class="pre">rng_i</span> <span class="pre">=</span> <span class="pre">default_rng(children[i])</span></code></p></li>
<li><p>For birthday collisions, <code class="docutils literal notranslate"><span class="pre">rng.integers(0,</span> <span class="pre">365,</span> <span class="pre">size=k)</span></code> gives k random birthdays; check for duplicates with <code class="docutils literal notranslate"><span class="pre">len(set(birthdays))</span> <span class="pre">&lt;</span> <span class="pre">k</span></code></p></li>
<li><p>The exact birthday formula can overflow; use <code class="docutils literal notranslate"><span class="pre">scipy.special.perm(365,</span> <span class="pre">k)</span></code> or compute in log space</p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Homework Assignments" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../part1_foundations/index.html" class="btn btn-neutral float-right" title="Part I: Foundations of Probability and Computation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>