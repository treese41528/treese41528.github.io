

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Section 1.3 Python Random Generation &mdash; STAT 418</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=3d0abd52" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT418/Website/part1_foundations/chapter1/ch1_3-python_random_generation.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Show solution';</script>
      <script>let toggleHintHide = 'Hide solution';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=8718e0ab"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Section 1.4 Chapter 1 Summary: Foundations in Place" href="ch1_4-chapter-summary.html" />
    <link rel="prev" title="Section 1.2 Probability Distributions: Theory and Computation" href="ch1_2-probability_distributions_review.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Course Content</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Part I: Foundations of Probability and Computation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Chapter 1: Statistical Paradigms and Core Concepts</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ch1_1-probability-and-inference-paradigms.html">Section 1.1 Paradigms of Probability and Statistical Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch1_1-probability-and-inference-paradigms.html#the-mathematical-foundation-kolmogorov-s-axioms">The Mathematical Foundation: Kolmogorov’s Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_1-probability-and-inference-paradigms.html#interpretations-of-probability">Interpretations of Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_1-probability-and-inference-paradigms.html#statistical-inference-paradigms">Statistical Inference Paradigms</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_1-probability-and-inference-paradigms.html#historical-and-philosophical-debates">Historical and Philosophical Debates</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_1-probability-and-inference-paradigms.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_1-probability-and-inference-paradigms.html#looking-ahead-our-course-focus">Looking Ahead: Our Course Focus</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_1-probability-and-inference-paradigms.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch1_2-probability_distributions_review.html">Section 1.2 Probability Distributions: Theory and Computation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch1_2-probability_distributions_review.html#from-abstract-foundations-to-concrete-tools">From Abstract Foundations to Concrete Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_2-probability_distributions_review.html#the-python-ecosystem-for-probability">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_2-probability_distributions_review.html#introduction-why-probability-distributions-matter">Introduction: Why Probability Distributions Matter</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_2-probability_distributions_review.html#id1">The Python Ecosystem for Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_2-probability_distributions_review.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_2-probability_distributions_review.html#continuous-distributions">Continuous Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_2-probability_distributions_review.html#additional-important-distributions">Additional Important Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_2-probability_distributions_review.html#summary-and-practical-guidelines">Summary and Practical Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_2-probability_distributions_review.html#conclusion">Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_2-probability_distributions_review.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Section 1.3 Python Random Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#from-mathematical-distributions-to-computational-samples">From Mathematical Distributions to Computational Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-python-ecosystem-at-a-glance">The Python Ecosystem at a Glance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#understanding-pseudo-random-number-generation">Understanding Pseudo-Random Number Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-standard-library-random-module">The Standard Library: <code class="docutils literal notranslate"><span class="pre">random</span></code> Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#numpy-fast-vectorized-random-sampling">NumPy: Fast Vectorized Random Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scipy-stats-the-complete-statistical-toolkit">SciPy Stats: The Complete Statistical Toolkit</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bringing-it-all-together-library-selection-guide">Bringing It All Together: Library Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="#looking-ahead-from-random-numbers-to-monte-carlo-methods">Looking Ahead: From Random Numbers to Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ch1_4-chapter-summary.html">Section 1.4 Chapter 1 Summary: Foundations in Place</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ch1_4-chapter-summary.html#the-three-pillars-of-chapter-1">The Three Pillars of Chapter 1</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_4-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_4-chapter-summary.html#what-lies-ahead-the-road-to-simulation">What Lies Ahead: The Road to Simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_4-chapter-summary.html#chapter-1-exercises-synthesis-problems">Chapter 1 Exercises: Synthesis Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="ch1_4-chapter-summary.html#references-and-further-reading">References and Further Reading</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part2_frequentist/index.html">Part II: Frequentist Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part2_frequentist/chapter2/index.html">Chapter 2: Monte Carlo Simulation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html">Monte Carlo Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#the-historical-development-of-monte-carlo-methods">The Historical Development of Monte Carlo Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#the-core-principle-expectation-as-integration">The Core Principle: Expectation as Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#theoretical-foundations">Theoretical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#variance-estimation-and-confidence-intervals">Variance Estimation and Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#comparison-with-deterministic-methods">Comparison with Deterministic Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#sample-size-determination">Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#convergence-diagnostics-and-monitoring">Convergence Diagnostics and Monitoring</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#chapter-2-1-exercises-monte-carlo-fundamentals-mastery">Chapter 2.1 Exercises: Monte Carlo Fundamentals Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#id1">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_1-monte-carlo-fundamentals.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html">Uniform Random Variates</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#why-uniform-the-universal-currency-of-randomness">Why Uniform? The Universal Currency of Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#the-paradox-of-computational-randomness">The Paradox of Computational Randomness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#chaotic-dynamical-systems-an-instructive-failure">Chaotic Dynamical Systems: An Instructive Failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#linear-congruential-generators">Linear Congruential Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#shift-register-generators">Shift-Register Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#the-kiss-generator-combining-strategies">The KISS Generator: Combining Strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#modern-generators-mersenne-twister-and-pcg">Modern Generators: Mersenne Twister and PCG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#statistical-testing-of-random-number-generators">Statistical Testing of Random Number Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#chapter-2-2-exercises-uniform-random-variates-mastery">Chapter 2.2 Exercises: Uniform Random Variates Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_2-uniform-random-variates.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html">Inverse CDF Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#mathematical-foundations">Mathematical Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#continuous-distributions-with-closed-form-inverses">Continuous Distributions with Closed-Form Inverses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#numerical-inversion">Numerical Inversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#discrete-distributions">Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#mixed-distributions">Mixed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#chapter-2-3-exercises-inverse-cdf-method-mastery">Chapter 2.3 Exercises: Inverse CDF Method Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#id1">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#transition-to-what-follows">Transition to What Follows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_3-inverse-cdf-method.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html">Transformation Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#why-transformation-methods">Why Transformation Methods?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#the-boxmuller-transform">The Box–Muller Transform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#the-polar-marsaglia-method">The Polar (Marsaglia) Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#method-comparison-boxmuller-vs-polar-vs-ziggurat">Method Comparison: Box–Muller vs Polar vs Ziggurat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#the-ziggurat-algorithm">The Ziggurat Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#the-clt-approximation-historical">The CLT Approximation (Historical)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#distributions-derived-from-the-normal">Distributions Derived from the Normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#multivariate-normal-generation">Multivariate Normal Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#implementation-guidance">Implementation Guidance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#chapter-2-4-exercises-transformation-methods-mastery">Chapter 2.4 Exercises: Transformation Methods Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_4-transformation-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html">Rejection Sampling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#the-dartboard-intuition">The Dartboard Intuition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#the-accept-reject-algorithm">The Accept-Reject Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#efficiency-analysis">Efficiency Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#choosing-the-proposal-distribution">Choosing the Proposal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#the-squeeze-principle">The Squeeze Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#geometric-example-sampling-from-the-unit-disk">Geometric Example: Sampling from the Unit Disk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#worked-examples">Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#limitations-and-the-curse-of-dimensionality">Limitations and the Curse of Dimensionality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#connections-to-other-methods">Connections to Other Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#chapter-2-5-exercises-rejection-sampling-mastery">Chapter 2.5 Exercises: Rejection Sampling Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_5-rejection-sampling.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html">Variance Reduction Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#the-variance-reduction-paradigm">The Variance Reduction Paradigm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#importance-sampling">Importance Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#control-variates">Control Variates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#antithetic-variates">Antithetic Variates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#stratified-sampling">Stratified Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#common-random-numbers">Common Random Numbers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#conditional-monte-carlo-raoblackwellization">Conditional Monte Carlo (Rao–Blackwellization)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#combining-variance-reduction-techniques">Combining Variance Reduction Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#chapter-2-6-exercises-variance-reduction-mastery">Chapter 2.6 Exercises: Variance Reduction Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_6-variance-reduction-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_7-chapter-summary.html">Chapter Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_7-chapter-summary.html#the-complete-monte-carlo-workflow">The Complete Monte Carlo Workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_7-chapter-summary.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_7-chapter-summary.html#quick-reference-tables">Quick Reference Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_7-chapter-summary.html#common-pitfalls-checklist">Common Pitfalls Checklist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_7-chapter-summary.html#connections-to-later-chapters">Connections to Later Chapters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_7-chapter-summary.html#learning-outcomes-checklist">Learning Outcomes Checklist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_7-chapter-summary.html#further-reading-optimization-and-missing-data">Further Reading: Optimization and Missing Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_7-chapter-summary.html#final-perspective">Final Perspective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter2/ch2_7-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../part2_frequentist/chapter3/index.html">Chapter 3: Parametric Inference and Likelihood Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html">Exponential Families</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#historical-origins-from-scattered-results-to-unified-theory">Historical Origins: From Scattered Results to Unified Theory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#the-canonical-exponential-family">The Canonical Exponential Family</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#converting-familiar-distributions">Converting Familiar Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#the-log-partition-function-a-moment-generating-machine">The Log-Partition Function: A Moment-Generating Machine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#sufficiency-capturing-all-parameter-information">Sufficiency: Capturing All Parameter Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#minimal-sufficiency-and-completeness">Minimal Sufficiency and Completeness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#conjugate-priors-and-bayesian-inference">Conjugate Priors and Bayesian Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#exponential-dispersion-models-and-glms">Exponential Dispersion Models and GLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#python-implementation">Python Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#chapter-3-1-exercises-exponential-families-mastery">Chapter 3.1 Exercises: Exponential Families Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_1-exponential-families.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html">Maximum Likelihood Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#the-likelihood-function">The Likelihood Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#the-score-function">The Score Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#fisher-information">Fisher Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#closed-form-maximum-likelihood-estimators">Closed-Form Maximum Likelihood Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#numerical-optimization-for-mle">Numerical Optimization for MLE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#asymptotic-properties-of-mles">Asymptotic Properties of MLEs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#the-cramer-rao-lower-bound">The Cramér-Rao Lower Bound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#the-invariance-property">The Invariance Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#likelihood-based-hypothesis-testing">Likelihood-Based Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#confidence-intervals-from-likelihood">Confidence Intervals from Likelihood</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#connection-to-bayesian-inference">Connection to Bayesian Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#chapter-3-2-exercises-maximum-likelihood-estimation-mastery">Chapter 3.2 Exercises: Maximum Likelihood Estimation Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_2-maximum-likelihood-estimation.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html">Sampling Variability and Variance Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html#statistical-estimators-and-their-properties">Statistical Estimators and Their Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html#sampling-distributions">Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html#the-delta-method">The Delta Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html#the-plug-in-principle">The Plug-in Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html#variance-estimation-methods">Variance Estimation Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html#applications-and-worked-examples">Applications and Worked Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_3-sampling-variability.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html">Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#matrix-calculus-foundations">Matrix Calculus Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#the-linear-model">The Linear Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#ordinary-least-squares-the-calculus-approach">Ordinary Least Squares: The Calculus Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#ordinary-least-squares-the-geometric-approach">Ordinary Least Squares: The Geometric Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#properties-of-the-ols-estimator">Properties of the OLS Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#the-gauss-markov-theorem">The Gauss-Markov Theorem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#estimating-the-error-variance">Estimating the Error Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#distributional-results-under-normality">Distributional Results Under Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#diagnostics-and-model-checking">Diagnostics and Model Checking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#numerical-stability-qr-decomposition">Numerical Stability: QR Decomposition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#model-selection-and-information-criteria">Model Selection and Information Criteria</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#regularization-ridge-and-lasso">Regularization: Ridge and LASSO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#chapter-3-4-exercises-linear-models-mastery">Chapter 3.4 Exercises: Linear Models Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_4-linear-models.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html">Generalized Linear Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#historical-context-unification-of-regression-methods">Historical Context: Unification of Regression Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#the-glm-framework-three-components">The GLM Framework: Three Components</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#score-equations-and-fisher-information">Score Equations and Fisher Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#iteratively-reweighted-least-squares">Iteratively Reweighted Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#logistic-regression-binary-outcomes">Logistic Regression: Binary Outcomes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#poisson-regression-count-data">Poisson Regression: Count Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#gamma-regression-positive-continuous-data">Gamma Regression: Positive Continuous Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#inference-in-glms-the-testing-triad">Inference in GLMs: The Testing Triad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#model-diagnostics">Model Diagnostics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#model-comparison-and-selection">Model Comparison and Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#quasi-likelihood-and-robust-inference">Quasi-Likelihood and Robust Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#further-reading">Further Reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#chapter-3-5-exercises-generalized-linear-models-mastery">Chapter 3.5 Exercises: Generalized Linear Models Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_5-generalized-linear-models.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_6-chapter-summary.html">Chapter Summary</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_6-chapter-summary.html#the-parametric-inference-pipeline">The Parametric Inference Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_6-chapter-summary.html#the-five-pillars-of-chapter-3">The Five Pillars of Chapter 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_6-chapter-summary.html#how-the-pillars-connect">How the Pillars Connect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_6-chapter-summary.html#method-selection-guide">Method Selection Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_6-chapter-summary.html#quick-reference-core-formulas">Quick Reference: Core Formulas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_6-chapter-summary.html#connections-to-future-material">Connections to Future Material</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_6-chapter-summary.html#practical-guidance">Practical Guidance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_6-chapter-summary.html#final-perspective">Final Perspective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter3/ch3_6-chapter-summary.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../part2_frequentist/chapter4/index.html">Chapter 4: Resampling Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html">The Sampling Distribution Problem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html#the-fundamental-target-sampling-distributions">The Fundamental Target: Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html#historical-development-the-quest-for-sampling-distributions">Historical Development: The Quest for Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html#three-routes-to-the-sampling-distribution">Three Routes to the Sampling Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html#when-asymptotics-fail-motivating-the-bootstrap">When Asymptotics Fail: Motivating the Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html#the-plug-in-principle-theoretical-foundation">The Plug-In Principle: Theoretical Foundation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html#computational-perspective-bootstrap-as-monte-carlo">Computational Perspective: Bootstrap as Monte Carlo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html#chapter-4-1-exercises">Chapter 4.1 Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_1-sampling-distribution-problem.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html">The Empirical Distribution and Plug-in Principle</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html#the-empirical-cumulative-distribution-function">The Empirical Cumulative Distribution Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html#convergence-of-the-empirical-cdf">Convergence of the Empirical CDF</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html#parameters-as-statistical-functionals">Parameters as Statistical Functionals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html#the-plug-in-principle">The Plug-in Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html#when-the-plug-in-principle-fails">When the Plug-in Principle Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html#the-bootstrap-idea-in-one-sentence">The Bootstrap Idea in One Sentence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html#computational-implementation">Computational Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html#section-4-2-exercises-ecdf-and-plug-in-mastery">Section 4.2 Exercises: ECDF and Plug-in Mastery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_2-empirical-distribution-plugin.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html">The Nonparametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#the-bootstrap-principle">The Bootstrap Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-standard-errors">Bootstrap Standard Errors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-bias-estimation">Bootstrap Bias Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-confidence-intervals">Bootstrap Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-for-regression">Bootstrap for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#bootstrap-diagnostics">Bootstrap Diagnostics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#when-bootstrap-fails">When Bootstrap Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_3-nonparametric-bootstrap.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html">Section 4.4: The Parametric Bootstrap</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html#the-parametric-bootstrap-principle">The Parametric Bootstrap Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html#location-scale-families">Location-Scale Families</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html#parametric-bootstrap-for-regression">Parametric Bootstrap for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html#confidence-intervals">Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html#model-checking-and-validation">Model Checking and Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html#when-parametric-bootstrap-fails">When Parametric Bootstrap Fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html#parametric-vs-nonparametric-a-decision-framework">Parametric vs. Nonparametric: A Decision Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_4-parametric-bootstrap.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html">Section 4.5: Jackknife Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html#historical-context-and-motivation">Historical Context and Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html#the-delete-1-jackknife">The Delete-1 Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html#jackknife-bias-estimation">Jackknife Bias Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html#the-delete-d-jackknife">The Delete-<span class="math notranslate nohighlight">\(d\)</span> Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html#jackknife-versus-bootstrap">Jackknife versus Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html#the-infinitesimal-jackknife">The Infinitesimal Jackknife</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_5-jackknife-methods.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html">Section 4.6 Bootstrap Hypothesis Testing and Permutation Tests</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#from-confidence-intervals-to-hypothesis-tests">From Confidence Intervals to Hypothesis Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#the-bootstrap-hypothesis-testing-framework">The Bootstrap Hypothesis Testing Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#permutation-tests-exact-tests-under-exchangeability">Permutation Tests: Exact Tests Under Exchangeability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#testing-equality-of-distributions">Testing Equality of Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#bootstrap-tests-for-regression">Bootstrap Tests for Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#bootstrap-vs-classical-tests">Bootstrap vs Classical Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#permutation-vs-bootstrap-choosing-the-right-approach">Permutation vs Bootstrap: Choosing the Right Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#multiple-testing-with-bootstrap">Multiple Testing with Bootstrap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#practical-considerations">Practical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#bringing-it-all-together">Bringing It All Together</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#exercises">Exercises</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../part2_frequentist/chapter4/ch4_6-bootstrap-hypothesis-testing.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part3_bayesian/index.html">Part III: Bayesian Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part3_bayesian/chapter5/index.html">Chapter 5: Bayesian Inference</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../part4_llms_datascience/index.html">Part IV: Large Language Models in Data Science</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../part4_llms_datascience/chapter6/index.html">Chapter 6: LLMs in Data Science Workflows</a><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Part I: Foundations of Probability and Computation</a></li>
          <li class="breadcrumb-item"><a href="index.html">Chapter 1: Statistical Paradigms and Core Concepts</a></li>
      <li class="breadcrumb-item active">Section 1.3 Python Random Generation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/part1_foundations/chapter1/ch1_3-python_random_generation.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="section-1-3-python-random-generation">
<span id="ch1-3-python-random-generation"></span><h1>Section 1.3 Python Random Generation<a class="headerlink" href="#section-1-3-python-random-generation" title="Link to this heading"></a></h1>
<section id="from-mathematical-distributions-to-computational-samples">
<h2>From Mathematical Distributions to Computational Samples<a class="headerlink" href="#from-mathematical-distributions-to-computational-samples" title="Link to this heading"></a></h2>
<p>In Chapter 1.1, we established what probability <em>means</em>—whether as long-run frequencies or degrees of belief. In Chapter 1.2, we catalogued the probability distributions that model real phenomena—Normal, Exponential, Gamma, Poisson, and dozens more—understanding their mathematical properties, relationships, and when they arise naturally.</p>
<p>But theoretical understanding alone doesn’t generate data. When we need 10,000 bootstrap samples, a million Monte Carlo iterations, or posterior draws from an MCMC chain, we must bridge the gap from mathematical abstraction to computational reality. This chapter provides that bridge: a comprehensive guide to Python’s ecosystem for random number generation and probability computation.</p>
<p>Sampling from probability distributions underpins <strong>simulation, Bayesian inference, uncertainty quantification, and generative modeling</strong>. Python offers a rich ecosystem—from the zero-dependency standard library to high-performance scientific computing frameworks. Understanding when and how to use each tool is essential for effective computational statistics.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p><strong>Understand</strong>: How pseudo-random number generators create reproducible “randomness” and why explicit seeding matters for scientific work</p></li>
<li><p><strong>Develop</strong>: Fluency with Python’s <code class="docutils literal notranslate"><span class="pre">random</span></code> module, NumPy’s <code class="docutils literal notranslate"><span class="pre">Generator</span></code> API, and SciPy’s <code class="docutils literal notranslate"><span class="pre">stats</span></code> distribution objects</p></li>
<li><p><strong>Implement</strong>: Sampling from all distributions covered in Chapter 1.2; weighted and stratified sampling; sequence operations</p></li>
<li><p><strong>Evaluate</strong>: Performance trade-offs, parameterization conventions, and management of parallel random streams</p></li>
</ul>
</div>
</section>
<section id="the-python-ecosystem-at-a-glance">
<h2>The Python Ecosystem at a Glance<a class="headerlink" href="#the-python-ecosystem-at-a-glance" title="Link to this heading"></a></h2>
<p>Before diving into details, here’s a map of the tools we’ll explore:</p>
<table class="docutils align-default" id="id1">
<caption><span class="caption-number">Table 3 </span><span class="caption-text">Python Libraries for Random Generation</span><a class="headerlink" href="#id1" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 30.0%" />
<col style="width: 30.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Category</p></th>
<th class="head"><p>Library</p></th>
<th class="head"><p>Why You Might Pick It</p></th>
<th class="head"><p>Best For</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Standard Library</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">random</span></code></p></td>
<td><p>Always available; quick scalar draws; simple shuffles; 11 classic distributions</p></td>
<td><p>Teaching, prototyping, dependency-free scripts</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Scientific Computing</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">numpy.random</span></code></p></td>
<td><p>Vectorized C/Fortran backends; 10–100× faster; array output; 50+ distributions</p></td>
<td><p>Monte Carlo, bootstrap, large-scale simulation</p></td>
</tr>
<tr class="row-even"><td><p><strong>Statistical Modeling</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code></p></td>
<td><p>100+ distributions; PDF/CDF/PPF/fitting; statistical tests</p></td>
<td><p>Distribution fitting, hypothesis testing, complete statistical toolkit</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Deep Learning</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch</span></code>, <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code></p></td>
<td><p>GPU acceleration; differentiable distributions</p></td>
<td><p>Neural network initialization, VAEs, reinforcement learning</p></td>
</tr>
<tr class="row-even"><td><p><strong>Probabilistic Programming</strong></p></td>
<td><p>PyMC, Pyro, Stan</p></td>
<td><p>High-level model syntax; MCMC &amp; VI engines</p></td>
<td><p>Complex Bayesian models (covered in Chapter 5)</p></td>
</tr>
</tbody>
</table>
<p>The choice of library depends on your task. As a rule of thumb:</p>
<ul class="simple">
<li><p><strong>Need just a few random numbers?</strong> → <code class="docutils literal notranslate"><span class="pre">random</span></code> module</p></li>
<li><p><strong>Need arrays of random numbers fast?</strong> → NumPy <code class="docutils literal notranslate"><span class="pre">Generator</span></code></p></li>
<li><p><strong>Need probability calculations (PDF, CDF, quantiles)?</strong> → <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code></p></li>
<li><p><strong>Building a Bayesian model?</strong> → PyMC, Pyro, or Stan (Chapter 5)</p></li>
</ul>
</section>
<section id="understanding-pseudo-random-number-generation">
<h2>Understanding Pseudo-Random Number Generation<a class="headerlink" href="#understanding-pseudo-random-number-generation" title="Link to this heading"></a></h2>
<p>Before using any library, we should understand what’s happening under the hood. Computers are deterministic machines—given the same input, they produce the same output. So how do they generate “random” numbers?</p>
<section id="the-nature-of-pseudo-randomness">
<h3>The Nature of Pseudo-Randomness<a class="headerlink" href="#the-nature-of-pseudo-randomness" title="Link to this heading"></a></h3>
<p><strong>Pseudo-random number generators (PRNGs)</strong> are deterministic algorithms that produce sequences of numbers which, while entirely predictable given the algorithm and starting point, pass stringent statistical tests for randomness. When you call <code class="docutils literal notranslate"><span class="pre">random.random()</span></code>, you’re executing a mathematical formula that computes the next number in a deterministic sequence.</p>
<p>This determinism is actually a feature, not a bug:</p>
<ol class="arabic simple">
<li><p><strong>Reproducibility</strong>: Given the same starting point (the <strong>seed</strong>), a PRNG produces exactly the same sequence. This enables scientific reproducibility—if you report bootstrap results, others can verify your exact computation.</p></li>
<li><p><strong>Debugging</strong>: When a simulation produces unexpected results, fixing the seed lets you reproduce the problematic run while investigating.</p></li>
<li><p><strong>Testing</strong>: Unit tests for stochastic code can have deterministic pass/fail criteria.</p></li>
</ol>
</section>
<section id="what-makes-a-good-prng">
<h3>What Makes a Good PRNG?<a class="headerlink" href="#what-makes-a-good-prng" title="Link to this heading"></a></h3>
<p>A sequence <span class="math notranslate nohighlight">\(u_1, u_2, u_3, \ldots\)</span> behaves like independent draws from <span class="math notranslate nohighlight">\(\text{Uniform}(0, 1)\)</span> if it satisfies:</p>
<p><strong>Uniformity</strong>: Values should be evenly distributed across <span class="math notranslate nohighlight">\([0, 1)\)</span>. Dividing into <span class="math notranslate nohighlight">\(k\)</span> equal bins, each should contain approximately <span class="math notranslate nohighlight">\(n/k\)</span> of <span class="math notranslate nohighlight">\(n\)</span> total values.</p>
<p><strong>Independence</strong>: Knowing <span class="math notranslate nohighlight">\(u_t\)</span> should provide no information about <span class="math notranslate nohighlight">\(u_{t+1}\)</span>. No correlation between values at any lag.</p>
<p><strong>Long period</strong>: The <strong>period</strong>—the length before the sequence repeats—should vastly exceed any practical simulation length.</p>
<p><strong>High-dimensional equidistribution</strong>: When consecutive outputs are used as coordinates in high-dimensional space, points should fill the space uniformly.</p>
<p>Modern PRNGs are tested against extensive statistical test suites (like TestU01’s BigCrush). The generators in Python and NumPy pass these tests.</p>
</section>
<section id="the-mersenne-twister">
<h3>The Mersenne Twister<a class="headerlink" href="#the-mersenne-twister" title="Link to this heading"></a></h3>
<p>Python’s standard library uses the <strong>Mersenne Twister</strong> (MT19937), developed by Matsumoto and Nishimura in 1997:</p>
<ul class="simple">
<li><p><strong>Period</strong>: <span class="math notranslate nohighlight">\(2^{19937} - 1\)</span> (approximately <span class="math notranslate nohighlight">\(10^{6001}\)</span>)—far exceeding any simulation need</p></li>
<li><p><strong>623-dimensional equidistribution</strong>: Suitable for high-dimensional Monte Carlo</p></li>
<li><p><strong>State size</strong>: 624 × 32-bit integers (19,968 bits)</p></li>
<li><p><strong>Speed</strong>: Uses simple bit operations; very fast</p></li>
</ul>
<p><strong>Limitations</strong>: Not cryptographically secure (given 624 outputs, the state can be reconstructed). For security applications, use Python’s <code class="docutils literal notranslate"><span class="pre">secrets</span></code> module.</p>
</section>
<section id="numpy-s-pcg64">
<h3>NumPy’s PCG64<a class="headerlink" href="#numpy-s-pcg64" title="Link to this heading"></a></h3>
<p>NumPy’s modern <code class="docutils literal notranslate"><span class="pre">Generator</span></code> API defaults to <strong>PCG64</strong> (Permuted Congruential Generator):</p>
<ul class="simple">
<li><p><strong>Period</strong>: <span class="math notranslate nohighlight">\(2^{128}\)</span> with smaller state (128 bits)</p></li>
<li><p><strong>Better statistical properties</strong>: Passes even more stringent tests</p></li>
<li><p><strong>Faster</strong>: Simpler operations on modern 64-bit CPUs</p></li>
<li><p><strong>Jumpable</strong>: Can efficiently skip ahead, enabling parallel streams</p></li>
</ul>
<p>For new projects, NumPy’s PCG64 is generally preferred over Mersenne Twister.</p>
</section>
</section>
<section id="the-standard-library-random-module">
<h2>The Standard Library: <code class="docutils literal notranslate"><span class="pre">random</span></code> Module<a class="headerlink" href="#the-standard-library-random-module" title="Link to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">random</span></code> module ships with every Python installation—no <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span></code> required. It’s ideal for teaching, prototyping, and situations where external dependencies are problematic.</p>
<section id="generating-random-numbers">
<h3>Generating Random Numbers<a class="headerlink" href="#generating-random-numbers" title="Link to this heading"></a></h3>
<p>The foundation of all random generation is the uniform distribution on <span class="math notranslate nohighlight">\([0, 1)\)</span>:</p>
<table class="docutils align-default" id="id2">
<caption><span class="caption-number">Table 4 </span><span class="caption-text">Basic Random Number Functions</span><a class="headerlink" href="#id2" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 15.0%" />
<col style="width: 60.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Function</p></th>
<th class="head"><p>Output</p></th>
<th class="head"><p>Notes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">random.random()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">float</span></code></p></td>
<td><p>Uniform on <span class="math notranslate nohighlight">\([0, 1)\)</span>; the fundamental building block</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">random.uniform(a,</span> <span class="pre">b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">float</span></code></p></td>
<td><p>Uniform on <span class="math notranslate nohighlight">\([a, b]\)</span>; implemented as <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">+</span> <span class="pre">(b-a)</span> <span class="pre">*</span> <span class="pre">random()</span></code>; if <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&gt;</span> <span class="pre">b</span></code> silently swaps</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">random.randint(a,</span> <span class="pre">b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Discrete uniform on <span class="math notranslate nohighlight">\(\{a, a+1, \ldots, b\}\)</span>; <strong>inclusive on both ends</strong></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">random.randrange(start,</span> <span class="pre">stop,</span> <span class="pre">step)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span></code></p></td>
<td><p>Like <code class="docutils literal notranslate"><span class="pre">range()</span></code> but random element; <strong>half-open</strong> (excludes <code class="docutils literal notranslate"><span class="pre">stop</span></code>)</p></td>
</tr>
</tbody>
</table>
<p><strong>Rule of thumb</strong>: Use <code class="docutils literal notranslate"><span class="pre">random()</span></code> for unit-interval floats; <code class="docutils literal notranslate"><span class="pre">uniform(a,</span> <span class="pre">b)</span></code> for self-documenting intervals; <code class="docutils literal notranslate"><span class="pre">randint(a,</span> <span class="pre">b)</span></code> for dice rolls and indices.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statistics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean</span><span class="p">,</span> <span class="n">pvariance</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># For reproducibility</span>

<span class="c1"># Generate U(0,1) samples</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>

<span class="c1"># Verify distributional properties</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;U(0,1)  n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  mean     : </span><span class="si">{</span><span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">  (theory 0.5000)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  variance : </span><span class="si">{</span><span class="n">pvariance</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">  (theory 0.0833)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  min…max  : </span><span class="si">{</span><span class="nb">min</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2"> … </span><span class="si">{</span><span class="nb">max</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="random-operations-on-sequences">
<h3>Random Operations on Sequences<a class="headerlink" href="#random-operations-on-sequences" title="Link to this heading"></a></h3>
<p>Beyond generating numbers, we often need to sample from existing sequences—selecting survey respondents, shuffling experimental treatments, or drawing cards.</p>
<table class="docutils align-default" id="id3">
<caption><span class="caption-number">Table 5 </span><span class="caption-text">Sequence Sampling Functions</span><a class="headerlink" href="#id3" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 28.0%" />
<col style="width: 12.0%" />
<col style="width: 12.0%" />
<col style="width: 10.0%" />
<col style="width: 10.0%" />
<col style="width: 28.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Function</p></th>
<th class="head"><p>Returns</p></th>
<th class="head"><p>Replacement?</p></th>
<th class="head"><p>Size</p></th>
<th class="head"><p>Weights?</p></th>
<th class="head"><p>When to Use</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">random.choice(seq)</span></code></p></td>
<td><p>One element</p></td>
<td><p>—</p></td>
<td><p>—</p></td>
<td><p>No</p></td>
<td><p>Pick a single winner, coin-flip between labels</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">random.choices(seq,</span> <span class="pre">k=,</span> <span class="pre">weights=)</span></code></p></td>
<td><p>List of <code class="docutils literal notranslate"><span class="pre">k</span></code></p></td>
<td><p><strong>With</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">k=</span></code></p></td>
<td><p>Yes</p></td>
<td><p>Bootstrap resampling, Monte Carlo from categorical</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">random.sample(seq,</span> <span class="pre">k)</span></code></p></td>
<td><p>List of <code class="docutils literal notranslate"><span class="pre">k</span></code> <strong>unique</strong></p></td>
<td><p><strong>Without</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">k</span></code> positional</p></td>
<td><p>No</p></td>
<td><p>Deal cards, random subset for cross-validation</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">random.shuffle(seq)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">None</span></code></p></td>
<td><p>—</p></td>
<td><p>whole seq</p></td>
<td><p>—</p></td>
<td><p>In-place permutation (e.g., shuffle deck)</p></td>
</tr>
</tbody>
</table>
<p><strong>Key distinction</strong>: <code class="docutils literal notranslate"><span class="pre">choices</span></code> (with replacement) allows duplicates; <code class="docutils literal notranslate"><span class="pre">sample</span></code> (without replacement) guarantees uniqueness. Bootstrap resampling uses <code class="docutils literal notranslate"><span class="pre">choices</span></code>; survey sampling uses <code class="docutils literal notranslate"><span class="pre">sample</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># choice: single random element</span>
<span class="n">volunteers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Alice&quot;</span><span class="p">,</span> <span class="s2">&quot;Bob&quot;</span><span class="p">,</span> <span class="s2">&quot;Carol&quot;</span><span class="p">,</span> <span class="s2">&quot;Deepak&quot;</span><span class="p">,</span> <span class="s2">&quot;Eve&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Today&#39;s volunteer: </span><span class="si">{</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">volunteers</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># choices: weighted sampling WITH replacement (loaded die)</span>
<span class="n">faces</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.20</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">]</span>  <span class="c1"># Biased toward high values</span>
<span class="n">rolls</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">faces</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Loaded die frequencies:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">face</span><span class="p">,</span> <span class="n">target_p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">faces</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">empirical_p</span> <span class="o">=</span> <span class="n">rolls</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">face</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">rolls</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">face</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">empirical_p</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">  (target </span><span class="si">{</span><span class="n">target_p</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="c1"># sample: WITHOUT replacement (poker hand)</span>
<span class="n">deck</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">r</span><span class="si">}{</span><span class="n">s</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="s2">&quot;♠♥♦♣&quot;</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="s2">&quot;A23456789TJQK&quot;</span><span class="p">]</span>
<span class="n">hand</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">deck</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Poker hand: </span><span class="si">{</span><span class="n">hand</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># shuffle: in-place randomization</span>
<span class="n">items</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shuffled: </span><span class="si">{</span><span class="n">items</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><code class="docutils literal notranslate"><span class="pre">shuffle()</span></code> works only on <strong>mutable</strong> sequences (lists). For strings or tuples, convert to a list first:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;HELLO&quot;</span>
<span class="n">letters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">letters</span><span class="p">)</span>
<span class="n">shuffled</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">letters</span><span class="p">)</span>  <span class="c1"># e.g., &quot;OELHL&quot;</span>
</pre></div>
</div>
</div>
</section>
<section id="distribution-generators">
<h3>Distribution Generators<a class="headerlink" href="#distribution-generators" title="Link to this heading"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">random</span></code> module provides generators for common continuous distributions. Each uses the <strong>rate</strong> or <strong>scale</strong> parameterization noted below—pay attention to avoid errors.</p>
<table class="docutils align-default" id="id4">
<caption><span class="caption-number">Table 6 </span><span class="caption-text">Continuous Distribution Functions in <code class="docutils literal notranslate"><span class="pre">random</span></code></span><a class="headerlink" href="#id4" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 30.0%" />
<col style="width: 35.0%" />
<col style="width: 35.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Function</p></th>
<th class="head"><p>Distribution</p></th>
<th class="head"><p>Parameters &amp; Notes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">gauss(mu,</span> <span class="pre">sigma)</span></code></p></td>
<td><p>Normal <span class="math notranslate nohighlight">\(N(\mu, \sigma^2)\)</span></p></td>
<td><p>Slightly faster than <code class="docutils literal notranslate"><span class="pre">normalvariate</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">normalvariate(mu,</span> <span class="pre">sigma)</span></code></p></td>
<td><p>Normal <span class="math notranslate nohighlight">\(N(\mu, \sigma^2)\)</span></p></td>
<td><p>Thread-safe version</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">expovariate(lambd)</span></code></p></td>
<td><p>Exponential with <strong>rate</strong> <span class="math notranslate nohighlight">\(\lambda\)</span></p></td>
<td><p>Mean = <span class="math notranslate nohighlight">\(1/\lambda\)</span>. <strong>Not scale!</strong></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">gammavariate(alpha,</span> <span class="pre">beta)</span></code></p></td>
<td><p>Gamma with shape <span class="math notranslate nohighlight">\(\alpha\)</span>, <strong>scale</strong> <span class="math notranslate nohighlight">\(\beta\)</span></p></td>
<td><p>Mean = <span class="math notranslate nohighlight">\(\alpha \beta\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">betavariate(alpha,</span> <span class="pre">beta)</span></code></p></td>
<td><p>Beta(<span class="math notranslate nohighlight">\(\alpha, \beta\)</span>)</p></td>
<td><p>Support <span class="math notranslate nohighlight">\([0, 1]\)</span>; mean = <span class="math notranslate nohighlight">\(\alpha/(\alpha+\beta)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">lognormvariate(mu,</span> <span class="pre">sigma)</span></code></p></td>
<td><p>Log-Normal</p></td>
<td><p><span class="math notranslate nohighlight">\(\exp(N(\mu, \sigma^2))\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">weibullvariate(alpha,</span> <span class="pre">beta)</span></code></p></td>
<td><p>Weibull with scale <span class="math notranslate nohighlight">\(\alpha\)</span>, shape <span class="math notranslate nohighlight">\(\beta\)</span></p></td>
<td><p>Note: scale first, shape second</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">paretovariate(alpha)</span></code></p></td>
<td><p>Pareto Type I with shape <span class="math notranslate nohighlight">\(\alpha\)</span></p></td>
<td><p>Support <span class="math notranslate nohighlight">\([1, \infty)\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">vonmisesvariate(mu,</span> <span class="pre">kappa)</span></code></p></td>
<td><p>Von Mises (circular normal)</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu\)</span> = mean angle, <span class="math notranslate nohighlight">\(\kappa\)</span> = concentration</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">triangular(low,</span> <span class="pre">high,</span> <span class="pre">mode)</span></code></p></td>
<td><p>Triangular</p></td>
<td><p>Peak at <code class="docutils literal notranslate"><span class="pre">mode</span></code></p></td>
</tr>
</tbody>
</table>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Normal distribution</span>
<span class="n">normal_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">gauss</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;N(0,1): </span><span class="si">{</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">normal_samples</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Exponential - RATE parameter (mean = 1/rate)</span>
<span class="c1"># For mean = 2, use rate = 0.5</span>
<span class="n">exp_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">expovariate</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Exp(rate=0.5, mean=2): </span><span class="si">{</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">exp_samples</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Gamma distribution</span>
<span class="n">gamma_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">gammavariate</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gamma(α=2, β=3): </span><span class="si">{</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">gamma_samples</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Beta distribution</span>
<span class="n">beta_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">betavariate</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Beta(2,5): </span><span class="si">{</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">beta_samples</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="note admonition">
<p class="admonition-title">Example 💡: Verifying Distribution Properties</p>
<p><strong>Problem:</strong> Verify that samples from standard distributions match their theoretical moments.</p>
<p><strong>Implementation:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statistics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean</span><span class="p">,</span> <span class="n">pvariance</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">gamma</span> <span class="k">as</span> <span class="n">math_gamma</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="n">distributions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;Normal(0,1)&quot;</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">gauss</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Exponential(λ=1)&quot;</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">expovariate</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Gamma(α=2, θ=3)&quot;</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">gammavariate</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">18</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Beta(2,5)&quot;</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">betavariate</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="mi">2</span><span class="o">/</span><span class="mi">7</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">5</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">49</span><span class="o">*</span><span class="mi">8</span><span class="p">)),</span>
<span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Distribution&#39;</span><span class="si">:</span><span class="s2">&lt;22</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Sample μ&#39;</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Theory μ&#39;</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Sample σ²&#39;</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="s1">&#39;Theory σ²&#39;</span><span class="si">:</span><span class="s2">&gt;10</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">66</span><span class="p">)</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span> <span class="n">mu_th</span><span class="p">,</span> <span class="n">var_th</span> <span class="ow">in</span> <span class="n">distributions</span><span class="p">:</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">sampler</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
    <span class="n">mu_emp</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">var_emp</span> <span class="o">=</span> <span class="n">pvariance</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">:</span><span class="s2">&lt;22</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">mu_emp</span><span class="si">:</span><span class="s2">&gt;10.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">mu_th</span><span class="si">:</span><span class="s2">&gt;10.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">var_emp</span><span class="si">:</span><span class="s2">&gt;10.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">var_th</span><span class="si">:</span><span class="s2">&gt;10.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Result:</strong> Sample moments closely match theoretical values, confirming correct implementation.</p>
</div>
</section>
<section id="controlling-randomness-seeds-and-state">
<h3>Controlling Randomness: Seeds and State<a class="headerlink" href="#controlling-randomness-seeds-and-state" title="Link to this heading"></a></h3>
<p>Reproducibility is essential for scientific computing. The <code class="docutils literal notranslate"><span class="pre">random</span></code> module provides three mechanisms:</p>
<table class="docutils align-default" id="id5">
<caption><span class="caption-number">Table 7 </span><span class="caption-text">State Control Functions</span><a class="headerlink" href="#id5" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 30.0%" />
<col style="width: 35.0%" />
<col style="width: 35.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Function</p></th>
<th class="head"><p>Purpose</p></th>
<th class="head"><p>Key Details</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">seed(a=None)</span></code></p></td>
<td><p>Initialize the PRNG</p></td>
<td><p>Same seed → identical sequence; <code class="docutils literal notranslate"><span class="pre">None</span></code> uses system entropy</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">getstate()</span></code></p></td>
<td><p>Capture full internal state</p></td>
<td><p>Returns ~6300-integer tuple (Mersenne Twister state)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">setstate(state)</span></code></p></td>
<td><p>Restore captured state</p></td>
<td><p>Resumes stream exactly where it left off</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Random(seed)</span></code></p></td>
<td><p>Independent RNG object</p></td>
<td><p>Keeps multiple deterministic streams without touching global</p></td>
</tr>
</tbody>
</table>
<p><strong>Typical patterns:</strong></p>
<table class="docutils align-default" id="id6">
<caption><span class="caption-number">Table 8 </span><span class="caption-text">When to Use Each Control Method</span><a class="headerlink" href="#id6" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 35.0%" />
<col style="width: 65.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Scenario</p></th>
<th class="head"><p>Recommended Approach</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Intro demo / unit test</p></td>
<td><p>Call <code class="docutils literal notranslate"><span class="pre">random.seed(42)</span></code> at the top</p></td>
</tr>
<tr class="row-odd"><td><p>Pause &amp; resume long simulation</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">state</span> <span class="pre">=</span> <span class="pre">random.getstate()</span></code> → save to disk → later <code class="docutils literal notranslate"><span class="pre">random.setstate(state)</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Parallel simulations</p></td>
<td><p>Create <code class="docutils literal notranslate"><span class="pre">random.Random(seed+i)</span></code> per worker to avoid overlap</p></td>
</tr>
<tr class="row-odd"><td><p>Temporary determinism</p></td>
<td><p>Store state, run code, restore: <code class="docutils literal notranslate"><span class="pre">state</span> <span class="pre">=</span> <span class="pre">getstate();</span> <span class="pre">...;</span> <span class="pre">setstate(state)</span></code></p></td>
</tr>
</tbody>
</table>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>

<span class="c1"># Reproducibility demonstration</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">run1</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># Reset to same seed</span>
<span class="n">run2</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Run 1: </span><span class="si">{</span><span class="n">run1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Run 2: </span><span class="si">{</span><span class="n">run2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Identical: </span><span class="si">{</span><span class="n">run1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">run2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># True</span>

<span class="c1"># State save/restore</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>  <span class="c1"># Advance state</span>
<span class="n">saved</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">getstate</span><span class="p">()</span>

<span class="n">batch1</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="n">random</span><span class="o">.</span><span class="n">setstate</span><span class="p">(</span><span class="n">saved</span><span class="p">)</span>  <span class="c1"># Restore</span>
<span class="n">batch2</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batches match: </span><span class="si">{</span><span class="n">batch1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">batch2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># True</span>
</pre></div>
</div>
</section>
</section>
<section id="numpy-fast-vectorized-random-sampling">
<h2>NumPy: Fast Vectorized Random Sampling<a class="headerlink" href="#numpy-fast-vectorized-random-sampling" title="Link to this heading"></a></h2>
<p>For serious scientific computing—Monte Carlo simulations, bootstrap resampling, machine learning—NumPy’s random module is essential. It’s typically <strong>50–100× faster</strong> than Python loops and provides far more distributions.</p>
<section id="why-numpy-is-the-default-for-scientific-work">
<h3>Why NumPy Is the Default for Scientific Work<a class="headerlink" href="#why-numpy-is-the-default-for-scientific-work" title="Link to this heading"></a></h3>
<table class="docutils align-default" id="id7">
<caption><span class="caption-number">Table 9 </span><span class="caption-text">NumPy Advantages</span><a class="headerlink" href="#id7" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 75.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Feature</p></th>
<th class="head"><p>What It Buys You</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>ndarray-native</strong></p></td>
<td><p>Draws arrive in the same structure you use for linear algebra, broadcasting, pandas I/O</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Vectorized C/Fortran core</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">rng.normal(size=1_000_000)</span></code> finishes in milliseconds—no Python loop overhead</p></td>
</tr>
<tr class="row-even"><td><p><strong>Modern Generator API</strong></p></td>
<td><p>Independent streams (<code class="docutils literal notranslate"><span class="pre">rng1</span></code>, <code class="docutils literal notranslate"><span class="pre">rng2</span></code>) → no accidental global-state collisions</p></td>
</tr>
<tr class="row-odd"><td><p><strong>PCG64 PRNG</strong></p></td>
<td><p>Tiny state, period <span class="math notranslate nohighlight">\(2^{128}\)</span>, passes BigCrush; spawns parallel streams safely</p></td>
</tr>
<tr class="row-even"><td><p><strong>Dozens of distributions</strong></p></td>
<td><p>Uniform to Dirichlet, plus multinomial, hypergeometric, log-series, …</p></td>
</tr>
</tbody>
</table>
</section>
<section id="the-modern-generator-api">
<h3>The Modern Generator API<a class="headerlink" href="#the-modern-generator-api" title="Link to this heading"></a></h3>
<p>NumPy provides two APIs: the <strong>legacy API</strong> (<code class="docutils literal notranslate"><span class="pre">np.random.rand()</span></code>, etc.) using global state, and the <strong>modern Generator API</strong> using explicit objects. Always use the modern API:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Create a Generator with specific seed</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Generate arrays of random numbers</span>
<span class="n">uniforms</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>           <span class="c1"># 10 U(0,1) values</span>
<span class="n">normals</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>   <span class="c1"># 10 N(0,1) values</span>
<span class="n">integers</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>   <span class="c1"># 10 dice rolls {1,2,3,4,5,6}</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Uniforms: </span><span class="si">{</span><span class="n">uniforms</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Normals: </span><span class="si">{</span><span class="n">normals</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Integers: </span><span class="si">{</span><span class="n">integers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Why explicit generators are better:</strong></p>
<ol class="arabic simple">
<li><p><strong>No hidden global state</strong>: Different code sections don’t interfere</p></li>
<li><p><strong>Clear reproducibility</strong>: Pass generators to functions explicitly</p></li>
<li><p><strong>Parallel safety</strong>: Create independent streams for workers</p></li>
<li><p><strong>Better algorithms</strong>: Default PCG64 beats Mersenne Twister</p></li>
</ol>
</section>
<section id="performance-comparison">
<h3>Performance Comparison<a class="headerlink" href="#performance-comparison" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">1_000_000</span>

<span class="c1"># Python standard library</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
<span class="n">python_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">python_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="c1"># NumPy Generator</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
<span class="n">numpy_samples</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">numpy_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Python: </span><span class="si">{</span><span class="n">python_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> sec&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NumPy:  </span><span class="si">{</span><span class="n">numpy_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> sec&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Speedup: </span><span class="si">{</span><span class="n">python_time</span><span class="o">/</span><span class="n">numpy_time</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">×&quot;</span><span class="p">)</span>
<span class="c1"># Typical: 50-100× speedup</span>
</pre></div>
</div>
<figure class="align-center" id="id8">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/numpy_performance.png"><img alt="Performance comparison showing NumPy 50-100× faster than Python loops" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/numpy_performance.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 20 </span><span class="caption-text"><strong>NumPy Performance Advantage.</strong> Speedups of 50–100× come from eliminating Python’s per-element overhead, not from faster random number algorithms.</span><a class="headerlink" href="#id8" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="univariate-distributions">
<h3>Univariate Distributions<a class="headerlink" href="#univariate-distributions" title="Link to this heading"></a></h3>
<p>NumPy provides generators for all distributions from Chapter 1.2:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="c1"># Continuous distributions</span>
<span class="n">uniform_01</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>                        <span class="c1"># U(0,1)</span>
<span class="n">uniform_ab</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>                <span class="c1"># U(-3, 2)</span>
<span class="n">normal</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>   <span class="c1"># N(100, 225)</span>
<span class="n">exponential</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>   <span class="c1"># Exp(scale=2), mean=2</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>      <span class="c1"># Gamma(k=2, θ=3)</span>
<span class="n">beta</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>                <span class="c1"># Beta(2, 5)</span>

<span class="c1"># Discrete distributions</span>
<span class="n">binomial</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>     <span class="c1"># Binom(20, 0.3)</span>
<span class="n">poisson</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">lam</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>             <span class="c1"># Poisson(λ=5)</span>
<span class="n">geometric</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">geometric</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>         <span class="c1"># Geom(p=0.2)</span>

<span class="c1"># Verify moments</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;N(100,15²):  mean=</span><span class="si">{</span><span class="n">normal</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, std=</span><span class="si">{</span><span class="n">normal</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Exp(θ=2):    mean=</span><span class="si">{</span><span class="n">exponential</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gamma(2,3):  mean=</span><span class="si">{</span><span class="n">gamma</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> (theory: 6)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Poisson(5):  mean=</span><span class="si">{</span><span class="n">poisson</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, var=</span><span class="si">{</span><span class="n">poisson</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id9">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/distribution_gallery.png"><img alt="Six distributions with histograms and theoretical curves" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/distribution_gallery.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 21 </span><span class="caption-text"><strong>Sampling from Common Distributions.</strong> Histograms of 10,000 samples with theoretical curves overlaid confirm correct implementation.</span><a class="headerlink" href="#id9" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="multivariate-distributions">
<h3>Multivariate Distributions<a class="headerlink" href="#multivariate-distributions" title="Link to this heading"></a></h3>
<p>NumPy excels at multivariate distributions essential for modeling correlated data:</p>
<p><strong>Multivariate Normal:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Bivariate normal with correlation ρ = 0.8</span>
<span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
       <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]]</span>

<span class="n">samples</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample correlation: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">T</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample covariance:</span><span class="se">\n</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id10">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/multivariate_normal.png"><img alt="Three scatter plots showing correlations ρ = -0.8, 0, 0.8" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/multivariate_normal.png" style="width: 100%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 22 </span><span class="caption-text"><strong>Bivariate Normal with Different Correlations.</strong> Negative correlation creates downward-sloping clouds; positive correlation creates upward-sloping clouds.</span><a class="headerlink" href="#id10" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Dirichlet Distribution:</strong></p>
<p>The Dirichlet generates probability vectors (samples sum to 1)—essential as a prior for categorical data in Bayesian statistics:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Dirichlet with concentration α = [2, 5, 3]</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">dirichlet</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dirichlet samples (each row sums to 1):&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: [</span><span class="si">{</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">s</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">], sum=</span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Theoretical mean = α / sum(α)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Theory mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="numpy-sampling-utilities">
<h3>NumPy Sampling Utilities<a class="headerlink" href="#numpy-sampling-utilities" title="Link to this heading"></a></h3>
<p>NumPy provides powerful functions for sampling from existing arrays:</p>
<table class="docutils align-default" id="id11">
<caption><span class="caption-number">Table 10 </span><span class="caption-text">NumPy Sampling Functions</span><a class="headerlink" href="#id11" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 35.0%" />
<col style="width: 65.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Function</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">rng.choice(a,</span> <span class="pre">size,</span> <span class="pre">replace,</span> <span class="pre">p,</span> <span class="pre">axis)</span></code></p></td>
<td><p>Weighted sampling with/without replacement; <strong>axis-aware</strong> (NumPy ≥1.23)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">rng.permutation(x,</span> <span class="pre">axis)</span></code></p></td>
<td><p>Return permuted <strong>copy</strong> along axis</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">rng.shuffle(x,</span> <span class="pre">axis)</span></code></p></td>
<td><p>Shuffle <strong>in-place</strong> along axis</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">rng.bytes(n)</span></code></p></td>
<td><p>Generate <code class="docutils literal notranslate"><span class="pre">n</span></code> random bytes</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">rng.integers(low,</span> <span class="pre">high,</span> <span class="pre">size)</span></code></p></td>
<td><p>Random integers in <code class="docutils literal notranslate"><span class="pre">[low,</span> <span class="pre">high)</span></code></p></td>
</tr>
</tbody>
</table>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>

<span class="c1"># Sample WITH replacement (bootstrap)</span>
<span class="n">bootstrap</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bootstrap sample: </span><span class="si">{</span><span class="n">bootstrap</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Sample WITHOUT replacement</span>
<span class="n">subset</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unique subset: </span><span class="si">{</span><span class="n">subset</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Weighted sampling</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
<span class="n">weighted</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weighted (favors 40,50): </span><span class="si">{</span><span class="n">weighted</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Axis-aware bootstrap of rows</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">boot_rows</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Original:</span><span class="se">\n</span><span class="si">{</span><span class="n">X</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bootstrap rows:</span><span class="se">\n</span><span class="si">{</span><span class="n">boot_rows</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id12">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/sampling_replacement.png"><img alt="Sampling with vs without replacement illustration" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/sampling_replacement.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 23 </span><span class="caption-text"><strong>Sampling With vs Without Replacement.</strong> Bootstrap resampling (with replacement) allows duplicates; simple random sampling (without) guarantees uniqueness.</span><a class="headerlink" href="#id12" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="parallel-random-number-generation">
<h3>Parallel Random Number Generation<a class="headerlink" href="#parallel-random-number-generation" title="Link to this heading"></a></h3>
<p>For parallel computing, each worker needs an <strong>independent</strong> random stream. Naively using seeds 0, 1, 2, … doesn’t guarantee independence. NumPy’s <code class="docutils literal notranslate"><span class="pre">SeedSequence</span></code> provides the solution:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpy.random</span><span class="w"> </span><span class="kn">import</span> <span class="n">SeedSequence</span><span class="p">,</span> <span class="n">default_rng</span>

<span class="k">def</span><span class="w"> </span><span class="nf">mc_pi</span><span class="p">(</span><span class="n">child_seed</span><span class="p">,</span> <span class="n">n_points</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate π using one worker&#39;s independent stream.&quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">default_rng</span><span class="p">(</span><span class="n">child_seed</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n_points</span><span class="p">),</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n_points</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_points</span>

<span class="c1"># Create master seed and spawn children</span>
<span class="n">master</span> <span class="o">=</span> <span class="n">SeedSequence</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">child_seeds</span> <span class="o">=</span> <span class="n">master</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Each worker gets independent stream</span>
<span class="n">estimates</span> <span class="o">=</span> <span class="p">[</span><span class="n">mc_pi</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span> <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">child_seeds</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;π estimates from 4 workers: </span><span class="si">{</span><span class="n">estimates</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">estimates</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️</p>
<p><strong>Never share a Generator across threads or processes!</strong> Each parallel worker must have its own <code class="docutils literal notranslate"><span class="pre">Generator</span></code> from <code class="docutils literal notranslate"><span class="pre">SeedSequence.spawn()</span></code>. Sharing leads to:</p>
<ul class="simple">
<li><p>Race conditions (undefined behavior)</p></li>
<li><p>Correlated streams (invalid statistics)</p></li>
<li><p>Non-reproducibility (results depend on timing)</p></li>
</ul>
</div>
</section>
</section>
<section id="scipy-stats-the-complete-statistical-toolkit">
<h2>SciPy Stats: The Complete Statistical Toolkit<a class="headerlink" href="#scipy-stats-the-complete-statistical-toolkit" title="Link to this heading"></a></h2>
<p>While NumPy generates samples fast, <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> provides the complete mathematical infrastructure: probability density functions, cumulative distributions, quantile functions, parameter fitting, and statistical tests.</p>
<section id="why-scipy-is-the-next-stop-after-numpy">
<h3>Why SciPy Is the “Next Stop” After NumPy<a class="headerlink" href="#why-scipy-is-the-next-stop-after-numpy" title="Link to this heading"></a></h3>
<table class="docutils align-default" id="id13">
<caption><span class="caption-number">Table 11 </span><span class="caption-text">SciPy Advantages Over NumPy Alone</span><a class="headerlink" href="#id13" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 30.0%" />
<col style="width: 70.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Feature</p></th>
<th class="head"><p>What It Buys You</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>100+ distributions</strong></p></td>
<td><p>Gaussian to Zipf, each with PDF, CDF, PPF, RVS, fit</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Analytic functions</strong></p></td>
<td><p>Evaluate density, quantile, or survival at any point—no Monte Carlo noise</p></td>
</tr>
<tr class="row-even"><td><p><strong>Parameter fitting</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.&lt;dist&gt;.fit(data)</span></code> returns MLEs in one line</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Hypothesis tests</strong></p></td>
<td><p>t-, Z-, KS-, Shapiro-Wilk, χ², Levene, Kruskal-Wallis, …</p></td>
</tr>
<tr class="row-even"><td><p><strong>Bootstrap helpers</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.bootstrap</span></code>, <code class="docutils literal notranslate"><span class="pre">stats.permutation_test</span></code></p></td>
</tr>
</tbody>
</table>
<p><strong>Decision cheat-sheet:</strong></p>
<table class="docutils align-default" id="id14">
<caption><span class="caption-number">Table 12 </span><span class="caption-text">When to Use NumPy vs SciPy</span><a class="headerlink" href="#id14" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 35.0%" />
<col style="width: 20.0%" />
<col style="width: 20.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Task</p></th>
<th class="head"><p>NumPy</p></th>
<th class="head"><p>SciPy</p></th>
<th class="head"><p>Go Beyond</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Vectorized random draws</p></td>
<td><p>✅</p></td>
<td><p>—</p></td>
<td><p>—</p></td>
</tr>
<tr class="row-odd"><td><p>Analytic PDF/CDF/quantile</p></td>
<td><p>—</p></td>
<td><p>✅</p></td>
<td><p>—</p></td>
</tr>
<tr class="row-even"><td><p>Fit distribution parameters</p></td>
<td><p>—</p></td>
<td><p>✅</p></td>
<td><p>—</p></td>
</tr>
<tr class="row-odd"><td><p>Classical tests (t, KS, χ², ANOVA)</p></td>
<td><p>—</p></td>
<td><p>✅</p></td>
<td><p>—</p></td>
</tr>
<tr class="row-even"><td><p>Linear/GLM/mixed models</p></td>
<td><p>—</p></td>
<td><p>—</p></td>
<td><p>statsmodels</p></td>
</tr>
<tr class="row-odd"><td><p>Full Bayesian inference</p></td>
<td><p>—</p></td>
<td><p>—</p></td>
<td><p>PyMC, Stan</p></td>
</tr>
</tbody>
</table>
</section>
<section id="the-frozen-distribution-pattern">
<h3>The Frozen Distribution Pattern<a class="headerlink" href="#the-frozen-distribution-pattern" title="Link to this heading"></a></h3>
<p>SciPy’s key design: create a distribution object with fixed parameters, then call methods on it:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Create &quot;frozen&quot; distribution</span>
<span class="n">iq_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="c1"># Access properties</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean: </span><span class="si">{</span><span class="n">iq_dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Variance: </span><span class="si">{</span><span class="n">iq_dist</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Median: </span><span class="si">{</span><span class="n">iq_dist</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Probability calculations</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(IQ ≤ 130) = </span><span class="si">{</span><span class="n">iq_dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">130</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(IQ &gt; 130) = </span><span class="si">{</span><span class="n">iq_dist</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="mi">130</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Quantiles</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;90th percentile: </span><span class="si">{</span><span class="n">iq_dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.90</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Random samples</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">iq_dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;5 samples: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="the-unified-interface">
<h3>The Unified Interface<a class="headerlink" href="#the-unified-interface" title="Link to this heading"></a></h3>
<p>Every distribution provides the same methods:</p>
<table class="docutils align-default" id="id15">
<caption><span class="caption-number">Table 13 </span><span class="caption-text">SciPy Distribution Methods</span><a class="headerlink" href="#id15" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 15.0%" />
<col style="width: 25.0%" />
<col style="width: 60.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Mathematical</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">pdf(x)</span></code>/<code class="docutils literal notranslate"><span class="pre">pmf(x)</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(f(x)\)</span> or <span class="math notranslate nohighlight">\(P(X=x)\)</span></p></td>
<td><p>Density (continuous) or mass (discrete)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">cdf(x)</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(F(x) = P(X \leq x)\)</span></p></td>
<td><p>Cumulative distribution function</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sf(x)</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(1 - F(x)\)</span></p></td>
<td><p>Survival function</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">ppf(q)</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(F^{-1}(q)\)</span></p></td>
<td><p>Quantile function (inverse CDF)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">rvs(size)</span></code></p></td>
<td><p>—</p></td>
<td><p>Random samples</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mean()</span></code>, <code class="docutils literal notranslate"><span class="pre">var()</span></code>, <code class="docutils literal notranslate"><span class="pre">std()</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(E[X]\)</span>, <span class="math notranslate nohighlight">\(\text{Var}(X)\)</span></p></td>
<td><p>Moments</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">interval(α)</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\([a,b]\)</span>: <span class="math notranslate nohighlight">\(P(a \leq X \leq b) = \alpha\)</span></p></td>
<td><p>Central probability interval</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">fit(data)</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(\hat{\theta}_{\text{MLE}}\)</span></p></td>
<td><p>Maximum likelihood estimation</p></td>
</tr>
</tbody>
</table>
<figure class="align-center" id="id16">
<a class="reference internal image-reference" href="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/scipy_methods.png"><img alt="Four panels showing PDF, CDF, PPF, and samples for a Gamma distribution" src="https://pqyjaywwccbnqpwgeiuv.supabase.co/storage/v1/object/public/STAT%20418%20Images/assets/Part1/scipy_methods.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 24 </span><span class="caption-text"><strong>SciPy Distribution Methods.</strong> (A) PDF gives density at any point. (B) CDF gives cumulative probability. (C) PPF (quantile function) inverts the CDF. (D) RVS generates samples matching the distribution.</span><a class="headerlink" href="#id16" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="parameterization-the-most-common-error-source">
<h3>Parameterization: The Most Common Error Source<a class="headerlink" href="#parameterization-the-most-common-error-source" title="Link to this heading"></a></h3>
<p>Different sources use different parameterizations. SciPy has its own conventions:</p>
<table class="docutils align-default" id="id17">
<caption><span class="caption-number">Table 14 </span><span class="caption-text">SciPy Parameterization Reference</span><a class="headerlink" href="#id17" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 18.0%" />
<col style="width: 32.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Distribution</p></th>
<th class="head"><p>SciPy Call</p></th>
<th class="head"><p>Notes &amp; Gotchas</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Normal</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.norm(loc=μ,</span> <span class="pre">scale=σ)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">scale</span></code> is std dev σ, <strong>NOT</strong> variance σ²</p></td>
</tr>
<tr class="row-odd"><td><p>Exponential</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.expon(scale=β)</span></code></p></td>
<td><p>Mean = scale = 1/rate. For rate λ=2, use <code class="docutils literal notranslate"><span class="pre">scale=0.5</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Gamma</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.gamma(a=k,</span> <span class="pre">scale=θ)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">a</span></code> is shape k. Mean = k·θ</p></td>
</tr>
<tr class="row-odd"><td><p>Beta</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.beta(a,</span> <span class="pre">b)</span></code></p></td>
<td><p>Shape parameters α, β</p></td>
</tr>
<tr class="row-even"><td><p>Chi-square</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.chi2(df)</span></code></p></td>
<td><p>Degrees of freedom only</p></td>
</tr>
<tr class="row-odd"><td><p>Student’s t</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.t(df)</span></code></p></td>
<td><p>Add <code class="docutils literal notranslate"><span class="pre">loc</span></code>, <code class="docutils literal notranslate"><span class="pre">scale</span></code> for non-standard</p></td>
</tr>
<tr class="row-even"><td><p>F</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.f(dfn,</span> <span class="pre">dfd)</span></code></p></td>
<td><p>Numerator df first</p></td>
</tr>
<tr class="row-odd"><td><p>Poisson</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.poisson(mu=λ)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mu</span></code> is the rate λ</p></td>
</tr>
<tr class="row-even"><td><p>Binomial</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.binom(n,</span> <span class="pre">p)</span></code></p></td>
<td><p>n trials, probability p</p></td>
</tr>
<tr class="row-odd"><td><p>Negative Binomial</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stats.nbinom(n,</span> <span class="pre">p)</span></code></p></td>
<td><p>Counts <strong>failures</strong> before n successes</p></td>
</tr>
</tbody>
</table>
<div class="warning admonition">
<p class="admonition-title">Common Pitfall ⚠️: Exponential Parameterization</p>
<p>The exponential distribution causes endless confusion:</p>
<ul class="simple">
<li><p><strong>Rate parameterization</strong> (textbooks): <span class="math notranslate nohighlight">\(f(x) = \lambda e^{-\lambda x}\)</span>, mean = <span class="math notranslate nohighlight">\(1/\lambda\)</span></p></li>
<li><p><strong>Scale parameterization</strong> (SciPy/NumPy): <span class="math notranslate nohighlight">\(f(x) = \frac{1}{\beta}e^{-x/\beta}\)</span>, mean = <span class="math notranslate nohighlight">\(\beta\)</span></p></li>
</ul>
<p>For mean = 2:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">random.expovariate(0.5)</span></code> — rate = 0.5</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rng.exponential(2)</span></code> — scale = 2</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stats.expon(scale=2)</span></code> — scale = 2</p></li>
</ul>
<p><strong>Always verify by checking the sample mean!</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Want mean = 2</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">expon</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Correct</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># ≈ 2.0</span>

<span class="c1"># Common mistake</span>
<span class="n">wrong</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">expon</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># This has mean = 0.5!</span>
</pre></div>
</div>
</div>
</section>
<section id="complete-analysis-example">
<h3>Complete Analysis Example<a class="headerlink" href="#complete-analysis-example" title="Link to this heading"></a></h3>
<div class="note admonition">
<p class="admonition-title">Example 💡: Distribution Fitting and Diagnostics</p>
<p><strong>Problem:</strong> Fit a Gamma distribution to data and assess the fit.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Generate &quot;observed&quot; data</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">true_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">true_dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

<span class="c1"># Fit Gamma distribution (fix location at 0)</span>
<span class="n">a_hat</span><span class="p">,</span> <span class="n">loc_hat</span><span class="p">,</span> <span class="n">scale_hat</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">floc</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fitted: shape=</span><span class="si">{</span><span class="n">a_hat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, scale=</span><span class="si">{</span><span class="n">scale_hat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True:   shape=2.000, scale=2.000&quot;</span><span class="p">)</span>

<span class="c1"># Create fitted distribution</span>
<span class="n">fitted</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">a_hat</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc_hat</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale_hat</span><span class="p">)</span>

<span class="c1"># Goodness-of-fit test</span>
<span class="n">D</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">fitted</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">KS test: D=</span><span class="si">{</span><span class="n">D</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, p-value=</span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Theoretical vs empirical quantiles</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">95th percentile: fitted=</span><span class="si">{</span><span class="n">fitted</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.95</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, empirical=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="mi">95</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="bringing-it-all-together-library-selection-guide">
<h2>Bringing It All Together: Library Selection Guide<a class="headerlink" href="#bringing-it-all-together-library-selection-guide" title="Link to this heading"></a></h2>
<p><strong>Use ``random`` (standard library) when:</strong></p>
<ul class="simple">
<li><p>Zero dependencies required</p></li>
<li><p>Teaching probability concepts</p></li>
<li><p>Simple prototypes or scripts</p></li>
<li><p>Sample sizes under ~10,000</p></li>
<li><p>You need <code class="docutils literal notranslate"><span class="pre">choice</span></code>, <code class="docutils literal notranslate"><span class="pre">shuffle</span></code>, <code class="docutils literal notranslate"><span class="pre">sample</span></code> on lists</p></li>
</ul>
<p><strong>Use NumPy ``Generator`` when:</strong></p>
<ul class="simple">
<li><p>Working with arrays and matrices</p></li>
<li><p>Sample sizes exceed 10,000</p></li>
<li><p>Performance is critical</p></li>
<li><p>You need multivariate distributions</p></li>
<li><p>Parallel computing with independent streams</p></li>
</ul>
<p><strong>Use ``scipy.stats`` when:</strong></p>
<ul class="simple">
<li><p>You need PDF, CDF, or quantile functions</p></li>
<li><p>Fitting distributions to data</p></li>
<li><p>Performing statistical tests</p></li>
<li><p>Computing theoretical properties exactly</p></li>
<li><p>You need exotic distributions (100+ available)</p></li>
</ul>
<p><strong>Combine them:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># SciPy for distribution definition and analysis</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">theoretical_mean</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">critical_value</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.95</span><span class="p">)</span>

<span class="c1"># NumPy for efficient sampling</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>

<span class="c1"># Verify</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Theory mean: </span><span class="si">{</span><span class="n">theoretical_mean</span><span class="si">}</span><span class="s2">, Sample mean: </span><span class="si">{</span><span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>Pseudo-randomness is deterministic</strong>: PRNGs produce sequences determined by their seed. Reproducibility requires explicit seeding.</p></li>
<li><p><strong>Three libraries, three purposes</strong>: Standard library for simplicity; NumPy for performance with arrays; SciPy for complete distribution analysis.</p></li>
<li><p><strong>Know your parameterizations</strong>: Rate vs scale causes endless bugs. <strong>Always verify sample means match expectations.</strong></p></li>
<li><p><strong>Vectorize for speed</strong>: NumPy provides 50–100× speedup by eliminating Python loop overhead.</p></li>
<li><p><strong>Independent streams for parallel work</strong>: Use <code class="docutils literal notranslate"><span class="pre">SeedSequence.spawn()</span></code>. Never share generators across threads/processes.</p></li>
<li><p><strong>Outcome alignment</strong>: This chapter directly supports Learning Outcome 1 (simulation techniques) and provides the computational foundation for all subsequent chapters.</p></li>
</ol>
</div>
</section>
<section id="looking-ahead-from-random-numbers-to-monte-carlo-methods">
<h2>Looking Ahead: From Random Numbers to Monte Carlo Methods<a class="headerlink" href="#looking-ahead-from-random-numbers-to-monte-carlo-methods" title="Link to this heading"></a></h2>
<p>With Python’s random generation ecosystem mastered, we are ready to put these tools to work. The ability to draw samples from probability distributions is not merely a computational convenience—it is the engine that powers modern statistical inference.</p>
<p>In <strong>Chapter 2</strong>, we turn to <strong>Monte Carlo methods</strong>: using random sampling to solve problems that would be analytically intractable. The techniques you’ve learned here—generating uniforms, transforming to other distributions, managing random streams—become the building blocks for:</p>
<ul class="simple">
<li><p><strong>Monte Carlo integration</strong>: Estimating integrals via random sampling, essential when closed-form solutions don’t exist</p></li>
<li><p><strong>The inverse CDF method</strong>: Transforming uniform samples to arbitrary distributions using quantile functions (<code class="docutils literal notranslate"><span class="pre">ppf</span></code>)</p></li>
<li><p><strong>Rejection sampling</strong>: Generating samples from complex distributions by accepting/rejecting proposals</p></li>
<li><p><strong>Variance reduction</strong>: Techniques like antithetic variates and control variates that improve Monte Carlo efficiency</p></li>
</ul>
<p>The connection is direct: every Monte Carlo estimate begins with a call to a random number generator. The <code class="docutils literal notranslate"><span class="pre">numpy.random.Generator</span></code> you’ve learned to use will generate the uniform samples; the <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> distributions will provide the CDFs and PDFs needed for transformations and density evaluation. Understanding the computational tools in this chapter is prerequisite to understanding <em>why</em> Monte Carlo methods work and <em>how</em> to implement them efficiently.</p>
<p>Consider the preview exercise on parallel Monte Carlo integration at the end of this chapter—it demonstrates exactly this bridge: spawning independent random streams, generating samples, and averaging to estimate an integral. Chapter 2 develops the theory behind why this works and when it fails.</p>
</section>
<section id="references-and-further-reading">
<h2>References and Further Reading<a class="headerlink" href="#references-and-further-reading" title="Link to this heading"></a></h2>
<p><strong>Pseudo-Random Number Generation</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="matsumotonishimura1998" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MatsumotoNishimura1998<span class="fn-bracket">]</span></span>
<p>Matsumoto, M., and Nishimura, T. (1998). Mersenne Twister: A 623-dimensionally equidistributed uniform pseudo-random number generator. <em>ACM Transactions on Modeling and Computer Simulation</em>, 8(1), 3–30.</p>
</div>
<div class="citation" id="oneill2014" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ONeill2014<span class="fn-bracket">]</span></span>
<p>O’Neill, M. E. (2014). PCG: A family of simple fast space-efficient statistically good algorithms for random number generation. Technical Report HMC-CS-2014-0905, Harvey Mudd College. <a class="reference external" href="https://www.pcg-random.org/">https://www.pcg-random.org/</a></p>
</div>
<div class="citation" id="lecuyersimard2007" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LEcuyerSimard2007<span class="fn-bracket">]</span></span>
<p>L’Ecuyer, P., and Simard, R. (2007). TestU01: A C library for empirical testing of random number generators. <em>ACM Transactions on Mathematical Software</em>, 33(4), Article 22.</p>
</div>
<div class="citation" id="knuth1997" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Knuth1997<span class="fn-bracket">]</span></span>
<p>Knuth, D. E. (1997). <em>The Art of Computer Programming, Volume 2: Seminumerical Algorithms</em> (3rd ed.). Addison-Wesley. The definitive reference on random number generation algorithms.</p>
</div>
</div>
<p><strong>Random Variate Generation</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="devroye1986" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Devroye1986<span class="fn-bracket">]</span></span>
<p>Devroye, L. (1986). <em>Non-Uniform Random Variate Generation</em>. New York: Springer-Verlag. Available free online at <a class="reference external" href="https://luc.devroye.org/rnbookindex.html">https://luc.devroye.org/rnbookindex.html</a></p>
</div>
</div>
<p><strong>Software Documentation</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="numpyrandom" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NumPyRandom<span class="fn-bracket">]</span></span>
<p>NumPy Community. (2024). NumPy random sampling documentation. <a class="reference external" href="https://numpy.org/doc/stable/reference/random/index.html">https://numpy.org/doc/stable/reference/random/index.html</a></p>
</div>
<div class="citation" id="scipystats" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SciPyStats<span class="fn-bracket">]</span></span>
<p>SciPy Community. (2024). SciPy statistical functions documentation. <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/stats.html">https://docs.scipy.org/doc/scipy/reference/stats.html</a></p>
</div>
<div class="citation" id="pythonrandom" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>PythonRandom<span class="fn-bracket">]</span></span>
<p>Python Software Foundation. (2024). <code class="docutils literal notranslate"><span class="pre">random</span></code> — Generate pseudo-random numbers. <a class="reference external" href="https://docs.python.org/3/library/random.html">https://docs.python.org/3/library/random.html</a></p>
</div>
</div>
<p><strong>Computational Statistics</strong></p>
<div role="list" class="citation-list">
<div class="citation" id="gentle2003" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Gentle2003<span class="fn-bracket">]</span></span>
<p>Gentle, J. E. (2003). <em>Random Number Generation and Monte Carlo Methods</em> (2nd ed.). Springer.</p>
</div>
<div class="citation" id="robertcasella2004" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>RobertCasella2004<span class="fn-bracket">]</span></span>
<p>Robert, C. P., and Casella, G. (2004). <em>Monte Carlo Statistical Methods</em> (2nd ed.). New York: Springer.</p>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ch1_2-probability_distributions_review.html" class="btn btn-neutral float-left" title="Section 1.2 Probability Distributions: Theory and Computation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ch1_4-chapter-summary.html" class="btn btn-neutral float-right" title="Section 1.4 Chapter 1 Summary: Foundations in Place" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>