

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=da1f3f80" />
      <link rel="stylesheet" type="text/css" href="../../_static/credits.css?v=f7efa099" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/Website/chapter11/lectures/11-3-comparing-two-means-independent-pooled.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=de5959cf"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption" href="11-4-comparing-two-means-independent-unpooled.html" />
    <link rel="prev" title="11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known" href="11-2-comparing-two-means-independent-sigmas-known.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#troubleshooting-guide">Troubleshooting Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#quick-reference-table">Quick Reference Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#getting-started-with-swirl">Getting Started with swirl</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#setup-and-use-swirl">Setup and Use swirl</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#alternative-r-learning-resources">Alternative R Learning Resources</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#base-r">Base R</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#tidyverse">tidyverse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#r-markdown">R Markdown</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#statistical-computing">Statistical Computing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#video-resources">Video Resources</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#function-reference-alphabetized-within-category">Function Reference (Alphabetized within Category)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#simulation-functions">Simulation Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#inference-functions">Inference Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#graphics-ggplot2">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#tables-reporting">Tables &amp; Reporting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#best-practices-common-pitfalls">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#appendix-quick-links">Appendix: Quick Links</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#assignments">Assignments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#getting-help">Getting Help</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Sequential Bayesian Updating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">11. Two Sample Procedures</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">11. </span>Two Sample Procedures</a></li>
      <li class="breadcrumb-item active"><span class="section-number">11.3. </span>Comparing the Means of Two Independent Populations - Pooled Variance Estimator</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter11/lectures/11-3-comparing-two-means-independent-pooled.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch11-3">
   <iframe
      id="video-ch11-3"
      title="STAT 350 – Chapter 11.3 Comparing Two Population Means Using Independent Samples: Pooled Estimator Video"
      src="https://www.youtube.com/embed/CuhPeUL6wEo?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><div class="tip admonition">
<p class="admonition-title">Slides</p>
<p><a class="reference external" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%2011%20Two%20Sample%20Procedures/CI%20and%20HT%20for%20Two%20Samples%20or%20Treatments_AC.pptx">Download Chapter 11 slides (PPTX)</a></p>
</div>
<section id="comparing-the-means-of-two-independent-populations-pooled-variance-estimator">
<h1><span class="section-number">11.3. </span>Comparing the Means of Two Independent Populations - Pooled Variance Estimator<a class="headerlink" href="#comparing-the-means-of-two-independent-populations-pooled-variance-estimator" title="Link to this heading"></a></h1>
<p>In practice, we typically do not know the population standard deviation for one population,
let alone two populations whose means we want to compare. The theoretical framework developed
in the previous section, while mathematically elegant, requires the unrealistic assumption of
known population variances. This section addresses the more realistic scenario where population
standard deviations must be estimated from sample data, beginning with the case where we can
reasonably assume both populations have equal variances.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p><strong>Problem we will solve</strong> – How to compare two population means when standard deviations are unknown</p></li>
</ul>
<p>but can be assumed equal across populations
• <strong>Tools we’ll learn</strong> – Pooled variance estimation and t-procedures for independent samples under
equal variance assumptions
• <strong>How it fits</strong> – This bridges the gap between theoretical z-procedures and practical applications,
introducing the complications that arise when parameters must be estimated</p>
</div>
<section id="the-transition-from-known-to-unknown-variances">
<h2><span class="section-number">11.3.1. </span>The Transition from Known to Unknown Variances<a class="headerlink" href="#the-transition-from-known-to-unknown-variances" title="Link to this heading"></a></h2>
<p>The assumption of known population standard deviations <span class="math notranslate nohighlight">\(\sigma_A\)</span> and <span class="math notranslate nohighlight">\(\sigma_B\)</span> served as a useful theoretical starting point, but practical statistical analysis requires methods that accommodate unknown parameters. When population variances must be estimated from sample data, we face several important changes:</p>
<p><strong>Increased Uncertainty</strong></p>
<p>Estimating variances from sample data introduces additional uncertainty beyond the sampling variability of the means themselves. This extra uncertainty must be properly accounted for in our inferential procedures.</p>
<p><strong>Distributional Changes</strong></p>
<p>Test statistics no longer follow standard normal distributions but instead follow t-distributions, requiring different critical values and probability calculations.</p>
<p><strong>Estimation Strategy Considerations</strong></p>
<p>When both populations have unknown variances, we must decide whether to estimate them separately or under some unifying assumption. This decision significantly affects both the complexity and performance of our procedures.</p>
</section>
<section id="the-equal-variance-assumption-mathematical-framework">
<h2><span class="section-number">11.3.2. </span>The Equal Variance Assumption: Mathematical Framework<a class="headerlink" href="#the-equal-variance-assumption-mathematical-framework" title="Link to this heading"></a></h2>
<p><strong>The Fundamental Assumption</strong></p>
<p>We now assume that while the population means <span class="math notranslate nohighlight">\(\mu_A\)</span> and <span class="math notranslate nohighlight">\(\mu_B\)</span> may differ (which is typically what we want to test), the population variances are equal:</p>
<div class="math notranslate nohighlight">
\[\sigma^2_A = \sigma^2_B = \sigma^2\]</div>
<p>This assumption states that both populations have the same underlying variability, differing only in their central tendencies. While the common variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> remains unknown, assuming equality allows us to pool information from both samples to estimate this single parameter.</p>
<p><strong>Implications for Standard Error</strong></p>
<p>Under the equal variance assumption, the standard error of our point estimator <span class="math notranslate nohighlight">\(\bar{X}_A - \bar{X}_B\)</span> simplifies from:</p>
<div class="math notranslate nohighlight">
\[\sqrt{\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}}\]</div>
<p>to:</p>
<div class="math notranslate nohighlight">
\[\sigma\sqrt{\frac{1}{n_A} + \frac{1}{n_B}}\]</div>
<p>This simplification occurs because <span class="math notranslate nohighlight">\(\sigma^2_A = \sigma^2_B = \sigma^2\)</span>, allowing us to factor out the common variance.</p>
</section>
<section id="the-pooled-variance-estimator-construction-and-properties">
<h2><span class="section-number">11.3.3. </span>The Pooled Variance Estimator: Construction and Properties<a class="headerlink" href="#the-pooled-variance-estimator-construction-and-properties" title="Link to this heading"></a></h2>
<p><strong>The Pooling Rationale</strong></p>
<p>When both sample variances <span class="math notranslate nohighlight">\(S^2_A\)</span> and <span class="math notranslate nohighlight">\(S^2_B\)</span> are estimating the same underlying parameter <span class="math notranslate nohighlight">\(\sigma^2\)</span>, we should not arbitrarily choose one and ignore the other. Instead, we can combine the information from both samples to create a more precise estimator of the common variance.</p>
<p>However, we cannot simply combine all observations into a single dataset because the populations have different means. The sample variance formula depends on deviations from the sample mean, and pooling observations with different means would distort our variance estimate.</p>
<p><strong>The Weighted Average Approach</strong></p>
<p>The pooled variance estimator combines the individual sample variances using a weighted average that accounts for the amount of information contributed by each sample:</p>
<div class="math notranslate nohighlight">
\[S^2_p = \frac{(n_A - 1)S^2_A + (n_B - 1)S^2_B}{n_A + n_B - 2}\]</div>
<p><strong>Understanding the Weights</strong></p>
<p>The weights <span class="math notranslate nohighlight">\((n_A - 1)\)</span> and <span class="math notranslate nohighlight">\((n_B - 1)\)</span> represent the degrees of freedom associated with each sample variance. These weights ensure that:</p>
<ol class="arabic simple">
<li><p><strong>Larger samples contribute more</strong>: If <span class="math notranslate nohighlight">\(n_A &gt; n_B\)</span>, then sample A receives higher weight in the pooled estimate</p></li>
<li><p><strong>Proportional representation</strong>: The contribution of each sample is proportional to the precision of its variance estimate</p></li>
<li><p><strong>Proper normalization</strong>: The weights sum to <span class="math notranslate nohighlight">\(n_A + n_B - 2\)</span>, which becomes the denominator</p></li>
</ol>
<p><strong>Degrees of Freedom Interpretation</strong></p>
<p>The denominator <span class="math notranslate nohighlight">\(n_A + n_B - 2\)</span> represents the total degrees of freedom for estimating the common variance:</p>
<ul class="simple">
<li><p>Total observations: <span class="math notranslate nohighlight">\(n_A + n_B\)</span></p></li>
<li><p>Parameters estimated: 2 (the means <span class="math notranslate nohighlight">\(\mu_A\)</span> and <span class="math notranslate nohighlight">\(\mu_B\)</span>)</p></li>
<li><p>Resulting degrees of freedom: <span class="math notranslate nohighlight">\(n_A + n_B - 2\)</span></p></li>
</ul>
<p><strong>Unbiasedness of the Pooled Estimator</strong></p>
<p>The pooled variance estimator is unbiased for the common variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> when the equal variance assumption holds. To establish this:</p>
<div class="math notranslate nohighlight">
\[E[S^2_p] = E\left[\frac{(n_A - 1)S^2_A + (n_B - 1)S^2_B}{n_A + n_B - 2}\right]\]</div>
<p>Since the weights are constants, expectation distributes:</p>
<div class="math notranslate nohighlight">
\[= \frac{(n_A - 1)E[S^2_A] + (n_B - 1)E[S^2_B]}{n_A + n_B - 2}\]</div>
<p>From single-sample theory, we know that sample variances are unbiased: <span class="math notranslate nohighlight">\(E[S^2_A] = \sigma^2_A\)</span> and <span class="math notranslate nohighlight">\(E[S^2_B] = \sigma^2_B\)</span>. Under our equal variance assumption, both equal <span class="math notranslate nohighlight">\(\sigma^2\)</span>:</p>
<div class="math notranslate nohighlight">
\[= \frac{(n_A - 1)\sigma^2 + (n_B - 1)\sigma^2}{n_A + n_B - 2} = \frac{\sigma^2[(n_A - 1) + (n_B - 1)]}{n_A + n_B - 2} = \frac{\sigma^2(n_A + n_B - 2)}{n_A + n_B - 2} = \sigma^2\]</div>
<p>Therefore, <span class="math notranslate nohighlight">\(E[S^2_p] = \sigma^2\)</span>, confirming unbiasedness.</p>
</section>
<section id="standard-error-estimation-with-pooled-variance">
<h2><span class="section-number">11.3.4. </span>Standard Error Estimation with Pooled Variance<a class="headerlink" href="#standard-error-estimation-with-pooled-variance" title="Link to this heading"></a></h2>
<p><strong>The Estimated Standard Error</strong></p>
<p>Using the pooled variance estimator, we estimate the standard error of <span class="math notranslate nohighlight">\(\bar{X}_A - \bar{X}_B\)</span> as:</p>
<div class="math notranslate nohighlight">
\[SE_p = S_p\sqrt{\frac{1}{n_A} + \frac{1}{n_B}}\]</div>
<p>where <span class="math notranslate nohighlight">\(S_p = \sqrt{S^2_p}\)</span> is the pooled standard deviation.</p>
<p><strong>Comparison to the Known Variance Case</strong></p>
<p>This estimated standard error replaces the theoretical standard error <span class="math notranslate nohighlight">\(\sigma\sqrt{\frac{1}{n_A} + \frac{1}{n_B}}\)</span> from the known variance case. The substitution of <span class="math notranslate nohighlight">\(S_p\)</span> for <span class="math notranslate nohighlight">\(\sigma\)</span> introduces the additional uncertainty that necessitates using t-distributions instead of the standard normal distribution.</p>
<p><strong>Information Pooling Benefits</strong></p>
<p>The pooled approach utilizes information from <span class="math notranslate nohighlight">\(n_A + n_B - 2\)</span> degrees of freedom to estimate the standard error, compared to <span class="math notranslate nohighlight">\(n_A - 1\)</span> or <span class="math notranslate nohighlight">\(n_B - 1\)</span> degrees of freedom if we used only one sample’s variance. This typically results in more precise estimation and improved statistical power.</p>
</section>
<section id="test-statistics-and-distributional-theory">
<h2><span class="section-number">11.3.5. </span>Test Statistics and Distributional Theory<a class="headerlink" href="#test-statistics-and-distributional-theory" title="Link to this heading"></a></h2>
<p><strong>The t-Test Statistic</strong></p>
<p>When using the pooled variance estimator, our test statistic becomes:</p>
<div class="math notranslate nohighlight">
\[T_{TS} = \frac{(\bar{X}_A - \bar{X}_B) - \Delta_0}{S_p\sqrt{\frac{1}{n_A} + \frac{1}{n_B}}}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Delta_0\)</span> is the hypothesized difference under the null hypothesis (typically 0).</p>
<p><strong>Distributional Properties</strong></p>
<p>Under the assumptions of:</p>
<ol class="arabic simple">
<li><p>Independent simple random sampling from each population</p></li>
<li><p>Normal distributions (or large enough samples for CLT)</p></li>
<li><p>Equal population variances: <span class="math notranslate nohighlight">\(\sigma^2_A = \sigma^2_B = \sigma^2\)</span></p></li>
<li><p>The null hypothesis is true</p></li>
</ol>
<p>the test statistic follows a t-distribution with <span class="math notranslate nohighlight">\(df = n_A + n_B - 2\)</span> degrees of freedom:</p>
<div class="math notranslate nohighlight">
\[T_{TS} \sim t_{n_A + n_B - 2}\]</div>
<p><strong>Why t-Distribution?</strong></p>
<p>The t-distribution arises because we are standardizing with an estimated standard error rather than the true standard error. The additional uncertainty from estimating <span class="math notranslate nohighlight">\(\sigma^2\)</span> with <span class="math notranslate nohighlight">\(S^2_p\)</span> manifests as the heavier tails characteristic of t-distributions.</p>
</section>
<section id="confidence-intervals-using-pooled-procedures">
<h2><span class="section-number">11.3.6. </span>Confidence Intervals Using Pooled Procedures<a class="headerlink" href="#confidence-intervals-using-pooled-procedures" title="Link to this heading"></a></h2>
<p><strong>The Pivotal Quantity</strong></p>
<p>For confidence interval construction, we use the pivotal quantity:</p>
<div class="math notranslate nohighlight">
\[T = \frac{(\bar{X}_A - \bar{X}_B) - (\mu_A - \mu_B)}{S_p\sqrt{\frac{1}{n_A} + \frac{1}{n_B}}}\]</div>
<p>This quantity follows a t-distribution with <span class="math notranslate nohighlight">\(n_A + n_B - 2\)</span> degrees of freedom and contains only one unknown parameter: <span class="math notranslate nohighlight">\(\mu_A - \mu_B\)</span>.</p>
<p><strong>Confidence Interval Formula</strong></p>
<p>A <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> confidence interval for <span class="math notranslate nohighlight">\(\mu_A - \mu_B\)</span> is:</p>
<div class="math notranslate nohighlight">
\[(\bar{x}_A - \bar{x}_B) \pm t_{\alpha/2, n_A + n_B - 2} \cdot S_p\sqrt{\frac{1}{n_A} + \frac{1}{n_B}}\]</div>
<p><strong>Components Analysis</strong></p>
<ul class="simple">
<li><p><strong>Point estimator</strong>: <span class="math notranslate nohighlight">\(\bar{x}_A - \bar{x}_B\)</span></p></li>
<li><p><strong>Critical value</strong>: <span class="math notranslate nohighlight">\(t_{\alpha/2, n_A + n_B - 2}\)</span> from the t-distribution</p></li>
<li><p><strong>Standard error</strong>: <span class="math notranslate nohighlight">\(S_p\sqrt{\frac{1}{n_A} + \frac{1}{n_B}}\)</span></p></li>
<li><p><strong>Margin of error</strong>: The product of critical value and standard error</p></li>
</ul>
</section>
<section id="when-to-use-pooled-procedures-practical-considerations">
<h2><span class="section-number">11.3.7. </span>When to Use Pooled Procedures: Practical Considerations<a class="headerlink" href="#when-to-use-pooled-procedures-practical-considerations" title="Link to this heading"></a></h2>
<p><strong>Appropriate Scenarios</strong></p>
<p>Pooled variance procedures are most appropriate when:</p>
<ol class="arabic simple">
<li><p><strong>Equal variance assumption is reasonable</strong>: The populations have similar variability patterns</p></li>
<li><p><strong>Process similarity</strong>: The data-generating mechanisms are similar except for location shifts</p></li>
<li><p><strong>Small sample sizes</strong>: The efficiency gains from pooling are most pronounced with limited data</p></li>
<li><p><strong>Experimental control</strong>: In designed experiments where conditions are controlled except for the treatment</p></li>
</ol>
<p><strong>Examples of Suitable Applications</strong></p>
<ul class="simple">
<li><p><strong>Manufacturing quality control</strong>: Comparing products from the same process under different settings</p></li>
<li><p><strong>Agricultural experiments</strong>: Testing fertilizer effects on crop yields using similar plots</p></li>
<li><p><strong>Medical trials</strong>: Comparing treatments when patient populations are homogeneous except for treatment assignment</p></li>
</ul>
<p><strong>Efficiency Considerations</strong></p>
<p>When the equal variance assumption holds, pooled procedures offer several advantages:</p>
<ol class="arabic simple">
<li><p><strong>Higher degrees of freedom</strong>: <span class="math notranslate nohighlight">\(n_A + n_B - 2\)</span> instead of separate estimations</p></li>
<li><p><strong>More precise standard error estimates</strong>: Utilizing all available information</p></li>
<li><p><strong>Increased statistical power</strong>: Better ability to detect true differences when they exist</p></li>
</ol>
<p><strong>Robustness Issues</strong></p>
<p>The pooled procedure’s performance depends critically on the validity of the equal variance assumption. When variances are substantially unequal, pooled procedures can:</p>
<ul class="simple">
<li><p><strong>Inflate Type I error rates</strong>: Lead to more false positives than the nominal <span class="math notranslate nohighlight">\(\alpha\)</span> level</p></li>
<li><p><strong>Reduce power</strong>: Decreased ability to detect true differences</p></li>
<li><p><strong>Produce misleading confidence intervals</strong>: Intervals that don’t achieve the stated coverage probability</p></li>
</ul>
</section>
<section id="the-alternative-non-pooled-procedures">
<h2><span class="section-number">11.3.8. </span>The Alternative: Non-Pooled Procedures<a class="headerlink" href="#the-alternative-non-pooled-procedures" title="Link to this heading"></a></h2>
<p><strong>When Equal Variance Assumption Fails</strong></p>
<p>If we cannot reasonably assume equal variances, we must estimate <span class="math notranslate nohighlight">\(\sigma^2_A\)</span> and <span class="math notranslate nohighlight">\(\sigma^2_B\)</span> separately:</p>
<div class="math notranslate nohighlight">
\[SE = \sqrt{\frac{S^2_A}{n_A} + \frac{S^2_B}{n_B}}\]</div>
<p>This approach avoids the equal variance assumption but introduces complications in determining appropriate degrees of freedom and critical values.</p>
<p><strong>Preview of Coming Complications</strong></p>
<p>The non-pooled approach leads to test statistics that don’t follow standard t-distributions, requiring approximation methods for degrees of freedom calculation. These procedures, while more flexible in their assumptions, are also more complex in their implementation and interpretation.</p>
<p><strong>The Trade-off</strong></p>
<p>The choice between pooled and non-pooled procedures represents a fundamental trade-off in statistical practice:</p>
<ul class="simple">
<li><p><strong>Pooled procedures</strong>: More efficient when assumptions hold, but potentially misleading when they don’t</p></li>
<li><p><strong>Non-pooled procedures</strong>: More robust to assumption violations, but less efficient when pooling would be appropriate</p></li>
</ul>
</section>
<section id="course-perspective-on-pooled-vs-non-pooled-methods">
<h2><span class="section-number">11.3.9. </span>Course Perspective on Pooled vs. Non-Pooled Methods<a class="headerlink" href="#course-perspective-on-pooled-vs-non-pooled-methods" title="Link to this heading"></a></h2>
<p><strong>Practical Recommendation</strong></p>
<p>As noted in the transcript, this course emphasizes non-pooled procedures for several practical reasons:</p>
<ol class="arabic simple">
<li><p><strong>Assumption-free approach</strong>: Avoids the need to verify equal variance assumptions</p></li>
<li><p><strong>General applicability</strong>: Works regardless of whether variances are equal or unequal</p></li>
<li><p><strong>Conservative nature</strong>: Provides valid inference even when equal variance assumption fails</p></li>
<li><p><strong>Modern statistical practice</strong>: Reflects current preferences in applied statistics</p></li>
</ol>
<p><strong>When Pooled Procedures Remain Valuable</strong></p>
<p>Despite the general preference for non-pooled methods, pooled procedures remain important in specific contexts:</p>
<ul class="simple">
<li><p><strong>Designed experiments</strong>: Where experimental control ensures similar variances</p></li>
<li><p><strong>Theoretical understanding</strong>: For comprehending the relationship between assumptions and procedures</p></li>
<li><p><strong>Historical context</strong>: For understanding classical statistical approaches</p></li>
<li><p><strong>Specific applications</strong>: Where domain knowledge strongly supports equal variance assumptions</p></li>
</ul>
<p><strong>Educational Value</strong></p>
<p>Understanding both approaches provides insight into:</p>
<ul class="simple">
<li><p><strong>The impact of assumptions</strong>: How different assumptions lead to different procedures</p></li>
<li><p><strong>Efficiency considerations</strong>: The statistical costs and benefits of making assumptions</p></li>
<li><p><strong>Methodological evolution</strong>: How statistical practice has developed over time</p></li>
</ul>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>Pooled variance procedures assume equal population variances</strong> (<span class="math notranslate nohighlight">\(\sigma^2_A = \sigma^2_B = \sigma^2\)</span>) while allowing means to differ.</p></li>
<li><p><strong>The pooled variance estimator</strong> <span class="math notranslate nohighlight">\(S^2_p = \frac{(n_A - 1)S^2_A + (n_B - 1)S^2_B}{n_A + n_B - 2}\)</span> combines information from both samples using weights proportional to degrees of freedom.</p></li>
<li><p><strong>Test statistics follow t-distributions</strong> with <span class="math notranslate nohighlight">\(df = n_A + n_B - 2\)</span> degrees of freedom when the equal variance assumption holds.</p></li>
<li><p><strong>Pooled procedures offer efficiency gains</strong> when assumptions are satisfied, providing more precise estimates and higher statistical power.</p></li>
<li><p><strong>The equal variance assumption is critical</strong> – violations can lead to incorrect Type I error rates and misleading confidence intervals.</p></li>
<li><p><strong>Confidence intervals use the familiar format</strong> with t-critical values: <span class="math notranslate nohighlight">\((\bar{x}_A - \bar{x}_B) \pm t_{\alpha/2, df} \cdot SE_p\)</span>.</p></li>
<li><p><strong>Modern practice often favors non-pooled procedures</strong> due to their robustness to assumption violations, despite potential efficiency losses.</p></li>
<li><p><strong>The choice between pooled and non-pooled approaches</strong> represents a fundamental trade-off between efficiency (when assumptions hold) and robustness (when they don’t).</p></li>
</ol>
</div>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p><strong>Pooled Variance Calculation</strong>: Two independent samples yield the following results:</p>
<ul class="simple">
<li><p>Sample A: <span class="math notranslate nohighlight">\(n_A = 12\)</span>, <span class="math notranslate nohighlight">\(S^2_A = 25.6\)</span></p></li>
<li><p>Sample B: <span class="math notranslate nohighlight">\(n_B = 15\)</span>, <span class="math notranslate nohighlight">\(S^2_B = 31.2\)</span></p></li>
</ul>
<ol class="loweralpha simple">
<li><p>Calculate the pooled variance estimator <span class="math notranslate nohighlight">\(S^2_p\)</span></p></li>
<li><p>Find the pooled standard deviation <span class="math notranslate nohighlight">\(S_p\)</span></p></li>
<li><p>Determine the degrees of freedom for the pooled procedure</p></li>
<li><p>Calculate the standard error <span class="math notranslate nohighlight">\(SE_p\)</span></p></li>
</ol>
</li>
<li><p><strong>Assumption Analysis</strong>: For each scenario, discuss whether the equal variance assumption seems reasonable and justify your answer:</p>
<ol class="loweralpha simple">
<li><p>Comparing customer satisfaction scores (1-10 scale) between two similar retail stores</p></li>
<li><p>Comparing income levels between urban and rural populations</p></li>
<li><p>Comparing reaction times before and after consuming caffeine (using different subjects)</p></li>
<li><p>Comparing crop yields between two fertilizer treatments on similar plots</p></li>
</ol>
</li>
<li><p><strong>Degrees of Freedom Impact</strong>: Explain why the pooled procedure uses <span class="math notranslate nohighlight">\(df = n_A + n_B - 2\)</span> degrees of freedom instead of <span class="math notranslate nohighlight">\((n_A - 1) + (n_B - 1)\)</span>. What parameters are being estimated, and how does this affect the degrees of freedom calculation?</p></li>
<li><p><strong>Efficiency Comparison</strong>: Two researchers study the same phenomenon. Researcher A uses sample sizes <span class="math notranslate nohighlight">\(n_A = n_B = 10\)</span>, while Researcher B uses <span class="math notranslate nohighlight">\(n_A = 15, n_B = 5\)</span> (same total sample size). Assuming equal population variances:</p>
<ol class="loweralpha simple">
<li><p>Which design will have a smaller standard error? Explain why.</p></li>
<li><p>How do the degrees of freedom compare between the two designs?</p></li>
<li><p>What practical considerations might favor one design over the other?</p></li>
</ol>
</li>
<li><p><strong>Unbiasedness Verification</strong>: Suppose <span class="math notranslate nohighlight">\(\sigma^2_A = 20\)</span> and <span class="math notranslate nohighlight">\(\sigma^2_B = 20\)</span> (equal variances). If <span class="math notranslate nohighlight">\(E[S^2_A] = 20\)</span> and <span class="math notranslate nohighlight">\(E[S^2_B] = 20\)</span>, verify algebraically that the pooled variance estimator with <span class="math notranslate nohighlight">\(n_A = 8\)</span> and <span class="math notranslate nohighlight">\(n_B = 12\)</span> is unbiased.</p></li>
<li><p><strong>Critical Thinking</strong>: A colleague claims, “We should always use pooled procedures because they’re more efficient.” Provide a balanced response discussing both the benefits and potential risks of this approach. What factors should guide the choice between pooled and non-pooled procedures?</p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="11-2-comparing-two-means-independent-sigmas-known.html" class="btn btn-neutral float-left" title="11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="11-4-comparing-two-means-independent-unpooled.html" class="btn btn-neutral float-right" title="11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
  <p class="footer-credits-inline">
    <strong>Website Credits:</strong>
    Website development by Dr. Timothy Reese and Halin Shin.
    Generative AI tools were used to draft and refine some prose, code, and documentation; all content was reviewed by the instructors.
    Models: OpenAI o3 (2025-04-16 release) and Anthropic Claude Opus 4.1 (2025-08-05).
  </p>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>