

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=581abb6a" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=de5959cf"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator" href="11-3-comparing-two-means-independent-pooled.html" />
    <link rel="prev" title="11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples" href="11-1-ci-ht-two-samples.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#simulation-exercise">Simulation Exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes‚Äô Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes‚Äô Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#quick-reference-table">Quick Reference Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#recommended-workflow">Recommended workflow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#function-reference-alphabetized-within-category">Function Reference (Alphabetized within Category)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#simulation-functions">Simulation Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#inference-functions">Inference Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#graphics-ggplot2">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#tables-reporting">Tables &amp; Reporting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#best-practices-common-pitfalls">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#appendix-quick-links">Appendix: Quick Links</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#assignments">Assignments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#getting-help">Getting Help</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes‚Äô Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When œÉ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When œÉ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">11. Two Sample Procedures</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">11. </span>Two Sample Procedures</a></li>
      <li class="breadcrumb-item active"><span class="section-number">11.2. </span>Comparing the Means of Two Independent Populations - Population Variances Are Known</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch11-2">
   <iframe
      id="video-ch11-2"
      title="STAT 350 ‚Äì Chapter 11.2 Comparing Two Population Means Using Independent Samples Video"
      src="https://www.youtube.com/embed/OKJxoLTK9GY?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="comparing-the-means-of-two-independent-populations-population-variances-are-known">
<h1><span class="section-number">11.2. </span>Comparing the Means of Two Independent Populations - Population Variances Are Known<a class="headerlink" href="#comparing-the-means-of-two-independent-populations-population-variances-are-known" title="Link to this heading">ÔÉÅ</a></h1>
<p>Having established the conceptual framework for two-sample procedures, we now develop the mathematical
foundation for comparing population means when samples are collected independently. This section focuses
on the theoretical case where population standard deviations are known, providing the groundwork for
understanding more realistic scenarios where these parameters must be estimated.</p>
<div class="important admonition">
<p class="admonition-title">Road Map üß≠</p>
<ul class="simple">
<li><p><strong>Problem we will solve</strong> ‚Äì How to construct rigorous hypothesis tests and confidence intervals for the difference between two population means using independent samples</p></li>
<li><p><strong>Tools we‚Äôll learn</strong> ‚Äì The sampling distribution theory for differences in sample means and z-procedures for two independent samples</p></li>
<li><p><strong>How it fits</strong> ‚Äì This establishes the mathematical foundation that will be extended to t-procedures when population standard deviations are unknown</p></li>
</ul>
</div>
<section id="mathematical-foundations-assumptions-and-framework">
<h2><span class="section-number">11.2.1. </span>Mathematical Foundations: Assumptions and Framework<a class="headerlink" href="#mathematical-foundations-assumptions-and-framework" title="Link to this heading">ÔÉÅ</a></h2>
<p>The validity of two-sample independent procedures rests on three fundamental assumptions that extend our single-sample framework to the comparative setting. These assumptions must be carefully verified before applying the methods we develop.</p>
<p><strong>Assumption 1: Independent Simple Random Sampling from Distinct Populations</strong></p>
<p>We assume that each group represents a simple random sample from its respective population of interest. This requirement has several components:</p>
<p>For Population A, we have random variables <span class="math notranslate nohighlight">\(X_{A1}, X_{A2}, \ldots, X_{An_A}\)</span> that are <strong>independently and identically distributed</strong> from a population with unknown mean <span class="math notranslate nohighlight">\(\mu_A\)</span> and known variance <span class="math notranslate nohighlight">\(\sigma^2_A\)</span>. The independence condition means that <span class="math notranslate nohighlight">\(X_{Ai}\)</span> is independent of <span class="math notranslate nohighlight">\(X_{Aj}\)</span> for all <span class="math notranslate nohighlight">\(i \neq j\)</span>, and the identical distribution condition ensures that <span class="math notranslate nohighlight">\(E[X_{Ai}] = \mu_A\)</span> and <span class="math notranslate nohighlight">\(\text{Var}[X_{Ai}] = \sigma^2_A\)</span> for all <span class="math notranslate nohighlight">\(i \in \{1, 2, \ldots, n_A\}\)</span>.</p>
<p>Similarly, for Population B, we have random variables <span class="math notranslate nohighlight">\(X_{B1}, X_{B2}, \ldots, X_{Bn_B}\)</span> that are independently and identically distributed from a population with unknown mean <span class="math notranslate nohighlight">\(\mu_B\)</span> and known variance <span class="math notranslate nohighlight">\(\sigma^2_B\)</span>.</p>
<p><strong>Assumption 2: Independence Between Populations</strong></p>
<p>The observations from one population are completely independent of those from the other population. Formally, this means that <span class="math notranslate nohighlight">\(X_{Ai}\)</span> is independent of <span class="math notranslate nohighlight">\(X_{Bj}\)</span> for all possible pairs of indices <span class="math notranslate nohighlight">\(i \in \{1, 2, \ldots, n_A\}\)</span> and <span class="math notranslate nohighlight">\(j \in \{1, 2, \ldots, n_B\}\)</span>.</p>
<p>This independence between populations is what distinguishes independent sample procedures from paired sample procedures. It ensures that the sampling process for one group has no effect on or relation to the selection of individuals or objects from the other group.</p>
<p><strong>Assumption 3: Normality of Sampling Distributions</strong></p>
<p>We require that the sampling distributions for the estimators of the means follow normal distributions. This can be satisfied through two pathways:</p>
<p>First, if the underlying populations are normally distributed, then the sample means will be exactly normally distributed regardless of sample size. Second, if the populations are not normal but the sample sizes are sufficiently large, the Central Limit Theorem ensures that the sample means are approximately normally distributed.</p>
<p>Under these conditions, we have:</p>
<div class="math notranslate nohighlight">
\[\bar{X}_A \sim N\left(\mu_A, \frac{\sigma_A}{\sqrt{n_A}}\right)\]</div>
<div class="math notranslate nohighlight">
\[\bar{X}_B \sim N\left(\mu_B, \frac{\sigma_B}{\sqrt{n_B}}\right)\]</div>
</section>
<section id="the-parameter-of-interest-and-natural-estimator">
<h2><span class="section-number">11.2.2. </span>The Parameter of Interest and Natural Estimator<a class="headerlink" href="#the-parameter-of-interest-and-natural-estimator" title="Link to this heading">ÔÉÅ</a></h2>
<p>In two-sample procedures, our primary interest lies not in the individual population means <span class="math notranslate nohighlight">\(\mu_A\)</span> and <span class="math notranslate nohighlight">\(\mu_B\)</span>, but rather in their difference. This shift in focus from individual parameters to comparative parameters is fundamental to the two-sample approach.</p>
<p><strong>The Target Parameter</strong></p>
<p>Our parameter of interest is:</p>
<div class="math notranslate nohighlight">
\[\theta = \mu_A - \mu_B\]</div>
<p>We can conceptualize this difference as a single parameter that captures the essence of the comparison we wish to make. The sign and magnitude of this difference tell us both the direction and size of any systematic difference between the populations.</p>
<p><strong>The Point Estimator</strong></p>
<p>Since we know that <span class="math notranslate nohighlight">\(\bar{X}_A\)</span> is an unbiased estimator of <span class="math notranslate nohighlight">\(\mu_A\)</span> and <span class="math notranslate nohighlight">\(\bar{X}_B\)</span> is an unbiased estimator of <span class="math notranslate nohighlight">\(\mu_B\)</span>, the natural point estimator for their difference is:</p>
<div class="math notranslate nohighlight">
\[\hat{\theta} = \bar{X}_A - \bar{X}_B\]</div>
<p>This estimator leverages the independent sampling structure by estimating each population mean separately and then computing their difference.</p>
</section>
<section id="theoretical-properties-of-the-point-estimator">
<h2><span class="section-number">11.2.3. </span>Theoretical Properties of the Point Estimator<a class="headerlink" href="#theoretical-properties-of-the-point-estimator" title="Link to this heading">ÔÉÅ</a></h2>
<p><strong>Unbiasedness</strong></p>
<p>The difference in sample means provides an unbiased estimate of the difference in population means. To establish this formally:</p>
<div class="math notranslate nohighlight">
\[E[\bar{X}_A - \bar{X}_B] = E[\bar{X}_A] - E[\bar{X}_B]\]</div>
<p>This equality follows from the linearity of expectation. Since each sample mean is an unbiased estimator of its respective population mean:</p>
<div class="math notranslate nohighlight">
\[E[\bar{X}_A] = \mu_A \quad \text{and} \quad E[\bar{X}_B] = \mu_B\]</div>
<p>Therefore:</p>
<div class="math notranslate nohighlight">
\[E[\bar{X}_A - \bar{X}_B] = \mu_A - \mu_B\]</div>
<p>The bias of our estimator is:</p>
<div class="math notranslate nohighlight">
\[\text{Bias}[\bar{X}_A - \bar{X}_B] = E[\bar{X}_A - \bar{X}_B] - (\mu_A - \mu_B) = 0\]</div>
<p><strong>Variance Calculation</strong></p>
<p>The variance of the difference in sample means depends critically on the independence assumption between populations. For independent random variables, the variance of their difference equals the sum of their individual variances:</p>
<div class="math notranslate nohighlight">
\[\text{Var}[\bar{X}_A - \bar{X}_B] = \text{Var}[\bar{X}_A] + \text{Var}[\bar{X}_B]\]</div>
<p>From single-sample theory, we know that the variance of a sample mean is the population variance divided by the sample size:</p>
<div class="math notranslate nohighlight">
\[\text{Var}[\bar{X}_A] = \frac{\sigma^2_A}{n_A} \quad \text{and} \quad \text{Var}[\bar{X}_B] = \frac{\sigma^2_B}{n_B}\]</div>
<p>Consequently:</p>
<div class="math notranslate nohighlight">
\[\text{Var}[\bar{X}_A - \bar{X}_B] = \frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}\]</div>
<p><strong>Standard Deviation</strong></p>
<p>The standard deviation of our estimator is:</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}_A - \bar{X}_B} = \sqrt{\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}}\]</div>
<p>It is crucial to note that this expression cannot be simplified to <span class="math notranslate nohighlight">\(\frac{\sigma_A}{\sqrt{n_A}} + \frac{\sigma_B}{\sqrt{n_B}}\)</span> because the square root function does not distribute across addition. The correct procedure is to first compute the variance by adding the individual variance terms, then take the square root of the entire sum.</p>
</section>
<section id="the-sampling-distribution-of-the-difference">
<h2><span class="section-number">11.2.4. </span>The Sampling Distribution of the Difference<a class="headerlink" href="#the-sampling-distribution-of-the-difference" title="Link to this heading">ÔÉÅ</a></h2>
<p>Under our stated assumptions, we can derive the complete sampling distribution of the difference in sample means.</p>
<p><strong>The Central Result</strong></p>
<p>The difference <span class="math notranslate nohighlight">\(\bar{X}_A - \bar{X}_B\)</span> follows a normal distribution with mean <span class="math notranslate nohighlight">\(\mu_A - \mu_B\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sqrt{\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\bar{X}_A - \bar{X}_B \sim N\left(\mu_A - \mu_B, \sqrt{\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}}\right)\]</div>
<p><strong>Theoretical Justification</strong></p>
<p>This result follows from the fundamental properties of normal distributions. Since <span class="math notranslate nohighlight">\(\bar{X}_A\)</span> and <span class="math notranslate nohighlight">\(\bar{X}_B\)</span> are each normally distributed and are independent of each other, their difference is also normally distributed. The mean of the difference equals the difference of the means, and the variance of the difference equals the sum of the variances (due to independence).</p>
<p><strong>Statistical Efficiency</strong></p>
<p>When the original populations are normally distributed, this estimator achieves the Cram√©r-Rao lower bound, making it the minimum variance unbiased estimator (MVUE) for the difference in means. This efficiency property provides theoretical justification for the widespread use of this approach.</p>
</section>
<section id="hypothesis-testing-procedures">
<h2><span class="section-number">11.2.5. </span>Hypothesis Testing Procedures<a class="headerlink" href="#hypothesis-testing-procedures" title="Link to this heading">ÔÉÅ</a></h2>
<p>The four-step hypothesis testing framework extends naturally to the two-sample setting, with modifications to accommodate the comparative nature of the research questions.</p>
<p><strong>Step 1: Parameter Identification</strong></p>
<p>In two-sample procedures, we must clearly identify both population means using contextually meaningful labels. Rather than generic labels like A and B, we should use descriptive terms that reflect the actual populations being studied. For example:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu_{\text{treatment}}\)</span> = true mean response for the treatment group</p></li>
<li><p><span class="math notranslate nohighlight">\(\mu_{\text{control}}\)</span> = true mean response for the control group</p></li>
</ul>
<p>The parameter identification should also specify the units of measurement and provide sufficient context for interpreting the parameters within the scope of the research question.</p>
<p><strong>Step 2: Hypothesis Formulation</strong></p>
<p>The hypotheses in two-sample procedures focus on the difference between population means. The general structure is:</p>
<div class="math notranslate nohighlight">
\[H_0: \mu_A - \mu_B = \Delta_0\]</div>
<p>The null value <span class="math notranslate nohighlight">\(\Delta_0\)</span> represents the hypothesized difference under the null hypothesis. In most applications, <span class="math notranslate nohighlight">\(\Delta_0 = 0\)</span>, corresponding to the hypothesis of equal population means. However, other values of <span class="math notranslate nohighlight">\(\Delta_0\)</span> are possible and meaningful in certain research contexts, such as non-inferiority testing or equivalence studies.</p>
<p>The choice of alternative hypothesis depends on the research question:</p>
<ul class="simple">
<li><p><strong>Two-sided alternative</strong> (<span class="math notranslate nohighlight">\(H_a: \mu_A - \mu_B \neq \Delta_0\)</span>): Used when we want to detect any difference from the null value</p></li>
<li><p><strong>Right-sided alternative</strong> (<span class="math notranslate nohighlight">\(H_a: \mu_A - \mu_B &gt; \Delta_0\)</span>): Used when we specifically want to establish that <span class="math notranslate nohighlight">\(\mu_A\)</span> exceeds <span class="math notranslate nohighlight">\(\mu_B\)</span> by more than <span class="math notranslate nohighlight">\(\Delta_0\)</span></p></li>
<li><p><strong>Left-sided alternative</strong> (<span class="math notranslate nohighlight">\(H_a: \mu_A - \mu_B &lt; \Delta_0\)</span>): Used when we specifically want to establish that <span class="math notranslate nohighlight">\(\mu_A\)</span> is less than <span class="math notranslate nohighlight">\(\mu_B\)</span> by more than <span class="math notranslate nohighlight">\(\Delta_0\)</span></p></li>
</ul>
<p><strong>Step 3: Test Statistic and P-Value Calculation</strong></p>
<p>When population standard deviations are known, we standardize our estimator to obtain a test statistic that follows a standard normal distribution:</p>
<div class="math notranslate nohighlight">
\[Z_{TS} = \frac{(\bar{X}_A - \bar{X}_B) - \Delta_0}{\sqrt{\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}}}\]</div>
<p>Under the null hypothesis, this test statistic follows a standard normal distribution: <span class="math notranslate nohighlight">\(Z_{TS} \sim N(0,1)\)</span>.</p>
<p>In the common case where <span class="math notranslate nohighlight">\(\Delta_0 = 0\)</span>, this simplifies to:</p>
<div class="math notranslate nohighlight">
\[Z_{TS} = \frac{\bar{X}_A - \bar{X}_B}{\sqrt{\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}}}\]</div>
<p>The p-value calculation follows the same principles as in single-sample z-tests, with the specific approach depending on the alternative hypothesis:</p>
<ul class="simple">
<li><p><strong>Two-sided test</strong>: <span class="math notranslate nohighlight">\(\text{p-value} = 2P(Z &gt; |Z_{TS}|)\)</span></p></li>
<li><p><strong>Right-sided test</strong>: <span class="math notranslate nohighlight">\(\text{p-value} = P(Z &gt; Z_{TS})\)</span></p></li>
<li><p><strong>Left-sided test</strong>: <span class="math notranslate nohighlight">\(\text{p-value} = P(Z &lt; Z_{TS})\)</span></p></li>
</ul>
<p><strong>Step 4: Decision and Conclusion</strong></p>
<p>The decision rule remains unchanged from single-sample procedures: compare the p-value to the predetermined significance level <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<ul class="simple">
<li><p>If p-value ‚â§ <span class="math notranslate nohighlight">\(\alpha\)</span>: Reject <span class="math notranslate nohighlight">\(H_0\)</span></p></li>
<li><p>If p-value &gt; <span class="math notranslate nohighlight">\(\alpha\)</span>: Fail to reject <span class="math notranslate nohighlight">\(H_0\)</span></p></li>
</ul>
<p>The conclusion template must be adapted to address the comparative nature of two-sample procedures:</p>
<p><em>‚ÄúThe data [does/does not] give [some/strong] support (p-value = [value]) to the claim that [statement of</em> <span class="math notranslate nohighlight">\(H_a\)</span> <em>in context about the difference in population means].‚Äù</em></p>
<p>The strength descriptors should reflect the magnitude of the p-value relative to conventional benchmarks and the significance level used in the study.</p>
</section>
<section id="confidence-intervals-for-the-difference-in-means">
<h2><span class="section-number">11.2.6. </span>Confidence Intervals for the Difference in Means<a class="headerlink" href="#confidence-intervals-for-the-difference-in-means" title="Link to this heading">ÔÉÅ</a></h2>
<p>Confidence intervals for the difference in population means follow the same pivotal quantity approach used in single-sample procedures, adapted for the two-sample context.</p>
<p><strong>The Pivotal Quantity</strong></p>
<p>Our pivotal quantity is constructed by standardizing the difference in sample means:</p>
<div class="math notranslate nohighlight">
\[Z = \frac{(\bar{X}_A - \bar{X}_B) - (\mu_A - \mu_B)}{\sqrt{\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}}}\]</div>
<p>This quantity satisfies the requirements for a pivotal quantity:</p>
<ol class="arabic simple">
<li><p>Its distribution (standard normal) does not depend on any unknown parameters</p></li>
<li><p>It contains exactly one unknown parameter of interest: <span class="math notranslate nohighlight">\(\mu_A - \mu_B\)</span></p></li>
<li><p>It has a known, tractable distribution that allows for probability calculations</p></li>
</ol>
<p><strong>Confidence Interval Construction</strong></p>
<p>For a <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> confidence interval, we begin with the probability statement:</p>
<div class="math notranslate nohighlight">
\[P\left(-z_{\alpha/2} &lt; \frac{(\bar{X}_A - \bar{X}_B) - (\mu_A - \mu_B)}{\sqrt{\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}}} &lt; z_{\alpha/2}\right) = 1 - \alpha\]</div>
<p>Through algebraic manipulation to isolate <span class="math notranslate nohighlight">\(\mu_A - \mu_B\)</span> in the center of the inequality, we obtain:</p>
<p><strong>Interpretation</strong></p>
<p>The confidence interval provides a range of plausible values for the true difference in population means. Specifically, we can state with <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> confidence that the true difference <span class="math notranslate nohighlight">\(\mu_A - \mu_B\)</span> lies within the computed interval.</p>
<p>The width of the confidence interval reflects the precision of our estimate, with narrower intervals indicating more precise estimation. The interval width depends on the confidence level, the population variances, and the sample sizes.</p>
</section>
<section id="illustrative-example-understanding-through-application">
<h2><span class="section-number">11.2.7. </span>Illustrative Example: Understanding Through Application<a class="headerlink" href="#illustrative-example-understanding-through-application" title="Link to this heading">ÔÉÅ</a></h2>
<p>To demonstrate these concepts concretely, consider a simplified example based on the theoretical framework we have established.</p>
<p><strong>Scenario Setup</strong></p>
<p>Suppose we have two independent samples with the following characteristics:</p>
<ul class="simple">
<li><p><strong>Group A</strong>: <span class="math notranslate nohighlight">\(n_A = 25\)</span>, <span class="math notranslate nohighlight">\(\bar{x}_A = 50\)</span>, <span class="math notranslate nohighlight">\(\sigma_A = 10\)</span> (known)</p></li>
<li><p><strong>Group B</strong>: <span class="math notranslate nohighlight">\(n_B = 30\)</span>, <span class="math notranslate nohighlight">\(\bar{x}_B = 45\)</span>, <span class="math notranslate nohighlight">\(\sigma_B = 12\)</span> (known)</p></li>
</ul>
<p>We wish to test <span class="math notranslate nohighlight">\(H_0: \mu_A - \mu_B = 0\)</span> versus <span class="math notranslate nohighlight">\(H_a: \mu_A - \mu_B \neq 0\)</span> at the <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span> significance level.</p>
<p><strong>Test Statistic Calculation</strong></p>
<p>The point estimate is:</p>
<p>The standard error is:</p>
<p>The test statistic is:</p>
<p><strong>P-Value and Decision</strong></p>
<p>For a two-sided test, the p-value is <span class="math notranslate nohighlight">\(2P(Z &gt; 1.68) \approx 2(0.0465) \approx 0.093\)</span>.</p>
<p>Since 0.093 &gt; 0.05, we fail to reject the null hypothesis at the 5% significance level.</p>
<p><strong>95% Confidence Interval</strong></p>
<p>The 95% confidence interval is:</p>
<p>This interval contains zero, which is consistent with our failure to reject the null hypothesis of equal means.</p>
</section>
<section id="the-transition-to-unknown-standard-deviations">
<h2><span class="section-number">11.2.8. </span>The Transition to Unknown Standard Deviations<a class="headerlink" href="#the-transition-to-unknown-standard-deviations" title="Link to this heading">ÔÉÅ</a></h2>
<p>While the assumption of known population standard deviations provides valuable theoretical insight, it is rarely
realistic in practice. When <span class="math notranslate nohighlight">\(\sigma_A\)</span> and <span class="math notranslate nohighlight">\(\sigma_B\)</span> must be estimated from sample data, our procedures
undergo important modifications:</p>
<p><strong>Changes in Test Statistics</strong></p>
<p>The test statistic becomes a t-statistic rather than a z-statistic, with the population standard deviations replaced by their sample estimates.</p>
<p><strong>Degrees of Freedom Considerations</strong></p>
<p>The determination of appropriate degrees of freedom depends on whether we can assume equal population variances, leading to two distinct approaches: pooled and unpooled procedures.</p>
<p><strong>Distribution Theory</strong></p>
<p>The sampling distribution changes from normal to t, requiring different critical values and p-value calculations.</p>
<p>These extensions, while maintaining the same fundamental logic, introduce additional complexity that will be addressed in subsequent sections.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaways üìù</p>
<ol class="arabic simple">
<li><p><strong>Two-sample independent procedures extend single-sample methods</strong> to comparative questions while requiring three fundamental assumptions: independent simple random sampling, independence between groups, and normal sampling distributions.</p></li>
<li><p><strong>The parameter of interest shifts from individual means to their difference</strong> (<span class="math notranslate nohighlight">\(\mu_A - \mu_B\)</span>), with the natural point estimator being <span class="math notranslate nohighlight">\(\bar{X}_A - \bar{X}_B\)</span>.</p></li>
<li><p><strong>The point estimator is unbiased with variance</strong> <span class="math notranslate nohighlight">\(\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}\)</span>, where the addition of variances follows from the independence assumption between groups.</p></li>
<li><p><strong>Test statistics follow standard normal distributions</strong> when population standard deviations are known, using <span class="math notranslate nohighlight">\(Z_{TS} = \frac{(\bar{X}_A - \bar{X}_B) - \Delta_0}{\sqrt{\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}}}\)</span>.</p></li>
<li><p><strong>The four-step hypothesis testing framework applies directly</strong>, with conclusions addressing differences between population means rather than individual parameter values.</p></li>
<li><p><strong>Confidence intervals follow the pivotal quantity approach</strong>, providing ranges of plausible values for the true difference in population means.</p></li>
<li><p><strong>Sample sizes may differ between groups</strong> without affecting the validity of the procedures, though equal sample sizes often provide optimal statistical efficiency.</p></li>
<li><p><strong>This theoretical foundation extends to t-procedures</strong> when population standard deviations must be estimated, maintaining the same logical structure while adapting to distributional changes.</p></li>
</ol>
</div>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">ÔÉÅ</a></h3>
<ol class="arabic simple">
<li><p><strong>Theoretical Understanding</strong>: Explain why the variance of <span class="math notranslate nohighlight">\(\bar{X}_A - \bar{X}_B\)</span> equals <span class="math notranslate nohighlight">\(\frac{\sigma^2_A}{n_A} + \frac{\sigma^2_B}{n_B}\)</span> rather than <span class="math notranslate nohighlight">\(\frac{\sigma^2_A}{n_A} - \frac{\sigma^2_B}{n_B}\)</span>. What assumption is crucial for this result?</p></li>
<li><p><strong>Assumption Analysis</strong>: For each of the following research scenarios, identify which assumptions might be violated and explain the potential consequences:</p>
<ol class="loweralpha simple">
<li><p>Comparing test scores between students in the same classroom, where some students work together</p></li>
<li><p>Measuring reaction times before and after caffeine consumption using the same participants</p></li>
<li><p>Comparing heights between adult males and females using a convenience sample from a shopping mall</p></li>
</ol>
</li>
<li><p><strong>Hypothesis Formulation</strong>: A manufacturer claims their new battery lasts at least 2 hours longer than the competitor‚Äôs battery. Set up appropriate hypotheses for testing this claim, clearly defining your parameters and explaining your choice of <span class="math notranslate nohighlight">\(\Delta_0\)</span>.</p></li>
<li><p><strong>Standard Error Calculation</strong>: Two independent samples have <span class="math notranslate nohighlight">\(n_A = 16\)</span>, <span class="math notranslate nohighlight">\(\sigma_A = 8\)</span>, <span class="math notranslate nohighlight">\(n_B = 25\)</span>, and <span class="math notranslate nohighlight">\(\sigma_B = 10\)</span>. Calculate the standard error of <span class="math notranslate nohighlight">\(\bar{X}_A - \bar{X}_B\)</span> and explain what this value represents in practical terms.</p></li>
<li><p><strong>Sample Size Effects</strong>: How would the standard error of <span class="math notranslate nohighlight">\(\bar{X}_A - \bar{X}_B\)</span> change if:</p>
<ol class="loweralpha simple">
<li><p>Both sample sizes were doubled?</p></li>
<li><p>Only <span class="math notranslate nohighlight">\(n_A\)</span> were doubled while <span class="math notranslate nohighlight">\(n_B\)</span> remained constant?</p></li>
<li><p>The total sample size remained constant but was redistributed equally between groups?</p></li>
</ol>
</li>
<li><p><strong>Confidence Interval Interpretation</strong>: A 90% confidence interval for <span class="math notranslate nohighlight">\(\mu_A - \mu_B\)</span> is calculated as (1.2, 7.8). Provide three different but equivalent ways to interpret this interval, and explain what happens to the interval width if the confidence level is increased to 95%.</p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="11-1-ci-ht-two-samples.html" class="btn btn-neutral float-left" title="11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="11-3-comparing-two-means-independent-pooled.html" class="btn btn-neutral float-right" title="11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>