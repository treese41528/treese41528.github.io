

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=581abb6a" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=de5959cf"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="12. ANOVA" href="../../chapter12/index.html" />
    <link rel="prev" title="11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption" href="11-4-comparing-two-means-independent-unpooled.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#simulation-exercise">Simulation Exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#quick-reference-table">Quick Reference Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#recommended-workflow">Recommended workflow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#getting-started-with-swirl">Getting Started with swirl</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#setup-and-use-swirl">Setup and Use swirl</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#alternative-r-learning-resources">Alternative R Learning Resources</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#base-r">Base R</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#tidyverse">tidyverse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#r-markdown">R Markdown</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#statistical-computing">Statistical Computing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#video-resources">Video Resources</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#function-reference-alphabetized-within-category">Function Reference (Alphabetized within Category)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#simulation-functions">Simulation Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#inference-functions">Inference Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#graphics-ggplot2">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#tables-reporting">Tables &amp; Reporting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#best-practices-common-pitfalls">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#appendix-quick-links">Appendix: Quick Links</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#assignments">Assignments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#getting-help">Getting Help</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">11. Two Sample Procedures</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">11. </span>Two Sample Procedures</a></li>
      <li class="breadcrumb-item active"><span class="section-number">11.5. </span>Analyzing the Mean of Paired Differences Between two Dependent Populations</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch11-5">
   <iframe
      id="video-ch11-5"
      title="STAT 350 – Chapter 11.5 Comparing Two Population Means Using Paired Samples Video"
      src="https://www.youtube.com/embed/9qEfrrRcbRw?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="analyzing-the-mean-of-paired-differences-between-two-dependent-populations">
<h1><span class="section-number">11.5. </span>Analyzing the Mean of Paired Differences Between two Dependent Populations<a class="headerlink" href="#analyzing-the-mean-of-paired-differences-between-two-dependent-populations" title="Link to this heading"></a></h1>
<p>In the independent sample procedures we have developed so far, we have operated under the fundamental assumption
that observations from one population are completely independent of observations from the other population.
However, many important research questions involve comparisons where this independence assumption is violated
by design. When observations are naturally linked or paired, we must modify our statistical approach to account
for these dependencies while gaining the substantial benefits that pairing can provide.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p><strong>Problem we will solve</strong> – How to compare two population means when observations are paired or matched,</p></li>
</ul>
<p>violating the independence assumption required for independent sample procedures
• <strong>Tools we’ll learn</strong> – Paired sample t-procedures that transform two-sample problems into familiar
one-sample analyses of differences
• <strong>How it fits</strong> – This provides a powerful alternative to independent samples that controls for individual
variability and often yields more precise inference about treatment effects</p>
</div>
<section id="when-independence-fails-the-paired-design-framework">
<h2><span class="section-number">11.5.1. </span>When Independence Fails: The Paired Design Framework<a class="headerlink" href="#when-independence-fails-the-paired-design-framework" title="Link to this heading"></a></h2>
<p>The independence assumption that underlies our previous two-sample procedures requires that the process of selecting individuals from one population has no effect on or relation to the selection from the other population. While this assumption is reasonable in many contexts, there are important scenarios where it is systematically violated by the nature of the research design or the inherent structure of the data.</p>
<p><strong>Characteristics of Paired Observations</strong></p>
<p>Paired sample procedures are appropriate when observations are linked by some underlying characteristic or relationship that creates dependencies between measurements. These dependencies can arise through several mechanisms:</p>
<p><strong>Same Subject Measured Twice</strong></p>
<p>The most common pairing scenario involves measuring the same individuals under two different conditions or at two different times. Examples include:</p>
<ul class="simple">
<li><p><strong>Before and after studies</strong>: Measuring patient blood pressure before and after treatment</p></li>
<li><p><strong>Pre-test and post-test designs</strong>: Assessing student performance before and after an educational intervention</p></li>
<li><p><strong>Crossover trials</strong>: Administering two different treatments to the same subjects with appropriate washout periods</p></li>
</ul>
<p>In these designs, each subject serves as their own control, eliminating between-subject variability from the comparison.</p>
<p><strong>Matched Subjects with Similar Characteristics</strong></p>
<p>Pairing can also involve different subjects who are matched on characteristics that might otherwise introduce substantial variability into the comparison:</p>
<ul class="simple">
<li><p><strong>Twin studies</strong>: Comparing outcomes between twins who receive different treatments</p></li>
<li><p><strong>Sibling pairs</strong>: Studying interventions within families to control for genetic and environmental factors</p></li>
<li><p><strong>Matched pairs</strong>: Deliberately pairing subjects on age, gender, disease severity, or other relevant characteristics</p></li>
</ul>
<p><strong>Naturally Paired Materials or Units</strong></p>
<p>Some research contexts involve natural pairing relationships:</p>
<ul class="simple">
<li><p><strong>Split-plot designs</strong>: Cutting material from the same source and applying different treatments to each piece</p></li>
<li><p><strong>Bilateral measurements</strong>: Comparing left versus right measurements on the same subjects</p></li>
<li><p><strong>Temporal dependencies</strong>: Measurements taken on consecutive days or under related conditions</p></li>
</ul>
<p><strong>The Statistical Rationale for Pairing</strong></p>
<p>Pairing is particularly valuable when the characteristic that links the observations creates large variability that might otherwise obscure the treatment effect of interest. By controlling for these lurking variables through the pairing mechanism, we can isolate the effect of the treatment or intervention being studied.</p>
<p>Consider a study evaluating the effectiveness of a new pain medication. If we used an independent sample design, individual differences in pain tolerance, medical history, and baseline pain levels would contribute substantial noise to our comparison. However, by measuring the same patients before and after treatment (a paired design), these individual characteristics affect both measurements equally and are eliminated when we analyze the differences.</p>
</section>
<section id="the-mathematical-foundation-working-with-differences">
<h2><span class="section-number">11.5.2. </span>The Mathematical Foundation: Working with Differences<a class="headerlink" href="#the-mathematical-foundation-working-with-differences" title="Link to this heading"></a></h2>
<p>The key insight in paired sample procedures is to transform the two-sample comparison problem into a one-sample analysis problem by focusing on the differences between paired observations.</p>
<p><strong>Parameter Definitions and Notation</strong></p>
<p>For paired samples, we have observations <span class="math notranslate nohighlight">\(X_{A1}, X_{A2}, \ldots, X_{An}\)</span> from population A and <span class="math notranslate nohighlight">\(X_{B1}, X_{B2}, \ldots, X_{Bn}\)</span> from population B, where <span class="math notranslate nohighlight">\(X_{Ai}\)</span> is paired with <span class="math notranslate nohighlight">\(X_{Bi}\)</span> for each <span class="math notranslate nohighlight">\(i\)</span>. The crucial aspect is that these observations are not independent across populations.</p>
<p>Rather than working with the original populations separately, we define the differences:</p>
<div class="math notranslate nohighlight">
\[D_i = X_{Ai} - X_{Bi} \text{ for } i = 1, 2, \ldots, n\]</div>
<p>These differences <span class="math notranslate nohighlight">\(D_1, D_2, \ldots, D_n\)</span> form a new dataset that captures the essence of the comparison while eliminating the correlation structure between the original observations.</p>
<p><strong>Population Parameters for Differences</strong></p>
<p>The population parameter of primary interest becomes the mean difference:</p>
<p>This parameter represents the average difference between the two conditions or treatments in the population.</p>
<p>The variance of the differences involves a more complex relationship:</p>
<p>Using the properties of variance for correlated random variables:</p>
<p>where <span class="math notranslate nohighlight">\(\rho_{AB}\)</span> is the correlation between paired observations.</p>
<p><strong>The Power of Avoiding Correlation Estimation</strong></p>
<p>While we could theoretically estimate the individual population parameters and their correlation to construct our inference procedures, this approach would be unnecessarily complex and potentially imprecise. Instead, paired procedures take the elegant approach of working directly with the differences, treating them as a simple random sample from the population of differences with mean <span class="math notranslate nohighlight">\(\mu_D\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2_D\)</span>.</p>
<p>This transformation eliminates the need to estimate or model the correlation structure, allowing us to apply the familiar one-sample t-procedures to the differences.</p>
</section>
<section id="sample-statistics-for-paired-data">
<h2><span class="section-number">11.5.3. </span>Sample Statistics for Paired Data<a class="headerlink" href="#sample-statistics-for-paired-data" title="Link to this heading"></a></h2>
<p><strong>Sample Mean Difference</strong></p>
<p>The sample mean difference provides our point estimator for <span class="math notranslate nohighlight">\(\mu_D\)</span>:</p>
<p>This estimator is unbiased: <span class="math notranslate nohighlight">\(E[\bar{D}] = \mu_D\)</span>.</p>
<p><strong>Sample Variance of Differences</strong></p>
<p>The sample variance of differences is calculated using the standard formula applied to the difference values:</p>
<p>This provides an unbiased estimator for <span class="math notranslate nohighlight">\(\sigma^2_D\)</span>: <span class="math notranslate nohighlight">\(E[S^2_D] = \sigma^2_D\)</span>.</p>
<p><strong>Sampling Distribution of the Sample Mean Difference</strong></p>
<p>Under the assumption that the differences are normally distributed (or that the Central Limit Theorem applies), the sample mean difference follows:</p>
<p>When <span class="math notranslate nohighlight">\(\sigma_D\)</span> is unknown and estimated by <span class="math notranslate nohighlight">\(S_D\)</span>, we obtain the t-distribution result that forms the foundation for our inference procedures.</p>
</section>
<section id="assumptions-for-paired-sample-procedures">
<h2><span class="section-number">11.5.4. </span>Assumptions for Paired Sample Procedures<a class="headerlink" href="#assumptions-for-paired-sample-procedures" title="Link to this heading"></a></h2>
<p>Paired sample procedures require three fundamental assumptions that mirror those for one-sample procedures:</p>
<p><strong>1. Independent Pairs</strong></p>
<p>Each pair <span class="math notranslate nohighlight">\((X_{Ai}, X_{Bi})\)</span> must be independent of all other pairs <span class="math notranslate nohighlight">\((X_{Aj}, X_{Bj})\)</span> for <span class="math notranslate nohighlight">\(i \neq j\)</span>. This means that while observations within a pair are dependent (which is the point of pairing), different pairs must be independently sampled.</p>
<p><strong>2. Simple Random Sampling from the Population of Pairs</strong></p>
<p>The pairs themselves must constitute a simple random sample from the broader population of potential pairs. This ensures that our sample is representative of the population we wish to make inferences about.</p>
<p><strong>3. Normality of Differences</strong></p>
<p>The differences <span class="math notranslate nohighlight">\(D_i\)</span> must be normally distributed, or the sample size must be large enough for the Central Limit Theorem to ensure that <span class="math notranslate nohighlight">\(\bar{D}\)</span> is approximately normally distributed. Note that this assumption concerns the distribution of differences, not the original observations.</p>
<p>This normality assumption is often more readily satisfied than normality of the original observations because the differencing process can reduce skewness when both original distributions are skewed in similar ways.</p>
</section>
<section id="hypothesis-testing-for-paired-samples-the-four-step-process">
<h2><span class="section-number">11.5.5. </span>Hypothesis Testing for Paired Samples: The Four-Step Process<a class="headerlink" href="#hypothesis-testing-for-paired-samples-the-four-step-process" title="Link to this heading"></a></h2>
<p>Paired sample hypothesis testing follows the same four-step framework as one-sample procedures, but with careful attention to defining the differences appropriately.</p>
<p><strong>Step 1: Parameter Identification and Difference Definition</strong></p>
<p>The parameter of interest is <span class="math notranslate nohighlight">\(\mu_D\)</span>, the mean difference between paired observations. Critically, we must explicitly define how the difference is calculated, as this determines the direction of our alternative hypothesis.</p>
<p>For example, if studying a training program’s effectiveness:
- <span class="math notranslate nohighlight">\(D = X_{\text{pre}} - X_{\text{post}}\)</span> (pre-training score minus post-training score)</p>
<p>The choice of difference direction should align with the research question and the anticipated direction of the effect.</p>
<p><strong>Step 2: Hypothesis Formulation</strong></p>
<p>Our hypotheses are formulated in terms of <span class="math notranslate nohighlight">\(\mu_D\)</span>:</p>
<ul class="simple">
<li><p><strong>Null hypothesis</strong>: <span class="math notranslate nohighlight">\(H_0: \mu_D = \Delta_0\)</span> (typically <span class="math notranslate nohighlight">\(\Delta_0 = 0\)</span>)</p></li>
<li><p><strong>Alternative hypotheses</strong>:
- Two-sided: <span class="math notranslate nohighlight">\(H_a: \mu_D \neq \Delta_0\)</span>
- Right-tailed: <span class="math notranslate nohighlight">\(H_a: \mu_D &gt; \Delta_0\)</span>
- Left-tailed: <span class="math notranslate nohighlight">\(H_a: \mu_D &lt; \Delta_0\)</span></p></li>
</ul>
<p>The choice of alternative depends on the research question and how we defined the differences in Step 1.</p>
<p><strong>Step 3: Test Statistic and P-Value Calculation</strong></p>
<p>The test statistic follows the familiar one-sample t-test format:</p>
<p>where <span class="math notranslate nohighlight">\(\bar{d}\)</span> is the observed sample mean difference, <span class="math notranslate nohighlight">\(s_d\)</span> is the sample standard deviation of differences, and <span class="math notranslate nohighlight">\(n\)</span> is the number of pairs.</p>
<p>Under the null hypothesis and our stated assumptions, this test statistic follows a t-distribution with <span class="math notranslate nohighlight">\(df = n - 1\)</span> degrees of freedom.</p>
<p>P-value calculation follows the same patterns as one-sample procedures:
- <strong>Two-sided</strong>: p-value = <span class="math notranslate nohighlight">\(2P(T &gt; |t_{TS}|)\)</span> where <span class="math notranslate nohighlight">\(T \sim t_{n-1}\)</span>
- <strong>Right-tailed</strong>: p-value = <span class="math notranslate nohighlight">\(P(T &gt; t_{TS})\)</span>
- <strong>Left-tailed</strong>: p-value = <span class="math notranslate nohighlight">\(P(T &lt; t_{TS})\)</span></p>
<p><strong>Step 4: Decision and Conclusion</strong></p>
<p>Compare the p-value to the predetermined significance level <span class="math notranslate nohighlight">\(\alpha\)</span> and draw conclusions in the context of the original research question, being careful to interpret results in terms of the mean difference as defined in Step 1.</p>
</section>
<section id="confidence-intervals-for-paired-differences">
<h2><span class="section-number">11.5.6. </span>Confidence Intervals for Paired Differences<a class="headerlink" href="#confidence-intervals-for-paired-differences" title="Link to this heading"></a></h2>
<p>Confidence intervals for the mean difference follow the standard one-sample format:</p>
<p><strong>Confidence Bounds for One-Sided Alternatives</strong></p>
<p>For one-sided alternatives, we construct confidence bounds rather than intervals:</p>
<p><strong>Upper confidence bound</strong> (for <span class="math notranslate nohighlight">\(H_a: \mu_D &lt; \Delta_0\)</span>):</p>
<p><strong>Lower confidence bound</strong> (for <span class="math notranslate nohighlight">\(H_a: \mu_D &gt; \Delta_0\)</span>):</p>
<p>These bounds provide ranges of plausible values for the true mean difference and can be used to assess both statistical and practical significance.</p>
</section>
<section id="a-complete-example-nursing-sensitivity-training-study">
<h2><span class="section-number">11.5.7. </span>A Complete Example: Nursing Sensitivity Training Study<a class="headerlink" href="#a-complete-example-nursing-sensitivity-training-study" title="Link to this heading"></a></h2>
<p>To illustrate the complete paired sample procedure, we analyze a study evaluating the effectiveness of sensitivity training for hospital nurses.</p>
<p><strong>Study Design and Context</strong></p>
<p>A regional hospital conducted a study to determine whether sensitivity training would improve the quality of care provided by their nursing staff. Eight nurses were selected, and their nursing skills were evaluated on a scale from 1 to 10, where higher scores indicate greater sensitivity to patients. After this initial assessment, the nurses participated in a training program, and their skills were evaluated again using the same scale.</p>
<p>Since each nurse serves as their own control (measured before and after training), this is clearly a paired design. The pairing controls for individual differences in baseline nursing ability, personality, experience, and other factors that might otherwise obscure the training effect.</p>
<p><strong>Data Analysis</strong></p>
<p>The data shows pre-training scores, post-training scores, and the calculated differences for each nurse:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Nurse</p></th>
<th class="head"><p>Pre-Training</p></th>
<th class="head"><p>Post-Training</p></th>
<th class="head"><p>Difference (Pre - Post)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>2.56</p></td>
<td><p>4.54</p></td>
<td><p>-1.98</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>3.22</p></td>
<td><p>5.33</p></td>
<td><p>-2.11</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>3.45</p></td>
<td><p>4.32</p></td>
<td><p>-0.87</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>5.55</p></td>
<td><p>7.45</p></td>
<td><p>-1.90</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>5.63</p></td>
<td><p>7.00</p></td>
<td><p>-1.37</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>7.89</p></td>
<td><p>9.80</p></td>
<td><p>-1.91</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p>7.66</p></td>
<td><p>7.33</p></td>
<td><p>0.33</p></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p>6.20</p></td>
<td><p>6.80</p></td>
<td><p>-0.60</p></td>
</tr>
</tbody>
</table>
<p>Summary statistics for the differences: <span class="math notranslate nohighlight">\(\bar{d} = -1.30\)</span>, <span class="math notranslate nohighlight">\(s_d = 0.8608\)</span>, <span class="math notranslate nohighlight">\(n = 8\)</span>.</p>
<p><strong>Step 1: Parameter Identification</strong></p>
<p>The parameter of interest is <span class="math notranslate nohighlight">\(\mu_D\)</span>, the true mean difference between pre-training and post-training nursing sensitivity scores, where <span class="math notranslate nohighlight">\(D = X_{\text{pre}} - X_{\text{post}}\)</span>.</p>
<p>Since higher scores indicate better performance, we expect training to increase scores, making the differences (pre minus post) negative on average.</p>
<p><strong>Step 2: Hypothesis Formulation</strong></p>
<p>We want to test whether the training improves nursing skills on average:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H_0: \mu_D \geq 0\)</span> (no improvement; pre-training scores are greater than or equal to post-training scores)</p></li>
<li><p><span class="math notranslate nohighlight">\(H_a: \mu_D &lt; 0\)</span> (improvement; pre-training scores are less than post-training scores)</p></li>
</ul>
<p>This is a left-tailed test with <span class="math notranslate nohighlight">\(\Delta_0 = 0\)</span>.</p>
<p><strong>Step 3: Test Statistic and P-Value</strong></p>
<p>The test statistic is:</p>
<p>With <span class="math notranslate nohighlight">\(df = n - 1 = 7\)</span> degrees of freedom.</p>
<p>For a left-tailed test, the p-value is:</p>
<p>p-value = <span class="math notranslate nohighlight">\(P(T_7 &lt; -4.2755) = 0.001838\)</span></p>
<p><strong>Step 4: Decision and Conclusion</strong></p>
<p>Since p-value = 0.001838 &lt; <span class="math notranslate nohighlight">\(\alpha = 0.01\)</span>, we reject the null hypothesis.</p>
<p><strong>Conclusion</strong>: The data gives strong support (p-value = 0.001838) to the claim that the population average nursing sensitivity scores improved after training for the population of nurses at the regional hospital.</p>
<p><strong>99% Upper Confidence Bound</strong></p>
<p>Since we conducted a left-tailed test, the corresponding confidence bound is an upper bound:</p>
<p>Critical value: <span class="math notranslate nohighlight">\(t_{0.01,7} = 2.998\)</span></p>
<p>Upper bound: <span class="math notranslate nohighlight">\(\mu_D &lt; -1.30 + 2.998 \times \frac{0.8608}{\sqrt{8}} = -1.30 + 0.913 = -0.387\)</span></p>
<p>We are 99% confident that the true mean difference between pre- and post-training scores is less than -0.387. Since this upper bound is negative, it confirms that the training program produces improvement (negative differences indicate post-training scores exceed pre-training scores).</p>
</section>
<section id="implementation-in-r">
<h2><span class="section-number">11.5.8. </span>Implementation in R<a class="headerlink" href="#implementation-in-r" title="Link to this heading"></a></h2>
<p><strong>Method 1: Using t.test() with Paired Data</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the data</span>
<span class="n">pre_training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">2.56</span><span class="p">,</span><span class="w"> </span><span class="m">3.22</span><span class="p">,</span><span class="w"> </span><span class="m">3.45</span><span class="p">,</span><span class="w"> </span><span class="m">5.55</span><span class="p">,</span><span class="w"> </span><span class="m">5.63</span><span class="p">,</span><span class="w"> </span><span class="m">7.89</span><span class="p">,</span><span class="w"> </span><span class="m">7.66</span><span class="p">,</span><span class="w"> </span><span class="m">6.20</span><span class="p">)</span>
<span class="n">post_training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">4.54</span><span class="p">,</span><span class="w"> </span><span class="m">5.33</span><span class="p">,</span><span class="w"> </span><span class="m">4.32</span><span class="p">,</span><span class="w"> </span><span class="m">7.45</span><span class="p">,</span><span class="w"> </span><span class="m">7.00</span><span class="p">,</span><span class="w"> </span><span class="m">9.80</span><span class="p">,</span><span class="w"> </span><span class="m">7.33</span><span class="p">,</span><span class="w"> </span><span class="m">6.80</span><span class="p">)</span>

<span class="c1"># Perform paired t-test</span>
<span class="nf">t.test</span><span class="p">(</span><span class="n">pre_training</span><span class="p">,</span><span class="w"> </span><span class="n">post_training</span><span class="p">,</span>
<span class="w">       </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span>
<span class="w">       </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.99</span><span class="p">,</span>
<span class="w">       </span><span class="n">paired</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span>
<span class="w">       </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;less&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Method 2: Manual Difference Calculation</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate differences manually</span>
<span class="n">differences</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">pre_training</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">post_training</span>

<span class="c1"># Perform one-sample t-test on differences</span>
<span class="nf">t.test</span><span class="p">(</span><span class="n">differences</span><span class="p">,</span>
<span class="w">       </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span>
<span class="w">       </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.99</span><span class="p">,</span>
<span class="w">       </span><span class="n">alternative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;less&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Both methods produce identical results, demonstrating that paired procedures are simply one-sample procedures applied to the differences.</p>
<p><strong>Key R Arguments for Paired Procedures</strong></p>
<ul class="simple">
<li><p><strong>paired = TRUE</strong>: Specifies that observations should be treated as paired</p></li>
<li><p><strong>alternative</strong>: Specifies the direction of the alternative hypothesis (“less”, “greater”, or “two.sided”)</p></li>
<li><p><strong>mu</strong>: The null hypothesis value <span class="math notranslate nohighlight">\(\Delta_0\)</span> (typically 0)</p></li>
<li><p><strong>conf.level</strong>: The confidence level for the corresponding confidence interval or bound</p></li>
</ul>
</section>
<section id="when-to-use-paired-vs-independent-procedures-a-decision-framework">
<h2><span class="section-number">11.5.9. </span>When to Use Paired vs. Independent Procedures: A Decision Framework<a class="headerlink" href="#when-to-use-paired-vs-independent-procedures-a-decision-framework" title="Link to this heading"></a></h2>
<p>The choice between paired and independent sample procedures is fundamental and depends on the study design and data structure. Making the wrong choice can lead to invalid inference or substantial loss of statistical power.</p>
<p><strong>Use Paired Procedures When:</strong></p>
<ol class="arabic simple">
<li><p><strong>Natural Pairing Exists</strong>: Observations are naturally linked through same subjects, matched characteristics, or other dependencies</p></li>
<li><p><strong>Large Lurking Variable Variance</strong>: There are important variables that create substantial variability but are controlled through pairing</p></li>
<li><p><strong>Pairing is Feasible</strong>: The study design allows for meaningful pairing without compromising other aspects of the research</p></li>
<li><p><strong>Power Considerations</strong>: When individual differences are large relative to treatment effects, pairing can substantially increase statistical power</p></li>
</ol>
<p><strong>Use Independent Procedures When:</strong></p>
<ol class="arabic simple">
<li><p><strong>No Natural Pairing</strong>: Observations come from distinct, unrelated populations with no meaningful way to create pairs</p></li>
<li><p><strong>Independence is Maintained</strong>: The sampling process for one group has no relationship to the sampling for the other group</p></li>
<li><p><strong>Large Sample Sizes</strong>: When sample sizes are large enough that the loss of efficiency from not pairing is acceptable</p></li>
<li><p><strong>Pairing is Inappropriate</strong>: When forcing artificial pairing would introduce bias or compromise the research design</p></li>
</ol>
<p><strong>Advantages of Paired Designs</strong></p>
<p><strong>Statistical Advantages:</strong></p>
<ul class="simple">
<li><p><strong>Increased Power</strong>: By controlling for individual variability, paired designs often have greater power to detect true differences</p></li>
<li><p><strong>Improved Precision</strong>: Standard errors are typically smaller when pairing is effective</p></li>
<li><p><strong>Reduced Sample Size Requirements</strong>: The same statistical power can often be achieved with fewer subjects</p></li>
</ul>
<p><strong>Practical Advantages:</strong></p>
<ul class="simple">
<li><p><strong>Cost Efficiency</strong>: Measuring the same subjects twice can be more economical than recruiting separate groups</p></li>
<li><p><strong>Ethical Considerations</strong>: In medical research, paired designs may be preferred when withholding treatment from a control group raises ethical concerns</p></li>
</ul>
<p><strong>Disadvantages of Paired Designs</strong></p>
<p><strong>Statistical Limitations:</strong></p>
<ul class="simple">
<li><p><strong>Dependency Requirements</strong>: Observations must be meaningfully paired, which is not always possible or appropriate</p></li>
<li><p><strong>Carryover Effects</strong>: In crossover designs, treatment effects from the first period may influence the second period</p></li>
<li><p><strong>Missing Data Complications</strong>: If one member of a pair is lost, the entire pair must typically be excluded from analysis</p></li>
</ul>
<p><strong>Practical Limitations:</strong></p>
<ul class="simple">
<li><p><strong>Logistical Complexity</strong>: Coordinating paired measurements can be more complex than independent sampling</p></li>
<li><p><strong>Time Constraints</strong>: Longitudinal paired designs require extended follow-up periods</p></li>
<li><p><strong>Subject Dropout</strong>: Higher risk of losing data when the same subjects must be measured multiple times</p></li>
</ul>
</section>
<section id="the-relationship-to-one-sample-procedures">
<h2><span class="section-number">11.5.10. </span>The Relationship to One-Sample Procedures<a class="headerlink" href="#the-relationship-to-one-sample-procedures" title="Link to this heading"></a></h2>
<p>Paired sample procedures demonstrate a fundamental principle in statistics: complex problems can often be reduced to simpler, well-understood methods through appropriate data transformation. By working with differences rather than original observations, we transform the two-sample paired problem into a one-sample problem about the mean difference.</p>
<p>This reduction allows us to leverage all the theory and methods we developed for one-sample procedures:</p>
<ul class="simple">
<li><p><strong>Test statistics</strong> follow the same t-distribution under the null hypothesis</p></li>
<li><p><strong>Confidence intervals</strong> use the same pivotal quantity approach</p></li>
<li><p><strong>Assumption checking</strong> focuses on the normality of differences rather than original observations</p></li>
<li><p><strong>Effect size calculations</strong> can be applied directly to the differences</p></li>
</ul>
<p><strong>Connection to Independent Sample Procedures</strong></p>
<p>Interestingly, when the correlation between paired observations is zero (<span class="math notranslate nohighlight">\(\rho_{AB} = 0\)</span>), the variance of differences becomes <span class="math notranslate nohighlight">\(\sigma^2_D = \sigma^2_A + \sigma^2_B\)</span>, which is exactly what we would use in independent sample procedures. In this case, pairing provides no advantage and may actually reduce power slightly due to the smaller degrees of freedom (<span class="math notranslate nohighlight">\(n-1\)</span> instead of <span class="math notranslate nohighlight">\(n_A + n_B - 2\)</span>).</p>
<p>However, when correlation is positive (which is typical in well-designed paired studies), the variance of differences is reduced: <span class="math notranslate nohighlight">\(\sigma^2_D = \sigma^2_A + \sigma^2_B - 2\sigma_A\sigma_B\rho_{AB} &lt; \sigma^2_A + \sigma^2_B\)</span>, leading to more precise inference.</p>
</section>
<section id="looking-forward-extensions-and-applications">
<h2><span class="section-number">11.5.11. </span>Looking Forward: Extensions and Applications<a class="headerlink" href="#looking-forward-extensions-and-applications" title="Link to this heading"></a></h2>
<p>The principles developed in paired sample procedures extend to more complex experimental designs and provide the foundation for understanding repeated measures analysis and longitudinal data methods. The key insight—that we can often simplify complex dependency structures by focusing on appropriate transformations of the data—appears throughout advanced statistical methodology.</p>
<p>In the context of our course progression, paired procedures complete our toolkit for comparing two population means. We now have methods that work whether populations are independent or dependent, whether variances are equal or unequal, and whether we want to make strong assumptions for efficiency or robust assumptions for broad applicability.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>Paired procedures apply when observations are linked</strong> through natural pairing relationships that violate the independence assumption of two-sample procedures.</p></li>
<li><p><strong>The key transformation is working with differences</strong> <span class="math notranslate nohighlight">\(D_i = X_{Ai} - X_{Bi}\)</span>, which reduces the two-sample problem to a familiar one-sample analysis.</p></li>
<li><p><strong>All inference focuses on the mean difference</strong> <span class="math notranslate nohighlight">\(\mu_D = \mu_A - \mu_B\)</span>, using test statistics of the form <span class="math notranslate nohighlight">\(t_{TS} = \frac{\bar{d} - \Delta_0}{s_d/\sqrt{n}}\)</span> with <span class="math notranslate nohighlight">\(n-1\)</span> degrees of freedom.</p></li>
<li><p><strong>Proper difference definition is crucial</strong> – the direction of subtraction must align with the research question and alternative hypothesis formulation.</p></li>
<li><p><strong>Pairing controls for individual variability</strong> that might otherwise obscure treatment effects, often leading to more powerful statistical tests.</p></li>
<li><p><strong>Three key assumptions</strong> must be satisfied: independent pairs, simple random sampling from the population of pairs, and normality of differences.</p></li>
<li><p><strong>R implementation</strong> uses <cite>t.test()</cite> with <cite>paired = TRUE</cite> or equivalent one-sample analysis of manually calculated differences.</p></li>
<li><p><strong>The choice between paired and independent procedures</strong> depends on study design, the presence of natural pairing relationships, and the magnitude of individual variability relative to treatment effects.</p></li>
</ol>
</div>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p><strong>Design Recognition</strong>: For each scenario below, determine whether a paired or independent sample design is most appropriate and explain your reasoning:</p>
<ol class="loweralpha simple">
<li><p>Comparing blood pressure medications by randomly assigning patients to receive either drug A or drug B</p></li>
<li><p>Evaluating a weight-loss program by measuring participants before and after the intervention</p></li>
<li><p>Studying gender differences in mathematical ability using standardized test scores</p></li>
<li><p>Comparing two teaching methods using identical twins, where one twin receives method A and the other receives method B</p></li>
<li><p>Assessing the effectiveness of a new sleep aid by measuring sleep quality before and after treatment</p></li>
</ol>
</li>
<li><p><strong>Difference Definition Impact</strong>: A researcher studies whether a new exercise program improves cardiovascular fitness, measured by time to complete a standard fitness test (in minutes, where lower times indicate better fitness).</p>
<ol class="loweralpha simple">
<li><p>If the difference is defined as <span class="math notranslate nohighlight">\(D = \text{Time}_{\text{before}} - \text{Time}_{\text{after}}\)</span>, write appropriate hypotheses to test whether the program improves fitness</p></li>
<li><p>If the difference is defined as <span class="math notranslate nohighlight">\(D = \text{Time}_{\text{after}} - \text{Time}_{\text{before}}\)</span>, write appropriate hypotheses for the same research question</p></li>
<li><p>Explain how the choice of difference definition affects the interpretation of results</p></li>
</ol>
</li>
<li><p><strong>Complete Analysis</strong>: Eight patients with chronic pain participated in a study of acupuncture therapy. Their pain levels were measured on a 10-point scale before and after a series of acupuncture treatments:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Patient</p></th>
<th class="head"><p>Before</p></th>
<th class="head"><p>After</p></th>
<th class="head"><p>Difference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>8.2</p></td>
<td><p>6.1</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>7.5</p></td>
<td><p>5.8</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>9.1</p></td>
<td><p>7.2</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>6.8</p></td>
<td><p>6.0</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>8.9</p></td>
<td><p>5.5</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>7.2</p></td>
<td><p>6.8</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p>8.5</p></td>
<td><p>6.9</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p>7.8</p></td>
<td><p>6.2</p></td>
<td></td>
</tr>
</tbody>
</table>
<ol class="loweralpha simple">
<li><p>Calculate the differences and summary statistics</p></li>
<li><p>Test whether acupuncture reduces pain levels on average (use <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>)</p></li>
<li><p>Construct a 95% confidence interval for the mean reduction in pain</p></li>
<li><p>Interpret your results in the context of the study</p></li>
</ol>
</li>
<li><p><strong>Assumption Checking</strong>: Explain what assumptions must be verified for paired sample procedures and describe how you would check each assumption with a small sample like the acupuncture study above.</p></li>
<li><p><strong>Power Comparison</strong>: Explain why paired designs often have higher statistical power than independent sample designs for detecting treatment effects. Under what circumstances might an independent design be preferred despite this power advantage?</p></li>
<li><p><strong>R Implementation</strong>: Write R code to analyze the acupuncture data from Exercise 3 using both the paired t.test() approach and the manual difference calculation approach. Verify that both methods produce identical results.</p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="11-4-comparing-two-means-independent-unpooled.html" class="btn btn-neutral float-left" title="11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../chapter12/index.html" class="btn btn-neutral float-right" title="12. ANOVA" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>