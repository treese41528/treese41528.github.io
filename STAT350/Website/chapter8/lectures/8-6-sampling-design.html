

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>8.6. Sampling Design &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=3c686048" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter8/lectures/8-6-sampling-design.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=8512422d"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.7. Sampling Bias" href="8-7-sampling-bias.html" />
    <link rel="prev" title="8.5. Examples of Experimental Design" href="8-5-examples-of-experimental-design.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#simulation-exercise">Simulation Exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes‚Äô Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes‚Äô Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Shape &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes‚Äô Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Discrete Random Variables and the CLT</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">8. Experimental Design</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When œÉ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When œÉ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">8. </span>Experimental Design</a></li>
      <li class="breadcrumb-item active"><span class="section-number">8.6. </span>Sampling Design</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter8/lectures/8-6-sampling-design.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch8-6">
   <iframe
      id="video-ch8-6"
      title="STAT 350 ‚Äì Chapter 8.6 Sampling Design Video"
      src="https://www.youtube.com/embed/kaUeguNY8mU?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="id1">
<h1><span class="section-number">8.6. </span>Sampling Design<a class="headerlink" href="#id1" title="Link to this heading">ÔÉÅ</a></h1>
<p>Understanding experimental design principles provides the framework for establishing causal relationships,
but even the most carefully designed experiment is only as strong as the sample of participants it studies.
How we select experimental units or subjects for our studies fundamentally determines whether our conclusions
can be generalized beyond the specific individuals we observe. This critical connection between sampling and
inference represents one of the most important‚Äîyet often overlooked‚Äîaspects of research design.</p>
<p>The transition from experimental design to sampling design marks a shift from internal validity (can we trust
the causal conclusions within our study?) to external validity (can we generalize our conclusions to the broader
population we care about?). While experimental design principles ensure that our comparisons are fair and unbiased,
sampling design principles ensure that our participants represent the population we want to understand.</p>
<div class="important admonition">
<p class="admonition-title">Road Map üß≠</p>
<ul class="simple">
<li><p><strong>Problem</strong>: How do we select participants for our studies so that results can be generalized to the populations we want to understand?</p></li>
<li><p><strong>Tool</strong>: Framework for understanding different sampling approaches, from convenience sampling to sophisticated randomized methods</p></li>
<li><p><strong>Pipeline</strong>: Proper sampling design enables the valid Sample ‚Üí Population inferences that are the ultimate goal of statistical research</p></li>
</ul>
</div>
<section id="the-foundation-of-statistical-inference">
<h2><span class="section-number">8.6.1. </span>The Foundation of Statistical Inference<a class="headerlink" href="#the-foundation-of-statistical-inference" title="Link to this heading">ÔÉÅ</a></h2>
<p>Before examining specific sampling methods, it‚Äôs essential to understand why sampling design matters so profoundly for statistical inference. The mathematical tools we use for drawing conclusions‚Äîconfidence intervals, hypothesis tests, regression analysis‚Äîall depend on specific assumptions about how our data were collected. When these assumptions are violated, our statistical procedures can produce misleading results, no matter how sophisticated the analysis.</p>
<p><strong>The Connection to IID Assumptions</strong></p>
<p>Most statistical inference procedures assume that our observations are <strong>independent and identically distributed (IID)</strong>. This seemingly abstract mathematical concept has very concrete implications for how we collect data:</p>
<p><strong>Independence</strong> means that observing one unit doesn‚Äôt influence the probability of observing any other unit, and that the characteristics of one unit don‚Äôt affect the characteristics of others in our sample.</p>
<p><strong>Identically distributed</strong> means that all units come from the same population with the same underlying probability distribution‚Äîthey‚Äôre all drawn from the same ‚Äústatistical population‚Äù with the same parameters.</p>
<p>When we violate these assumptions through poor sampling design, our statistical inference procedures lose their validity. Standard errors become incorrect, confidence intervals don‚Äôt have their stated coverage rates, and hypothesis tests don‚Äôt control error rates as intended.</p>
<p><strong>The Population-Sample-Population Cycle</strong></p>
<p>Statistical inference follows a logical cycle that depends entirely on proper sampling design:</p>
<ol class="arabic simple">
<li><p><strong>Define the target population</strong> we want to understand</p></li>
<li><p><strong>Draw a representative sample</strong> from that population using appropriate methods</p></li>
<li><p><strong>Analyze the sample data</strong> using statistical procedures</p></li>
<li><p><strong>Generalize results back to the target population</strong> with known levels of uncertainty</p></li>
</ol>
<p>Each step depends on the previous ones. If our sample isn‚Äôt representative of our target population (step 2), then our analysis (step 3) and conclusions (step 4) will be invalid, no matter how sophisticated our statistical methods.</p>
</section>
<section id="the-challenge-of-representativeness">
<h2><span class="section-number">8.6.2. </span>The Challenge of Representativeness<a class="headerlink" href="#the-challenge-of-representativeness" title="Link to this heading">ÔÉÅ</a></h2>
<p>The concept of <strong>representativeness</strong> is central to sampling design, but it‚Äôs more complex than it might initially appear. A representative sample is one that accurately reflects the characteristics of the population from which it‚Äôs drawn, but achieving representativeness requires careful attention to potential sources of bias.</p>
<p><strong>What Makes a Sample Representative?</strong></p>
<p>A representative sample should:</p>
<ul class="simple">
<li><p>Include appropriate proportions of different subgroups within the population</p></li>
<li><p>Capture the full range of variability present in the population</p></li>
<li><p>Avoid systematic exclusion of certain types of individuals</p></li>
<li><p>Reflect the diversity of opinions, characteristics, or responses present in the population</p></li>
</ul>
<p><strong>Why Representativeness Is Challenging</strong></p>
<p>Several factors make it difficult to achieve truly representative samples:</p>
<p><strong>Population Definition Challenges</strong>: Before we can sample representatively, we must clearly define our target population. This seemingly simple task often reveals complex decisions about inclusion and exclusion criteria.</p>
<p><strong>Access and Feasibility Issues</strong>: Some members of the population may be much easier to reach than others, creating systematic biases in who ends up in our sample.</p>
<p><strong>Response and Participation Patterns</strong>: Even with perfect sampling procedures, certain types of people may be more or less likely to agree to participate, creating post-sampling biases.</p>
<p><strong>Cost and Resource Constraints</strong>: Truly representative sampling can be expensive and time-consuming, leading researchers to make compromises that affect representativeness.</p>
<p><strong>Hidden Population Structure</strong>: Populations often have complex internal structure that isn‚Äôt immediately apparent, making it easy to miss important subgroups or relationships.</p>
</section>
<section id="non-random-sampling-methods-understanding-the-limitations">
<h2><span class="section-number">8.6.3. </span>Non-Random Sampling Methods: Understanding the Limitations<a class="headerlink" href="#non-random-sampling-methods-understanding-the-limitations" title="Link to this heading">ÔÉÅ</a></h2>
<p>While we generally prefer randomized sampling methods for statistical inference, non-random sampling approaches are common in practice. Understanding their limitations helps us recognize when they might be appropriate (usually for preliminary investigations) and when they create serious threats to validity.</p>
<p><strong>Convenience Sampling: The Path of Least Resistance</strong></p>
<p><strong>Convenience sampling</strong> selects participants based solely on ease of access and availability. This approach is attractive because it‚Äôs simple, fast, and inexpensive to implement, making it tempting for researchers with limited resources or tight timelines.</p>
<p><strong>Common Examples of Convenience Sampling</strong></p>
<p><strong>Academic Research</strong>: A psychology professor studies decision-making by recruiting students from her own classes. While convenient, this sample only represents college students in that particular major at that specific institution.</p>
<p><strong>Medical Research</strong>: A doctor studies the effectiveness of a new treatment by enrolling patients who visit his clinic. This sample may systematically exclude people who can‚Äôt afford medical care, live far from the clinic, or prefer different healthcare providers.</p>
<p><strong>Market Research</strong>: A company surveys customers who visit their website or respond to email invitations. This approach misses potential customers who don‚Äôt engage with the company online.</p>
<p><strong>Political Polling</strong>: News outlets conduct ‚Äúperson on the street‚Äù interviews in busy downtown areas. Such samples systematically overrepresent people who work downtown, have flexible schedules, and are comfortable talking to reporters.</p>
<p><strong>Why Convenience Sampling Creates Bias</strong></p>
<p>Convenience sampling creates <strong>systematic bias</strong> because the characteristics that make people easily accessible often correlate with other important variables:</p>
<p><strong>Geographic Clustering</strong>: Sampling from easily accessible locations (like college campuses or shopping malls) concentrates the sample in specific geographic areas that may not represent broader populations.</p>
<p><strong>Socioeconomic Bias</strong>: People with more flexible schedules, reliable transportation, and discretionary time are more likely to be available for convenience sampling, creating systematic socioeconomic biases.</p>
<p><strong>Demographic Patterns</strong>: Age, employment status, family situation, and health status all affect availability and accessibility, leading to systematic under- or over-representation of certain demographic groups.</p>
<p><strong>Behavioral Correlates</strong>: The behaviors and attitudes that make people easy to recruit (outgoing personality, willingness to participate in research, comfort with authority figures) may correlate with the very outcomes researchers want to study.</p>
<p><strong>When Convenience Sampling Might Be Appropriate</strong></p>
<p>Despite its limitations, convenience sampling can serve legitimate purposes in certain contexts:</p>
<p><strong>Preliminary Research</strong>: When exploring whether a phenomenon exists or developing research methods, convenience samples can provide initial insights at low cost.</p>
<p><strong>Proof of Concept Studies</strong>: Testing whether an intervention can work under any circumstances might justify convenience sampling before investing in more expensive representative studies.</p>
<p><strong>Method Development</strong>: When developing new measurement instruments or refining research procedures, convenience samples can be adequate for initial testing.</p>
<p><strong>Extreme Case Analysis</strong>: When studying rare phenomena or extreme cases, convenience sampling might be the only feasible approach.</p>
<p><strong>Voluntary Response Sampling: Self-Selection Bias</strong></p>
<p><strong>Voluntary response sampling</strong> occurs when individuals self-select into the study based on their own willingness or motivation to participate. This approach is common in online surveys, call-in polls, and studies that recruit participants through advertisements or social media.</p>
<p><strong>The Psychology of Voluntary Response</strong></p>
<p>People who volunteer for research studies differ systematically from those who don‚Äôt in several important ways:</p>
<p><strong>Strong Opinions</strong>: Individuals with extreme views on the topic being studied are much more likely to participate than those with moderate or neutral opinions.</p>
<p><strong>Personal Investment</strong>: People who feel personally affected by the research topic are more likely to volunteer, creating samples that overrepresent those with direct stakes in the outcomes.</p>
<p><strong>Altruistic Motivation</strong>: Some people participate in research to help others or advance scientific knowledge, but this motivation isn‚Äôt randomly distributed across the population.</p>
<p><strong>Time and Resources</strong>: Voluntary participation requires discretionary time and often involves some cost (transportation, lost wages, childcare), systematically excluding those without such resources.</p>
<p><strong>Comfort with Research</strong>: Some people are more comfortable with research settings, authority figures, or formal procedures, affecting who volunteers.</p>
<p><strong>Media Examples and Their Biases</strong></p>
<p>Television call-in polls provide clear examples of voluntary response bias:</p>
<p><strong>Political Issues</strong>: When news programs ask viewers to call in with their opinions on political topics, respondents typically have much stronger views than the general population. The results often show more extreme positions than scientific polls of the same topics.</p>
<p><strong>Product Reviews</strong>: Online product reviews suffer from voluntary response bias because people with very positive or very negative experiences are much more likely to write reviews than those with neutral experiences.</p>
<p><strong>Comment Sections</strong>: Online comment sections on news articles or social media posts systematically overrepresent people with strong opinions and those comfortable expressing views in public forums.</p>
<p><strong>Why Voluntary Response Fails for Inference</strong></p>
<p>Voluntary response sampling creates several problems for statistical inference:</p>
<p><strong>Unrepresentative Opinions</strong>: The sample systematically overrepresents extreme views and underrepresents moderate positions, creating a distorted picture of population sentiment.</p>
<p><strong>Unknown Bias Direction</strong>: While we know bias exists, we often can‚Äôt determine its direction or magnitude, making it impossible to correct for the bias statistically.</p>
<p><strong>Violation of Random Sampling Assumptions</strong>: Statistical inference procedures assume some form of random sampling, but voluntary response samples violate these assumptions in fundamental ways.</p>
<p><strong>Non-Generalizable Results</strong>: Results from voluntary response samples can only be generalized to other people who would voluntarily respond under similar circumstances‚Äîa much more limited population than researchers typically want to study.</p>
<p><strong>The Limitations of Expert Judgment</strong></p>
<p>Some researchers attempt to improve on simple convenience or voluntary response sampling by using their expertise to construct more balanced samples. While this might seem like an improvement, it introduces different types of bias:</p>
<p><strong>Researcher Bias</strong>: Even well-intentioned researchers have unconscious biases that affect their sampling decisions, potentially creating systematic patterns they don‚Äôt recognize.</p>
<p><strong>Limited Perspective</strong>: Individual researchers can‚Äôt anticipate all the factors that might affect representativeness, particularly complex interactions between variables they haven‚Äôt considered.</p>
<p><strong>Unmeasurable Bias</strong>: Because the sampling process isn‚Äôt based on known probabilities, there‚Äôs no way to measure or adjust for the bias introduced by human judgment.</p>
<p><strong>False Confidence</strong>: Expert-constructed samples might appear more representative than convenience samples, leading to overconfidence in results that are still fundamentally biased.</p>
</section>
<section id="random-sampling-methods-the-foundation-of-valid-inference">
<h2><span class="section-number">8.6.4. </span>Random Sampling Methods: The Foundation of Valid Inference<a class="headerlink" href="#random-sampling-methods-the-foundation-of-valid-inference" title="Link to this heading">ÔÉÅ</a></h2>
<p>Random sampling methods provide the foundation for valid statistical inference by ensuring that every member of the population has a known, non-zero probability of being included in the sample. This probabilistic foundation enables us to quantify uncertainty and make valid generalizations from samples to populations.</p>
<p><strong>The Philosophy of Randomization in Sampling</strong></p>
<p>Randomization in sampling serves the same fundamental purpose as randomization in experimental design: it removes systematic bias and replaces it with known, manageable random variation. When we can‚Äôt control all the factors that might affect who ends up in our sample, randomization ensures that these factors balance out across many possible samples.</p>
<p><strong>Key Properties of Random Sampling</strong></p>
<p><strong>Known Selection Probabilities</strong>: For every member of the population, we can calculate the probability that they‚Äôll be included in our sample. This probabilistic foundation enables statistical inference.</p>
<p><strong>Unbiased Selection</strong>: The sampling process doesn‚Äôt systematically favor any particular type of person or outcome. Any biases that remain are due to random chance rather than systematic factors.</p>
<p><strong>Quantifiable Uncertainty</strong>: Because we understand the probabilistic mechanism that generated our sample, we can calculate the uncertainty associated with our estimates and test results.</p>
<p><strong>Reproducible Methods</strong>: Random sampling procedures can be described precisely and replicated by other researchers, enabling scientific verification of results.</p>
<p><strong>Independence</strong>: When properly implemented, random sampling ensures that the selection of one unit doesn‚Äôt influence the probability of selecting any other unit (or provides a close approximation to independence).</p>
<p><strong>Simple Random Sampling: The Gold Standard</strong></p>
<p><strong>Simple Random Sampling (SRS)</strong> represents the conceptual foundation for most statistical inference procedures. In SRS, every possible unit in the population has exactly the same probability of being selected, and every possible sample of a given size has exactly the same probability of being chosen.</p>
<p><strong>Definition and Properties</strong></p>
<p>A simple random sample of size <span class="math notranslate nohighlight">\(n\)</span> from a population of size <span class="math notranslate nohighlight">\(N\)</span> is selected such that:</p>
<ul class="simple">
<li><p>Every individual in the population has probability <span class="math notranslate nohighlight">\(\frac{n}{N}\)</span> of being included in the sample</p></li>
<li><p>Every possible sample of size <span class="math notranslate nohighlight">\(n\)</span> has probability <span class="math notranslate nohighlight">\(\frac{1}{\binom{N}{n}}\)</span> of being selected</p></li>
<li><p>The selection of each unit is independent of the selection of every other unit (approximately, when sampling without replacement from large populations)</p></li>
</ul>
<p><strong>Implementation Procedure</strong></p>
<p>Implementing SRS requires a systematic approach:</p>
<p><strong>Step 1: Define the Target Population</strong></p>
<p>This crucial first step often reveals complexities not initially apparent. Questions to address include:</p>
<ul class="simple">
<li><p>Who exactly belongs to the population of interest?</p></li>
<li><p>What are the geographic, temporal, or other boundaries of the population?</p></li>
<li><p>How do we handle people who move in or out of the population during the study?</p></li>
<li><p>What do we do about people who are temporarily unavailable or difficult to reach?</p></li>
</ul>
<p><strong>Step 2: Create a Sampling Frame</strong></p>
<p>The <strong>sampling frame</strong> is a complete list of all units in the target population, with each unit uniquely identified. This is often the most challenging practical aspect of SRS:</p>
<p><strong>Ideal Requirements</strong>: The sampling frame should include every member of the target population exactly once, with current and accurate contact information for each unit.</p>
<p><strong>Practical Challenges</strong>: Real sampling frames often have problems like incomplete coverage (missing some population members), overcoverage (including people who shouldn‚Äôt be in the population), duplication (the same person listed multiple times), or outdated information.</p>
<p><strong>Common Sampling Frames</strong>: Telephone directories, voter registration lists, institutional enrollment records, membership databases, and government records all serve as sampling frames, each with specific strengths and limitations.</p>
<p><strong>Step 3: Assign Unique Labels</strong></p>
<p>Each unit in the sampling frame receives a unique identifier. This might be:</p>
<ul class="simple">
<li><p>Sequential numbering (1, 2, 3, ‚Ä¶, N)</p></li>
<li><p>Existing ID numbers (Social Security numbers, student ID numbers, account numbers)</p></li>
<li><p>Systematic codes that preserve anonymity while maintaining uniqueness</p></li>
</ul>
<p><strong>Step 4: Generate Random Sample</strong></p>
<p>Use a truly random process to select which units will be included:</p>
<p><strong>Random Number Generation</strong>: Use computer random number generators, random number tables, or other chance mechanisms to select unit labels.</p>
<p><strong>Without Replacement</strong>: Typically, we sample without replacement to ensure each person appears in the sample at most once.</p>
<p><strong>Sample Size Determination</strong>: The sample size should be determined based on statistical power analysis, precision requirements, and resource constraints.</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter8/simple_random_sampling_diagram.png"><img alt="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter8/simple_random_sampling_diagram.png" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter8/simple_random_sampling_diagram.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 8.7 </span><span class="caption-text"><em>Simple Random Sampling Process: From population enumeration to final sample selection</em></span><a class="headerlink" href="#id4" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Mathematical Foundation</strong></p>
<p>The mathematical properties of SRS provide the foundation for statistical inference:</p>
<p><strong>Probability of Selection</strong>: Each unit has probability <span class="math notranslate nohighlight">\(\frac{n}{N}\)</span> of being selected.</p>
<p><strong>Sample Probability</strong>: The probability of obtaining any specific sample of size <span class="math notranslate nohighlight">\(n\)</span> is <span class="math notranslate nohighlight">\(\frac{1}{\binom{N}{n}}\)</span>.</p>
<p><strong>Independence Approximation</strong>: When <span class="math notranslate nohighlight">\(N\)</span> is large relative to <span class="math notranslate nohighlight">\(n\)</span>, sampling without replacement behaves approximately like sampling with replacement, justifying independence assumptions.</p>
<p><strong>Unbiased Estimation</strong>: Sample statistics computed from SRS are unbiased estimators of corresponding population parameters.</p>
<p><strong>Implementation in R</strong></p>
<p>R provides built-in functions for implementing simple random sampling:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Method 1: Sample from a vector of IDs</span>
<span class="n">population_ids</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;ID001&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;ID002&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;ID003&quot;</span><span class="p">,</span><span class="w"> </span><span class="kc">...</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;ID9804&quot;</span><span class="p">)</span>
<span class="n">sample_ids</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="n">population_ids</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>

<span class="c1"># Method 2: Sample indices from a dataset</span>
<span class="n">N</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nrow</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="w">  </span><span class="c1"># Population size</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5</span><span class="w">             </span><span class="c1"># Sample size</span>
<span class="n">sample_indices</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="n">sampled_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">dataset</span><span class="p">[</span><span class="n">sample_indices</span><span class="p">,</span><span class="w"> </span><span class="p">]</span>

<span class="c1"># Method 3: Using sampling weights (for unequal probability sampling)</span>
<span class="n">weights</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.1</span><span class="p">,</span><span class="w"> </span><span class="m">0.2</span><span class="p">,</span><span class="w"> </span><span class="m">0.1</span><span class="p">,</span><span class="w"> </span><span class="m">0.3</span><span class="p">,</span><span class="w"> </span><span class="m">0.3</span><span class="p">)</span><span class="w">  </span><span class="c1"># Must sum to 1</span>
<span class="n">sample_ids</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="n">population_ids</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">weights</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Why SRS is ‚ÄúSimple‚Äù in Name Only</strong></p>
<p>Despite its name, simple random sampling is often far from simple to implement in practice:</p>
<p><strong>Sampling Frame Challenges</strong>: Creating a complete, accurate sampling frame can be extremely difficult for large or dynamic populations.</p>
<p><strong>Cost and Logistics</strong>: Contacting randomly selected individuals who might be scattered across large geographic areas can be expensive and time-consuming.</p>
<p><strong>Response Rates</strong>: Even with perfect random selection, non-response can introduce bias if certain types of people are systematically less likely to participate.</p>
<p><strong>Rare Populations</strong>: When studying rare characteristics or small subgroups, SRS might require enormous sample sizes to capture enough individuals of interest.</p>
<p><strong>Advantages of Simple Random Sampling</strong></p>
<p><strong>Statistical Validity</strong>: SRS satisfies the assumptions required for most statistical inference procedures, enabling valid confidence intervals, hypothesis tests, and other analyses.</p>
<p><strong>Unbiased Estimation</strong>: Sample statistics provide unbiased estimates of population parameters, meaning they‚Äôre correct on average across all possible samples.</p>
<p><strong>Quantifiable Precision</strong>: We can calculate exact standard errors and confidence intervals, providing precise measures of uncertainty.</p>
<p><strong>Broad Applicability</strong>: SRS works for any population and any characteristic, without requiring advance knowledge of population structure.</p>
<p><strong>Scientific Credibility</strong>: Results from well-executed SRS studies are generally accepted as valid by the scientific community and policymakers.</p>
<p><strong>Limitations and Practical Challenges</strong></p>
<p><strong>Cost and Efficiency</strong>: SRS can be expensive and inefficient, particularly when the population is geographically dispersed or difficult to access.</p>
<p><strong>Rare Subgroups</strong>: Important subgroups might be so rare that they rarely appear in random samples of feasible size.</p>
<p><strong>Sampling Frame Problems</strong>: The quality of SRS depends entirely on the quality of the sampling frame, which may be incomplete, outdated, or biased.</p>
<p><strong>Non-Response Issues</strong>: Random sampling design can‚Äôt control whether selected individuals actually participate, and non-response can introduce serious biases.</p>
<p><strong>Practical Implementation</strong>: The ideal of SRS often must be compromised due to practical constraints, potentially affecting the validity of inference procedures.</p>
</section>
<section id="stratified-random-sampling-balancing-representation-and-efficiency">
<h2><span class="section-number">8.6.5. </span>Stratified Random Sampling: Balancing Representation and Efficiency<a class="headerlink" href="#stratified-random-sampling-balancing-representation-and-efficiency" title="Link to this heading">ÔÉÅ</a></h2>
<p>When populations contain important subgroups that differ substantially from each other, <strong>stratified random sampling</strong> provides a method for ensuring adequate representation of all subgroups while potentially improving the precision of population estimates.</p>
<p><strong>The Motivation for Stratification</strong></p>
<p>Simple random sampling works well when the population is relatively homogeneous, but many populations contain distinct subgroups that differ systematically in characteristics relevant to the study. In such cases, SRS faces several potential problems:</p>
<p><strong>Subgroup Representation</strong>: Small but important subgroups might be severely underrepresented or even completely missing from random samples.</p>
<p><strong>Precision Loss</strong>: If subgroups vary dramatically in the characteristics being studied, combining them in a single analysis can reduce statistical precision.</p>
<p><strong>Administrative Needs</strong>: Policy makers and practitioners often need separate information about different subgroups, not just overall population averages.</p>
<p><strong>Efficiency Concerns</strong>: Some subgroups might be much more expensive or difficult to sample than others, suggesting that unequal sampling rates might be more efficient.</p>
<p><strong>How Stratified Sampling Works</strong></p>
<p>Stratified sampling addresses these issues by dividing the population into <strong>strata</strong> (subgroups) based on characteristics known before sampling, then conducting separate random samples within each stratum.</p>
<p><strong>Step 1: Define Strata</strong></p>
<p>Strata should be:</p>
<p><strong>Homogeneous within</strong>: Units within each stratum should be as similar as possible with respect to the characteristics being studied.</p>
<p><strong>Heterogeneous between</strong>: Different strata should differ substantially from each other on the characteristics of interest.</p>
<p><strong>Based on available information</strong>: Stratification variables must be known for the entire population before sampling begins.</p>
<p><strong>Relevant to the research question</strong>: Stratification variables should be related to the outcomes being studied.</p>
<p><strong>Manageable in number</strong>: Too many strata can create logistical complications and require very large sample sizes.</p>
<p><strong>Step 2: Determine Sample Allocation</strong></p>
<p>Once strata are defined, researchers must decide how many units to sample from each stratum. This allocation decision significantly affects both the cost and precision of the resulting estimates.</p>
<p><strong>Step 3: Conduct Simple Random Sampling Within Strata</strong></p>
<p>Within each stratum, conduct independent simple random samples of the predetermined sizes.</p>
<p><strong>Step 4: Combine Strata Results</strong></p>
<p>Analyze data from each stratum separately and then combine results to produce population estimates, properly accounting for the stratified sampling design.</p>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter8/stratified_sampling_detailed.png"><img alt="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter8/stratified_sampling_detailed.png" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter8/stratified_sampling_detailed.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 8.8 </span><span class="caption-text"><em>Stratified Random Sampling: From population stratification to combined analysis</em></span><a class="headerlink" href="#id5" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p><strong>Allocation Methods: Deciding How Much to Sample from Each Stratum</strong></p>
<p>The choice of allocation method significantly affects both the cost and precision of stratified sampling. Different allocation strategies optimize different objectives.</p>
<p><strong>Uniform Allocation: Equal Representation</strong></p>
<p><strong>Uniform allocation</strong> samples the same number of units from each stratum, regardless of stratum size. This approach ensures equal precision for estimates within each stratum and is particularly useful when:</p>
<ul class="simple">
<li><p>The primary goal is comparing subgroups rather than estimating overall population parameters</p></li>
<li><p>All strata are considered equally important for policy or scientific purposes</p></li>
<li><p>Stratum sizes are roughly similar</p></li>
<li><p>The cost of sampling is similar across strata</p></li>
</ul>
<p><strong>Implementation</strong>: If we want a total sample size of <span class="math notranslate nohighlight">\(n\)</span> with <span class="math notranslate nohighlight">\(M\)</span> strata, we sample <span class="math notranslate nohighlight">\(\frac{n}{M}\)</span> units from each stratum (rounding as necessary to get integer values).</p>
<p><strong>Advantages</strong>: Simple to implement, ensures adequate representation of all subgroups, provides equal precision for subgroup estimates.</p>
<p><strong>Disadvantages</strong>: May be inefficient for estimating overall population parameters, oversamples small strata and undersamples large strata relative to their population proportions.</p>
<p><strong>Proportional Allocation: Maintaining Population Structure</strong></p>
<p><strong>Proportional allocation</strong> samples from each stratum in proportion to the stratum‚Äôs size in the population. This approach maintains the population‚Äôs natural structure in the sample.</p>
<p><strong>Implementation</strong>: For stratum <span class="math notranslate nohighlight">\(i\)</span> with <span class="math notranslate nohighlight">\(m_i\)</span> units in a population of size <span class="math notranslate nohighlight">\(N = \sum_{i=1}^M m_i\)</span>, sample size is:</p>
<div class="math notranslate nohighlight">
\[n_i = n \times \frac{m_i}{N}\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the total desired sample size.</p>
<p><strong>Advantages</strong>:
- Provides unbiased estimates of population parameters with relatively simple analysis
- Maintains representativeness across subgroups
- Often more cost-effective than uniform allocation
- Results can be analyzed as if they came from simple random sampling</p>
<p><strong>Disadvantages</strong>:
- Small strata may have very small sample sizes, limiting the precision of subgroup estimates
- May not be optimal for detecting differences between subgroups
- Doesn‚Äôt account for different levels of variability within strata</p>
<p><strong>Example</strong>: In a population with 60% urban residents and 40% rural residents, a proportionally allocated sample of 1000 would include 600 urban and 400 rural residents.</p>
<p><strong>Variation Allocation: Optimizing for Precision</strong></p>
<p><strong>Variation allocation</strong> (also called <strong>optimal allocation</strong>) determines sample sizes based on the variability within each stratum. Strata with higher variability receive larger sample sizes because they require more observations to achieve the same level of precision.</p>
<p><strong>Implementation</strong>: Sample size for stratum <span class="math notranslate nohighlight">\(i\)</span> is proportional to the standard deviation within that stratum:</p>
<div class="math notranslate nohighlight">
\[n_i = n \times \frac{s_i}{\sum_{j=1}^M s_j}\]</div>
<p>where <span class="math notranslate nohighlight">\(s_i\)</span> is the standard deviation of the variable of interest in stratum <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p><strong>Advantages</strong>:
- Minimizes the standard error of population estimates for a given total sample size
- Allocates resources efficiently by focusing sampling effort where variability is highest
- Can substantially improve precision compared to proportional allocation when strata have very different variability levels</p>
<p><strong>Disadvantages</strong>:
- Requires advance knowledge of variability within each stratum, typically from pilot studies or previous research
- May result in very unequal sample sizes across strata
- Optimization is specific to one variable; if multiple variables are important, optimal allocation for one may be poor for others
- More complex to implement and analyze</p>
<p><strong>When to Use Variation Allocation</strong>: This approach is most valuable when:
- Precise population estimates are the primary goal
- Previous data or pilot studies provide reliable estimates of within-stratum variability
- Strata differ substantially in their variability
- The cost of additional sampling is high enough to justify the complexity</p>
<p><strong>Optimal Allocation: Balancing Multiple Objectives</strong></p>
<p><strong>Optimal allocation</strong> extends variation allocation by incorporating cost considerations along with precision objectives. This approach recognizes that sampling costs often vary dramatically across strata.</p>
<p><strong>Implementation</strong>: The optimal allocation balances precision gains against cost differences:</p>
<div class="math notranslate nohighlight">
\[n_i = n \times \frac{m_i s_i / \sqrt{c_i}}{\sum_{j=1}^M m_j s_j / \sqrt{c_j}}\]</div>
<p>where <span class="math notranslate nohighlight">\(c_i\)</span> is the cost of sampling one unit from stratum <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p><strong>Cost Considerations</strong>: Costs might vary across strata due to:
- Geographic dispersion (rural areas might be more expensive to reach)
- Accessibility (some populations require special recruitment efforts)
- Response rates (groups with lower response rates effectively cost more per completed interview)
- Language or cultural barriers (requiring specialized staff or procedures)
- Institutional requirements (some settings require additional permissions or procedures)</p>
<p><strong>Advanced Optimization</strong>: In practice, optimal allocation often involves more complex optimization that considers:
- Multiple variables of interest with different importance weights
- Non-response patterns that vary across strata
- Budget constraints that limit total sampling effort
- Minimum sample size requirements for subgroup analysis
- Political or administrative requirements for subgroup representation</p>
<p><strong>Advantages of Stratified Sampling</strong></p>
<p><strong>Guaranteed Subgroup Representation</strong>: Unlike SRS, stratified sampling ensures that all important subgroups are represented in the sample with adequate sample sizes for meaningful analysis.</p>
<p><strong>Improved Precision</strong>: When strata are more homogeneous than the overall population, stratified sampling typically provides more precise estimates than SRS of the same size.</p>
<p><strong>Separate Subgroup Analysis</strong>: Stratified designs naturally provide data for analyzing subgroups separately, meeting the needs of researchers and policymakers who need subgroup-specific information.</p>
<p><strong>Flexible Resource Allocation</strong>: Different allocation strategies allow researchers to optimize for different objectives (precision, cost, subgroup representation) depending on study goals.</p>
<p><strong>Reduced Sampling Costs</strong>: When strata are geographically or administratively clustered, stratified sampling can reduce travel and coordination costs.</p>
<p><strong>Administrative Benefits</strong>: Organizations often prefer stratified designs because they ensure representation of all important constituencies or organizational units.</p>
<p><strong>Implementation Challenges and Considerations</strong></p>
<p><strong>Stratification Variable Selection</strong>: Choosing appropriate stratification variables requires balancing statistical efficiency with practical feasibility:</p>
<ul class="simple">
<li><p>Variables should be strongly related to the outcomes of interest</p></li>
<li><p>Information must be available for the entire population before sampling</p></li>
<li><p>Too many stratification variables create too many strata with small sample sizes</p></li>
<li><p>Variables should create strata of reasonable minimum sizes</p></li>
</ul>
<p><strong>Boundary Issues</strong>: Deciding exactly how to define strata can be challenging:
- Where to set cutpoints for continuous variables (age groups, income levels)
- How to handle units that could belong to multiple strata
- What to do about units with missing information on stratification variables
- How to handle units that change strata during the study period</p>
<p><strong>Analysis Complexity</strong>: Stratified sampling requires more complex analysis procedures:
- Need to account for stratification in calculating standard errors and confidence intervals
- Must use appropriate statistical software that handles survey design features
- May need specialized expertise for proper analysis
- Results presentation becomes more complex when reporting subgroup estimates</p>
<p><strong>Sample Size Planning</strong>: Determining appropriate sample sizes for stratified designs requires more complex calculations:
- Must consider precision requirements for both overall estimates and subgroup estimates
- Need to balance competing objectives when subgroup precision conflicts with overall precision
- Must account for different allocation strategies in power analyses
- Should consider potential non-response patterns that might vary across strata</p>
<p><strong>Quality Control</strong>: Stratified sampling requires additional quality control measures:
- Ensuring proper implementation of sampling procedures within each stratum
- Monitoring response rates and data quality across strata
- Checking that stratification was implemented correctly
- Verifying that analysis properly accounts for the stratified design</p>
<p><strong>When Stratified Sampling is Most Valuable</strong></p>
<p>Stratified sampling provides the greatest benefits when:</p>
<p><strong>Subgroups Differ Substantially</strong>: When important subgroups have very different characteristics, stratification can greatly improve precision and ensure adequate representation.</p>
<p><strong>Subgroup Analysis is Important</strong>: When researchers need reliable estimates for specific subgroups, not just overall population averages.</p>
<p><strong>Cost Varies Across Subgroups</strong>: When some subgroups are much more expensive or difficult to reach than others, stratification allows for efficient resource allocation.</p>
<p><strong>Administrative Structure Exists</strong>: When the population naturally divides into administrative or geographic units that can serve as strata.</p>
<p><strong>Previous Information Available</strong>: When prior research or administrative data provides information about subgroup characteristics that can guide stratification and allocation decisions.</p>
<p>Stratified sampling represents a sophisticated approach to sampling design that can substantially improve both the efficiency and validity of research studies. However, it requires careful planning, implementation, and analysis to realize these benefits. When properly executed, stratified sampling provides a powerful tool for ensuring that research results are both statistically precise and representative of all important population subgroups.</p>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">8.6.6. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading">ÔÉÅ</a></h2>
<p>Understanding sampling design provides the crucial link between data collection and statistical inference. While experimental design principles ensure that our studies can establish causal relationships, sampling design principles ensure that those relationships generalize to the populations we want to understand. Together, these design principles create the foundation for reliable, actionable research findings.</p>
<p>As we move toward actual statistical inference methods in subsequent chapters, remember that every confidence interval, hypothesis test, and regression analysis depends on assumptions about how the data were collected. Poor sampling design can invalidate even the most sophisticated statistical analysis, while good sampling design enables simple statistical methods to produce profound insights about populations and processes we care about.</p>
<p>TAKEAWAY BOX IS TOO LONG!!</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaways üìù</p>
<ol class="arabic simple">
<li><p><strong>Sampling design determines inferential validity</strong>: The methods used to select participants fundamentally determine whether statistical inference procedures are valid and whether results can be generalized.</p></li>
<li><p><strong>Non-random sampling creates systematic bias</strong>: Convenience and voluntary response sampling are simple and cheap but introduce biases that cannot be measured or corrected, limiting their use to preliminary investigations.</p></li>
<li><p><strong>Random sampling enables valid inference</strong>: Methods like simple random sampling and stratified random sampling provide the probabilistic foundation required for statistical inference procedures.</p></li>
<li><p><strong>Simple random sampling is the gold standard</strong>: SRS gives every population member equal selection probability and satisfies the IID assumptions required for most statistical procedures.</p></li>
<li><p><strong>Stratified sampling improves efficiency and representation</strong>: When populations contain distinct subgroups, stratified sampling can improve precision while ensuring adequate subgroup representation.</p></li>
<li><p><strong>Population Definition Challenge</strong>: You want to study ‚Äúsocial media usage among teenagers‚Äù but need to define your target population precisely.</p></li>
</ol>
<ol class="loweralpha simple">
<li><p>What specific decisions must you make about age boundaries, geographic scope, and inclusion criteria?</p></li>
<li><p>How might different population definitions affect your sampling approach?</p></li>
<li><p>What sampling frame could you realistically use for this population?</p></li>
<li><p>What groups might be systematically excluded from common sampling frames?</p></li>
</ol>
</div>
<ol class="arabic" start="7">
<li><p><strong>Sample Size and Precision</strong>: Explain why stratified sampling with proportional allocation often provides more precise estimates than simple random sampling of the same total size. Use a concrete example to illustrate your explanation.</p></li>
<li><p><strong>Real-World Implementation</strong>: Choose a research question that interests you and design a complete sampling plan that includes:</p>
<ol class="loweralpha simple">
<li><p>Clear definition of the target population</p></li>
<li><p>Identification of an appropriate sampling frame</p></li>
<li><p>Choice between simple random sampling and stratified sampling with justification</p></li>
<li><p>If using stratified sampling, specification of strata and allocation method</p></li>
<li><p>Discussion of likely implementation challenges and how you would address them</p></li>
</ol>
</li>
<li><p><strong>Voluntary Response Analysis</strong>: A local newspaper publishes an online survey asking readers about their support for a proposed tax increase. The survey receives 2,847 responses, with 73% opposing the tax.</p>
<ol class="loweralpha simple">
<li><p>What type of sampling method is this?</p></li>
<li><p>Why might these results not represent the views of all local residents?</p></li>
<li><p>What specific types of people might be overrepresented in this sample?</p></li>
<li><p>How might the results differ if the same question were asked in a scientific poll using random sampling?</p></li>
</ol>
</li>
<li><p><strong>Sampling Frame Evaluation</strong>: A researcher wants to study the health behaviors of adults in a mid-sized city and is considering three possible sampling frames:</p>
<ul class="simple">
<li><p>Telephone directory listings</p></li>
<li><p>Voter registration records</p></li>
<li><p>Driver‚Äôs license records</p></li>
</ul>
<p>For each sampling frame, identify what groups would likely be underrepresented or overrepresented, and discuss how these biases might affect a study of health behaviors.Allocation strategies serve different objectives**: Uniform allocation ensures equal subgroup representation, proportional allocation maintains population structure, and variation allocation optimizes precision.</p>
</li>
</ol>
<blockquote>
<div><ol class="arabic simple" start="7">
<li><p><strong>Implementation challenges are substantial</strong>: Both SRS and stratified sampling face practical challenges including sampling frame construction, cost management, and non-response handling.</p></li>
<li><p><strong>Design complexity must match study objectives</strong>: The choice between different sampling methods should depend on research goals, resource constraints, and the structure of the target population.</p></li>
</ol>
</div></blockquote>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">ÔÉÅ</a></h3>
<ol class="arabic simple">
<li><p><strong>Sampling Method Classification</strong>: For each scenario below, identify the sampling method being used and explain its major strengths and limitations:</p>
<ol class="loweralpha simple">
<li><p>A political pollster calls every 50th person in the phone directory.</p></li>
<li><p>A news website asks visitors to vote in an online poll about a current issue.</p></li>
<li><p>A health researcher obtains a list of all registered patients at area hospitals and randomly selects 500 for a nutrition study.</p></li>
<li><p>A marketing company recruits participants for a focus group by approaching shoppers at a mall entrance.</p></li>
</ol>
</li>
<li><p><strong>Simple Random Sampling Implementation</strong>: You want to conduct a simple random sample of 100 students from a university with 25,000 enrolled students.</p>
<ol class="loweralpha simple">
<li><p>Describe the complete procedure you would use, including how you would obtain a sampling frame.</p></li>
<li><p>What practical challenges might you encounter?</p></li>
<li><p>How would you handle students who are selected but don‚Äôt respond?</p></li>
<li><p>Write R code to select the sample assuming you have a dataset called <cite>student_roster</cite>.</p></li>
</ol>
</li>
<li><p><strong>Stratified Sampling Design</strong>: A state education department wants to study teacher job satisfaction using a sample of 600 teachers. The state has 120 elementary schools, 80 middle schools, and 60 high schools.</p>
<ol class="loweralpha simple">
<li><p>Explain why stratified sampling might be preferable to simple random sampling for this study.</p></li>
<li><p>Calculate sample sizes for each stratum using proportional allocation.</p></li>
<li><p>Calculate sample sizes using uniform allocation.</p></li>
<li><p>Discuss the advantages and disadvantages of each allocation method for this study.</p></li>
</ol>
</li>
<li><p><strong>Bias in Non-Random Sampling</strong>: A researcher wants to study exercise habits among adults and recruits participants by posting flyers at gyms, health food stores, and medical clinics.</p>
<ol class="loweralpha simple">
<li><p>What type of sampling method is this?</p></li>
<li><p>Identify at least three specific ways this sampling method might create bias.</p></li>
<li><p>Explain why the bias cannot be corrected through statistical analysis.</p></li>
<li><p>Suggest an alternative sampling approach that would reduce these biases.</p></li>
</ol>
</li>
<li><p><strong>Allocation Method Comparison</strong>: A market research company is studying smartphone usage across three age groups: 18-30 (40% of population), 31-50 (35% of population), and 51+ (25% of population). Previous research suggests that usage variability is highest in the 18-30 group and lowest in the 51+ group.</p>
<ol class="loweralpha simple">
<li><p>Calculate sample sizes for each age group using proportional allocation (total n = 900).</p></li>
<li><p>Explain when you might prefer uniform allocation instead.</p></li>
<li><p>Describe how variation allocation would differ from proportional allocation.</p></li>
<li><p>What additional information would you need to implement optimal allocation?</p></li>
</ol>
</li>
<li><p><a href="#id2"><span class="problematic" id="id3">**</span></a></p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="8-5-examples-of-experimental-design.html" class="btn btn-neutral float-left" title="8.5. Examples of Experimental Design" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="8-7-sampling-bias.html" class="btn btn-neutral float-right" title="8.7. Sampling Bias" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>