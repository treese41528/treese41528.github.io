

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>8.2. Experimental Design Principles &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=bcfce81d" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter8/lectures/8-2-experimental-design-principles.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.3. Basic Types of Experimental Design" href="8-3-basic-types-of-experimental-design.html" />
    <link rel="prev" title="8.1. Experimental and Sampling Designs" href="8-1-experimental-and-sampling-designs.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Shape &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Discrete Random Variables and the CLT</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">8. Experimental Design</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">8. </span>Experimental Design</a></li>
      <li class="breadcrumb-item active"><span class="section-number">8.2. </span>Experimental Design Principles</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter8/lectures/8-2-experimental-design-principles.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch8-2">
   <iframe
      id="video-ch8-2"
      title="STAT 350 – Chapter 8.2 Experimental Design Principles Video"
      src="https://www.youtube.com/embed/BOFWktiCddI?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="id1">
<h1><span class="section-number">8.2. </span>Experimental Design Principles<a class="headerlink" href="#id1" title="Link to this heading"></a></h1>
<p>Experimental design is the only method that allows us to establish causal relationships between variables with
confidence. But not all experiments are created equal. The difference between a well-designed experiment that
produces reliable conclusions and a poorly designed study that wastes resources and misleads researchers lies
in adhering to fundamental principles that have been refined through decades of scientific practice.</p>
<p>These principles aren’t arbitrary rules—they address specific threats to the validity of experimental conclusions.
Each principle tackles a different way that experiments can go wrong, and when all three are properly implemented,
they create a powerful framework for discovering causal relationships in the face of natural variability and
confounding factors.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p><strong>Problem</strong>: How do we design experiments that isolate the effects we want to study while controlling for everything else that might influence our results?</p></li>
<li><p><strong>Tool</strong>: Three fundamental principles—Control, Randomization, and Replication—that work together to ensure valid causal inference</p></li>
<li><p><strong>Pipeline</strong>: These principles form the foundation that makes our Sample → Population inferences reliable and scientifically defensible</p></li>
</ul>
</div>
<section id="the-language-of-experimental-design">
<h2><span class="section-number">8.2.1. </span>The Language of Experimental Design<a class="headerlink" href="#the-language-of-experimental-design" title="Link to this heading"></a></h2>
<p>Before exploring the principles themselves, we need to establish the vocabulary that experimental designers use to communicate precisely about study structure and implementation.</p>
<p><strong>Experimental Units and Subjects</strong></p>
<p><strong>Experimental units</strong> are the objects or entities being studied in an experiment—the things to which treatments are applied and from which responses are measured. When these units happen to be human beings, we call them <strong>experimental subjects</strong> or simply <strong>subjects</strong>.</p>
<p>The choice of experimental unit is crucial and depends on the research question. In agricultural studies, experimental units might be individual plants, plots of land, or entire fields. In medical research, they’re typically individual patients. In educational research, they could be individual students, classrooms, or entire schools, depending on where the treatment is applied.</p>
<p><strong>Factors, Levels, and Treatments</strong></p>
<p><strong>Factors</strong> are the independent variables that the experimenter can manipulate or control. These represent the potential causes we want to study. Each factor can take on different values called <strong>levels</strong>. Think of factors as categorical variables where each category represents a different setting or condition we want to test.</p>
<p>For example, in studying plant growth, fertilizer type might be a factor with levels “organic,” “synthetic,” and “none.” Water amount might be another factor with levels “low,” “medium,” and “high.” Temperature could be a third factor with levels “cool,” “moderate,” and “warm.”</p>
<p>A <strong>treatment</strong> represents a specific combination of factor levels. If we have three factors each with three levels, one treatment might be “organic fertilizer + low water + cool temperature,” while another might be “synthetic fertilizer + high water + warm temperature.” The number of possible treatments equals the product of the number of levels across all factors.</p>
<p><strong>Response Variables</strong></p>
<p>The <strong>response variable</strong> (also called the dependent variable) is what we measure to assess the effect of our treatments. This is the outcome we believe might be influenced by our factors. In the plant growth example, our response variable might be final plant height, biomass, or fruit production.</p>
<p>The response variable must be something we can measure objectively and consistently across all experimental units. It should also be relevant to the research question and sensitive enough to detect meaningful differences between treatments.</p>
<p><strong>A Concrete Example: Crop Yield Study</strong></p>
<p>Consider a study investigating how different agricultural practices affect crop yield. Our factors might include:</p>
<ul class="simple">
<li><p><strong>Fertilizer</strong>: Two types (Type 1, Type 2)</p></li>
<li><p><strong>Water quantity</strong>: Five levels (0.2, 0.4, 0.6, 0.8, 1.0 gallons per square foot)</p></li>
<li><p><strong>Vitamins</strong>: Three brands (Brand A, Brand B, Brand C)</p></li>
<li><p><strong>Pesticides</strong>: Three chemical combinations (Combo 1, Combo 2, Combo 3)</p></li>
</ul>
<p>This gives us <span class="math notranslate nohighlight">\(2 \times 5 \times 3 \times 3 = 90\)</span> possible treatments. Each treatment represents a unique combination of all four factors, such as “Type 1 fertilizer + 0.6 gallons water + Brand B vitamins + Combo 2 pesticides.”</p>
<p>Our experimental units would be individual crop plots, and our response variable might be yield measured in bushels per acre. The goal is to determine which combination of factors produces the highest yield.</p>
</section>
<section id="the-three-principles-of-well-designed-experiments">
<h2><span class="section-number">8.2.2. </span>The Three Principles of Well-Designed Experiments<a class="headerlink" href="#the-three-principles-of-well-designed-experiments" title="Link to this heading"></a></h2>
<p>For an experiment to reliably establish causal relationships, it must satisfy three fundamental principles. These principles work together—each addresses different threats to validity, and weakening any one of them compromises the entire study.</p>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter8/three_principles_diagram.png"><img alt="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter8/three_principles_diagram.png" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter8/three_principles_diagram.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 8.1 </span><span class="caption-text"><em>The three principles work together to create the foundation for causal inference</em></span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Why These Principles Matter</strong></p>
<p>Without proper adherence to these principles, what we observe in our results might not be due to our treatments at all. It could be due to:</p>
<ul class="simple">
<li><p><strong>Environmental differences</strong> between treatment groups (violating Control)</p></li>
<li><p><strong>Systematic assignment patterns</strong> that create non-comparable groups (violating Randomization)</p></li>
<li><p><strong>Small sample sizes</strong> that amplify the effects of unusual observations (violating Replication)</p></li>
</ul>
<p>When all three principles are met, we can be confident that observed differences in our response variable are genuinely caused by our treatments rather than by these alternative explanations.</p>
</section>
<section id="principle-1-control-the-foundation-of-comparison">
<h2><span class="section-number">8.2.3. </span>Principle 1: Control – The Foundation of Comparison<a class="headerlink" href="#principle-1-control-the-foundation-of-comparison" title="Link to this heading"></a></h2>
<p>The principle of control addresses a fundamental question: how do we know whether a treatment effect is meaningful? Without something to compare against, even dramatic changes could be due to natural variation rather than our intervention.</p>
<p><strong>The Need for Comparison</strong></p>
<p>Imagine testing a new fertilizer and observing that plants grow to an average height of 24 inches. Is this good? Bad? Impossible to say without a baseline for comparison. The principle of control requires that we establish this baseline through careful design of comparison groups.</p>
<p><strong>Control Groups as Baselines</strong></p>
<p>A <strong>control group</strong> serves as the standard against which we measure treatment effects. This group receives either no treatment at all or a standard “status quo” treatment that represents current practice. In medical studies, this might be a placebo or the current standard of care. In agricultural studies, it might be conventional farming practices.</p>
<p>The control group answers the crucial question: “What would have happened if we had done nothing (or continued current practice)?” By comparing treatment outcomes to control outcomes, we can isolate the specific effect of our intervention.</p>
<p><strong>Why Statistical Significance Requires Control</strong></p>
<p><strong>Statistical significance</strong> means that the difference we observe is larger than what we would expect from random chance alone. But “larger than what?” That’s where the control group becomes essential. We need a baseline to determine whether our treatment effect is:</p>
<ul class="simple">
<li><p><strong>Meaningful</strong>: Substantially different from the status quo</p></li>
<li><p><strong>Statistically significant</strong>: Unlikely to be due to random variation</p></li>
<li><p><strong>Practically important</strong>: Large enough to matter in real-world applications</p></li>
</ul>
<p>Without a control group, we cannot establish any of these crucial properties.</p>
<p><strong>Maintaining Comparable Conditions</strong></p>
<p>For control groups to provide valid comparisons, they must be treated identically to treatment groups in every way except for the specific treatment being tested. This means:</p>
<ul class="simple">
<li><p><strong>Same environment</strong>: Control and treatment groups should be studied under the same conditions</p></li>
<li><p><strong>Same procedures</strong>: Data collection, timing, and measurement protocols should be identical</p></li>
<li><p><strong>Same attention</strong>: Subjects should receive the same level of interaction with researchers</p></li>
</ul>
<p>Any systematic difference in how groups are treated (other than the treatment itself) can confound our results and make causal inference impossible.</p>
<p><strong>The Placebo Effect and Blinding</strong></p>
<p>In medical and behavioral research, the <strong>placebo effect</strong> presents a special challenge. This phenomenon occurs when people experience real physiological or psychological changes simply because they believe they’re receiving treatment, even when the “treatment” is inert.</p>
<p><strong>Placebos as Active Controls</strong></p>
<p>A <strong>placebo</strong> is a dummy treatment designed to be indistinguishable from the real treatment but lacking the active ingredient. Sugar pills that look identical to medication, saline injections that feel like real injections, or sham procedures that mimic real surgeries all serve as placebos.</p>
<p>Placebos serve two crucial functions:</p>
<ol class="arabic simple">
<li><p><strong>They control for the placebo effect</strong> by giving control subjects the same psychological experience as treatment subjects</p></li>
<li><p><strong>They enable blinding</strong> by making it impossible for subjects to know their group assignment</p></li>
</ol>
<p><strong>Single and Double Blinding</strong></p>
<p><strong>Blinding</strong> prevents knowledge of group assignments from influencing behavior or measurements. There are two types:</p>
<p><strong>Single-blind experiments</strong> keep either subjects or researchers unaware of group assignments, but not both. This might be used when it’s impossible to hide the treatment from researchers (such as surgical procedures) but subjects can remain unaware of which specific treatment they received.</p>
<p><strong>Double-blind experiments</strong> keep both subjects and researchers unaware of group assignments. This represents the gold standard for eliminating bias, as it prevents both subject expectations and researcher expectations from influencing results.</p>
<p>Double-blinding is particularly important when:</p>
<ul class="simple">
<li><p>Outcomes are subjective or require researcher judgment</p></li>
<li><p>Researchers have strong expectations about which treatment should work</p></li>
<li><p>Subjects’ knowledge of their treatment could affect their behavior or reporting</p></li>
</ul>
<p><strong>Matching Conditions Across Groups</strong></p>
<p>Even placebo groups must match treatment groups in all relevant aspects. If treatment groups receive different dosage levels, placebo groups should also receive different dosage levels of the inert substance. If treatment subjects receive extra attention or monitoring, control subjects should receive equivalent attention.</p>
<p>This attention to detail ensures that any observed differences truly reflect treatment effects rather than differences in the experimental experience.</p>
<p><strong>Blocking: Advanced Control for Known Confounders</strong></p>
<p>Sometimes we know that certain characteristics of our experimental units will strongly influence the response, even though these characteristics aren’t what we want to study. <strong>Blocking</strong> provides a method for controlling these <strong>extraneous variables</strong>.</p>
<p>In <strong>randomized block design (RBD)</strong>, we group experimental units into <strong>blocks</strong> based on similar characteristics before randomly assigning treatments within each block. For example:</p>
<ul class="simple">
<li><p><strong>Medical studies</strong>: Block by age, sex, or disease severity</p></li>
<li><p><strong>Agricultural studies</strong>: Block by soil type, field location, or previous crop</p></li>
<li><p><strong>Educational studies</strong>: Block by prior achievement level or school district</p></li>
</ul>
<p>Blocking is particularly valuable when we don’t have enough experimental units to rely on randomization alone to balance out the effects of these extraneous variables. It’s also cost-effective because it allows us to achieve the same precision with fewer total units.</p>
<p><strong>Why Control is Fundamental</strong></p>
<p>The principle of control is fundamental because it provides the logical foundation for causal inference. Without proper controls:</p>
<ul class="simple">
<li><p>We cannot distinguish treatment effects from natural variation</p></li>
<li><p>We cannot establish statistical significance</p></li>
<li><p>We cannot rule out alternative explanations for our observations</p></li>
<li><p>Our conclusions lack scientific credibility</p></li>
</ul>
<p>Control transforms experiments from mere descriptions of what happened to rigorous tests of what caused what to happen.</p>
</section>
<section id="principle-2-randomization-ensuring-fair-comparisons">
<h2><span class="section-number">8.2.4. </span>Principle 2: Randomization – Ensuring Fair Comparisons<a class="headerlink" href="#principle-2-randomization-ensuring-fair-comparisons" title="Link to this heading"></a></h2>
<p>While control provides the framework for comparison, randomization ensures that the groups being compared are actually comparable. This principle addresses one of the most insidious threats to experimental validity: the systematic assignment of experimental units to treatments in ways that create fundamental differences between groups.</p>
<p><strong>The Problem Randomization Solves</strong></p>
<p>Many variables can influence experimental outcomes—some we know about, others we don’t, and still others we can’t easily measure or control. If experimental units with certain characteristics systematically end up in certain treatment groups, we can’t tell whether observed differences are due to treatments or due to these underlying characteristics.</p>
<p>Consider a medical study where researchers unconsciously assign sicker patients to the treatment group (hoping to help them) and healthier patients to the control group. Any observed benefit of treatment could be due to the treatment itself, or it could be because the sicker patients had more room for improvement.</p>
<p><strong>How Randomization Creates Comparable Groups</strong></p>
<p><strong>Randomization</strong> means using chance—not human judgment, convenience, or any other systematic method—to assign experimental units to treatment groups. When done properly, randomization has remarkable properties:</p>
<p><strong>Equal Expected Composition</strong>: On average, across many possible randomizations, each treatment group will have the same distribution of relevant characteristics. While any single randomization might produce some imbalance, there’s no systematic bias toward any particular pattern.</p>
<p><strong>Unbiased Assignment</strong>: No confounding variable is systematically associated with treatment assignment. This breaks the link between potential confounders and treatments, allowing us to attribute differences in outcomes to treatments rather than to pre-existing differences.</p>
<p><strong>Probabilistic Modeling</strong>: Because we control the randomization process, we can model it mathematically. This enables us to use statistical inference methods that depend on knowing the probability model for how units ended up in different groups.</p>
<p><strong>A Practical Randomization Example</strong></p>
<p>Suppose we have 125 participants to randomize into one control group and three treatment groups (four groups total). A simple randomization procedure might work as follows:</p>
<ol class="arabic simple">
<li><p><strong>Create a master list</strong> of all 125 participants</p></li>
<li><p><strong>Assign each participant a random number</strong> or draw names from a hat</p></li>
<li><p><strong>Use a randomization device</strong> (like a four-sided die) to assign each participant:</p>
<ul class="simple">
<li><p>Roll 1 = Control group</p></li>
<li><p>Roll 2 = Treatment 1</p></li>
<li><p>Roll 3 = Treatment 2</p></li>
<li><p>Roll 4 = Treatment 3</p></li>
</ul>
</li>
<li><p><strong>Continue until all participants are assigned</strong></p></li>
</ol>
<p>This procedure gives each participant an equal probability of ending up in any group, regardless of their characteristics.</p>
<p><strong>Limitations of Simple Randomization</strong></p>
<p>While conceptually straightforward, simple randomization can sometimes produce unbalanced group sizes by chance. With 125 participants and four groups, we might end up with groups of sizes 25, 28, 35, and 37—not drastically different, but not optimal either.</p>
<p>For better balance, researchers often use <strong>restricted randomization</strong> procedures that ensure more equal group sizes while maintaining the random assignment principle. These might involve:</p>
<ul class="simple">
<li><p><strong>Block randomization</strong>: Randomly assigning participants in small blocks to ensure regular balance</p></li>
<li><p><strong>Stratified randomization</strong>: Balancing on important characteristics while maintaining randomness within strata</p></li>
</ul>
<p><strong>Why Human Judgment Fails</strong></p>
<p>It might seem that an expert could do better than random assignment by carefully balancing groups on known important variables. This intuition is wrong for several reasons:</p>
<p><strong>Unconscious Bias</strong>: Even well-intentioned researchers unconsciously favor certain assignments based on their expectations or desires to help particular subjects.</p>
<p><strong>Unknown Variables</strong>: Experts can only balance on variables they know about and can measure. Randomization balances on all variables, including those we haven’t identified or can’t measure.</p>
<p><strong>Complex Interactions</strong>: The optimal balance across multiple variables simultaneously is mathematically complex. Random assignment handles this complexity automatically.</p>
<p><strong>Statistical Validity</strong>: Our statistical methods assume random assignment. Non-random assignment invalidates these methods, even if it produces apparently better balance on observed variables.</p>
<p><strong>Randomization Enables Statistical Inference</strong></p>
<p>Perhaps most importantly, randomization provides the foundation for statistical inference. Our probability models, hypothesis tests, and confidence intervals all depend on understanding how experimental units were assigned to groups.</p>
<p>With randomization, we can:</p>
<ul class="simple">
<li><p><strong>Calculate exact probabilities</strong> for observing various outcomes under different hypotheses</p></li>
<li><p><strong>Control error rates</strong> in our statistical tests</p></li>
<li><p><strong>Quantify uncertainty</strong> through confidence intervals</p></li>
<li><p><strong>Make valid inferences</strong> about treatment effects</p></li>
</ul>
<p>Without randomization, we lose this entire inferential framework. We might still be able to describe what happened in our particular study, but we can’t generalize those findings or make probability statements about their reliability.</p>
<p><strong>Why Randomization is Essential</strong></p>
<p>Randomization is essential because it:</p>
<ul class="simple">
<li><p><strong>Creates unbiased treatment groups</strong> that differ only by chance</p></li>
<li><p><strong>Eliminates systematic confounding</strong> between treatments and other variables</p></li>
<li><p><strong>Enables valid statistical inference</strong> through known probability models</p></li>
<li><p><strong>Provides fairness</strong> in treatment assignment</p></li>
<li><p><strong>Builds scientific credibility</strong> by removing researcher discretion from group assignment</p></li>
</ul>
<p>Without proper randomization, even the most sophisticated statistical analysis cannot produce reliable causal conclusions.</p>
</section>
<section id="principle-3-replication-building-reliable-evidence">
<h2><span class="section-number">8.2.5. </span>Principle 3: Replication – Building Reliable Evidence<a class="headerlink" href="#principle-3-replication-building-reliable-evidence" title="Link to this heading"></a></h2>
<p>The third principle addresses a fundamental challenge in experimental science: distinguishing genuine treatment effects from the noise of natural variation. Even in well-controlled, properly randomized experiments, individual observations can be misleading due to chance. Replication provides the solution by ensuring we have enough evidence to draw reliable conclusions.</p>
<p><strong>The Problem of Chance Variation</strong></p>
<p><strong>Statistical variation</strong> is inevitable in experimental data. Even when treatments have real effects, individual responses will vary due to natural differences between experimental units, measurement error, and random environmental factors. With small samples, this variation can easily mask true treatment effects or create the appearance of effects where none exist.</p>
<p>Consider testing a new medication with only two patients in the treatment group and two in the control group. If one treatment patient happens to be naturally resilient and one control patient happens to be particularly susceptible to the condition, the treatment might appear dramatically effective even if it has no real benefit. Conversely, a genuinely effective treatment might appear useless if the treatment patients happen to be less responsive than the control patients.</p>
<p><strong>How Replication Addresses Variation</strong></p>
<p><strong>Replication</strong> means using enough experimental units within each treatment group so that individual variation averages out, revealing the underlying treatment effects. The principle works through the law of large numbers: as sample sizes increase, sample averages become increasingly reliable estimates of true population averages.</p>
<p>With adequate replication:</p>
<ul class="simple">
<li><p><strong>Individual outliers</strong> have less influence on group averages</p></li>
<li><p><strong>Natural variation</strong> becomes predictable and manageable</p></li>
<li><p><strong>Treatment effects</strong> become distinguishable from random fluctuations</p></li>
<li><p><strong>Statistical power</strong> increases, making it easier to detect real effects when they exist</p></li>
</ul>
<p><strong>Multiple Independent Measurements</strong></p>
<p>The key insight behind replication is that we need <strong>multiple independent measurements</strong> of the same effect. Each experimental unit provides one independent observation of how the treatment affects the response variable. The more independent observations we have, the more reliable our conclusions become.</p>
<p>Independence is crucial here. Ten measurements from the same experimental unit (like taking a patient’s blood pressure ten times) don’t provide the same information as one measurement each from ten different experimental units. The repeated measurements from the same unit are not independent—they’re all influenced by that particular unit’s characteristics.</p>
<p><strong>Estimating True Treatment Effects</strong></p>
<p><strong>Replication enables us to estimate the true effect of treatments under investigation.</strong> With enough experimental units in each group, we can:</p>
<ul class="simple">
<li><p><strong>Estimate average treatment effects</strong> with known precision</p></li>
<li><p><strong>Quantify uncertainty</strong> in our estimates through standard errors and confidence intervals</p></li>
<li><p><strong>Distinguish signal from noise</strong> by comparing treatment effects to their standard errors</p></li>
<li><p><strong>Achieve adequate statistical power</strong> to detect effects of practical importance</p></li>
</ul>
<p>The relationship between sample size and precision follows the familiar pattern from sampling distributions: standard errors decrease proportionally to the square root of sample size. This means that to halve our uncertainty, we need four times as many experimental units.</p>
<p><strong>Balancing Precision and Resources</strong></p>
<p>Replication requires resources—more experimental units mean higher costs, longer study durations, and greater logistical complexity. The challenge is finding the right balance between:</p>
<p><strong>Statistical Requirements</strong>: Having enough units to detect meaningful effects with adequate power and precision.</p>
<p><strong>Practical Constraints</strong>: Working within available budgets, timeframes, and logistical capabilities.</p>
<p><strong>Ethical Considerations</strong>: Not exposing more subjects to potential risks than necessary, while still gathering sufficient evidence for reliable conclusions.</p>
<p><strong>Power Analysis</strong>: Modern experimental design uses power analysis to determine optimal sample sizes before data collection begins. This involves specifying:</p>
<ul class="simple">
<li><p>The minimum effect size worth detecting</p></li>
<li><p>The desired probability of detecting that effect (statistical power)</p></li>
<li><p>The acceptable risk of false positive results (significance level)</p></li>
<li><p>The expected variability in the response</p></li>
</ul>
<p><strong>Replication Across Different Levels</strong></p>
<p>Replication can occur at multiple levels, each providing different types of evidence:</p>
<p><strong>Within-Study Replication</strong>: Multiple experimental units within each treatment group in a single study. This is the basic requirement for reliable statistical inference.</p>
<p><strong>Cross-Study Replication</strong>: Multiple independent studies investigating the same research question. This provides evidence that effects are not specific to particular populations, settings, or time periods.</p>
<p><strong>Systematic Replication</strong>: Studies that deliberately vary certain aspects (populations, settings, methods) while maintaining the core research question. This helps establish the generalizability of findings.</p>
<p><strong>Why Small Samples are Dangerous</strong></p>
<p>Inadequate replication creates multiple problems:</p>
<p><strong>Unreliable Results</strong>: Small samples produce highly variable results. The same treatment might appear beneficial in one small study and harmful in another, simply due to chance.</p>
<p><strong>False Discoveries</strong>: With small samples, chance differences between groups can easily appear statistically significant, leading to false conclusions about treatment effects.</p>
<p><strong>Missed Discoveries</strong>: Real but modest treatment effects might not be detectable with small samples, leading to incorrect conclusions that treatments are ineffective.</p>
<p><strong>Unrepresentative Samples</strong>: Small samples might accidentally over-represent certain types of subjects or conditions, limiting the generalizability of results.</p>
<p><strong>The Economics of Replication</strong></p>
<p>While replication requires upfront investment in larger studies, it’s economically efficient in the long run:</p>
<ul class="simple">
<li><p><strong>Reduces wasted resources</strong> on follow-up studies to clarify ambiguous results</p></li>
<li><p><strong>Increases confidence</strong> in decision-making based on study results</p></li>
<li><p><strong>Prevents costly mistakes</strong> from implementing ineffective or harmful treatments</p></li>
<li><p><strong>Accelerates scientific progress</strong> by providing definitive rather than preliminary evidence</p></li>
</ul>
<p><strong>Why Replication is Fundamental</strong></p>
<p>Replication is fundamental because it:</p>
<ul class="simple">
<li><p><strong>Distinguishes signal from noise</strong> in experimental data</p></li>
<li><p><strong>Provides reliable estimates</strong> of treatment effects</p></li>
<li><p><strong>Enables adequate statistical power</strong> to detect meaningful effects</p></li>
<li><p><strong>Builds scientific credibility</strong> through reproducible results</p></li>
<li><p><strong>Supports sound decision-making</strong> based on study findings</p></li>
</ul>
<p>Without adequate replication, experiments become exercises in anecdote rather than rigorous scientific investigations.</p>
</section>
<section id="the-synergy-of-the-three-principles">
<h2><span class="section-number">8.2.6. </span>The Synergy of the Three Principles<a class="headerlink" href="#the-synergy-of-the-three-principles" title="Link to this heading"></a></h2>
<p>While each principle addresses different threats to experimental validity, their true power emerges when they work together synergistically. Each principle compensates for the limitations of the others, creating a robust framework for causal inference.</p>
<p><strong>How the Principles Interact</strong></p>
<p><strong>Control without Randomization</strong> can create systematic biases in group assignment that no amount of control can eliminate. Even perfect environmental control cannot compensate for systematic differences in the types of subjects assigned to different groups.</p>
<p><strong>Randomization without Control</strong> can create fair group assignments, but without proper controls we cannot distinguish treatment effects from environmental differences or measurement artifacts.</p>
<p><strong>Replication without Control or Randomization</strong> simply gives us more precise estimates of biased or confounded effects. Large samples cannot fix fundamental design flaws.</p>
<p><strong>Control and Randomization without Replication</strong> can create unbiased but unreliable results. We might have the right approach but insufficient evidence to draw confident conclusions.</p>
<p><strong>The Gold Standard: All Three Together</strong></p>
<p>When all three principles are properly implemented:</p>
<ol class="arabic simple">
<li><p><strong>Control</strong> ensures we can meaningfully compare treatment and control groups</p></li>
<li><p><strong>Randomization</strong> ensures the groups are comparable and enables statistical inference</p></li>
<li><p><strong>Replication</strong> ensures our conclusions are reliable and generalizable</p></li>
</ol>
<p>This combination creates experiments capable of producing definitive evidence for causal relationships—the foundation of evidence-based decision making in science, medicine, policy, and business.</p>
<p><strong>No Perfect Studies</strong></p>
<p>It’s important to recognize that no study is ever perfect. Real-world constraints always require compromises. The goal is not perfection but rather ensuring that all three principles are satisfied well enough to support reliable conclusions.</p>
<p>Sometimes one principle might be stronger than others to compensate for unavoidable weaknesses. For example, if perfect randomization is impossible due to ethical constraints, researchers might invest more heavily in control and replication to maintain study validity.</p>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">8.2.7. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<p>These three principles provide the foundation that makes statistical inference possible and reliable. When we move to confidence intervals, hypothesis testing, and other inferential methods in subsequent chapters, we’ll depend critically on:</p>
<ul class="simple">
<li><p><strong>Control</strong> to ensure our comparisons address the right research questions</p></li>
<li><p><strong>Randomization</strong> to justify our probabilistic models and inference procedures</p></li>
<li><p><strong>Replication</strong> to provide adequate precision and power</p></li>
</ul>
<p>Understanding these principles deeply is essential because they determine not just how we design studies, but also how we interpret statistical results and assess the credibility of research findings.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>Three principles are essential</strong> for establishing causal relationships: Control, Randomization, and Replication must all be satisfied for valid experimental inference.</p></li>
<li><p><strong>Control provides the basis for comparison</strong> through control groups and standardized conditions, while also addressing confounding through techniques like blinding and blocking.</p></li>
<li><p><strong>Randomization creates comparable groups</strong> by using chance to assign treatments, eliminating systematic bias and enabling statistical inference.</p></li>
<li><p><strong>Replication ensures reliable conclusions</strong> by providing enough observations to distinguish genuine effects from random variation.</p></li>
<li><p><strong>The principles work synergistically</strong>: Each addresses different threats to validity, and all three must be present for experiments to produce trustworthy causal evidence.</p></li>
<li><p><strong>Design determines analysis</strong>: The quality of experimental design directly determines the validity and reliability of any subsequent statistical analysis.</p></li>
<li><p><strong>These principles enable statistical inference</strong>: The methods we’ll learn in upcoming chapters depend fundamentally on these design principles being properly implemented.</p></li>
</ol>
</div>
<p>The transition from understanding probability and sampling distributions to conducting statistical inference requires more than mathematical sophistication—it demands careful attention to how data are collected. These three principles provide the foundation that transforms statistical analysis from mathematical exercise to scientific discovery.</p>
<p>As we continue through this chapter, we’ll explore specific experimental designs that implement these principles in different research contexts, common problems that arise when principles are violated, and practical strategies for designing studies that produce reliable, actionable results. This foundation will prove essential when we begin using sample data to draw conclusions about populations in subsequent chapters.</p>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Identifying Principle Violations</strong>: For each scenario, identify which experimental design principle is being violated and explain the potential consequences:</p>
<ol class="loweralpha simple">
<li><p>A researcher tests a new teaching method by using it in morning classes and comparing results to evening classes using traditional methods.</p></li>
<li><p>A medical study assigns the first 50 volunteers to the treatment group and the next 50 to the control group.</p></li>
<li><p>An agricultural experiment tests a new fertilizer using only 3 plots for treatment and 3 plots for control.</p></li>
<li><p>A psychology study tests an intervention but forgets to include a control group entirely.</p></li>
</ol>
</li>
<li><p><strong>The Importance of Control Groups</strong>: A researcher claims that a new study method improves test scores because students using the method averaged 78% on the final exam. Explain why this conclusion is not justified and describe what additional information would be needed.</p></li>
<li><p><strong>Randomization Procedures</strong>: Design a randomization procedure for assigning 200 patients to one of four treatment groups (including one control group). Explain why your procedure is better than having a doctor assign patients based on their professional judgment.</p></li>
<li><p><strong>Sample Size and Replication</strong>: A study finds that a new medication reduces symptoms in 7 out of 10 patients in the treatment group, compared to 3 out of 10 in the control group.</p>
<ol class="loweralpha simple">
<li><p>Calculate the improvement rate for each group.</p></li>
<li><p>Explain why these results might not be reliable despite the apparent difference.</p></li>
<li><p>What sample size might be needed to draw confident conclusions?</p></li>
</ol>
</li>
<li><p><strong>Blinding in Practice</strong>: For each research scenario, determine whether single-blind, double-blind, or no blinding is feasible, and explain your reasoning:</p>
<ol class="loweralpha simple">
<li><p>Testing whether a new surgical technique reduces recovery time</p></li>
<li><p>Comparing the effectiveness of two different pain medications</p></li>
<li><p>Evaluating whether a new teaching method improves learning</p></li>
<li><p>Testing whether a new fertilizer increases crop yield</p></li>
</ol>
</li>
<li><p><strong>Blocking Design</strong>: An educational researcher wants to test whether a new curriculum improves math achievement. The study will include students from three different grade levels (3rd, 4th, and 5th grade).</p>
<ol class="loweralpha simple">
<li><p>Explain why blocking by grade level might be important.</p></li>
<li><p>Describe how you would implement a randomized block design for this study.</p></li>
<li><p>Compare this approach to simple randomization across all students.</p></li>
</ol>
</li>
<li><p><strong>Principle Integration</strong>: Design a complete experiment to test whether background music affects concentration during studying. Your design should clearly address all three principles and explain how they work together to enable causal inference.</p></li>
<li><p><strong>Real-World Constraints</strong>: Consider testing a new traffic light system to reduce accidents at intersections. Identify practical constraints that might make it difficult to implement each of the three principles perfectly, and suggest realistic compromises that maintain the study’s validity.</p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="8-1-experimental-and-sampling-designs.html" class="btn btn-neutral float-left" title="8.1. Experimental and Sampling Designs" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="8-3-basic-types-of-experimental-design.html" class="btn btn-neutral float-right" title="8.3. Basic Types of Experimental Design" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>