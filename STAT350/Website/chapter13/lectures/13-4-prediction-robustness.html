

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>13.4. Prediction and Robustness &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=2f168d12" />
      <link rel="stylesheet" type="text/css" href="../../_static/credits.css?v=f7efa099" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/Website/chapter13/lectures/13-4-prediction-robustness.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=7e0058eb"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="13.3. Model Diagnostics and Statistical Inference" href="13-3-diagnostics-inference.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#exam-2-preparation-materials-not-comprensive-for-final">Exam 2 Preparation Materials (Not comprensive for final)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#troubleshooting-guide">Troubleshooting Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-and-binomial-distributions">Part 1: The Bernoulli and Binomial Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#the-binomial-distribution">The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-poisson-distribution">Part 2: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-other-named-discrete-distributions">Part 3: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-standard-normal-table">Part 2: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-z-score-transformation">Part 3: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html">Worksheet 11: The Central Limit Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#tutorial-generating-the-sampling-distribution-of-bar-x">Tutorial: Generating the Sampling Distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-1-exploring-clt-with-skewed-distributions">Part 1: Exploring CLT with Skewed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-2-application-of-the-clt">Part 2: Application of the CLT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-3-beyond-mean-and-sum">Part 3: Beyond Mean and Sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-4-exploring-clt-generalizability-with-ai-assistance-exploration">Part 4: Exploring CLT Generalizability with AI Assistance (Exploration)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html">Worksheet 12: Point Estimators and Unbiased Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-1-estimating-parameters-of-the-exponential-distribution">Part 1: Estimating Parameters of the Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-2-estimating-the-maximum-of-a-uniform-distribution">Part 2: Estimating the Maximum of a Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-3-minimum-variance-unbiased-estimators-mvue">Part 3: Minimum Variance Unbiased Estimators (MVUE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html">Worksheet 13: Introduction to Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-1-pivotal-quantities-and-deriving-confidence-intervals">Part 1: Pivotal Quantities and Deriving Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-2-sample-size-determination">Part 2: Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-3-one-sided-confidence-bounds">Part 3: One-Sided Confidence Bounds</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-4-confidence-intervals-when-is-unknown">Part 4: Confidence Intervals When σ is Unknown</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html">Worksheet 14: Student’s t-Distribution and Statistical Power</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#assumptions-for-t-distribution-inference">Assumptions for t-Distribution Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-1-analyzing-chick-growth-with-confidence-intervals">Part 1: Analyzing Chick Growth with Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-2-introduction-to-hypothesis-testing">Part 2: Introduction to Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-3-sample-size-determination-and-power-analysis">Part 3: Sample Size Determination and Power Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html">The Hypothesis Testing Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-test-statistic-known">The Test Statistic (Known σ)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#distribution-of-the-test-statistic">Distribution of the Test Statistic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-p-value">The p-value</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#part-1-simulating-test-statistics-and-p-values">Part 1: Simulating Test Statistics and P-values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1a-simulation-when-null-hypothesis-is-true">Question 1a: Simulation When Null Hypothesis is True</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1b-simulation-when-null-hypothesis-is-false">Question 1b: Simulation When Null Hypothesis is False</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1c-comparing-the-two-scenarios">Question 1c: Comparing the Two Scenarios</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-t-test-when-is-unknown">The t-Test When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-t-test-statistic">The t-Test Statistic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#properties-of-the-t-distribution">Properties of the t-Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#relationship-between-confidence-intervals-and-hypothesis-tests">Relationship Between Confidence Intervals and Hypothesis Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#part-2-epa-ozone-concentration-analysis">Part 2: EPA Ozone Concentration Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2a-assumptions-and-exploratory-analysis">Question 2a: Assumptions and Exploratory Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2b-full-hypothesis-testing-procedure">Question 2b: Full Hypothesis Testing Procedure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2c-manual-verification">Question 2c: Manual Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2d-confidence-bound">Question 2d: Confidence Bound</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2e-power-calculation">Question 2e: Power Calculation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html">Worksheet 16: Two-Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-1-independent-vs-paired-designs">Part 1: Independent vs. Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-2-independent-samples-with-known-variances">Part 2: Independent Samples with Known Variances</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-3-pooled-two-sample-t-test-equal-variances">Part 3: Pooled Two-Sample t-Test (Equal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-4-welch-s-two-sample-t-test-unequal-variances">Part 4: Welch’s Two-Sample t-Test (Unequal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html">Worksheet 17: Paired Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-1-theory-and-procedure-for-paired-samples">Part 1: Theory and Procedure for Paired Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-2-sleep-study-analysis">Part 2: Sleep Study Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-3-sample-size-calculation-for-paired-designs">Part 3: Sample Size Calculation for Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html">Worksheet 18: One-Way ANOVA (Analysis of Variance)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#why-use-one-way-anova">Why Use One-Way ANOVA?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#one-way-anova-assumptions">One-Way ANOVA Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#one-way-anova-f-test-statistic-and-sources-of-variation">One-Way ANOVA F-test Statistic and Sources of Variation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#notation-and-setup">Notation and Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-1-computing-the-overall-sample-mean">Part 1: Computing the Overall Sample Mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-2-checking-the-equal-variance-assumption">Part 2: Checking the Equal Variance Assumption</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-3-pooled-variance-estimator">Part 3: Pooled Variance Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-4-within-group-variability-sum-of-squares-within-sse">Part 4: Within-Group Variability (Sum of Squares Within, SSE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-5-between-group-variability-sum-of-squares-among-ssa">Part 5: Between-Group Variability (Sum of Squares Among, SSA)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-6-total-variability-and-partitioning">Part 6: Total Variability and Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-7-degrees-of-freedom">Part 7: Degrees of Freedom</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-8-mean-squares">Part 8: Mean Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-9-the-f-test-statistic">Part 9: The F-Test Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-10-computing-the-p-value-and-making-a-decision">Part 10: Computing the P-Value and Making a Decision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-11-completing-the-anova-table">Part 11: Completing the ANOVA Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-12-limitations-and-follow-up-questions">Part 12: Limitations and Follow-Up Questions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html">Worksheet 19: Multiple Comparisons and Post-Hoc Testing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#the-multiple-comparisons-problem">The Multiple Comparisons Problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#methods-to-control-the-family-wise-error-rate">Methods to Control the Family-Wise Error Rate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-1-simulation-study-type-i-error-with-multiple-comparison-methods">Part 1: Simulation Study - Type I Error with Multiple Comparison Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-2-applying-tukey-s-hsd-to-worksheet-18-data">Part 2: Applying Tukey’s HSD to Worksheet 18 Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-3-comprehensive-anova-analysis-toothgrowth-dataset">Part 3: Comprehensive ANOVA Analysis - ToothGrowth Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html">Worksheet 20: Introduction to Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#from-anova-to-regression-same-core-ideas-new-application">From ANOVA to Regression: Same Core Ideas, New Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#the-simple-linear-regression-model">The Simple Linear Regression Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#least-squares">Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-1-deriving-least-squares-estimators">Part 1: Deriving Least Squares Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-2-the-general-simple-linear-regression-estimators">Part 2: The General Simple Linear Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-3-sampling-distributions-of-regression-estimators">Part 3: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-4-practice-problems">Part 4: Practice Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html">Worksheet 21: Inference for Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-1-sampling-distributions-of-regression-estimators">Part 1: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-2-checking-regression-assumptions">Part 2: Checking Regression Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-3-bird-data-analysis">Part 3: Bird Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-4-regression-anova">Part 4: Regression ANOVA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html">Worksheet 22: Model Assessment and Prediction in Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-1-the-coefficient-of-determination">Part 1: The Coefficient of Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-2-confidence-intervals-vs-prediction-intervals">Part 2: Confidence Intervals vs. Prediction Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-3-simulation-study-ci-vs-pi-coverage">Part 3: Simulation Study — CI vs. PI Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-4-prediction-with-the-bird-data">Part 4: Prediction with the Bird Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-5-diamonds-data-analysis">Part 5: Diamonds Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html">Getting Started with R and RStudio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#getting-started-with-swirl">Getting Started with swirl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#alternative-r-learning-resources">Alternative R Learning Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_quick_reference.html">Quick Reference Table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html">Computer Assignments and Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-structure">Assignment Structure</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html">Function Reference Part 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#simulation-functions">Simulation Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html">Function Reference Part 2: Inference Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html#diagnostic-plots-for-assumptions">Diagnostic Plots for Assumptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#tables-reporting">Tables &amp; Reporting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#data-import-validation">Data Import &amp; Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#statistical-assumptions">Statistical Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#common-errors-to-avoid">Common Errors to Avoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#workflow-template">Workflow Template</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html">Course Datasets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#primary-course-dataset-apprating">Primary Course Dataset - AppRating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#tutorial-support-datasets">Tutorial Support Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#loading-datasets-in-r">Loading Datasets in R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#built-in-r-datasets-used-in-course">Built-in R Datasets Used in Course</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#data-download-and-organization">Data Download and Organization</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Sequential Bayesian Updating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. The Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. The Foundation of Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Connecting CI and HT; <em>t</em>-Test for μ When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. The Four Steps to Hypothesis Testing and Understanding the Result</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Statistical Inference for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Independent Two-Sample Analysis When Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Independent Two-Sample Analysis - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Independent Two-Sample Analysis - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Paired Two-Sample Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. ANOVA F-Test and Its Relationship to Two-Sample <em>t</em>-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">13. Simple Linear Regression</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">13.4. Prediction and Robustness</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">13. </span>Simple Linear Regression</a></li>
      <li class="breadcrumb-item active"><span class="section-number">13.4. </span>Prediction and Robustness</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter13/lectures/13-4-prediction-robustness.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch13-9">
   <iframe
      id="video-ch13-9"
      title="STAT 350 – Chapter 13.9 Prediction and Uncertainty - Confidence Intervals for the Mean Response at a Point/Prediction Intervals at a Point Video"
      src="https://www.youtube.com/embed/zUyxH0AL530?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><div class="tip admonition">
<p class="admonition-title">Slides 📊</p>
<p><a class="reference external" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%2013%20Linear%20Regression/SimpleLinearRegression_AC.pptx">Download Chapter 13 slides (PPTX)</a></p>
</div>
<section id="prediction-and-robustness">
<h1><span class="section-number">13.4. </span>Prediction and Robustness<a class="headerlink" href="#prediction-and-robustness" title="Link to this heading"></a></h1>
<p>We have now developed the complete foundation for simple linear regression: model fitting, assumption checking,
and statistical inference for model parameters. This final chapter completes our regression toolkit by
addressing two critical questions:</p>
<ul class="simple">
<li><p>How do we make predictions with appropriate uncertainty quantification?</p></li>
<li><p>When can we trust our inference procedures despite violations of the normality assumption?</p></li>
</ul>
<p>This chapter represents the culmination of our statistical journey through STAT 350, bringing together concepts
from descriptive statistics, probability, sampling distributions, and inference into a comprehensive framework.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p>Build awareness of the dangers of extrapolation.</p></li>
<li><p>Understand the difference between the two prediction tasks in regression: predicting the mean response versus
predicting a single response.</p></li>
<li><p>Construct intervals for the both types of prediction and compare their shared characteristics and key differences.</p></li>
<li><p>Discuss how CLT makes certain linear regression inference tasks robust, but not all.</p></li>
<li><p>Organize all components of linear regression into a single workflow using a complete example.</p></li>
</ul>
</div>
<section id="the-danger-of-extrapolation">
<h2><span class="section-number">13.4.1. </span>The Danger of Extrapolation<a class="headerlink" href="#the-danger-of-extrapolation" title="Link to this heading"></a></h2>
<p>One of the most important applications of linear regression is <strong>prediction</strong>—using the fitted model to estimate the
response for a new explanatory input <span class="math notranslate nohighlight">\(x^*\)</span>. However, a fitted model is reliable for prediction only if the
explanatory value is “reasonable” for the model. To understand what counts as reasonable, we should first
understand the difference between <strong>interpolation</strong> and <strong>extrapolation</strong>.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/extrapolation.png"><img alt="Extrapolation" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/extrapolation.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 13.32 </span><span class="caption-text">Scatter plot with extrapolation regions marked</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Interpolation</strong> involves making predictions for explanatory variable values that fall <strong>within the range</strong> of values
used to create the regression line. These predictions are generally trustworthy because:</p>
<ul class="simple">
<li><p>Our model has been “trained” on data within this range.</p></li>
<li><p>We have evidence that the linear relationship holds in this region.</p></li>
<li><p>Our model assumptions have been validated using data from this range.</p></li>
</ul>
<p><strong>Extrapolation</strong> involves using the regression line for prediction <strong>outside the observed range</strong> of the explanatory variable.
This is risky because:</p>
<ul class="simple">
<li><p>We have no evidence that the linear relationship continues outside this range.</p></li>
<li><p>Model assumptions may not hold in unobserved regions.</p></li>
</ul>
<p>In essence, the only <span class="math notranslate nohighlight">\(x^*\)</span> values suitable for prediction are those within the observed range of <span class="math notranslate nohighlight">\(X\)</span>.
Extrapolation should be avoided whenever possible.</p>
</section>
<section id="two-types-of-prediction-and-their-distributional-foundation">
<h2><span class="section-number">13.4.2. </span>Two Types of Prediction and Their Distributional Foundation<a class="headerlink" href="#two-types-of-prediction-and-their-distributional-foundation" title="Link to this heading"></a></h2>
<section id="two-types-of-prediction">
<h3>Two Types of Prediction<a class="headerlink" href="#two-types-of-prediction" title="Link to this heading"></a></h3>
<p>Prediction in regression analysis involves finding a suitable response for a given explanatory value <span class="math notranslate nohighlight">\(x^*\)</span>.
This seemingly simple task, however, breaks down to two different questions depending on
the target of estimation:</p>
<ol class="arabic">
<li><p>What is the average of all responses to the explanatory value <span class="math notranslate nohighlight">\(x^*\)</span>?</p>
<p>We call the average of all responses to an explanatory value <span class="math notranslate nohighlight">\(x^*\)</span> the <strong>mean response</strong>, and
we answer this question by computing a <strong>confidence interval for the mean response</strong>.</p>
</li>
<li><p>What will be the value of one new response associated with the explanatory value <span class="math notranslate nohighlight">\(x^*\)</span>?</p>
<p>When our interest is in estimating a single response to a given explanatory value <span class="math notranslate nohighlight">\(x^*\)</span>,
we call our target the <strong>predicted response</strong>. We answer this
question using a <strong>prediction interval</strong>.</p>
</li>
</ol>
<p>The different types of prediction give rise to inferences with different characterizations of uncertainty.
We begin by analyzing the distributional properties of the corresponding prediction estimators.</p>
</section>
<section id="distribution-of-the-mean-response-estimator">
<h3>1. Distribution of the Mean Response Estimator<a class="headerlink" href="#distribution-of-the-mean-response-estimator" title="Link to this heading"></a></h3>
<p>Mathematically, the <strong>true mean response</strong> can be written as:</p>
<div class="math notranslate nohighlight">
\[E[Y|X=x^*] = \beta_0 + \beta_1 x^*.\]</div>
<p>For conciseness, let us assume that the value of <span class="math notranslate nohighlight">\(x^*\)</span> is clear from context and write <span class="math notranslate nohighlight">\(\mu^* = E[Y|X=x^*]\)</span>.</p>
<section id="the-mean-response-estimator">
<h4>The Mean Response Estimator<a class="headerlink" href="#the-mean-response-estimator" title="Link to this heading"></a></h4>
<p>The logical choice for an estimator of the mean response is:</p>
<div class="math notranslate nohighlight">
\[\hat{\mu}^* = b_0 + b_1 x^*,\]</div>
<p>where the unknown regression parameters are replaced by their estimators, <span class="math notranslate nohighlight">\(b_0\)</span> and <span class="math notranslate nohighlight">\(b_1\)</span>.
Let us further analyze the distribution of <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span>.</p>
</section>
<section id="expected-value-of-hat-mu">
<h4>Expected Value of <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span><a class="headerlink" href="#expected-value-of-hat-mu" title="Link to this heading"></a></h4>
<div class="math notranslate nohighlight">
\[\begin{split}E[\hat{\mu}^*] &amp;= E[b_0 + b_1 x^*] = E[b_0] + E[b_1]x^* \\
&amp;= \beta_0 + \beta_1 x^* = \mu^*\end{split}\]</div>
<p>The parameter estimators <span class="math notranslate nohighlight">\(b_0\)</span> and <span class="math notranslate nohighlight">\(b_1\)</span> are unbiased, which
in turn makes the mean response also unbiased.</p>
</section>
<section id="variance-of-hat-mu">
<h4>Variance of <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span><a class="headerlink" href="#variance-of-hat-mu" title="Link to this heading"></a></h4>
<p>Using the identity <span class="math notranslate nohighlight">\(b_0 = \bar{Y} - b_1\bar{x}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\hat{\mu}^* &amp;= b_0 + b_1 x^*\\
&amp;= (\bar{Y} - b_1\bar{x}) + b_1 x^* \\
&amp;= \bar{Y} + b_1(x^* - \bar{x})\end{split}\]</div>
<p>Now using the expression of <span class="math notranslate nohighlight">\(b_1\)</span> as a linear combination of the responses (see Eq. <a class="reference internal" href="13-3-diagnostics-inference.html#equation-slope-linear-comb">(13.10)</a>):</p>
<div class="math notranslate nohighlight" id="equation-mean-response-linear-comb">
<span class="eqno">(13.11)<a class="headerlink" href="#equation-mean-response-linear-comb" title="Link to this equation"></a></span>\[\begin{split}\hat{\mu}^* &amp;= \bar{Y} +(x^* - \bar{x})\sum_{i=1}^n \left(\frac{x_i - \bar{x}}{S_{XX}}\right) Y_i \\
&amp;= \frac{1}{n}\sum_{i=1}^n Y_i + \frac{(x^* - \bar{x})}{S_{XX}}\sum_{i=1}^n (x_i - \bar{x}) Y_i\\
&amp;= \sum_{i=1}^n \left(\frac{1}{n} + \frac{(x^* - \bar{x})}{S_{XX}}(x_i - \bar{x})\right) Y_i\end{split}\]</div>
<p>Using the independence of the <span class="math notranslate nohighlight">\(Y_i\)</span> terms:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{Var}[\hat{\mu}^*] &amp;= \text{Var}\left[\sum_{i=1}^n \left(\frac{1}{n} + \frac{(x^* - \bar{x})}{S_{XX}}(x_i - \bar{x})\right) Y_i\right]\\
&amp;= \sigma^2 \left(\frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right)\end{split}\]</div>
</section>
<section id="distribution-of-hat-mu-under-normality">
<h4>Distribution of <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span> Under Normality<a class="headerlink" href="#distribution-of-hat-mu-under-normality" title="Link to this heading"></a></h4>
<p>From Eq <a class="reference internal" href="#equation-mean-response-linear-comb">(13.11)</a>, it is evident that <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span> is a linear combination of the responses.
Given that the normality assumption holds, therefore,</p>
<div class="math notranslate nohighlight">
\[\hat{\mu}^* \sim N\left(\beta_0 + \beta_1 x^*, \quad \sigma^2 \left(\frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right)\right)\]</div>
</section>
</section>
<section id="distribution-of-the-single-response-estimator">
<h3>2. Distribution of the Single Response Estimator<a class="headerlink" href="#distribution-of-the-single-response-estimator" title="Link to this heading"></a></h3>
<p>Denoting the predicted response as <span class="math notranslate nohighlight">\(Y^*\)</span>, its mathematical identity is:</p>
<div class="math notranslate nohighlight">
\[Y^* = \beta_0 + \beta_1x^* + \varepsilon^*,\]</div>
<p>where <span class="math notranslate nohighlight">\(\varepsilon^* \sim N(0, \sigma^2)\)</span> is a new error term, independent of
the data used to fit the model. Replacing the unknown regression parameters with their estimators,
we define the estimator of <span class="math notranslate nohighlight">\(Y^*\)</span> as:</p>
<div class="math notranslate nohighlight">
\[\hat{Y}^* = b_0 + b_1 x^* + \varepsilon^*\]</div>
<section id="expected-value-of-hat-y">
<h4>Expected Value of <span class="math notranslate nohighlight">\(\hat{Y}^*\)</span><a class="headerlink" href="#expected-value-of-hat-y" title="Link to this heading"></a></h4>
<div class="math notranslate nohighlight">
\[E[\hat{Y}^*] = E[\hat{\mu}^* + \varepsilon^*] = \beta_0 + \beta_1 x^*\]</div>
<p>The expected value is equal to the true mean response <span class="math notranslate nohighlight">\(\mu^*\)</span>, which is also the
expected value of <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span>.</p>
</section>
<section id="variance-of-hat-y">
<h4><strong>Variance of</strong> <span class="math notranslate nohighlight">\(\hat{Y}^*\)</span><a class="headerlink" href="#variance-of-hat-y" title="Link to this heading"></a></h4>
<p>Since the new error term <span class="math notranslate nohighlight">\(\varepsilon^*\)</span> is independent of the data used to fit the regression:</p>
<div class="math notranslate nohighlight" id="equation-single-response-var">
<span class="eqno">(13.12)<a class="headerlink" href="#equation-single-response-var" title="Link to this equation"></a></span>\[\begin{split}\text{Var}[\hat{Y}^*] &amp;= \text{Var}[\hat{\mu}^*] + \text{Var}[\varepsilon^*]\\
&amp;= \sigma^2 \left(\frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right) + \sigma^2\\
&amp;= \sigma^2 \left(1 + \frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right)\end{split}\]</div>
<p>From the first step of Eq. <a class="reference internal" href="#equation-single-response-var">(13.12)</a>, we note that <span class="math notranslate nohighlight">\(\hat{Y}^*\)</span> accounts
for <strong>two sources of variability</strong>:</p>
<ol class="arabic simple">
<li><p>Uncertainty in estimating the mean response with <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span></p></li>
<li><p>Natural variability of individual observations around the mean response</p></li>
</ol>
<p>Since <span class="math notranslate nohighlight">\(\hat{Y}^*\)</span> is essentially <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span> with an additional source of variability,
<strong>its variance is always greater than the variance of the mean response estimator.</strong></p>
</section>
<section id="distribution-of-hat-y-under-normality">
<h4>Distribution of <span class="math notranslate nohighlight">\(\hat{Y}^*\)</span> Under Normality<a class="headerlink" href="#distribution-of-hat-y-under-normality" title="Link to this heading"></a></h4>
<p>If both <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span> and <span class="math notranslate nohighlight">\(\varepsilon^*\)</span> are normally distributed, their sum <span class="math notranslate nohighlight">\(\hat{Y}^*\)</span>
is also normal. Given that the normality assumption holds,</p>
<div class="math notranslate nohighlight">
\[\hat{Y}^* \sim N\left(\beta_0 + \beta_1 x^*, \sigma^2 \left(1 + \frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right)\right)\]</div>
</section>
</section>
</section>
<section id="confidence-and-prediction-intervals">
<h2><span class="section-number">13.4.3. </span>Confidence and Prediction Intervals<a class="headerlink" href="#confidence-and-prediction-intervals" title="Link to this heading"></a></h2>
<p>We are mainly concerned with two-sided intervals for prediction tasks. The intervals follow the standard form:</p>
<div class="math notranslate nohighlight">
\[\text{estimate} \pm t_{\alpha/2, n-2} \widehat{SE}(\text{estimate}).\]</div>
<p>Since <span class="math notranslate nohighlight">\(\sigma^2\)</span> is unknown, the true standard errors are not available and must be estimated by
replacing <span class="math notranslate nohighlight">\(\sigma^2\)</span> with <span class="math notranslate nohighlight">\(s^2 = MSE\)</span>.
This leads to <span class="math notranslate nohighlight">\(t\)</span>-based confidence intervals with <span class="math notranslate nohighlight">\(df=n-2\)</span>.</p>
<section id="confidence-intervals-for-mean-response">
<h3>1. Confidence Intervals for Mean Response<a class="headerlink" href="#confidence-intervals-for-mean-response" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight" id="equation-conf-int">
<span class="eqno">(13.13)<a class="headerlink" href="#equation-conf-int" title="Link to this equation"></a></span>\[(b_0 + b_1 x^*) \pm t_{\alpha/2, n-2} \sqrt{\text{MSE} \cdot \left(\frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right)}\]</div>
<p><strong>Interpretation</strong>: We are <span class="math notranslate nohighlight">\((1-\alpha) \times 100\%\)</span> confident that the true mean of all responses for
explanatory value <span class="math notranslate nohighlight">\(x^*\)</span> lies within this interval.</p>
</section>
<section id="prediction-interval-for-single-response">
<h3>2. Prediction Interval for Single Response<a class="headerlink" href="#prediction-interval-for-single-response" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight" id="equation-pred-int">
<span class="eqno">(13.14)<a class="headerlink" href="#equation-pred-int" title="Link to this equation"></a></span>\[(b_0 + b_1 x^*) \pm t_{\alpha/2, n-2} \sqrt{\text{MSE} \cdot \left(1 + \frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right)}\]</div>
<p><strong>Interpretation</strong>: We are <span class="math notranslate nohighlight">\((1-\alpha) \times 100\%\)</span> confident that a new response with
explanatory value <span class="math notranslate nohighlight">\(x^*\)</span> falls within this interval.</p>
<p>Despite its definition, <span class="math notranslate nohighlight">\(\hat{y}^*\)</span> cannot contain <span class="math notranslate nohighlight">\(\varepsilon^*\)</span> as part of its
computational formula because <span class="math notranslate nohighlight">\(\hat{y}^*\)</span> must be a number, while <span class="math notranslate nohighlight">\(\varepsilon^*\)</span> is a random variable.
In Eq <a class="reference internal" href="#equation-pred-int">(13.14)</a>, we can consider <span class="math notranslate nohighlight">\(\varepsilon^*\)</span> as replaced with its best point estimate, <span class="math notranslate nohighlight">\(0\)</span>.</p>
</section>
<section id="confidence-and-prediction-bands">
<h3>Confidence and Prediction Bands<a class="headerlink" href="#confidence-and-prediction-bands" title="Link to this heading"></a></h3>
<p>By evaluating Equations <a class="reference internal" href="#equation-conf-int">(13.13)</a> and <a class="reference internal" href="#equation-pred-int">(13.14)</a> over a range of <span class="math notranslate nohighlight">\(x^*\)</span> values, we can construct and
visualize the <strong>confidence band</strong> and the <strong>prediction band</strong> on a scatter plot:</p>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/bands.png"><img alt="Confidence band vs prediction band" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/bands.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 13.33 </span><span class="caption-text">Comparison of confidence band and prediction band</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>The confidence band provides the range of plausible values for the
<strong>true mean response line</strong> <span class="math notranslate nohighlight">\(\mu_{Y|X=x} = \beta_0 + \beta_1 x\)</span> across the entire range of
explanatory variable values.</p></li>
<li><p>The prediction band marks a plausible region for individual observations.</p></li>
</ul>
</section>
<section id="key-observations">
<h3>Key Observations<a class="headerlink" href="#key-observations" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>Prediction intervals (band) are <strong>always wider</strong> than confidence intervals (band) for the mean response.</p>
<ul>
<li><p>Mathematically, this is due to due to the additional <span class="math notranslate nohighlight">\(+1\)</span> term in the standard error of the prediction interval.</p></li>
<li><p>Intuitively, a mean is always more stable than a single observation.</p></li>
</ul>
</li>
<li><p>At <span class="math notranslate nohighlight">\(x^* = \bar{x}\)</span>, the <span class="math notranslate nohighlight">\(\frac{(x^* - \bar{x})^2}{S_{XX}}\)</span> term becomes zero and the
standard error formulas simplify significantly for both intervals. By consequence,
the bands have a “bow-tie” or curved shape, narrowest at <span class="math notranslate nohighlight">\((\bar{x}, \bar{y})\)</span>.</p></li>
<li><p>Points falling outside the prediction band suggest potential outliers or model inadequacy.</p></li>
</ul>
<div class="important admonition">
<p class="admonition-title">Important Considerations for  Multiple Predictions</p>
<p>Constructing many intervals simultaneously leads to a concern about FWER, as we are aware from
the multiple comparisons procedure for ANOVA. To address this issue,</p>
<ul class="simple">
<li><p>Use more conservative confidence levels (e.g., 99% instead of 95%).</p></li>
<li><p>Apply multiple comparison corrections (beyond this course’s scope).</p></li>
<li><p>Understand that individual intervals have the stated coverage probability, but simultaneous coverage is lower.</p></li>
</ul>
</div>
<hr class="docutils" />
<div class="video-placeholder" role="group" aria-labelledby="video-ch13-10">
   <iframe
      id="video-ch13-10"
      title="STAT 350 – Chapter 13.10 Robustness to Normality Assumptions Video"
      src="https://www.youtube.com/embed/J8NtyRd48QU?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div></section>
</section>
<section id="robustness-to-normality-assumptions">
<h2><span class="section-number">13.4.4. </span>Robustness to Normality Assumptions<a class="headerlink" href="#robustness-to-normality-assumptions" title="Link to this heading"></a></h2>
<p>What happens to the inference results of linear regression when the normality assumption is violated?
This discussion mirrors our earlier discussions about robustness in single-sample and two-sample
procedures, but regression also presents some unique considerations.</p>
<section id="the-central-limit-theorem-in-regression">
<h3>The Central Limit Theorem in Regression<a class="headerlink" href="#the-central-limit-theorem-in-regression" title="Link to this heading"></a></h3>
<p>Different inference procedures in the same regression context have varying sensitivity to normality violations.
The key characteristic that distinguishes robust methods from non-robust ones is whether the central estimator is
an <strong>average</strong> or involves a <strong>single observation</strong>. When the estimator is constructed through
averaging a large enough number of responses,
this mitigates the non-normality of individual outcomes and allows safer use of
the associated inference methods.</p>
<section id="parameter-estimation-robust">
<h4>1. Parameter Estimation (Robust)<a class="headerlink" href="#parameter-estimation-robust" title="Link to this heading"></a></h4>
<div class="math notranslate nohighlight">
\[b_1 = \frac{1}{S_{XX}} \sum_{i=1}^n (x_i - \bar{x}) Y_i\]</div>
<div class="math notranslate nohighlight">
\[b_0 = \sum_{i=1}^n \left(\frac{1}{n} - \frac{\bar{x}}{S_{XX}}(x_i - \bar{x})\right) Y_i\]</div>
<p>Both estimators are weighted averages of the <span class="math notranslate nohighlight">\(Y_i\)</span>’s.</p>
</section>
<section id="mean-response-prediction-robust">
<h4>2. Mean Response Prediction (Robust)<a class="headerlink" href="#mean-response-prediction-robust" title="Link to this heading"></a></h4>
<div class="math notranslate nohighlight">
\[\hat{\mu}^* = \sum_{i=1}^n \left(\frac{1}{n} + \frac{(x^* - \bar{x})}{S_{XX}}(x_i - \bar{x})\right) Y_i\]</div>
<p>This is also a weighted average of the <span class="math notranslate nohighlight">\(Y_i\)</span>’s.</p>
</section>
<section id="single-response-prediction-not-robust">
<h4>3. Single Response Prediction (NOT Robust)<a class="headerlink" href="#single-response-prediction-not-robust" title="Link to this heading"></a></h4>
<div class="math notranslate nohighlight">
\[\hat{Y}^* = \hat{\mu}^* + \varepsilon^*\]</div>
<p>While <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span> benefits from CLT, the additional error term <span class="math notranslate nohighlight">\(\varepsilon^*\)</span> does not.
This new error term represents a <strong>single draw</strong> from the error distribution, not an average.</p>
<p><strong>Critical Limitation</strong>: If the error terms are not normally distributed, prediction intervals may have
incorrect coverage rates. The intervals might be too wide, too narrow, or asymmetric, depending on the true error distribution.</p>
</section>
</section>
<section id="practical-implications-for-real-data-analysis">
<h3>Practical Implications for Real Data Analysis<a class="headerlink" href="#practical-implications-for-real-data-analysis" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Always verify the normality assumption</strong> using residual diagnostics.</p></li>
<li><p><strong>For small samples</strong> (<span class="math notranslate nohighlight">\(n &lt; 20\)</span>), normality is more critical for all procedures.</p></li>
<li><p>Normality violations are particularly problematic <strong>for prediction intervals</strong>.</p></li>
<li><p><strong>Consider transformations</strong> if normality violations are severe.</p></li>
<li><p><strong>Acknowledge limitations</strong> when reporting results with questionable normality.</p></li>
</ul>
<hr class="docutils" />
<div class="video-placeholder" role="group" aria-labelledby="video-ch13-11">
   <iframe
      id="video-ch13-11"
      title="STAT 350 – Chapter 13.11 Linear Regression Prediction Example - Cetane Number Video"
      src="https://www.youtube.com/embed/XiQd9bhOSl4?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div></section>
</section>
<section id="example-of-complete-linear-regression-workflow">
<h2><span class="section-number">13.4.5. </span>Example of Complete Linear Regression Workflow<a class="headerlink" href="#example-of-complete-linear-regression-workflow" title="Link to this heading"></a></h2>
<div class="note admonition">
<p class="admonition-title">Example 💡: Cetane Number and Iodine Value</p>
<p>The <strong>cetane number</strong> is a critical property that specifies the ignition quality of fuel used in diesel engines.
Determination of this number for biodiesel fuel is expensive and time-consuming. Researchers want to explore using
a simple linear regression model to predict cetane number from the <strong>iodine value</strong>.</p>
<p><strong>Variables</strong>:</p>
<ul class="simple">
<li><p><strong>Response (Y)</strong>: Cetane Number (CN) - measures ignition quality</p></li>
<li><p><strong>Explanatory (X)</strong>: Iodine Value (IV) - the amount of iodine necessary to saturate a sample of 100 grams of oil</p></li>
</ul>
<p>A sample of 14 different biodiesel fuels was collected, with both iodine value and cetane number measured for each fuel.
Can iodine value be used to predict cetane number through a simple linear relationship?</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 20.0%" />
<col style="width: 40.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Obs</p></th>
<th class="head"><p>Iodine Value (IV)</p></th>
<th class="head"><p>Cetane Number (CN)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>132.0</p></td>
<td><p>46.0</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>129.0</p></td>
<td><p>48.0</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>120.0</p></td>
<td><p>51.0</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>113.2</p></td>
<td><p>52.1</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>105.0</p></td>
<td><p>54.0</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>92.0</p></td>
<td><p>52.0</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p>84.0</p></td>
<td><p>59.0</p></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p>83.2</p></td>
<td><p>58.7</p></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><p>88.4</p></td>
<td><p>61.6</p></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><p>59.0</p></td>
<td><p>64.0</p></td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><p>80.0</p></td>
<td><p>61.4</p></td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><p>81.5</p></td>
<td><p>54.6</p></td>
</tr>
<tr class="row-even"><td><p>13</p></td>
<td><p>71.0</p></td>
<td><p>58.8</p></td>
</tr>
<tr class="row-odd"><td><p>14</p></td>
<td><p>69.2</p></td>
<td><p>58.0</p></td>
</tr>
</tbody>
</table>
<p><strong>A. Exploratory Data Analysis</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the dataset</span>
<span class="n">iodine_value</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">132.0</span><span class="p">,</span><span class="w"> </span><span class="m">129.0</span><span class="p">,</span><span class="w"> </span><span class="m">120.0</span><span class="p">,</span><span class="w"> </span><span class="m">113.2</span><span class="p">,</span><span class="w"> </span><span class="m">105.0</span><span class="p">,</span><span class="w"> </span><span class="m">92.0</span><span class="p">,</span><span class="w"> </span><span class="m">84.0</span><span class="p">,</span>
<span class="w">                  </span><span class="m">83.2</span><span class="p">,</span><span class="w"> </span><span class="m">88.4</span><span class="p">,</span><span class="w"> </span><span class="m">59.0</span><span class="p">,</span><span class="w"> </span><span class="m">80.0</span><span class="p">,</span><span class="w"> </span><span class="m">81.5</span><span class="p">,</span><span class="w"> </span><span class="m">71.0</span><span class="p">,</span><span class="w"> </span><span class="m">69.2</span><span class="p">)</span>
<span class="n">cetane_number</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">46.0</span><span class="p">,</span><span class="w"> </span><span class="m">48.0</span><span class="p">,</span><span class="w"> </span><span class="m">51.0</span><span class="p">,</span><span class="w"> </span><span class="m">52.1</span><span class="p">,</span><span class="w"> </span><span class="m">54.0</span><span class="p">,</span><span class="w"> </span><span class="m">52.0</span><span class="p">,</span><span class="w"> </span><span class="m">59.0</span><span class="p">,</span>
<span class="w">                  </span><span class="m">58.7</span><span class="p">,</span><span class="w"> </span><span class="m">61.6</span><span class="p">,</span><span class="w"> </span><span class="m">64.0</span><span class="p">,</span><span class="w"> </span><span class="m">61.4</span><span class="p">,</span><span class="w"> </span><span class="m">54.6</span><span class="p">,</span><span class="w"> </span><span class="m">58.8</span><span class="p">,</span><span class="w"> </span><span class="m">58.0</span><span class="p">)</span>

<span class="c1"># Create data frame</span>
<span class="n">cetane_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="n">IodineValue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iodine_value</span><span class="p">,</span>
<span class="n">CetaneNumber</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cetane_number</span>
<span class="p">)</span>

<span class="c1"># Initial scatter plot</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">cetane_data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">IodineValue</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CetaneNumber</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="nf">geom_point</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="nf">geom_smooth</span><span class="p">(</span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lm</span><span class="p">,</span><span class="w"> </span><span class="n">formula</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="o">~</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">se</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="nf">labs</span><span class="p">(</span>
<span class="w">   </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Cetane Number vs Iodine Value&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Iodine Value (IV)&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Cetane Number (CN)&quot;</span>
<span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/cetane_scatter.png"><img alt="Cetane number vs iodine value scatter plot" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/cetane_scatter.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 13.34 </span><span class="caption-text">Scatter plot of cetane number vs iodine value data</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Negative linear trend visible</p></li>
<li><p>Points roughly follow a straight line pattern</p></li>
<li><p>No extreme outliers apparent</p></li>
</ul>
<p><strong>B. Model Fitting</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the linear regression model</span>
<span class="n">fit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">CetaneNumber</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">IodineValue</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cetane_data</span><span class="p">)</span>

<span class="c1"># Get basic summary</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Extract coefficients</span>
<span class="n">b0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[</span><span class="s">&#39;(Intercept)&#39;</span><span class="p">]</span>
<span class="n">b1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[</span><span class="s">&#39;IodineValue&#39;</span><span class="p">]</span>

<span class="c1"># Display fitted equation</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Fitted equation: CN =&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">b0</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;+&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;* IV&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[\hat{y} = 75.212 - 0.2094 x\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(b_0 = 75.212\)</span>: Cetane number is predicted to be <span class="math notranslate nohighlight">\(75.212\)</span> when iodine value is <span class="math notranslate nohighlight">\(0\)</span>.
This is <strong>not practically meaningful</strong> since <span class="math notranslate nohighlight">\(IV = 0\)</span> is outside our data range.</p></li>
<li><p><span class="math notranslate nohighlight">\(b_1 = -0.2094\)</span>: For each unit increase in iodine value, the cetane number decreases by an average
of <span class="math notranslate nohighlight">\(0.2094\)</span> units</p></li>
</ul>
<p><strong>C. Comprehensive Assumption Checking</strong></p>
<p>Before proceeding with inference, we must verify that our model assumptions are reasonable.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate residuals and fitted values</span>
<span class="n">cetane_data</span><span class="o">$</span><span class="n">residuals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">residuals</span>
<span class="n">cetane_data</span><span class="o">$</span><span class="n">fitted</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">fitted.values</span>

<span class="c1"># Residual plot</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">cetane_data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">IodineValue</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">residuals</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">labs</span><span class="p">(</span>
<span class="w">      </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Residual Plot&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Iodine Value&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Residuals&quot;</span>
<span class="w">   </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">theme_minimal</span><span class="p">()</span>


<span class="c1"># Histogram of residuals</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">cetane_data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">residuals</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">after_stat</span><span class="p">(</span><span class="n">density</span><span class="p">)),</span><span class="w"> </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span>
<span class="w">                  </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lightblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">geom_density</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">stat_function</span><span class="p">(</span>
<span class="w">      </span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dnorm</span><span class="p">,</span>
<span class="w">      </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span>
<span class="w">         </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">cetane_data</span><span class="o">$</span><span class="n">residuals</span><span class="p">),</span>
<span class="w">         </span><span class="n">sd</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">cetane_data</span><span class="o">$</span><span class="n">residuals</span><span class="p">)</span>
<span class="w">      </span><span class="p">),</span>
<span class="w">      </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="n">size</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="m">1</span>
<span class="w">   </span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Histogram of Residuals with Normal Overlay&quot;</span><span class="p">)</span>



<span class="n">xbar.resids</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">cetane_data</span><span class="o">$</span><span class="n">residuals</span><span class="p">)</span>
<span class="n">s.resids</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">cetane_data</span><span class="o">$</span><span class="n">residuals</span><span class="p">)</span>

<span class="c1"># QQ plotq</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">cetane_data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">sample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">residuals</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">stat_qq</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">geom_abline</span><span class="p">(</span><span class="n">slope</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s.resids</span><span class="p">,</span><span class="w"> </span><span class="n">intercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">xbar.resids</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.5</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;purple&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">   </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;QQ Plot of Residuals&quot;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/cetane_residual.png"><img alt="Cetane number vs iodine value residual plot" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/cetane_residual.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 13.35 </span><span class="caption-text">Residual plot of cetane number vs iodine value data</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/cetane_normality.png"><img alt="Cetane number vs iodine value plots for normality assessment" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/cetane_normality.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 13.36 </span><span class="caption-text">Normality assessment plots of cetane number vs iodine value data; Upper: histogram of residuals;
lower: QQ plot of residuals</span><a class="headerlink" href="#id5" title="Link to this image"></a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><strong>Independence</strong>: This must be evaluated based on data collection procedures.</p></li>
<li><p><strong>Linearity</strong>: The residual plot shows no obvious patterns or curvature, supporting the linearity assumption.</p></li>
<li><p><strong>Constant Variance</strong>: The residual plot shows some regions where points cluster more tightly than others, but with
only 14 observations, it’s difficult to definitively assess the assumption. The violations don’t appear
severe enough to invalidate the analysis.</p></li>
<li><p><strong>Normality</strong>: The histogram shows roughly
symmetric distribution with no extreme outliers. The QQ plot shows some fluctuation but no systematic departures
from linearity. The normality assumption appears reasonable, though drawing a definitive conclusion is challenging due to
small sample size.</p></li>
</ul>
<p><strong>D. F-test for Model Utility</strong></p>
<p>The hypothesis are:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H_0\)</span>: There is no linear association between iodine value and cetane number.</p></li>
<li><p><span class="math notranslate nohighlight">\(H_a\)</span>: There is a linear association between iodine value and cetane number.</p></li>
</ul>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(R^2 = 0.7906\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(f_{TS}=45.35\)</span> with <span class="math notranslate nohighlight">\(df_1=1\)</span> and <span class="math notranslate nohighlight">\(df_2=n-2=12\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p\)</span>-value <span class="math notranslate nohighlight">\(=2.091e-05\)</span></p></li>
</ul>
<p>With p-value &lt; 0.001, we reject <span class="math notranslate nohighlight">\(H_0\)</span> at any reasonable significance level. There is
strong evidence of a linear association between iodine value and cetane number.</p>
<p><strong>E. Inference on the Slope Parameter</strong></p>
<p>From <code class="docutils literal notranslate"><span class="pre">summary(fit)</span></code>, we also obtain:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(b_1=-0.20939\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\widehat{SE}=0.03109\)</span> for the slope estimate</p></li>
<li><p><span class="math notranslate nohighlight">\(t_{TS} = -6.734\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(p\)</span>-value <span class="math notranslate nohighlight">\(=2.09 \times 10^{-5}\)</span></p></li>
</ul>
<p>A hypothesis test on <span class="math notranslate nohighlight">\(H_a: \beta_1 \neq 0\)</span> would yield the same conclusion as the model utility test.</p>
<p>95% Confidence Interval for Slope:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate confidence interval for slope</span>
<span class="nf">confint</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="s">&#39;IodineValue&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span>

<span class="c1"># output: (-0.277, -0.142)</span>
</pre></div>
</div>
<p>We are 95% confident that each unit increase in iodine value is associated with a decrease in cetane number
between 0.142 and 0.277 units.</p>
<p><strong>F. Prediction Applications</strong></p>
<p><strong>Q1.</strong> What is the expected cetane number for a biodiesel fuel with iodine value of 75?</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create new data for prediction</span>
<span class="n">new_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">IodineValue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">75</span><span class="p">)</span>

<span class="c1"># Confidence interval for mean response</span>
<span class="n">conf_interval</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new_data</span><span class="p">,</span>
<span class="w">                        </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;confidence&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.99</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">conf_interval</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Predicted mean cetane number: 59.51</p></li>
<li><p>99% Confidence interval: (57.74, 61.28)</p></li>
</ul>
<p>We are 99% confident that the average cetane number for all biodiesel fuels with iodine value 75 is
between 57.74 and 61.28.</p>
<p><strong>Q2.</strong> What is the predicted response for a new biodiesel fuel with iodine value of 75?</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prediction interval for individual response</span>
<span class="n">pred_interval</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new_data</span><span class="p">,</span>
<span class="w">                        </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;prediction&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.99</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">pred_interval</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Predicted individual cetane number: 59.51</p></li>
<li><p>99% Prediction interval: (54.19, 64.83)</p></li>
</ul>
<p>We are 99% confident that a new biodiesel fuel with iodine value 75 will have a cetane number
between 54.19 and 64.83.</p>
<p><strong>Creating Confidence and Prediction Bands</strong>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate confidence and prediction bands</span>
<span class="n">conf_band</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;confidence&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.99</span><span class="p">)</span>
<span class="n">pred_band</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;prediction&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.99</span><span class="p">)</span>

<span class="c1"># Comprehensive visualization</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">cetane_data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">IodineValue</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CetaneNumber</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="c1"># Prediction bands (outer)</span>
<span class="nf">geom_ribbon</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">ymin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred_band</span><span class="p">[,</span><span class="m">2</span><span class="p">],</span><span class="w"> </span><span class="n">ymax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred_band</span><span class="p">[,</span><span class="m">3</span><span class="p">]),</span>
<span class="w">            </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lightblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="c1"># Confidence bands (inner)</span>
<span class="nf">geom_ribbon</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">ymin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">conf_band</span><span class="p">[,</span><span class="m">2</span><span class="p">],</span><span class="w"> </span><span class="n">ymax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">conf_band</span><span class="p">[,</span><span class="m">3</span><span class="p">]),</span>
<span class="w">            </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="c1"># Data points</span>
<span class="nf">geom_point</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="c1"># Regression line</span>
<span class="nf">geom_smooth</span><span class="p">(</span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lm&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">se</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="nf">labs</span><span class="p">(</span>
<span class="w">   </span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Cetane Number Prediction Model&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Dark blue: 99% Confidence bands, Light blue: 99% Prediction bands&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Iodine Value&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Cetane Number&quot;</span>
<span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/cetane_bands.png"><img alt="Confidence and prediction bands for cetane number versus iodine value" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/cetane_bands.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 13.37 </span><span class="caption-text">Confidence and prediction bands for cetane number versus iodine value</span><a class="headerlink" href="#id6" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>G. Practical Conclusions and Limitations</strong></p>
<p>There is compelling evidence (<span class="math notranslate nohighlight">\(p &lt; 0.001\)</span>) of a negative linear association between iodine value and cetane number in
biodiesel fuels. The model explains approximately 79% of the variation in cetane number, suggesting that iodine value
is a useful predictor for this important fuel quality measure.</p>
<p>With only 14 observations, however, our conclusions should be considered preliminary. Larger studies would provide more
definitive results. Some minor violations of the constant variance assumption were noted, which could affect the
reliability of prediction intervals. Predictions should only be made within the range of observed iodine values (59-132).
Extrapolation beyond this range is not justified.</p>
</div>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">13.4.6. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>Interpolation is safe, extrapolation is dangerous</strong>. Predictions should only be made within the range of observed
explanatory variable values used to fit the model.</p></li>
<li><p><strong>Confidence intervals for mean response</strong> estimate
average behavior, while <strong>prediction intervals for individual observations</strong> account for additional uncertainty from
new error terms. For this reason, prediction intervals are always wider than confidence intervals for means response.</p></li>
<li><p>The Central Limit Theorem provides robustness for estimators that ivolve averaging, but
<strong>individual predictions are not robust to normality violations</strong>.</p></li>
</ol>
</div>
</section>
<section id="exercises">
<h2><span class="section-number">13.4.7. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h2>
<div class="note admonition">
<p class="admonition-title">Exercise 1: Confidence Interval vs. Prediction Interval</p>
<p>A manufacturing engineer has developed a regression model relating machine runtime (hours) to production output (units): <span class="math notranslate nohighlight">\(\hat{y} = 120 + 85x\)</span>.</p>
<p>For <span class="math notranslate nohighlight">\(x^* = 8\)</span> hours:</p>
<ol class="loweralpha simple">
<li><p>What is the point prediction for production output?</p></li>
<li><p>Explain the difference between:</p>
<ul class="simple">
<li><p>A confidence interval for the mean response at <span class="math notranslate nohighlight">\(x^* = 8\)</span></p></li>
<li><p>A prediction interval for an individual response at <span class="math notranslate nohighlight">\(x^* = 8\)</span></p></li>
</ul>
</li>
<li><p>Which interval will always be wider? Explain why mathematically.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Point prediction</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(\hat{y} = 120 + 85(8) = 120 + 680 = 800\)</span> units</p>
<p class="sd-card-text"><strong>Part (b): Difference between intervals</strong></p>
<p class="sd-card-text"><strong>CI for mean response:</strong> Estimates the <em>average</em> production output across ALL 8-hour runs. The uncertainty comes only from estimating the regression line (where is the true line?).</p>
<p class="sd-card-text"><strong>PI for individual:</strong> Predicts the output for a <em>single</em> 8-hour run. The uncertainty includes both:</p>
<ol class="arabic simple">
<li><p class="sd-card-text">Regression line estimation (same as CI)</p></li>
<li><p class="sd-card-text">Random variation of individual observations around the true line</p></li>
</ol>
<p class="sd-card-text"><strong>Part (c): Which is wider?</strong></p>
<p class="sd-card-text">The <strong>prediction interval is always wider</strong> because of the mathematical structure:</p>
<div class="math notranslate nohighlight">
\[\text{Var}(\hat{\mu}^*) = \sigma^2\left(\frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right)\]</div>
<div class="math notranslate nohighlight">
\[\text{Var}(\hat{Y}^*) = \sigma^2\left(1 + \frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right)\]</div>
<p class="sd-card-text">The extra “+1” in the PI formula accounts for individual variation (<span class="math notranslate nohighlight">\(\sigma^2\)</span>), which is always positive.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 2: Computing Prediction Intervals</p>
<p>Using the production output regression from Exercise 1 with the following additional information:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n = 20\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{x} = 6.5\)</span> hours</p></li>
<li><p><span class="math notranslate nohighlight">\(MSE = 2500\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(S_{XX} = 180\)</span></p></li>
</ul>
<p>For <span class="math notranslate nohighlight">\(x^* = 8\)</span> hours:</p>
<ol class="loweralpha simple">
<li><p>Calculate <span class="math notranslate nohighlight">\(SE_{\hat{\mu}^*}\)</span> (standard error for mean response).</p></li>
<li><p>Construct a 95% confidence interval for the mean production output when runtime is 8 hours.</p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(SE_{\hat{Y}^*}\)</span> (standard error for individual prediction).</p></li>
<li><p>Construct a 95% prediction interval for the production output of a single run lasting 8 hours.</p></li>
<li><p>Compare the widths of the two intervals. What explains the difference?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): SE for mean response</strong></p>
<div class="math notranslate nohighlight">
\[SE_{\hat{\mu}^*} = \sqrt{MSE\left(\frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right)} = \sqrt{2500\left(\frac{1}{20} + \frac{(8-6.5)^2}{180}\right)}\]</div>
<div class="math notranslate nohighlight">
\[= \sqrt{2500\left(0.05 + \frac{2.25}{180}\right)} = \sqrt{2500(0.05 + 0.0125)} = \sqrt{2500(0.0625)} = \sqrt{156.25} = 12.50\]</div>
<p class="sd-card-text"><strong>Part (b): 95% CI for mean response</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(df = n - 2 = 18\)</span>, <span class="math notranslate nohighlight">\(t_{0.025, 18} = 2.101\)</span></p>
<div class="math notranslate nohighlight">
\[CI = \hat{y} \pm t^* \cdot SE_{\hat{\mu}^*} = 800 \pm 2.101(12.50) = 800 \pm 26.26\]</div>
<p class="sd-card-text"><strong>95% CI: (773.74, 826.26)</strong> units</p>
<p class="sd-card-text">We are 95% confident that the average production for all 8-hour runs is between 774 and 826 units.</p>
<p class="sd-card-text"><strong>Part (c): SE for individual prediction</strong></p>
<div class="math notranslate nohighlight">
\[SE_{\hat{Y}^*} = \sqrt{MSE\left(1 + \frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\right)} = \sqrt{2500\left(1 + 0.0625\right)} = \sqrt{2656.25} = 51.54\]</div>
<p class="sd-card-text"><strong>Part (d): 95% PI for individual</strong></p>
<div class="math notranslate nohighlight">
\[PI = \hat{y} \pm t^* \cdot SE_{\hat{Y}^*} = 800 \pm 2.101(51.54) = 800 \pm 108.29\]</div>
<p class="sd-card-text"><strong>95% PI: (691.71, 908.29)</strong> units</p>
<p class="sd-card-text">We are 95% confident that a single 8-hour run will produce between 692 and 908 units.</p>
<p class="sd-card-text"><strong>Part (e): Width comparison</strong></p>
<ul class="simple">
<li><p class="sd-card-text">CI width = 2 × 26.26 = 52.5 units</p></li>
<li><p class="sd-card-text">PI width = 2 × 108.29 = 216.6 units</p></li>
</ul>
<p class="sd-card-text">The PI is <strong>4.1 times wider</strong> than the CI. The difference is due to the “+1” term in the PI variance formula, which accounts for individual variation around the regression line.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 3: Extrapolation Warning</p>
<figure class="align-center" id="id7">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch13-4/fig1_extrapolation.png"><img alt="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch13-4/fig1_extrapolation.png" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch13-4/fig1_extrapolation.png" style="width: 70%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 13.38 </span><span class="caption-text">Scatter plot with regression line and extrapolation regions</span><a class="headerlink" href="#id7" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>A data analyst developed a regression model predicting website load time (Y, seconds) from page size (X, MB) using data where X ranged from 0.5 to 4.0 MB.</p>
<p>The fitted model is <span class="math notranslate nohighlight">\(\hat{y} = 0.8 + 0.6x\)</span>.</p>
<ol class="loweralpha simple">
<li><p>For a 2.5 MB page, calculate the predicted load time. Is this interpolation or extrapolation?</p></li>
<li><p>For a 7.0 MB page, calculate the predicted load time. Is this interpolation or extrapolation?</p></li>
<li><p>Why should the analyst be cautious about the prediction in part (b)?</p></li>
<li><p>The model predicts <span class="math notranslate nohighlight">\(\hat{y} = -0.4\)</span> seconds for <span class="math notranslate nohighlight">\(x = -2\)</span>. What does this impossible prediction tell us about extrapolation?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Prediction at x = 2.5</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(\hat{y} = 0.8 + 0.6(2.5) = 0.8 + 1.5 = 2.3\)</span> seconds</p>
<p class="sd-card-text">This is <strong>interpolation</strong> because 2.5 MB is within the observed range of 0.5 to 4.0 MB.</p>
<p class="sd-card-text"><strong>Part (b): Prediction at x = 7.0</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(\hat{y} = 0.8 + 0.6(7.0) = 0.8 + 4.2 = 5.0\)</span> seconds</p>
<p class="sd-card-text">This is <strong>extrapolation</strong> because 7.0 MB is outside the observed range of 0.5 to 4.0 MB.</p>
<p class="sd-card-text"><strong>Part (c): Cautions about extrapolation</strong></p>
<p class="sd-card-text">The analyst should be cautious because:</p>
<ul class="simple">
<li><p class="sd-card-text">No data supports the linear relationship beyond 4.0 MB</p></li>
<li><p class="sd-card-text">The relationship may curve, plateau, or change behavior at larger file sizes</p></li>
<li><p class="sd-card-text">Server behavior at large page sizes may differ fundamentally (caching, timeout limits)</p></li>
<li><p class="sd-card-text">Uncertainty is much higher outside the observed range</p></li>
<li><p class="sd-card-text">The linear model is only validated within the observed data range</p></li>
</ul>
<p class="sd-card-text"><strong>Part (d): Impossible prediction</strong></p>
<p class="sd-card-text">The prediction of −0.4 seconds for x = −2 MB demonstrates that extrapolation can produce <strong>nonsensical results</strong>.</p>
<p class="sd-card-text">This shows that:</p>
<ul class="simple">
<li><p class="sd-card-text">Linear models are only approximations valid within the observed range</p></li>
<li><p class="sd-card-text">The mathematical equation has no physical constraints</p></li>
<li><p class="sd-card-text">Extrapolation can lead to predictions that violate reality (negative time, negative file size)</p></li>
<li><p class="sd-card-text">The model should never be used outside its validated range</p></li>
</ul>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 4: Effect of x* Location on Interval Width</p>
<p>The variance of the mean response estimator is:</p>
<div class="math notranslate nohighlight">
\[\text{Var}(\hat{\mu}^*) = \sigma^2 \left( \frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}} \right)\]</div>
<ol class="loweralpha simple">
<li><p>At what value of <span class="math notranslate nohighlight">\(x^*\)</span> is this variance minimized?</p></li>
<li><p>What happens to the variance as <span class="math notranslate nohighlight">\(x^*\)</span> moves further from <span class="math notranslate nohighlight">\(\bar{x}\)</span>?</p></li>
<li><p>Explain intuitively why predictions are most precise near <span class="math notranslate nohighlight">\(\bar{x}\)</span>.</p></li>
<li><p>How does this relate to the danger of extrapolation?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Minimum variance location</strong></p>
<p class="sd-card-text">Variance is minimized when <span class="math notranslate nohighlight">\(x^* = \bar{x}\)</span>.</p>
<p class="sd-card-text">At this point, the term <span class="math notranslate nohighlight">\(\frac{(x^* - \bar{x})^2}{S_{XX}} = 0\)</span>, leaving only the <span class="math notranslate nohighlight">\(\frac{1}{n}\)</span> term.</p>
<p class="sd-card-text"><strong>Part (b): Variance as x* moves away</strong></p>
<p class="sd-card-text">Variance <strong>increases</strong> as <span class="math notranslate nohighlight">\(|x^* - \bar{x}|\)</span> increases.</p>
<p class="sd-card-text">The increase is quadratic because of the <span class="math notranslate nohighlight">\((x^* - \bar{x})^2\)</span> term. Moving twice as far from <span class="math notranslate nohighlight">\(\bar{x}\)</span> quadruples this component of variance.</p>
<p class="sd-card-text"><strong>Part (c): Intuitive explanation</strong></p>
<p class="sd-card-text">We have the most information about Y near the center of our X data because:</p>
<ul class="simple">
<li><p class="sd-card-text">The regression line is “anchored” at <span class="math notranslate nohighlight">\((\bar{x}, \bar{y})\)</span></p></li>
<li><p class="sd-card-text">Near <span class="math notranslate nohighlight">\(\bar{x}\)</span>, small errors in slope estimation have minimal effect</p></li>
<li><p class="sd-card-text">Far from <span class="math notranslate nohighlight">\(\bar{x}\)</span>, slope errors get amplified (like a lever arm)</p></li>
<li><p class="sd-card-text">More data points cluster near the middle in most datasets</p></li>
</ul>
<p class="sd-card-text"><strong>Part (d): Connection to extrapolation</strong></p>
<p class="sd-card-text">As <span class="math notranslate nohighlight">\(x^*\)</span> moves outside the data range:</p>
<ul class="simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\((x^* - \bar{x})^2\)</span> grows very large</p></li>
<li><p class="sd-card-text">Prediction variance becomes extremely high</p></li>
<li><p class="sd-card-text">Confidence and prediction intervals become very wide</p></li>
<li><p class="sd-card-text">The mathematical uncertainty reflects real scientific uncertainty</p></li>
</ul>
<p class="sd-card-text">This is why extrapolation is unreliable — the variance formula mathematically captures the increasing uncertainty.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 5: Prediction Using R Output</p>
<p>From a regression of compressive strength (psi) on curing time (days) for concrete:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;</span><span class="w"> </span><span class="n">fit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">Strength</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Time</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">concrete</span><span class="p">)</span>
<span class="o">&gt;</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="n">Coefficients</span><span class="o">:</span>
<span class="w">            </span><span class="n">Estimate</span><span class="w"> </span><span class="n">Std.</span><span class="w"> </span><span class="n">Error</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="nf">Pr</span><span class="p">(</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span><span class="p">)</span>
<span class="p">(</span><span class="n">Intercept</span><span class="p">)</span><span class="w"> </span><span class="m">1850.000</span><span class="w">    </span><span class="m">125.400</span><span class="w">  </span><span class="m">14.752</span><span class="w">  </span><span class="o">&lt;</span><span class="w"> </span><span class="m">2e-16</span><span class="w"> </span><span class="o">***</span>
<span class="n">Time</span><span class="w">         </span><span class="m">180.500</span><span class="w">     </span><span class="m">18.200</span><span class="w">   </span><span class="m">9.918</span><span class="w"> </span><span class="m">3.45e-10</span><span class="w"> </span><span class="o">***</span>

<span class="n">Residual</span><span class="w"> </span><span class="n">standard</span><span class="w"> </span><span class="n">error</span><span class="o">:</span><span class="w"> </span><span class="m">245.6</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="m">28</span><span class="w"> </span><span class="n">degrees</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">freedom</span>

<span class="o">&gt;</span><span class="w"> </span><span class="n">new_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">Time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">14</span><span class="p">)</span>
<span class="o">&gt;</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">new_data</span><span class="p">,</span><span class="w"> </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;confidence&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span>
<span class="w">       </span><span class="n">fit</span><span class="w">      </span><span class="n">lwr</span><span class="w">      </span><span class="n">upr</span>
<span class="m">1</span><span class="w"> </span><span class="m">4377.000</span><span class="w"> </span><span class="m">4256.123</span><span class="w"> </span><span class="m">4497.877</span>

<span class="o">&gt;</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">new_data</span><span class="p">,</span><span class="w"> </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;prediction&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span>
<span class="w">       </span><span class="n">fit</span><span class="w">      </span><span class="n">lwr</span><span class="w">      </span><span class="n">upr</span>
<span class="m">1</span><span class="w"> </span><span class="m">4377.000</span><span class="w"> </span><span class="m">3862.456</span><span class="w"> </span><span class="m">4891.544</span>
</pre></div>
</div>
<ol class="loweralpha simple">
<li><p>Write the fitted regression equation.</p></li>
<li><p>Calculate the predicted strength at 14 days using your equation. Verify it matches the output.</p></li>
<li><p>Interpret the 95% confidence interval for mean response in context.</p></li>
<li><p>Interpret the 95% prediction interval in context.</p></li>
<li><p>Why is the prediction interval so much wider than the confidence interval?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Fitted equation</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(\widehat{Strength} = 1850 + 180.5 \times Time\)</span></p>
<p class="sd-card-text"><strong>Part (b): Verification</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(\hat{y} = 1850 + 180.5(14) = 1850 + 2527 = 4377\)</span> psi ✓</p>
<p class="sd-card-text">This matches the “fit” value in the R output.</p>
<p class="sd-card-text"><strong>Part (c): CI interpretation</strong></p>
<p class="sd-card-text">We are 95% confident that the <strong>mean</strong> compressive strength of all concrete samples cured for 14 days is between 4256 and 4498 psi.</p>
<p class="sd-card-text"><strong>Part (d): PI interpretation</strong></p>
<p class="sd-card-text">We are 95% confident that a <strong>single new</strong> concrete sample cured for 14 days will have compressive strength between 3862 and 4892 psi.</p>
<p class="sd-card-text"><strong>Part (e): Why PI is wider</strong></p>
<p class="sd-card-text">The PI is wider because it accounts for <strong>individual variation</strong> — a single sample’s strength varies around the mean, adding uncertainty beyond just estimating where the mean is.</p>
<ul class="simple">
<li><p class="sd-card-text">CI width: 4497.877 − 4256.123 = 241.8 psi</p></li>
<li><p class="sd-card-text">PI width: 4891.544 − 3862.456 = 1029.1 psi</p></li>
</ul>
<p class="sd-card-text">The PI is about 4.3 times wider, reflecting the additional <span class="math notranslate nohighlight">\(\sigma^2\)</span> term in the variance formula.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 6: CLT and Prediction Robustness</p>
<p>Consider a regression model where the true errors follow a skewed distribution rather than a normal distribution.</p>
<ol class="loweralpha simple">
<li><p>Will the point estimates <span class="math notranslate nohighlight">\(b_0\)</span> and <span class="math notranslate nohighlight">\(b_1\)</span> still be unbiased? Explain.</p></li>
<li><p>For large samples, will confidence intervals for <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span> still achieve approximately nominal coverage? Why?</p></li>
<li><p>For large samples, will confidence intervals for the mean response <span class="math notranslate nohighlight">\(\mu^*\)</span> still work well? Why?</p></li>
<li><p>For large samples, will prediction intervals for individual responses still achieve nominal coverage? Explain why the CLT doesn’t help here.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Unbiasedness of estimates</strong></p>
<p class="sd-card-text"><strong>Yes</strong>, <span class="math notranslate nohighlight">\(b_0\)</span> and <span class="math notranslate nohighlight">\(b_1\)</span> are still unbiased.</p>
<p class="sd-card-text">Unbiasedness requires:</p>
<ul class="simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(E[\varepsilon_i] = 0\)</span> (errors have mean zero)</p></li>
<li><p class="sd-card-text">Correct model specification (linearity)</p></li>
</ul>
<p class="sd-card-text">Normality is NOT required for unbiasedness. The least squares estimates are BLUE (Best Linear Unbiased Estimators) regardless of the error distribution.</p>
<p class="sd-card-text"><strong>Part (b): CIs for coefficients</strong></p>
<p class="sd-card-text"><strong>Yes</strong>, approximately. For large samples, the Central Limit Theorem ensures that <span class="math notranslate nohighlight">\(b_0\)</span> and <span class="math notranslate nohighlight">\(b_1\)</span> are approximately normally distributed, regardless of the error distribution.</p>
<p class="sd-card-text">Since the t-intervals rely on this normality, they achieve approximately nominal coverage for large n.</p>
<p class="sd-card-text"><strong>Part (c): CI for mean response</strong></p>
<p class="sd-card-text"><strong>Yes</strong>. The estimator <span class="math notranslate nohighlight">\(\hat{\mu}^* = b_0 + b_1 x^*\)</span> is a weighted average of the Y values, so the CLT applies. For large samples, <span class="math notranslate nohighlight">\(\hat{\mu}^*\)</span> is approximately normal, and the confidence interval works well.</p>
<p class="sd-card-text"><strong>Part (d): PI for individual responses</strong></p>
<p class="sd-card-text"><strong>No</strong>, the CLT does not help prediction intervals.</p>
<p class="sd-card-text">The prediction interval accounts for a <strong>new error</strong> <span class="math notranslate nohighlight">\(\varepsilon_{new}\)</span>:</p>
<div class="math notranslate nohighlight">
\[Y_{new} = \beta_0 + \beta_1 x^* + \varepsilon_{new}\]</div>
<p class="sd-card-text">This new error is NOT averaged — it retains its original (skewed) distribution. The PI formula assumes <span class="math notranslate nohighlight">\(\varepsilon_{new} \sim N(0, \sigma^2)\)</span>, so if errors are actually skewed, the PI can have poor coverage even with large n.</p>
<p class="sd-card-text">This is a fundamental limitation: we can’t “average away” individual variation.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 7: Complete Regression Analysis</p>
<p>An environmental engineer studies the relationship between industrial wastewater pH (X) and dissolved oxygen concentration (Y, mg/L) in a river. Data from <span class="math notranslate nohighlight">\(n = 22\)</span> sampling sites yields:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Fitted model: Y_hat = 12.8 - 0.95X

Summary Statistics:
- x_bar = 6.8
- S_XX = 45.2
- MSE = 2.89
- R² = 0.68
</pre></div>
</div>
<ol class="loweralpha simple">
<li><p>Interpret the slope in context.</p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(SE_{b_1}\)</span> and test whether pH has a significant effect on dissolved oxygen at <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>.</p></li>
<li><p>For a new site with pH = 7.2:</p>
<ul class="simple">
<li><p>Calculate the point prediction</p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(SE_{\hat{\mu}^*}\)</span> and construct a 95% CI for mean DO</p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(SE_{\hat{Y}^*}\)</span> and construct a 95% PI for an individual observation</p></li>
</ul>
</li>
<li><p>A site upstream has pH = 4.5 (outside the observed range of 5.8 to 8.2). Should the engineer use this model to predict DO at that site? Explain.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Slope interpretation</strong></p>
<p class="sd-card-text">For each unit increase in pH, dissolved oxygen concentration decreases by 0.95 mg/L, on average.</p>
<p class="sd-card-text"><strong>Part (b): Hypothesis test</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(SE_{b_1} = \sqrt{\frac{MSE}{S_{XX}}} = \sqrt{\frac{2.89}{45.2}} = \sqrt{0.0639} = 0.253\)</span></p>
<p class="sd-card-text">Test: <span class="math notranslate nohighlight">\(H_0: \beta_1 = 0\)</span> vs. <span class="math notranslate nohighlight">\(H_a: \beta_1 \neq 0\)</span></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(t_{TS} = \frac{-0.95 - 0}{0.253} = -3.76\)</span></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(df = 22 - 2 = 20\)</span></p>
<p class="sd-card-text">P-value = <code class="docutils literal notranslate"><span class="pre">2</span> <span class="pre">*</span> <span class="pre">pt(3.76,</span> <span class="pre">20,</span> <span class="pre">lower.tail</span> <span class="pre">=</span> <span class="pre">FALSE)</span></code> = 0.0012</p>
<p class="sd-card-text">At <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, since 0.0012 &lt; 0.05, <strong>reject</strong> <span class="math notranslate nohighlight">\(H_0\)</span>. There is sufficient evidence of a significant linear relationship between pH and dissolved oxygen.</p>
<p class="sd-card-text"><strong>Part (c): Predictions at x* = 7.2</strong></p>
<p class="sd-card-text"><strong>Point prediction:</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(\hat{y} = 12.8 - 0.95(7.2) = 12.8 - 6.84 = 5.96\)</span> mg/L</p>
<p class="sd-card-text"><strong>SE for mean response:</strong></p>
<div class="math notranslate nohighlight">
\[SE_{\hat{\mu}^*} = \sqrt{2.89\left(\frac{1}{22} + \frac{(7.2-6.8)^2}{45.2}\right)} = \sqrt{2.89(0.0455 + 0.00354)} = \sqrt{2.89(0.0490)} = 0.376\]</div>
<p class="sd-card-text"><strong>95% CI:</strong> <span class="math notranslate nohighlight">\(t_{0.025, 20} = 2.086\)</span></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(CI = 5.96 \pm 2.086(0.376) = 5.96 \pm 0.78\)</span></p>
<p class="sd-card-text"><strong>95% CI: (5.18, 6.74)</strong> mg/L</p>
<p class="sd-card-text"><strong>SE for individual:</strong></p>
<div class="math notranslate nohighlight">
\[SE_{\hat{Y}^*} = \sqrt{2.89\left(1 + \frac{1}{22} + \frac{0.16}{45.2}\right)} = \sqrt{2.89(1.049)} = \sqrt{3.032} = 1.741\]</div>
<p class="sd-card-text"><strong>95% PI:</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(PI = 5.96 \pm 2.086(1.741) = 5.96 \pm 3.63\)</span></p>
<p class="sd-card-text"><strong>95% PI: (2.33, 9.59)</strong> mg/L</p>
<p class="sd-card-text"><strong>Part (d): Extrapolation warning</strong></p>
<p class="sd-card-text"><strong>No</strong>, the engineer should NOT use this model for pH = 4.5 because:</p>
<ul class="simple">
<li><p class="sd-card-text">This is outside the observed range (5.8 to 8.2) — extrapolation</p></li>
<li><p class="sd-card-text">Chemical relationships may change at extreme pH values</p></li>
<li><p class="sd-card-text">The linear model is not validated for acidic conditions</p></li>
<li><p class="sd-card-text">The prediction would have very high uncertainty</p></li>
</ul>
<p class="sd-card-text">The engineer should collect data at lower pH values before making predictions in that range.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 8: Confidence and Prediction Bands</p>
<figure class="align-center" id="id8">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch13-4/fig2_bands.png"><img alt="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch13-4/fig2_bands.png" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch13-4/fig2_bands.png" style="width: 75%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 13.39 </span><span class="caption-text">Regression line with confidence and prediction bands</span><a class="headerlink" href="#id8" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>The figure shows a fitted regression line with two sets of bands.</p>
<ol class="loweralpha simple">
<li><p>Identify which bands are the confidence bands (for mean response) and which are the prediction bands.</p></li>
<li><p>Why do both sets of bands have a “curved” shape rather than being parallel to the regression line?</p></li>
<li><p>At what X value are the bands narrowest? Why?</p></li>
<li><p>If sample size increased substantially, what would happen to:</p>
<ul class="simple">
<li><p>The confidence bands?</p></li>
<li><p>The prediction bands?</p></li>
</ul>
</li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Identifying bands</strong></p>
<ul class="simple">
<li><p class="sd-card-text"><strong>Inner bands (darker/narrower):</strong> Confidence bands for mean response</p></li>
<li><p class="sd-card-text"><strong>Outer bands (lighter/wider):</strong> Prediction bands for individual observations</p></li>
</ul>
<p class="sd-card-text">The prediction bands are always wider because they include individual variation.</p>
<p class="sd-card-text"><strong>Part (b): Curved shape</strong></p>
<p class="sd-card-text">Both sets of bands are curved because the variance depends on <span class="math notranslate nohighlight">\((x^* - \bar{x})^2\)</span>:</p>
<div class="math notranslate nohighlight">
\[\text{Var} \propto \frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{XX}}\]</div>
<p class="sd-card-text">As <span class="math notranslate nohighlight">\(x^*\)</span> moves away from <span class="math notranslate nohighlight">\(\bar{x}\)</span>, the second term increases, making the bands wider. This creates the characteristic “bowtie” or “hyperbolic” shape.</p>
<p class="sd-card-text"><strong>Part (c): Narrowest location</strong></p>
<p class="sd-card-text">Both bands are narrowest at <span class="math notranslate nohighlight">\(x = \bar{x}\)</span> (the mean of X).</p>
<p class="sd-card-text">At this point, <span class="math notranslate nohighlight">\((x^* - \bar{x})^2 = 0\)</span>, minimizing the variance formula. This is where we have the most precise estimates.</p>
<p class="sd-card-text"><strong>Part (d): Effect of increasing n</strong></p>
<p class="sd-card-text"><strong>Confidence bands:</strong> Will shrink substantially. The <span class="math notranslate nohighlight">\(\frac{1}{n}\)</span> term decreases, and the overall estimation uncertainty decreases with more data.</p>
<p class="sd-card-text"><strong>Prediction bands:</strong> Will shrink only slightly. While the <span class="math notranslate nohighlight">\(\frac{1}{n}\)</span> term decreases, the dominant “+1” term (representing <span class="math notranslate nohighlight">\(\sigma^2\)</span> for individual variation) remains unchanged. Individual observations will always vary around the line regardless of how precisely we estimate the line.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 9: Comprehensive Case Study</p>
<p>A pharmaceutical company studies the relationship between drug concentration in blood plasma (X, μg/mL) and time to symptom relief (Y, minutes) for <span class="math notranslate nohighlight">\(n = 30\)</span> patients. Complete analysis:</p>
<figure class="align-center" id="id9">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch13-4/fig3_pharma_diagnostics.png"><img alt="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch13-4/fig3_pharma_diagnostics.png" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch13-4/fig3_pharma_diagnostics.png" style="width: 95%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 13.40 </span><span class="caption-text">Diagnostic plots for pharmaceutical data</span><a class="headerlink" href="#id9" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Regression output:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Y_hat = 95.2 - 8.4X

ANOVA:
Source      df    SS       MS        F
Regression   1   4256    4256    42.56
Error       28   2800     100
Total       29   7056

Additional: x_bar = 5.5, S_XX = 168
</pre></div>
</div>
<ol class="loweralpha simple">
<li><p>Assess the model assumptions using the diagnostic plots.</p></li>
<li><p>Calculate and interpret <span class="math notranslate nohighlight">\(R^2\)</span>.</p></li>
<li><p>Test model utility at <span class="math notranslate nohighlight">\(\alpha = 0.01\)</span> using the four-step procedure.</p></li>
<li><p>Construct a 99% confidence interval for the slope.</p></li>
<li><p>For a patient with plasma concentration <span class="math notranslate nohighlight">\(x^* = 6.0\)</span> μg/mL:</p>
<ul class="simple">
<li><p>Calculate the predicted time to relief</p></li>
<li><p>Construct a 95% CI for mean time to relief</p></li>
<li><p>Construct a 95% PI for this patient’s time to relief</p></li>
<li><p>Which interval should the doctor quote when counseling the individual patient?</p></li>
</ul>
</li>
<li><p>Another patient has <span class="math notranslate nohighlight">\(x^* = 12.0\)</span> μg/mL (outside the data range of 2-9). What should the doctor do?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Assumption assessment</strong></p>
<ul class="simple">
<li><p class="sd-card-text"><strong>Linearity:</strong> ✓ Satisfied — residual plot shows random scatter around zero, no curvature</p></li>
<li><p class="sd-card-text"><strong>Independence:</strong> Assumed satisfied (cross-sectional patient data)</p></li>
<li><p class="sd-card-text"><strong>Normality:</strong> ✓ Approximately satisfied — histogram roughly symmetric, QQ-plot points near the line</p></li>
<li><p class="sd-card-text"><strong>Equal variance:</strong> ✓ Approximately satisfied — residual plot shows consistent spread</p></li>
</ul>
<p class="sd-card-text">All LINE assumptions appear reasonably satisfied.</p>
<p class="sd-card-text"><strong>Part (b): R² calculation and interpretation</strong></p>
<div class="math notranslate nohighlight">
\[R^2 = \frac{SSR}{SST} = \frac{4256}{7056} = 0.603\]</div>
<p class="sd-card-text">Approximately 60.3% of the variation in time to symptom relief is explained by the linear relationship with drug concentration.</p>
<p class="sd-card-text"><strong>Part (c): Model utility test</strong></p>
<p class="sd-card-text"><strong>Step 1:</strong> Let <span class="math notranslate nohighlight">\(\beta_1\)</span> = the true change in relief time (minutes) per μg/mL increase in drug concentration.</p>
<p class="sd-card-text"><strong>Step 2:</strong></p>
<ul class="simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(H_0: \beta_1 = 0\)</span> (no linear relationship)</p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(H_a: \beta_1 \neq 0\)</span> (linear relationship exists)</p></li>
</ul>
<p class="sd-card-text"><strong>Step 3:</strong> From ANOVA table: <span class="math notranslate nohighlight">\(F_{TS} = 42.56\)</span> with df = (1, 28)</p>
<p class="sd-card-text">P-value = <code class="docutils literal notranslate"><span class="pre">pf(42.56,</span> <span class="pre">1,</span> <span class="pre">28,</span> <span class="pre">lower.tail</span> <span class="pre">=</span> <span class="pre">FALSE)</span></code> = 4.2 × 10⁻⁷</p>
<p class="sd-card-text"><strong>Step 4:</strong> At <span class="math notranslate nohighlight">\(\alpha = 0.01\)</span>, since p-value (4.2 × 10⁻⁷) &lt; 0.01, we <strong>reject</strong> <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<p class="sd-card-text">There is sufficient evidence to conclude that drug concentration has a significant linear relationship with time to symptom relief.</p>
<p class="sd-card-text"><strong>Part (d): 99% CI for slope</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(SE_{b_1} = \sqrt{\frac{MSE}{S_{XX}}} = \sqrt{\frac{100}{168}} = 0.772\)</span></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(t_{0.005, 28} = 2.763\)</span></p>
<div class="math notranslate nohighlight">
\[CI = -8.4 \pm 2.763(0.772) = -8.4 \pm 2.13\]</div>
<p class="sd-card-text"><strong>99% CI: (−10.53, −6.27)</strong></p>
<p class="sd-card-text"><strong>Part (e): Predictions at x* = 6.0</strong></p>
<p class="sd-card-text"><strong>Point prediction:</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(\hat{y} = 95.2 - 8.4(6.0) = 95.2 - 50.4 = 44.8\)</span> minutes</p>
<p class="sd-card-text"><strong>SE for mean response:</strong></p>
<div class="math notranslate nohighlight">
\[SE_{\hat{\mu}^*} = \sqrt{100\left(\frac{1}{30} + \frac{(6.0-5.5)^2}{168}\right)} = \sqrt{100(0.0333 + 0.00149)} = \sqrt{3.48} = 1.87\]</div>
<p class="sd-card-text"><strong>95% CI:</strong> <span class="math notranslate nohighlight">\(t_{0.025, 28} = 2.048\)</span></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(CI = 44.8 \pm 2.048(1.87) = 44.8 \pm 3.83\)</span></p>
<p class="sd-card-text"><strong>95% CI: (40.97, 48.63)</strong> minutes</p>
<p class="sd-card-text"><strong>SE for individual:</strong></p>
<div class="math notranslate nohighlight">
\[SE_{\hat{Y}^*} = \sqrt{100\left(1 + \frac{1}{30} + \frac{0.25}{168}\right)} = \sqrt{100(1.0348)} = 10.17\]</div>
<p class="sd-card-text"><strong>95% PI:</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(PI = 44.8 \pm 2.048(10.17) = 44.8 \pm 20.83\)</span></p>
<p class="sd-card-text"><strong>95% PI: (23.97, 65.63)</strong> minutes</p>
<p class="sd-card-text"><strong>Which to quote?</strong> The doctor should quote the <strong>prediction interval</strong> (24 to 66 minutes) when counseling the individual patient, because this captures the uncertainty for a single person’s response, not just the average.</p>
<p class="sd-card-text"><strong>Part (f): Extrapolation warning</strong></p>
<p class="sd-card-text">The doctor should <strong>NOT use this model</strong> for x* = 12.0 μg/mL because:</p>
<ul class="simple">
<li><p class="sd-card-text">This is outside the observed data range (2-9 μg/mL)</p></li>
<li><p class="sd-card-text">Extrapolation is unreliable</p></li>
<li><p class="sd-card-text">Drug effects may plateau or become toxic at high concentrations</p></li>
<li><p class="sd-card-text">The linear relationship is not validated at this concentration</p></li>
</ul>
<p class="sd-card-text"><strong>Recommendation:</strong> Conduct additional studies at higher concentrations before making predictions, or use pharmacokinetic models appropriate for that dose range.</p>
</div>
</details></div>
</section>
<hr class="docutils" />
<section id="additional-practice-problems">
<h2><span class="section-number">13.4.8. </span>Additional Practice Problems<a class="headerlink" href="#additional-practice-problems" title="Link to this heading"></a></h2>
<p><strong>Practice 1:</strong> A study finds <span class="math notranslate nohighlight">\(r = 0.75\)</span> between study time and exam score. Calculate and interpret <span class="math notranslate nohighlight">\(R^2\)</span>.</p>
<p><strong>Practice 2:</strong> Given <span class="math notranslate nohighlight">\(b_1 = 2.5\)</span>, <span class="math notranslate nohighlight">\(SE_{b_1} = 0.8\)</span>, <span class="math notranslate nohighlight">\(n = 25\)</span>:</p>
<ol class="loweralpha simple">
<li><p>Construct a 95% CI for <span class="math notranslate nohighlight">\(\beta_1\)</span></p></li>
<li><p>Test <span class="math notranslate nohighlight">\(H_0: \beta_1 = 0\)</span> at <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span></p></li>
</ol>
<p><strong>Practice 3:</strong> For a regression with <span class="math notranslate nohighlight">\(n = 40\)</span>, <span class="math notranslate nohighlight">\(\bar{x} = 50\)</span>, <span class="math notranslate nohighlight">\(S_{XX} = 2000\)</span>, <span class="math notranslate nohighlight">\(MSE = 100\)</span>:</p>
<ol class="loweralpha simple">
<li><p>Calculate <span class="math notranslate nohighlight">\(SE_{\hat{\mu}^*}\)</span> at <span class="math notranslate nohighlight">\(x^* = 55\)</span></p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(SE_{\hat{Y}^*}\)</span> at <span class="math notranslate nohighlight">\(x^* = 55\)</span></p></li>
</ol>
<p><strong>Practice 4:</strong> True or False with justification:</p>
<ol class="loweralpha simple">
<li><p><span class="math notranslate nohighlight">\(R^2 = 0.64\)</span> means 64% of variation in Y is explained by X.</p></li>
<li><p>A significant F-test guarantees the model is useful for prediction.</p></li>
<li><p>Prediction intervals shrink to zero as sample size increases.</p></li>
<li><p>The regression line always passes through <span class="math notranslate nohighlight">\((\bar{x}, \bar{y})\)</span>.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Answers to Practice Problems</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Practice 1:</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(R^2 = r^2 = (0.75)^2 = 0.5625\)</span></p>
<p class="sd-card-text">56.25% of the variation in exam scores is explained by the linear relationship with study time.</p>
<p class="sd-card-text"><strong>Practice 2:</strong></p>
<ol class="loweralpha">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(df = 23\)</span>, <span class="math notranslate nohighlight">\(t_{0.025, 23} = 2.069\)</span></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(CI = 2.5 \pm 2.069(0.8) = 2.5 \pm 1.66\)</span></p>
<p class="sd-card-text"><strong>95% CI: (0.84, 4.16)</strong></p>
</li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(t_{TS} = \frac{2.5}{0.8} = 3.125\)</span></p>
<p class="sd-card-text">P-value = <code class="docutils literal notranslate"><span class="pre">2</span> <span class="pre">*</span> <span class="pre">pt(3.125,</span> <span class="pre">23,</span> <span class="pre">lower.tail</span> <span class="pre">=</span> <span class="pre">FALSE)</span></code> = 0.0048</p>
<p class="sd-card-text">Since 0.0048 &lt; 0.05, <strong>reject</strong> <span class="math notranslate nohighlight">\(H_0\)</span>. Significant relationship exists.</p>
</li>
</ol>
<p class="sd-card-text"><strong>Practice 3:</strong></p>
<ol class="loweralpha simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(SE_{\hat{\mu}^*} = \sqrt{100\left(\frac{1}{40} + \frac{(55-50)^2}{2000}\right)} = \sqrt{100(0.025 + 0.0125)} = \sqrt{3.75} = 1.94\)</span></p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(SE_{\hat{Y}^*} = \sqrt{100\left(1 + \frac{1}{40} + \frac{25}{2000}\right)} = \sqrt{100(1.0375)} = \sqrt{103.75} = 10.19\)</span></p></li>
</ol>
<p class="sd-card-text"><strong>Practice 4:</strong></p>
<ol class="loweralpha simple">
<li><p class="sd-card-text"><strong>TRUE</strong> — This is the correct interpretation of <span class="math notranslate nohighlight">\(R^2\)</span>.</p></li>
<li><p class="sd-card-text"><strong>FALSE</strong> — Statistical significance doesn’t guarantee practical usefulness. A significant model with <span class="math notranslate nohighlight">\(R^2 = 0.05\)</span> explains little variation and makes poor predictions.</p></li>
<li><p class="sd-card-text"><strong>FALSE</strong> — Prediction intervals include individual variation (<span class="math notranslate nohighlight">\(\sigma^2\)</span>), which doesn’t decrease with sample size. PIs shrink slightly but never to zero.</p></li>
<li><p class="sd-card-text"><strong>TRUE</strong> — This is a mathematical property of least squares regression. The fitted line always passes through the point <span class="math notranslate nohighlight">\((\bar{x}, \bar{y})\)</span>.</p></li>
</ol>
</div>
</details></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="13-3-diagnostics-inference.html" class="btn btn-neutral float-left" title="13.3. Model Diagnostics and Statistical Inference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
  <p class="footer-credits-inline">
    <strong>Website Credits:</strong>
    Website development by Dr. Timothy Reese and Halin Shin.
    Generative AI tools were used to draft and refine some prose, code, and documentation; all content was reviewed by the instructors.
    Models: OpenAI o3 (2025-04-16 release) and Anthropic Claude Opus 4.1 (2025-08-05).
  </p>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 

<!-- Floating Chat Button -->
<button id="chatbot-toggle" class="chatbot-fab" aria-label="Open AI Course Assistant" aria-expanded="false">
  <span class="chatbot-fab-badge">BETA</span>
  <svg class="chatbot-fab-icon chatbot-icon-open" fill="none" stroke="currentColor" viewBox="0 0 24 24">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
          d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"/>
  </svg>
  <svg class="chatbot-fab-icon chatbot-icon-close" fill="none" stroke="currentColor" viewBox="0 0 24 24" style="display:none;">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
  </svg>
  <span class="chatbot-fab-text">Ask AI Assistant</span>
</button>

<!-- Chat Panel - Fullscreen -->
<div id="chatbot-panel" class="chatbot-panel" aria-hidden="true">
  <div class="chatbot-panel-topbar">
    <button id="chatbot-close" class="chatbot-panel-close-minimal" aria-label="Close chat">
      <svg width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
      </svg>
    </button>
    <a href="https://advert-cingular-employer-humor.trycloudflare.com/" 
       target="_blank" 
       rel="noopener noreferrer" 
       class="chatbot-newtab">
      <svg width="16" height="16" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
              d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"/>
      </svg>
      Open in new tab
    </a>
  </div>
  <iframe id="chatbot-iframe" class="chatbot-iframe" title="STAT 350 AI Course Assistant"></iframe>
</div>

<script>
(function() {
  const CHATBOT_BASE_URL = 'https://advert-cingular-employer-humor.trycloudflare.com/';
  
  const toggle = document.getElementById('chatbot-toggle');
  const panel = document.getElementById('chatbot-panel');
  const closeBtn = document.getElementById('chatbot-close');
  const iframe = document.getElementById('chatbot-iframe');
  const iconOpen = toggle.querySelector('.chatbot-icon-open');
  const iconClose = toggle.querySelector('.chatbot-icon-close');
  
  let isOpen = false;
  let iframeLoaded = false;
  
  function getPageContext() {
    const pageTitle = document.title || '';
    const pageUrl = window.location.href;
    const pagePath = window.location.pathname;
    
    const h1 = document.querySelector('.rst-content h1, h1');
    const heading = h1 ? h1.textContent.replace(/[¶#]/g, '').trim() : '';
    
    const breadcrumbs = document.querySelectorAll('.wy-breadcrumbs li a');
    const breadcrumbPath = Array.from(breadcrumbs).map(a => a.textContent.trim()).join(' > ');
    
    const chapterMatch = pagePath.match(/chapter(\d+)/i);
    const chapter = chapterMatch ? 'Chapter ' + chapterMatch[1] : '';
    
    return {
      title: heading || pageTitle,
      url: pageUrl,
      path: pagePath,
      breadcrumbs: breadcrumbPath,
      chapter: chapter
    };
  }
  
  function buildChatbotUrl(context) {
    const params = new URLSearchParams();
    if (context.title) params.set('page_title', context.title);
    if (context.url) params.set('page_url', context.url);
    if (context.chapter) params.set('chapter', context.chapter);
    if (context.breadcrumbs) params.set('breadcrumbs', context.breadcrumbs);
    
    const queryString = params.toString();
    return queryString ? CHATBOT_BASE_URL + '?' + queryString : CHATBOT_BASE_URL;
  }
  
  function openChat() {
    const context = getPageContext();
    
    const newUrl = buildChatbotUrl(context);
    if (!iframeLoaded || iframe.dataset.lastUrl !== context.url) {
      iframe.src = newUrl;
      iframe.dataset.lastUrl = context.url;
      iframeLoaded = true;
    }
    
    panel.classList.add('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'false');
    toggle.setAttribute('aria-expanded', 'true');
    iconOpen.style.display = 'none';
    iconClose.style.display = 'block';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Close';
    isOpen = true;
    
    toggle.classList.add('chatbot-fab-opened');
    
    // Prevent body scroll when panel is open
    document.body.style.overflow = 'hidden';
  }
  
  function closeChat() {
    panel.classList.remove('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'true');
    toggle.setAttribute('aria-expanded', 'false');
    iconOpen.style.display = 'block';
    iconClose.style.display = 'none';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Ask AI Assistant';
    isOpen = false;
    
    // Restore body scroll
    document.body.style.overflow = '';
  }
  
  function toggleChat() {
    if (isOpen) {
      closeChat();
    } else {
      openChat();
    }
  }
  
  toggle.addEventListener('click', toggleChat);
  closeBtn.addEventListener('click', closeChat);
  
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape' && isOpen) {
      closeChat();
    }
  });
})();
</script>


</body>
</html>