

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>10.3. Hypothesis Test for the Population Mean When œÉ Is Unknown &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=3c686048" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=8512422d"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="10.4. P-values, Statistical Significance, and Formal Conclusion" href="10-4-pvalue-significance-conclusion.html" />
    <link rel="prev" title="10.2. Hypothesis Test for the Population Mean When œÉ is Known" href="10-2-ht-for-mean-sigma-known.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#simulation-exercise">Simulation Exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes‚Äô Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes‚Äô Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Shape &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes‚Äô Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Discrete Random Variables and the CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When œÉ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">10. Hypothesis Testing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When œÉ is Known</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">10.3. Hypothesis Test for the Population Mean When œÉ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">10. </span>Hypothesis Testing</a></li>
      <li class="breadcrumb-item active"><span class="section-number">10.3. </span>Hypothesis Test for the Population Mean When œÉ Is Unknown</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter10/lectures/10-3-ht-for-mean-sigma-unknown.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch10-3">
   <iframe
      id="video-ch10-3"
      title="STAT 350 ‚Äì Chapter 10.3 Hypothesis Test and Confidence Interval-Bound Video"
      src="https://www.youtube.com/embed/oVXZ-UAhrwQ?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="hypothesis-test-for-the-population-mean-when-is-unknown">
<h1><span class="section-number">10.3. </span>Hypothesis Test for the Population Mean When œÉ Is Unknown<a class="headerlink" href="#hypothesis-test-for-the-population-mean-when-is-unknown" title="Link to this heading">ÔÉÅ</a></h1>
<p>Hypothesis testing and confidence intervals are complementary tools that approach statistical inference from different angles.
While hypothesis tests provide yes-or-no answers about specific parameter values, confidence intervals give us ranges of plausible
values. Understanding their deep connection not only provides computational shortcuts but also reinforces the underlying logic of
statistical inference.</p>
<div class="important admonition">
<p class="admonition-title">Road Map üß≠</p>
<ul class="simple">
<li><p><strong>Problem we will solve</strong> ‚Äì How hypothesis tests and confidence intervals/bounds are two sides of the same coin, and how to extend these relationships when œÉ is unknown</p></li>
<li><p><strong>Tool we‚Äôll learn</strong> ‚Äì The duality principle connecting tests and intervals, then t-procedures when œÉ must be estimated</p></li>
<li><p><strong>How it fits</strong> ‚Äì This completes our understanding of inference for population means, showing how different approaches yield consistent conclusions</p></li>
</ul>
</div>
<section id="the-duality-of-hypothesis-tests-and-confidence-intervals">
<h2><span class="section-number">10.3.1. </span>The Duality of Hypothesis Tests and Confidence Intervals<a class="headerlink" href="#the-duality-of-hypothesis-tests-and-confidence-intervals" title="Link to this heading">ÔÉÅ</a></h2>
<p><strong>Two Perspectives on the Same Question</strong></p>
<p>Confidence intervals and hypothesis tests address the same fundamental question from different angles:</p>
<ul class="simple">
<li><p><strong>Confidence intervals</strong> quantify uncertainty in our estimation of unknown population parameters, providing a region of plausible values for the truth</p></li>
<li><p><strong>Hypothesis tests</strong> start from a specific assumption and assess whether our data provides sufficient evidence to reject that assumption</p></li>
</ul>
<p>The key insight is that these approaches are mathematically equivalent under certain conditions. A confidence interval contains exactly those null hypothesis values that would <strong>not be rejected</strong> in a corresponding hypothesis test.</p>
<p><strong>The Fundamental Duality Principle</strong></p>
<p>For the duality to work, we need one crucial condition:</p>
<div class="math notranslate nohighlight">
\[\text{Confidence Level} + \text{Significance Level} = 1\]</div>
<p>That is, <span class="math notranslate nohighlight">\(C + \alpha = 1\)</span>, where <span class="math notranslate nohighlight">\(C\)</span> is the confidence coefficient and <span class="math notranslate nohighlight">\(\alpha\)</span> is the significance level.</p>
<p>When this condition holds:
- If <span class="math notranslate nohighlight">\(\mu_0\)</span> lies <strong>inside</strong> the confidence interval ‚Üí <strong>fail to reject</strong> <span class="math notranslate nohighlight">\(H_0: \mu = \mu_0\)</span>
- If <span class="math notranslate nohighlight">\(\mu_0\)</span> lies <strong>outside</strong> the confidence interval ‚Üí <strong>reject</strong> <span class="math notranslate nohighlight">\(H_0: \mu = \mu_0\)</span></p>
<p><strong>Why This Works</strong></p>
<p>Both procedures use the same sampling distribution and the same critical values, just applied in different ways:</p>
<ul class="simple">
<li><p><strong>Confidence intervals</strong> ask: ‚ÄúWhat parameter values are consistent with this sample?‚Äù</p></li>
<li><p><strong>Hypothesis tests</strong> ask: ‚ÄúIs this specific parameter value consistent with this sample?‚Äù</p></li>
</ul>
<p>The mathematical machinery is identical‚Äîonly the perspective changes.</p>
</section>
<section id="two-sided-tests-and-confidence-intervals-when-is-known">
<h2><span class="section-number">10.3.2. </span>Two-Sided Tests and Confidence Intervals, When œÉ Is Known<a class="headerlink" href="#two-sided-tests-and-confidence-intervals-when-is-known" title="Link to this heading">ÔÉÅ</a></h2>
<p><strong>The Standard Case</strong></p>
<p>For testing <span class="math notranslate nohighlight">\(H_0: \mu = \mu_0\)</span> versus <span class="math notranslate nohighlight">\(H_a: \mu \neq \mu_0\)</span> when <span class="math notranslate nohighlight">\(\sigma\)</span> is known, we use:</p>
<p><strong>Hypothesis Test:</strong></p>
<ul class="simple">
<li><p><strong>Test statistic</strong>: <span class="math notranslate nohighlight">\(Z_{TS} = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}}\)</span></p></li>
<li><p><strong>Decision rule</strong>: Reject <span class="math notranslate nohighlight">\(H_0\)</span> if <span class="math notranslate nohighlight">\(|Z_{TS}| &gt; z_{\alpha/2}\)</span></p></li>
<li><p><strong>P-value</strong>: <span class="math notranslate nohighlight">\(2P(Z &gt; |Z_{TS}|)\)</span></p></li>
</ul>
<p><strong>Confidence Interval:</strong></p>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\(\left(\bar{x} - z_{\alpha/2} \frac{\sigma}{\sqrt{n}}, \bar{x} + z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\right)\)</span></p></li>
<li><p><strong>Interpretation</strong>: We‚Äôre <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> confident the true mean lies in this interval</p></li>
</ul>
<p><strong>The Connection</strong></p>
<p>Both procedures use the same critical value <span class="math notranslate nohighlight">\(z_{\alpha/2}\)</span> from the standard normal distribution. The test rejects when the observed sample mean is more than <span class="math notranslate nohighlight">\(z_{\alpha/2}\)</span> standard errors away from <span class="math notranslate nohighlight">\(\mu_0\)</span>. The confidence interval includes all values that are within <span class="math notranslate nohighlight">\(z_{\alpha/2}\)</span> standard errors of the observed sample mean.</p>
</section>
<section id="one-sided-tests-and-confidence-bounds-when-is-known">
<h2><span class="section-number">10.3.3. </span>One-Sided Tests and Confidence Bounds, When œÉ Is Known<a class="headerlink" href="#one-sided-tests-and-confidence-bounds-when-is-known" title="Link to this heading">ÔÉÅ</a></h2>
<p><strong>Right-Tailed Tests and Lower Bounds</strong></p>
<p>For testing <span class="math notranslate nohighlight">\(H_0: \mu \leq \mu_0\)</span> versus <span class="math notranslate nohighlight">\(H_a: \mu &gt; \mu_0\)</span>:</p>
<p><strong>Hypothesis Test:</strong></p>
<ul class="simple">
<li><p><strong>Test statistic</strong>: <span class="math notranslate nohighlight">\(Z_{TS} = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}}\)</span></p></li>
<li><p><strong>Decision rule</strong>: Reject <span class="math notranslate nohighlight">\(H_0\)</span> if <span class="math notranslate nohighlight">\(Z_{TS} &gt; z_{\alpha}\)</span></p></li>
<li><p><strong>P-value</strong>: <span class="math notranslate nohighlight">\(P(Z &gt; Z_{TS})\)</span></p></li>
</ul>
<p><strong>Lower Confidence Bound:</strong></p>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\(\mu &gt; \bar{x} - z_{\alpha} \frac{\sigma}{\sqrt{n}}\)</span></p></li>
<li><p><strong>Interpretation</strong>: We‚Äôre <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> confident the true mean exceeds this lower bound</p></li>
</ul>
<p><strong>The Logic</strong>: If we believe <span class="math notranslate nohighlight">\(\mu &gt; \mu_0\)</span>, then plausible values should extend upward from some lower threshold.</p>
<p><strong>Left-Tailed Tests and Upper Bounds</strong></p>
<p>For testing <span class="math notranslate nohighlight">\(H_0: \mu \geq \mu_0\)</span> versus <span class="math notranslate nohighlight">\(H_a: \mu &lt; \mu_0\)</span>:</p>
<p><strong>Hypothesis Test:</strong></p>
<ul class="simple">
<li><p><strong>Test statistic</strong>: <span class="math notranslate nohighlight">\(Z_{TS} = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}}\)</span></p></li>
<li><p><strong>Decision rule</strong>: Reject <span class="math notranslate nohighlight">\(H_0\)</span> if <span class="math notranslate nohighlight">\(Z_{TS} &lt; -z_{\alpha}\)</span></p></li>
<li><p><strong>P-value</strong>: <span class="math notranslate nohighlight">\(P(Z &lt; Z_{TS})\)</span></p></li>
</ul>
<p><strong>Upper Confidence Bound:</strong></p>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\(\mu &lt; \bar{x} + z_{\alpha} \frac{\sigma}{\sqrt{n}}\)</span></p></li>
<li><p><strong>Interpretation</strong>: We‚Äôre <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> confident the true mean is below this upper bound</p></li>
</ul>
<p><strong>The Logic</strong>: If we believe <span class="math notranslate nohighlight">\(\mu &lt; \mu_0\)</span>, then plausible values should extend downward from some upper threshold.</p>
<p><strong>Direction Principle</strong></p>
<p>A helpful way to remember: <strong>the direction of the alternative hypothesis indicates the direction in which plausible values extend</strong>.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H_a: \mu &gt; \mu_0\)</span> ‚Üí plausible values extend upward ‚Üí need lower bound</p></li>
<li><p><span class="math notranslate nohighlight">\(H_a: \mu &lt; \mu_0\)</span> ‚Üí plausible values extend downward ‚Üí need upper bound</p></li>
</ul>
</section>
<section id="a-complete-example-quality-control-for-cherry-tomatoes">
<h2><span class="section-number">10.3.4. </span>A Complete Example: Quality Control for Cherry Tomatoes<a class="headerlink" href="#a-complete-example-quality-control-for-cherry-tomatoes" title="Link to this heading">ÔÉÅ</a></h2>
<p>Let‚Äôs demonstrate the duality principle with a comprehensive example that shows both the confidence interval and hypothesis testing approaches.</p>
<p><strong>The Scenario</strong></p>
<p>Tom Green oversees quality control for a large produce company. He obtains a simple random sample of four packages of cherry tomatoes, each labeled 1/2 lb (227g). The average weight from Tom‚Äôs four packages is 222g. The packaging process has a known standard deviation of 5g, and package weights are normally distributed.</p>
<p><strong>The Questions</strong></p>
<ol class="arabic simple">
<li><p>Construct a 95% confidence interval for the mean weight</p></li>
<li><p>Test at <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span> whether there‚Äôs evidence the machine needs revision (i.e., the mean differs from 227g)</p></li>
</ol>
<p><strong>Given Information</strong></p>
<ul class="simple">
<li><p>Sample size: <span class="math notranslate nohighlight">\(n = 4\)</span></p></li>
<li><p>Sample mean: <span class="math notranslate nohighlight">\(\bar{x} = 222\)</span> grams</p></li>
<li><p>Population standard deviation: <span class="math notranslate nohighlight">\(\sigma = 5\)</span> grams (<strong>known</strong>)</p></li>
<li><p>Target weight: <span class="math notranslate nohighlight">\(\mu_0 = 227\)</span> grams</p></li>
<li><p>Significance level: <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span></p></li>
</ul>
<p><strong>Step 1: Construct the 95% Confidence Interval</strong></p>
<p>Since <span class="math notranslate nohighlight">\(\sigma\)</span> is known and the data is normally distributed, we use:</p>
<div class="math notranslate nohighlight">
\[\left(\bar{x} - z_{\alpha/2} \frac{\sigma}{\sqrt{n}}, \bar{x} + z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\right)\]</div>
<p>For 95% confidence, <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, so we need <span class="math notranslate nohighlight">\(z_{0.025}\)</span>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find critical value</span>
<span class="n">z_critical</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">qnorm</span><span class="p">(</span><span class="m">0.025</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="n">z_critical</span>
<span class="c1"># [1] 1.959964</span>
</pre></div>
</div>
<p>Calculate the interval:</p>
<div class="math notranslate nohighlight">
\[\left(222 - 1.96 \times \frac{5}{\sqrt{4}}, 222 + 1.96 \times \frac{5}{\sqrt{4}}\right)\]</div>
<div class="math notranslate nohighlight">
\[\left(222 - 1.96 \times 2.5, 222 + 1.96 \times 2.5\right) = (217.1, 226.9)\]</div>
<p><strong>Interpretation</strong>: We are 95% confident that the true mean weight of cherry tomato packages lies between 217.1 and 226.9 grams.</p>
<p><strong>Step 2: Use Duality to Answer the Hypothesis Test</strong></p>
<p>We want to test:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H_0: \mu = 227\)</span> (machine is properly calibrated)</p></li>
<li><p><span class="math notranslate nohighlight">\(H_a: \mu \neq 227\)</span> (machine needs revision)</p></li>
</ul>
<p>Since our confidence level is 95% and our significance level is 5%, we have <span class="math notranslate nohighlight">\(C + \alpha = 0.95 + 0.05 = 1.0\)</span>, so the duality relationship applies.</p>
<p><strong>Checking the interval</strong>: Our 95% confidence interval is (217.1, 226.9). The null value <span class="math notranslate nohighlight">\(\mu_0 = 227\)</span> lies <strong>outside</strong> this interval (227 &gt; 226.9).</p>
<p><strong>Conclusion from duality</strong>: Since 227 is not in the confidence interval, we <strong>reject</strong> the null hypothesis.</p>
<p><strong>Step 3: Verify with Formal Hypothesis Test</strong></p>
<p>Let‚Äôs confirm this conclusion using the standard hypothesis testing procedure:</p>
<div class="math notranslate nohighlight">
\[Z_{TS} = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}} = \frac{222 - 227}{5/\sqrt{4}} = \frac{-5}{2.5} = -2.0\]</div>
<p>For a two-sided test:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">z_test_stat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">-2.0</span>
<span class="n">p_value</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">z_test_stat</span><span class="p">),</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="n">p_value</span>
<span class="c1"># [1] 0.04550026</span>
</pre></div>
</div>
<p><strong>Decision</strong>: Since p-value = 0.0455 &lt; <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, we <strong>reject</strong> the null hypothesis.</p>
<p><strong>Consistency Check</strong>: Both approaches give the same conclusion! This confirms the duality relationship.</p>
<p><strong>Practical Interpretation</strong></p>
<p>The instructor notes that 227 is ‚Äújust barely not in the interval,‚Äù which explains why the p-value (0.0455) is just slightly below 0.05. This suggests:</p>
<ul class="simple">
<li><p>The evidence against proper calibration is statistically significant but not overwhelming</p></li>
<li><p>With only 4 packages, we should be cautious about strong conclusions</p></li>
<li><p>Additional data collection might provide more definitive evidence</p></li>
</ul>
</section>
<section id="from-z-procedures-to-t-procedures-when-is-unknown">
<h2><span class="section-number">10.3.5. </span>From Z-Procedures to T-Procedures: When œÉ is Unknown<a class="headerlink" href="#from-z-procedures-to-t-procedures-when-is-unknown" title="Link to this heading">ÔÉÅ</a></h2>
<div class="video-placeholder" role="group" aria-labelledby="video-ch10-3-1">
   <iframe
      id="video-ch10-3-1"
      title="STAT 350 ‚Äì Chapter 10.3.1 Test Statistic when œÉ is Unknown Video"
      src="https://www.youtube.com/embed/Qf1OChGzcQE?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><p><strong>The Realistic Scenario</strong></p>
<p>In the cherry tomato example, we assumed the population standard deviation was known (<span class="math notranslate nohighlight">\(\sigma = 5\)</span> grams). This convenient assumption allowed us to use z-procedures, but it‚Äôs rarely realistic. If we don‚Äôt know the population mean <span class="math notranslate nohighlight">\(\mu\)</span> (which is why we‚Äôre testing it), we almost certainly don‚Äôt know <span class="math notranslate nohighlight">\(\sigma\)</span> either.</p>
<p><strong>The Impact of Unknown œÉ</strong></p>
<p>When we replace the unknown <span class="math notranslate nohighlight">\(\sigma\)</span> with our sample estimate <span class="math notranslate nohighlight">\(s\)</span>, we introduce additional uncertainty into our procedures. The sample standard deviation <span class="math notranslate nohighlight">\(s\)</span> is itself a random variable that varies from sample to sample, and this extra variability must be accounted for.</p>
<p><strong>The T-Test Statistic</strong></p>
<p>When <span class="math notranslate nohighlight">\(\sigma\)</span> is unknown, our test statistic becomes:</p>
<div class="math notranslate nohighlight">
\[t_{TS} = \frac{\bar{X} - \mu_0}{s/\sqrt{n}}\]</div>
<p>Under the assumptions that:</p>
<ul class="simple">
<li><p>The data comes from a normal distribution (or the sample size is large enough for CLT)</p></li>
<li><p>The observations are independent</p></li>
<li><p>The null hypothesis is true</p></li>
</ul>
<p>This test statistic follows a <strong>t-distribution</strong> with <span class="math notranslate nohighlight">\(df = n-1\)</span> degrees of freedom.</p>
<p><strong>Why the T-Distribution?</strong></p>
<p>The t-distribution accounts for the additional uncertainty from estimating <span class="math notranslate nohighlight">\(\sigma\)</span>:</p>
<ul class="simple">
<li><p><strong>Symmetric</strong> around zero (like the standard normal)</p></li>
<li><p><strong>Heavier tails</strong> than the standard normal (reflecting extra uncertainty)</p></li>
<li><p><strong>Approaches</strong> the standard normal as sample size increases</p></li>
<li><p><strong>Degrees of freedom</strong> control the ‚Äúheaviness‚Äù of the tails</p></li>
</ul>
<p><strong>The Convergence Property</strong></p>
<p>As sample size increases:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(s\)</span> becomes a better estimate of <span class="math notranslate nohighlight">\(\sigma\)</span></p></li>
<li><p>The t-distribution approaches the standard normal distribution</p></li>
<li><p>The difference between t-tests and z-tests becomes negligible</p></li>
</ul>
<p>For large samples (<span class="math notranslate nohighlight">\(n &gt; 100\)</span>), t-procedures and z-procedures give virtually identical results.</p>
</section>
<section id="duality-revisited-t-procedures">
<h2><span class="section-number">10.3.6. </span>Duality Revisited: T-Procedures<a class="headerlink" href="#duality-revisited-t-procedures" title="Link to this heading">ÔÉÅ</a></h2>
<p>The beautiful duality relationship we established for z-procedures carries over directly to t-procedures. The only change is that we use t-distributions instead of the standard normal distribution.</p>
<p><strong>Two-Sided Tests and Confidence Intervals (œÉ Unknown)</strong></p>
<p>For testing <span class="math notranslate nohighlight">\(H_0: \mu = \mu_0\)</span> versus <span class="math notranslate nohighlight">\(H_a: \mu \neq \mu_0\)</span>:</p>
<p><strong>Hypothesis Test:</strong></p>
<ul class="simple">
<li><p><strong>Test statistic</strong>: <span class="math notranslate nohighlight">\(t_{TS} = \frac{\bar{x} - \mu_0}{s/\sqrt{n}}\)</span></p></li>
<li><p><strong>P-value</strong>: <span class="math notranslate nohighlight">\(2P(T_{n-1} &gt; |t_{TS}|)\)</span></p></li>
<li><p><strong>R code</strong>: <cite>2 * pt(abs(t_test_stat), df = n-1, lower.tail = FALSE)</cite></p></li>
</ul>
<p><strong>Confidence Interval:</strong></p>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\(\bar{x} \pm t_{\alpha/2,n-1} \frac{s}{\sqrt{n}}\)</span></p></li>
<li><p><strong>R code for critical value</strong>: <cite>qt(alpha/2, df = n-1, lower.tail = FALSE)</cite></p></li>
</ul>
<p><strong>Duality</strong>: If <span class="math notranslate nohighlight">\(\mu_0\)</span> lies outside the <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> confidence interval, reject <span class="math notranslate nohighlight">\(H_0\)</span> at significance level <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p><strong>One-Sided Tests and Confidence Bounds (œÉ Unknown)</strong></p>
<p><strong>Right-tailed test</strong> (<span class="math notranslate nohighlight">\(H_a: \mu &gt; \mu_0\)</span>) with <strong>lower confidence bound</strong>:</p>
<ul class="simple">
<li><p><strong>P-value</strong>: <span class="math notranslate nohighlight">\(P(T_{n-1} &gt; t_{TS})\)</span></p></li>
<li><p><strong>Lower bound</strong>: <span class="math notranslate nohighlight">\(\mu &gt; \bar{x} - t_{\alpha,n-1} \frac{s}{\sqrt{n}}\)</span></p></li>
<li><p><strong>Duality</strong>: If <span class="math notranslate nohighlight">\(\mu_0\)</span> lies below the lower bound, reject <span class="math notranslate nohighlight">\(H_0\)</span></p></li>
</ul>
<p><strong>Left-tailed test</strong> (<span class="math notranslate nohighlight">\(H_a: \mu &lt; \mu_0\)</span>) with <strong>upper confidence bound</strong>:</p>
<ul class="simple">
<li><p><strong>P-value</strong>: <span class="math notranslate nohighlight">\(P(T_{n-1} &lt; t_{TS})\)</span></p></li>
<li><p><strong>Upper bound</strong>: <span class="math notranslate nohighlight">\(\mu &lt; \bar{x} + t_{\alpha,n-1} \frac{s}{\sqrt{n}}\)</span></p></li>
<li><p><strong>Duality</strong>: If <span class="math notranslate nohighlight">\(\mu_0\)</span> lies above the upper bound, reject <span class="math notranslate nohighlight">\(H_0\)</span></p></li>
</ul>
</section>
<section id="a-complete-t-test-example-radon-detector-accuracy">
<h2><span class="section-number">10.3.7. </span>A Complete T-Test Example: Radon Detector Accuracy<a class="headerlink" href="#a-complete-t-test-example-radon-detector-accuracy" title="Link to this heading">ÔÉÅ</a></h2>
<p>Let‚Äôs work through a comprehensive example that demonstrates t-procedures and their duality relationships.</p>
<p><strong>The Research Question</strong></p>
<p>How accurate are radon detectors sold to homeowners? University researchers placed 12 detectors in a chamber exposed to exactly 105 picocuries per liter of radon. If the detectors work properly, they should read close to 105 on average.</p>
<p><strong>Study Design</strong></p>
<ul class="simple">
<li><p><strong>Sample</strong>: SRS of 12 radon detectors</p></li>
<li><p><strong>True exposure</strong>: 105 picocuries per liter</p></li>
<li><p><strong>Population standard deviation</strong>: <strong>Unknown</strong> (must be estimated)</p></li>
<li><p><strong>Significance level</strong>: <span class="math notranslate nohighlight">\(\alpha = 0.10\)</span> (10%)</p></li>
<li><p><strong>Assumption</strong>: Detector readings are normally distributed</p></li>
</ul>
<p><strong>The Data</strong></p>
<p>Picocuries per liter readings: 91.9, 97.8, 111.4, 122.3, 105.4, 95.0, 103.8, 99.6, 119.3, 104.8, 101.7, 96.6</p>
<p><strong>Step 1: State the Hypotheses</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H_0: \mu = 105\)</span> (detectors are accurate)</p></li>
<li><p><span class="math notranslate nohighlight">\(H_a: \mu \neq 105\)</span> (detectors are not accurate)</p></li>
</ul>
<p><strong>Step 2: Calculate Sample Statistics</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data</span>
<span class="n">readings</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">91.9</span><span class="p">,</span><span class="w"> </span><span class="m">97.8</span><span class="p">,</span><span class="w"> </span><span class="m">111.4</span><span class="p">,</span><span class="w"> </span><span class="m">122.3</span><span class="p">,</span><span class="w"> </span><span class="m">105.4</span><span class="p">,</span><span class="w"> </span><span class="m">95.0</span><span class="p">,</span>
<span class="w">              </span><span class="m">103.8</span><span class="p">,</span><span class="w"> </span><span class="m">99.6</span><span class="p">,</span><span class="w"> </span><span class="m">119.3</span><span class="p">,</span><span class="w"> </span><span class="m">104.8</span><span class="p">,</span><span class="w"> </span><span class="m">101.7</span><span class="p">,</span><span class="w"> </span><span class="m">96.6</span><span class="p">)</span>

<span class="c1"># Calculate sample statistics</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">readings</span><span class="p">)</span>
<span class="n">x_bar</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">readings</span><span class="p">)</span>
<span class="n">s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">readings</span><span class="p">)</span>
<span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span>

<span class="c1"># Results</span>
<span class="n">n</span><span class="w">        </span><span class="c1"># 12</span>
<span class="n">x_bar</span><span class="w">    </span><span class="c1"># 104.1333</span>
<span class="n">s</span><span class="w">        </span><span class="c1"># 9.397421</span>
<span class="n">df</span><span class="w">       </span><span class="c1"># 11</span>
</pre></div>
</div>
<p><strong>Step 3: Calculate the Test Statistic</strong></p>
<div class="math notranslate nohighlight">
\[t_{TS} = \frac{\bar{x} - \mu_0}{s/\sqrt{n}} = \frac{104.1333 - 105}{9.397421/\sqrt{12}} = \frac{-0.8667}{2.7136} = -0.319\]</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">mu_0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">105</span>
<span class="n">t_test_stat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">x_bar</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mu_0</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">s</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="n">t_test_stat</span>
<span class="c1"># [1] -0.319</span>
</pre></div>
</div>
<p><strong>Step 4: Calculate the P-Value</strong></p>
<p>For a two-sided test with <span class="math notranslate nohighlight">\(df = 11\)</span>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">p_value</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">pt</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">t_test_stat</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">11</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="n">p_value</span>
<span class="c1"># [1] 0.755</span>
</pre></div>
</div>
<p><strong>Step 5: Make the Decision</strong></p>
<p>Since p-value = 0.755 &gt; <span class="math notranslate nohighlight">\(\alpha = 0.10\)</span>, we <strong>fail to reject</strong> the null hypothesis.</p>
<p><strong>Step 6: Construct the Complementary Confidence Interval</strong></p>
<p>For the duality relationship, we need a 90% confidence interval (since <span class="math notranslate nohighlight">\(C + \alpha = 0.90 + 0.10 = 1.0\)</span>):</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate 90% confidence interval</span>
<span class="n">alpha</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.10</span>
<span class="n">t_critical</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">qt</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">11</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="n">t_critical</span>
<span class="c1"># [1] 1.795885</span>

<span class="n">margin_error</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">t_critical</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">s</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="n">ci_lower</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x_bar</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">margin_error</span>
<span class="n">ci_upper</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x_bar</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">margin_error</span>

<span class="nf">c</span><span class="p">(</span><span class="n">ci_lower</span><span class="p">,</span><span class="w"> </span><span class="n">ci_upper</span><span class="p">)</span>
<span class="c1"># [1] 99.26145 109.00521</span>
</pre></div>
</div>
<p><strong>Step 7: Verify Duality</strong></p>
<p>The 90% confidence interval is (99.3, 109.0). Since <span class="math notranslate nohighlight">\(\mu_0 = 105\)</span> lies <strong>within</strong> this interval, the duality principle tells us we should fail to reject <span class="math notranslate nohighlight">\(H_0\)</span>‚Äîwhich matches our hypothesis test conclusion.</p>
<p><strong>Step 8: Interpretation</strong></p>
<p>We do not have sufficient evidence to conclude that the radon detectors deviate from the true exposure level. The large p-value (0.755) indicates that the observed sample mean (104.1) is very consistent with the null hypothesis value (105.0). The data suggests the detectors are operating as intended by the manufacturer.</p>
</section>
<section id="why-such-a-large-p-value">
<h2><span class="section-number">10.3.8. </span>Why Such a Large P-Value?<a class="headerlink" href="#why-such-a-large-p-value" title="Link to this heading">ÔÉÅ</a></h2>
<p>The p-value of 0.755 is quite large, indicating strong consistency between our data and the null hypothesis. Several factors contribute:</p>
<ol class="arabic simple">
<li><p><strong>Small effect size</strong>: Sample mean (104.1) very close to null value (105.0)</p></li>
<li><p><strong>Small sample size</strong>: Only 12 observations limits precision</p></li>
<li><p><strong>Substantial variability</strong>: Sample standard deviation (9.4) is relatively large</p></li>
<li><p><strong>Two-sided test</strong>: We‚Äôre checking for deviations in either direction</p></li>
</ol>
<p>This example illustrates that ‚Äúfailing to reject‚Äù doesn‚Äôt mean ‚Äúaccepting‚Äù the null hypothesis. It means we lack sufficient evidence to conclude the detectors are systematically inaccurate.</p>
</section>
<section id="comprehensive-summary-all-t-procedures">
<h2><span class="section-number">10.3.9. </span>Comprehensive Summary: All T-Procedures<a class="headerlink" href="#comprehensive-summary-all-t-procedures" title="Link to this heading">ÔÉÅ</a></h2>
<p>When <span class="math notranslate nohighlight">\(\sigma\)</span> is unknown, we use the test statistic <span class="math notranslate nohighlight">\(t_{TS} = \frac{\bar{x} - \mu_0}{s/\sqrt{n}}\)</span> with <span class="math notranslate nohighlight">\(df = n-1\)</span>.</p>
<p><strong>Two-Tailed Tests (:math:`H_a: mu neq mu_0`)</strong></p>
<p><em>Hypothesis Test:</em></p>
<ul class="simple">
<li><p><strong>P-value</strong>: <span class="math notranslate nohighlight">\(2 \times P(T_{n-1} &gt; |t_{TS}|)\)</span></p></li>
<li><p><strong>R code</strong>: <cite>2 * pt(abs(t_test_stat), df = n-1, lower.tail = FALSE)</cite></p></li>
</ul>
<p><em>Confidence Interval:</em></p>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\(\bar{x} \pm t_{\alpha/2,n-1} \frac{s}{\sqrt{n}}\)</span></p></li>
<li><p><strong>R code</strong>: <cite>qt(alpha/2, df = n-1, lower.tail = FALSE)</cite></p></li>
<li><p><strong>Duality</strong>: If <span class="math notranslate nohighlight">\(\mu_0\)</span> outside interval ‚Üí reject; if inside ‚Üí fail to reject</p></li>
</ul>
<p><strong>Right-Tailed Tests (:math:`H_a: mu &gt; mu_0`)</strong></p>
<p><em>Hypothesis Test:</em></p>
<ul class="simple">
<li><p><strong>P-value</strong>: <span class="math notranslate nohighlight">\(P(T_{n-1} &gt; t_{TS})\)</span></p></li>
<li><p><strong>R code</strong>: <cite>pt(t_test_stat, df = n-1, lower.tail = FALSE)</cite></p></li>
</ul>
<p><em>Lower Confidence Bound:</em></p>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\(\mu &gt; \bar{x} - t_{\alpha,n-1} \frac{s}{\sqrt{n}}\)</span></p></li>
<li><p><strong>R code</strong>: <cite>qt(alpha, df = n-1, lower.tail = FALSE)</cite></p></li>
<li><p><strong>Duality</strong>: If <span class="math notranslate nohighlight">\(\mu_0\)</span> below bound ‚Üí reject; if above ‚Üí fail to reject</p></li>
</ul>
<p><strong>Left-Tailed Tests (:math:`H_a: mu &lt; mu_0`)</strong></p>
<p><em>Hypothesis Test:</em></p>
<ul class="simple">
<li><p><strong>P-value</strong>: <span class="math notranslate nohighlight">\(P(T_{n-1} &lt; t_{TS})\)</span></p></li>
<li><p><strong>R code</strong>: <cite>pt(t_test_stat, df = n-1, lower.tail = TRUE)</cite></p></li>
</ul>
<p><em>Upper Confidence Bound:</em></p>
<ul class="simple">
<li><p><strong>Formula</strong>: <span class="math notranslate nohighlight">\(\mu &lt; \bar{x} + t_{\alpha,n-1} \frac{s}{\sqrt{n}}\)</span></p></li>
<li><p><strong>R code</strong>: <cite>qt(alpha, df = n-1, lower.tail = FALSE)</cite></p></li>
<li><p><strong>Duality</strong>: If <span class="math notranslate nohighlight">\(\mu_0\)</span> above bound ‚Üí reject; if below ‚Üí fail to reject</p></li>
</ul>
</section>
<section id="key-differences-t-vs-z-procedures">
<h2><span class="section-number">10.3.10. </span>Key Differences: T vs. Z Procedures<a class="headerlink" href="#key-differences-t-vs-z-procedures" title="Link to this heading">ÔÉÅ</a></h2>
<p><strong>Critical Values</strong></p>
<p>For any given significance level, t critical values are always larger than z critical values (except as <span class="math notranslate nohighlight">\(n \to \infty\)</span>). This means:</p>
<ul class="simple">
<li><p><strong>Confidence intervals</strong> using t are wider than those using z</p></li>
<li><p><strong>Hypothesis tests</strong> using t require more extreme test statistics to reject <span class="math notranslate nohighlight">\(H_0\)</span></p></li>
<li><p><strong>P-values</strong> from t-tests are generally larger than corresponding z-tests</p></li>
</ul>
<p><strong>Why This Makes Sense</strong></p>
<p>The larger critical values reflect our uncertainty about <span class="math notranslate nohighlight">\(\sigma\)</span>. When we estimate <span class="math notranslate nohighlight">\(\sigma\)</span> with <span class="math notranslate nohighlight">\(s\)</span>, we should be less confident in our conclusions, which the t-distribution captures through its heavier tails.</p>
<p><strong>Sample Size Impact</strong></p>
<ul class="simple">
<li><p><strong>Small samples</strong> (<span class="math notranslate nohighlight">\(n &lt; 15\)</span>): Substantial difference between t and z procedures</p></li>
<li><p><strong>Moderate samples</strong> (<span class="math notranslate nohighlight">\(15 \leq n &lt; 30\)</span>): Noticeable but manageable differences</p></li>
<li><p><strong>Large samples</strong> (<span class="math notranslate nohighlight">\(n \geq 30\)</span>): Differences become negligible</p></li>
</ul>
</section>
<section id="when-assumptions-are-violated">
<h2><span class="section-number">10.3.11. </span>When Assumptions Are Violated<a class="headerlink" href="#when-assumptions-are-violated" title="Link to this heading">ÔÉÅ</a></h2>
<p>T-procedures assume data comes from a normal distribution. While t-tests are reasonably robust to moderate departures from normality, serious violations can be problematic, especially with small samples.</p>
<p><strong>Alternative Approaches</strong></p>
<ol class="arabic simple">
<li><p><strong>Data transformation</strong> (e.g., log transformation for right-skewed data)</p></li>
<li><p><strong>Non-parametric methods</strong> (e.g., Wilcoxon signed-rank test)</p></li>
<li><p><strong>Bootstrap methods</strong> for empirical sampling distributions</p></li>
<li><p><strong>Exact distributional methods</strong> when the true distribution is known</p></li>
</ol>
<p><strong>Conservative Guidelines</strong></p>
<ul class="simple">
<li><p><strong>Always plot your data</strong> to check assumptions</p></li>
<li><p><strong>Report any concerns</strong> about normality in small samples</p></li>
<li><p><strong>Consider alternatives</strong> when assumptions are clearly violated</p></li>
<li><p><strong>Remember</strong>: For large samples, t-procedures are quite robust due to the CLT</p></li>
</ul>
</section>
<section id="the-power-of-duality">
<h2><span class="section-number">10.3.12. </span>The Power of Duality<a class="headerlink" href="#the-power-of-duality" title="Link to this heading">ÔÉÅ</a></h2>
<p>Understanding the duality between hypothesis tests and confidence intervals provides several advantages:</p>
<p><strong>Computational Efficiency</strong></p>
<p>Sometimes it‚Äôs easier to construct a confidence interval and check whether <span class="math notranslate nohighlight">\(\mu_0\)</span> falls inside than to calculate a p-value directly.</p>
<p><strong>Deeper Understanding</strong></p>
<p>Duality reinforces that both procedures quantify the same underlying uncertainty‚Äîthey just present it differently.</p>
<p><strong>Practical Insight</strong></p>
<p>Confidence intervals show the magnitude of effects, while hypothesis tests provide yes/no answers. Together, they give a complete picture.</p>
<p><strong>Consistency Check</strong></p>
<p>When results from the two approaches don‚Äôt align, it signals an error in calculations or assumptions.</p>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">10.3.13. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading">ÔÉÅ</a></h2>
<div class="important admonition">
<p class="admonition-title">Key Takeaways üìù</p>
<ol class="arabic simple">
<li><p><strong>Hypothesis tests and confidence intervals are dual procedures</strong> that address the same questions from different perspectives, connected by the relationship <span class="math notranslate nohighlight">\(C + \alpha = 1\)</span>.</p></li>
<li><p><strong>Duality works for both z-procedures</strong> (œÉ known) and <strong>t-procedures</strong> (œÉ unknown), with the same logical framework applying to both.</p></li>
<li><p><strong>T-distributions have heavier tails</strong> than the standard normal, reflecting additional uncertainty when estimating œÉ with s.</p></li>
<li><p><strong>Direction of alternative hypothesis determines confidence bound type</strong>: <span class="math notranslate nohighlight">\(H_a: \mu &gt; \mu_0\)</span> pairs with lower bounds, <span class="math notranslate nohighlight">\(H_a: \mu &lt; \mu_0\)</span> pairs with upper bounds.</p></li>
<li><p><strong>T-procedures approach z-procedures</strong> as sample size increases, with negligible differences for large samples (<span class="math notranslate nohighlight">\(n &gt; 100\)</span>).</p></li>
<li><p><strong>Failing to reject doesn‚Äôt mean accepting</strong> the null hypothesis‚Äîit means insufficient evidence against it.</p></li>
<li><p><strong>Practical interpretation requires considering</strong> both statistical significance and practical importance in context.</p></li>
<li><p><strong>Assumptions matter most for small samples</strong>‚Äînormality becomes less critical as sample size increases due to CLT.</p></li>
</ol>
</div>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">ÔÉÅ</a></h3>
<ol class="arabic simple">
<li><p><strong>Duality Verification</strong>: A researcher constructs a 95% confidence interval for Œº and gets (12.3, 18.7). Without doing any calculations, determine the outcome of testing <span class="math notranslate nohighlight">\(H_0: \mu = 15\)</span> vs. <span class="math notranslate nohighlight">\(H_a: \mu \neq 15\)</span> at <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>. Explain your reasoning.</p></li>
<li><p><strong>Coffee Shop Service</strong>: A coffee shop claims average service time is 3 minutes. You time 15 customers and find <span class="math notranslate nohighlight">\(\bar{x} = 3.4\)</span> minutes, <span class="math notranslate nohighlight">\(s = 0.8\)</span> minutes.
a) Test the claim at <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>
b) Construct a 95% confidence interval
c) Verify that your results from (a) and (b) are consistent</p></li>
<li><p><strong>One-Sided Bounds</strong>: A manufacturer wants to show their batteries last <strong>more than</strong> 20 hours on average. With 12 batteries, they get <span class="math notranslate nohighlight">\(\bar{x} = 22.1\)</span> hours, <span class="math notranslate nohighlight">\(s = 3.5\)</span> hours.
a) What type of confidence bound is appropriate?
b) Test at <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span> using the hypothesis test approach
c) Verify using the appropriate 95% confidence bound</p></li>
<li><p><strong>Sample Size Impact</strong>: Explain why a t-test with <span class="math notranslate nohighlight">\(n = 5\)</span> requires a larger test statistic to reject <span class="math notranslate nohighlight">\(H_0\)</span> than a z-test with the same data and significance level. What does this say about our confidence in conclusions from small samples?</p></li>
<li><p><strong>Cherry Tomato Follow-up</strong>: In the cherry tomato example, suppose œÉ had been unknown and estimated as <span class="math notranslate nohighlight">\(s = 5\)</span> grams from the sample of 4 packages. Rework the entire analysis using t-procedures and compare your conclusions to the original z-procedure results.</p></li>
<li><p><strong>Critical Thinking</strong>: A study reports ‚Äúno significant difference‚Äù with <span class="math notranslate nohighlight">\(p = 0.12\)</span> and <span class="math notranslate nohighlight">\(n = 8\)</span>. The researcher concludes the null hypothesis is true. Identify at least three problems with this reasoning and suggest better ways to interpret the results.</p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="10-2-ht-for-mean-sigma-known.html" class="btn btn-neutral float-left" title="10.2. Hypothesis Test for the Population Mean When œÉ is Known" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="10-4-pvalue-significance-conclusion.html" class="btn btn-neutral float-right" title="10.4. P-values, Statistical Significance, and Formal Conclusion" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>