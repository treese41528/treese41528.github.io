

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=bac617f8" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="4. Probability" href="../../chapter4/index.html" />
    <link rel="prev" title="3.4. Measures of Variability - Interquartile Range and Five-Number Summary" href="3-4-measures-of-variability-IQR-and-5-number-summary.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Shape &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">3. Numerical Summaries</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes‚Äô Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Discrete Random Variables and the CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When œÉ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When œÉ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">3. </span>Numerical Summaries</a></li>
      <li class="breadcrumb-item active"><span class="section-number">3.5. </span>Choosing the Right Measure &amp; Comparing Measures Across Data Sets</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder">
  <iframe
    src="https://www.youtube.com/embed/if-8h2DECQg?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
    allowfullscreen>
  </iframe>
</div><section id="choosing-the-right-measure-comparing-measures-across-data-sets">
<h1><span class="section-number">3.5. </span>Choosing the Right Measure &amp; Comparing Measures Across Data Sets<a class="headerlink" href="#choosing-the-right-measure-comparing-measures-across-data-sets" title="Link to this heading">ÔÉÅ</a></h1>
<p>Now that we‚Äôve explored different measures of central tendency and spread, we need to <strong>determine
which measures are most appropriate for different types of data</strong>. The effectiveness of each
measure depends on the distribution shape and the presence of outliers.</p>
<div class="important admonition">
<p class="admonition-title">Road Map üß≠</p>
<ul class="simple">
<li><p>Understand what it means for a measure to be <strong>resistant</strong>.</p></li>
<li><p>Examine how skewness affects different measures of center and spread.</p></li>
<li><p>Learn which measures to choose when dealing with outliers.</p></li>
<li><p>Explore <strong>standardization</strong> for comparing observations across different datasets.</p></li>
<li><p>See how side-by-side boxplots can compare distributions across groups.</p></li>
</ul>
</div>
<section id="resistant-and-non-resistant-measures">
<h2><span class="section-number">3.5.1. </span>Resistant and Non-Resistant Measures<a class="headerlink" href="#resistant-and-non-resistant-measures" title="Link to this heading">ÔÉÅ</a></h2>
<p>One of the most important considerations when choosing summary statistics is whether
they are resistant to outliers and extreme values. This is because under the presence of
extreme values, certain measures lose their representative power for the data set.</p>
<ul class="simple">
<li><p>A <strong>resistant measure</strong> is one that isn‚Äôt strongly affected by extreme values in the dataset,</p></li>
<li><p>A <strong>non-resistant measure</strong> can be heavily influenced by them.</p></li>
</ul>
<p>Skewed distributions provide an excellent way to understand the concept of resistance.
Let‚Äôs examine what happens to our measures of center and spread when data is skewed.</p>
<figure class="align-center" id="id1">
<span id="skewed-dists"></span><a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter3/box_plot_vs_histogram.png"><img alt="Comparison of negatively and positively skewed distributions" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter3/box_plot_vs_histogram.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 3.8 </span><span class="caption-text"><em>Comparison of negatively and positively skewed distributions with box plots and measures of center</em></span><a class="headerlink" href="#id1" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p>In the figure above, we can see:</p>
<ol class="arabic simple">
<li><p><strong>Negatively Skewed Distribution</strong> (left): The data is bunched toward the higher end with a
tail extending to the left.</p></li>
<li><p><strong>Positively Skewed Distribution</strong> (right): The data is bunched toward the lower end with a
tail extending to the right.</p></li>
</ol>
<section id="effect-of-skewness-on-numerical-summary-measures">
<h3>Effect of skewness on numerical summary measures<a class="headerlink" href="#effect-of-skewness-on-numerical-summary-measures" title="Link to this heading">ÔÉÅ</a></h3>
<p><strong>1. Sample mean is pulled towards the tail</strong></p>
<blockquote>
<div><p>Notice how the mean (solid dot) is pulled in the direction of the tail, while the median remains
firmly in the middle of the ordered data.</p>
</div></blockquote>
<p><strong>2. Many points in the tail are marked as explicit points</strong></p>
<blockquote>
<div><p>When data is skewed, box plots often flag many points as ‚Äúexplicit‚Äù
in the direction of the tail.</p>
<p>However, these flagged points don‚Äôt necessarily represent true outliers.
They may simply be part of the natural tail behavior of the distribution.</p>
<p>Recall that real outliers typically show a clear gap between them and the rest of the data.
These points should be investigated more thoroughly to determine if they are real outliers,
but it is evident that many explicit points on <a class="reference internal" href="#skewed-dists"><span class="std std-numref">Fig. 3.8</span></a> are not.</p>
</div></blockquote>
</section>
</section>
<section id="choosing-the-right-pair-of-measures">
<h2><span class="section-number">3.5.2. </span>Choosing the Right Pair of measures<a class="headerlink" href="#choosing-the-right-pair-of-measures" title="Link to this heading">ÔÉÅ</a></h2>
<section id="sample-mean-vs-sample-median">
<h3>Sample Mean vs. Sample Median<a class="headerlink" href="#sample-mean-vs-sample-median" title="Link to this heading">ÔÉÅ</a></h3>
<p>As we can see from the skewed distributions,</p>
<ul class="simple">
<li><p>The sample mean (xÃÑ) is <strong>non-resistant</strong> because it‚Äôs calculated using all data
values and gives equal weight to each observation, including outliers. As a result,
it is pulled towards values which are far from the main trend of the data.</p></li>
<li><p>The sample median (xÃÉ) is <strong>resistant</strong> because it depends only on the order (ranks)
of most of the data, not the exact values.</p></li>
</ul>
</section>
<section id="sample-variance-standard-deviation-vs-iqr">
<h3>Sample Variance (Standard Deviation) vs. IQR<a class="headerlink" href="#sample-variance-standard-deviation-vs-iqr" title="Link to this heading">ÔÉÅ</a></h3>
<p>Similarly, our measures of spread also differ in their resistance to outliers:</p>
<ul class="simple">
<li><p>The sample variance (s¬≤) and standard deviation (s) are <strong>non-resistant</strong> because:
- They depend on the distance from each point to the sample mean, which is already non-resistant.
- They square these distances, giving even more weight to extreme values.</p></li>
<li><p>The interquartile range (IQR) is <strong>resistant</strong> because:
- It only considers the middle 50% of the data
- It‚Äôs not affected by extreme values in either tail</p></li>
</ul>
</section>
<section id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Link to this heading">ÔÉÅ</a></h3>
<table class="docutils align-center" style="width: 90%">
<colgroup>
<col style="width: 28.6%" />
<col style="width: 14.3%" />
<col style="width: 28.6%" />
<col style="width: 28.6%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property of data distribution</p></th>
<th class="head"><p>Resistance required?</p></th>
<th class="head"><p>Measure of center</p></th>
<th class="head"><p>Measure of variability</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Skewed or has outliers</p></td>
<td><p>Yes</p></td>
<td><p>Sample median</p></td>
<td><p>IQR</p></td>
</tr>
<tr class="row-odd"><td><p>Reasonably symmetric and has no outliers</p></td>
<td><p>No</p></td>
<td><p>Sample mean</p></td>
<td><p>Sample variance (sd)</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="comparing-measures-among-data-sets">
<h2><span class="section-number">3.5.3. </span>Comparing Measures Among Data Sets<a class="headerlink" href="#comparing-measures-among-data-sets" title="Link to this heading">ÔÉÅ</a></h2>
<section id="side-by-side-box-plots-for-group-comparisons">
<h3>Side-by-Side Box Plots for Group Comparisons<a class="headerlink" href="#side-by-side-box-plots-for-group-comparisons" title="Link to this heading">ÔÉÅ</a></h3>
<p>When comparing a quantitative variable across categories,
side-by-side box plots provide an excellent visualization tool.</p>
<figure class="align-center" id="id2">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter3/singer-heights-boxplot.png"><img alt="Side-by-side box plots of heights by voice type" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter3/singer-heights-boxplot.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 3.9 </span><span class="caption-text"><em>Heights of singers in the New York Choral Society (1979) by voice type</em></span><a class="headerlink" href="#id2" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p>This example shows the heights of singers in the New York Choral Society,
categorized by voice type (soprano, alto, tenor, and bass). The box plots allow us to
compare the distributions and see patterns:</p>
<div class="note admonition">
<p class="admonition-title">Example : Plotting and interpret a side-by-side box plot</p>
<p>Interpretation</p>
<ul class="simple">
<li><p>Tenors and basses (typically male) tend to be taller than sopranos and altos (typically female)</p></li>
<li><p>There is some overlap in heights between altos and tenors</p></li>
<li><p>Each voice type shows a different distribution of heights</p></li>
</ul>
</div>
<p>This code produces a plot similar to the one shown in the figure above. Let‚Äôs break down what each part of the code does:</p>
<ol class="arabic simple">
<li><p>We first organize our data in a data frame with two columns: <cite>Voice</cite> (the categorical variable) and <cite>Height</cite> (the quantitative variable)</p></li>
<li><p>We create a custom function <cite>convert_in_to_ft</cite> to display heights in a more readable format</p></li>
<li><p>We use <cite>ggplot2</cite> to create the visualization:
- <cite>stat_boxplot(geom = ‚Äúerrorbar‚Äù)</cite> adds the whisker ends
- <cite>geom_boxplot(fill = ‚Äúpurple‚Äù)</cite> creates the box plots with purple fill
- <cite>stat_summary()</cite> adds dots representing the means
- Various theming options control the appearance of text and labels</p></li>
</ol>
</section>
<section id="standardization-comparing-apples-to-oranges-with-z-scores">
<h3>Standardization: Comparing Apples to Oranges with Z-Scores<a class="headerlink" href="#standardization-comparing-apples-to-oranges-with-z-scores" title="Link to this heading">ÔÉÅ</a></h3>
<p>Often, we need to compare observations from different variables that
use different scales or units. <strong>Standardization</strong> allows us to convert values
to a common scale, making direct comparisons possible.</p>
<p>The <strong>z-score</strong> (or standardized value) for an observation is calculated as:</p>
<div class="math notranslate nohighlight">
\[z_i = \frac{x_i - \bar{x}}{s}\]</div>
<p>Where:
* x_i is the original observation
* xÃÑ is the sample mean
* s is the sample standard deviation</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter3/z-score-formula.png"><img alt="Z-score formula and explanation" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter3/z-score-formula.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 3.10 </span><span class="caption-text"><em>Z-score formula and properties</em></span><a class="headerlink" href="#id3" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
<p>Z-scores tell us how many standard deviations an observation is from the mean:</p>
<ul class="simple">
<li><p>Positive z-scores indicate values above the mean</p></li>
<li><p>Negative z-scores indicate values below the mean</p></li>
<li><p>A z-score of 0 indicates a value equal to the mean</p></li>
</ul>
<p>For example, z = -2.25 means the observation is 2.25 standard deviations below the mean.</p>
</section>
<section id="properties-and-uses-of-z-scores">
<h3>Properties and Uses of Z-Scores<a class="headerlink" href="#properties-and-uses-of-z-scores" title="Link to this heading">ÔÉÅ</a></h3>
<p>Z-scores have several important properties:</p>
<ol class="arabic simple">
<li><p>They express relative standing in terms of standard deviations from the mean</p></li>
<li><p>They allow for direct comparison of observations from different distributions</p></li>
<li><p>They are unitless measures (the original units cancel out in the calculation)</p></li>
<li><p>The sum of all z-scores in a dataset is always 0</p></li>
</ol>
<p>Z-scores are particularly useful when:</p>
<ul class="simple">
<li><p>Comparing performances across different measures (e.g., comparing a student‚Äôs standing in both math and reading)</p></li>
<li><p>Identifying unusual observations (values with z-scores above 3 or below -3 are often considered unusual)</p></li>
<li><p>Creating standardized scales for assessment or evaluation</p></li>
</ul>
</section>
<section id="computing-z-scores-in-r">
<h3>Computing Z-Scores in R<a class="headerlink" href="#computing-z-scores-in-r" title="Link to this heading">ÔÉÅ</a></h3>
<p>Calculating z-scores in R is straightforward. You can use the built-in <cite>scale()</cite> function or calculate them manually:</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-number">Listing 3.1 </span><span class="caption-text">Computing z-scores in R</span><a class="headerlink" href="#id4" title="Link to this code">ÔÉÅ</a></div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sample data</span>
<span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">8</span><span class="p">,</span><span class="w"> </span><span class="m">7</span><span class="p">,</span><span class="w"> </span><span class="m">9</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">)</span>

<span class="c1"># Method 1: Using the scale() function</span>
<span class="n">z_scores</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">scale</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Method 2: Manual calculation</span>
<span class="n">z_scores_manual</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Print the results</span>
<span class="nf">print</span><span class="p">(</span><span class="n">z_scores</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">z_scores_manual</span><span class="p">)</span>

<span class="c1"># Verify that the sum of z-scores is (approximately) zero</span>
<span class="nf">sum</span><span class="p">(</span><span class="n">z_scores</span><span class="p">)</span>

<span class="c1"># Example of comparing values from different distributions</span>
<span class="c1"># Test scores from two different exams</span>
<span class="n">math_scores</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">78</span><span class="p">,</span><span class="w"> </span><span class="m">85</span><span class="p">,</span><span class="w"> </span><span class="m">92</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">88</span><span class="p">,</span><span class="w"> </span><span class="m">75</span><span class="p">)</span>
<span class="n">english_scores</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">82</span><span class="p">,</span><span class="w"> </span><span class="m">90</span><span class="p">,</span><span class="w"> </span><span class="m">88</span><span class="p">,</span><span class="w"> </span><span class="m">72</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">85</span><span class="p">,</span><span class="w"> </span><span class="m">80</span><span class="p">)</span>

<span class="c1"># Calculate z-scores for both distributions</span>
<span class="n">math_z</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">scale</span><span class="p">(</span><span class="n">math_scores</span><span class="p">)</span>
<span class="n">english_z</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">scale</span><span class="p">(</span><span class="n">english_scores</span><span class="p">)</span>

<span class="c1"># Create a data frame to compare a student&#39;s performance on both tests</span>
<span class="c1"># For example, comparing the performance of student #2</span>
<span class="n">comparison</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="w">  </span><span class="n">Subject</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Math&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;English&quot;</span><span class="p">),</span>
<span class="w">  </span><span class="n">Raw_Score</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">math_scores</span><span class="p">[</span><span class="m">2</span><span class="p">],</span><span class="w"> </span><span class="n">english_scores</span><span class="p">[</span><span class="m">2</span><span class="p">]),</span>
<span class="w">  </span><span class="n">Z_Score</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">math_z</span><span class="p">[</span><span class="m">2</span><span class="p">],</span><span class="w"> </span><span class="n">english_z</span><span class="p">[</span><span class="m">2</span><span class="p">])</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">comparison</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>This code demonstrates how to calculate z-scores and how they can be used to compare performance across different distributions. The output shows that even though the raw scores might differ, the z-scores provide a standardized measure that allows for direct comparison.</p>
</section>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">3.5.4. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading">ÔÉÅ</a></h2>
<div class="important admonition">
<p class="admonition-title">Key Takeaways üìù</p>
<ol class="arabic simple">
<li><p><strong>Resistant measures</strong> (median, IQR) are not strongly affected by outliers and skewness and should be used when data is skewed or contains outliers.</p></li>
<li><p><strong>Non-resistant measures</strong> (mean, standard deviation) are influenced by extreme values but have better statistical properties for symmetric distributions without outliers.</p></li>
<li><p>The <strong>mean</strong> is always pulled in the direction of the tail in skewed distributions, while the <strong>median</strong> remains representative of the center.</p></li>
<li><p><strong>Side-by-side box plots</strong> allow us to compare distributions of a quantitative variable across categories of a categorical variable.</p></li>
<li><p><strong>Z-scores</strong> standardize observations by expressing them in terms of standard deviations from the mean, enabling comparisons across different distributions.</p></li>
<li><p>When analyzing data, always consider the shape of the distribution and the presence of outliers when choosing summary measures.</p></li>
</ol>
</div>
<section id="looking-ahead-from-description-to-inference">
<h3>Looking Ahead: From Description to Inference<a class="headerlink" href="#looking-ahead-from-description-to-inference" title="Link to this heading">ÔÉÅ</a></h3>
<p>The numerical summary measures we‚Äôve explored in this chapter are fundamental tools for descriptive statistics‚Äîthey help us characterize and understand our sample data. However, in future chapters, these measures will also serve as the foundation for statistical inference.</p>
<p>In particular, the concepts of resistant and non-resistant measures connect to important properties of statistical estimators:</p>
<ul class="simple">
<li><p><strong>Unbiasedness</strong>: Does the estimator target the correct population parameter on average?</p></li>
<li><p><strong>Consistency</strong>: Does the estimator converge to the true parameter as sample size increases?</p></li>
<li><p><strong>Efficiency</strong>: How much variability does the estimator have?</p></li>
<li><p><strong>Robustness</strong>: How well does the estimator perform when assumptions are violated?</p></li>
</ul>
<p>The sample mean is an unbiased estimator of the population mean, but it lacks robustness to outliers. The sample median, while not always the most efficient estimator, provides robustness when dealing with skewed distributions or data with outliers.</p>
<p>As we transition from descriptive statistics to probability in the next chapter, and then to statistical inference, keep these properties in mind. The choices we make about which measures to use will impact the validity and reliability of our statistical conclusions.</p>
<p>In the next chapter, we‚Äôll begin exploring probability concepts that provide the theoretical foundation for statistical inference.</p>
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">ÔÉÅ</a></h3>
<ol class="arabic simple">
<li><p><strong>Resistant vs. Non-Resistant Measures</strong>: For each of the following datasets, state whether you would use the mean and standard deviation or the median and IQR as summary measures, and explain why:
a) Annual salaries of employees at a small company with one extremely high-paid CEO
b) Heights of randomly selected adult males from a normally distributed population
c) Times to completion of a task with a few extremely slow performances</p></li>
<li><p><strong>Interpreting Z-Scores</strong>: A student took tests in both math and English. She scored 85 on the math test (mean = 75, sd = 5) and 88 on the English test (mean = 80, sd = 10).
a) Calculate the z-score for each test result
b) On which test did she perform better relative to her peers?
c) Explain why we can‚Äôt compare the raw scores directly</p></li>
<li><p><strong>Skewed Distributions</strong>: Using the dataset {3, 4, 5, 5, 6, 7, 8, 15, 22}:
a) Create a dot plot or histogram and describe the shape of the distribution
b) Calculate the mean, median, standard deviation, and IQR
c) Explain how the relationship between the mean and median confirms your assessment of the distribution shape
d) Which measures would you recommend for summarizing this dataset?</p></li>
<li><p><strong>Side-by-Side Box Plot Interpretation</strong>: A researcher collects data on the recovery time (in days) for patients using three different treatments:
* Treatment A: {5, 7, 8, 9, 10, 12, 14}
* Treatment B: {3, 4, 5, 6, 7, 8, 20}
* Treatment C: {8, 9, 10, 11, 12, 13, 14}</p>
<ol class="loweralpha simple">
<li><p>Create side-by-side box plots for the three treatments</p></li>
<li><p>Which treatment appears to have the shortest typical recovery time?</p></li>
<li><p>Which treatment has the most consistent results?</p></li>
<li><p>Are there any potential outliers? If so, how might they affect your assessment?</p></li>
</ol>
</li>
<li><p><strong>Z-Score Application</strong>: The heights of adult female volleyball players have a mean of 180 cm with a standard deviation of 5 cm. The heights of adult female gymnasts have a mean of 155 cm with a standard deviation of 6 cm.
a) If a woman is 172 cm tall, calculate her z-score relative to both the volleyball player and gymnast populations
b) Relative to their respective sports, would this woman be considered tall or short?
c) Explain how z-scores help us make this comparison despite the different means and standard deviations</p></li>
</ol>
</section>
</section>
<section id="appendix-code-for-creating-a-side-by-side-box-plot">
<h2><span class="section-number">3.5.5. </span>Appendix: Code for Creating a Side-by-Side Box Plot<a class="headerlink" href="#appendix-code-for-creating-a-side-by-side-box-plot" title="Link to this heading">ÔÉÅ</a></h2>
<p>Let‚Äôs first walk through how to create side-by-side box plots in R using the New York Choral
Society height data. First, we‚Äôll need to structure our data properly. Here‚Äôs the dataset:</p>
<blockquote>
<div><div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-number">Listing 3.2 </span><span class="caption-text">Singer heights data (in inches)</span><a class="headerlink" href="#id5" title="Link to this code">ÔÉÅ</a></div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Singer heights data (in inches)</span>
<span class="n">singer_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="n">Voice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="s">&quot;Soprano&quot;</span><span class="p">,</span><span class="w"> </span><span class="m">36</span><span class="p">),</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="s">&quot;Alto&quot;</span><span class="p">,</span><span class="w"> </span><span class="m">35</span><span class="p">),</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="s">&quot;Tenor&quot;</span><span class="p">,</span><span class="w"> </span><span class="m">21</span><span class="p">),</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="s">&quot;Bass&quot;</span><span class="p">,</span><span class="w"> </span><span class="m">39</span><span class="p">)),</span>
<span class="n">Height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span>
<span class="w">   </span><span class="c1"># Soprano heights</span>
<span class="w">   </span><span class="m">64</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">60</span><span class="p">,</span><span class="w"> </span><span class="m">61</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">63</span><span class="p">,</span><span class="w"> </span><span class="m">67</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">63</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">63</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">61</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span>
<span class="w">   </span><span class="c1"># Alto heights</span>
<span class="w">   </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">67</span><span class="p">,</span><span class="w"> </span><span class="m">67</span><span class="p">,</span><span class="w"> </span><span class="m">63</span><span class="p">,</span><span class="w"> </span><span class="m">67</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">63</span><span class="p">,</span><span class="w"> </span><span class="m">72</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">61</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">64</span><span class="p">,</span><span class="w"> </span><span class="m">60</span><span class="p">,</span><span class="w"> </span><span class="m">61</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">62</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">64</span><span class="p">,</span><span class="w"> </span><span class="m">63</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">69</span><span class="p">,</span><span class="w"> </span><span class="m">61</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">61</span><span class="p">,</span><span class="w"> </span><span class="m">63</span><span class="p">,</span><span class="w"> </span><span class="m">64</span><span class="p">,</span><span class="w"> </span><span class="m">67</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span>
<span class="w">   </span><span class="c1"># Tenor heights</span>
<span class="w">   </span><span class="m">69</span><span class="p">,</span><span class="w"> </span><span class="m">72</span><span class="p">,</span><span class="w"> </span><span class="m">71</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">76</span><span class="p">,</span><span class="w"> </span><span class="m">74</span><span class="p">,</span><span class="w"> </span><span class="m">71</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">67</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">65</span><span class="p">,</span><span class="w"> </span><span class="m">72</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">73</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">67</span><span class="p">,</span><span class="w"> </span><span class="m">64</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span>
<span class="w">   </span><span class="c1"># Bass heights</span>
<span class="w">   </span><span class="m">72</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">72</span><span class="p">,</span><span class="w"> </span><span class="m">69</span><span class="p">,</span><span class="w"> </span><span class="m">73</span><span class="p">,</span><span class="w"> </span><span class="m">71</span><span class="p">,</span><span class="w"> </span><span class="m">72</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">71</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">71</span><span class="p">,</span><span class="w"> </span><span class="m">73</span><span class="p">,</span><span class="w"> </span><span class="m">73</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">75</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">71</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">74</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">75</span><span class="p">,</span><span class="w"> </span><span class="m">75</span><span class="p">,</span><span class="w"> </span><span class="m">69</span><span class="p">,</span><span class="w"> </span><span class="m">72</span><span class="p">,</span><span class="w"> </span><span class="m">71</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">71</span><span class="p">,</span><span class="w"> </span><span class="m">68</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">75</span><span class="p">,</span><span class="w"> </span><span class="m">72</span><span class="p">,</span><span class="w"> </span><span class="m">66</span><span class="p">,</span><span class="w"> </span><span class="m">72</span><span class="p">,</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="m">69</span>
<span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Remove any zero values (missing data)</span>
<span class="n">singer_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">subset</span><span class="p">(</span><span class="n">singer_data</span><span class="p">,</span><span class="w"> </span><span class="n">Height</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now we can create the box plots using ggplot2:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">caption<span class="colon">:</span></dt>
<dd class="field-odd"><p>Creating side-by-side box plots with ggplot2</p>
</dd>
</dl>
<p>library(ggplot2)</p>
<p># Create a function to convert heights in inches to feet and inches format for labels
convert_in_to_ft &lt;- function(values) {</p>
<blockquote>
<div><p>feet &lt;- floor(values / 12)
inches &lt;- floor(values %% 12)
value &lt;- sprintf(‚Äú%sft %sin‚Äù, feet, inches)
return(value)</p>
</div></blockquote>
<p>}</p>
<p># Create the side-by-side box plots
ggplot(singer_data, aes(x = Voice, y = Height)) +</p>
<blockquote>
<div><p>stat_boxplot(geom = ‚Äúerrorbar‚Äù) +     # Add whisker ends
geom_boxplot(fill = ‚Äúpurple‚Äù) +       # Create box plots with purple fill
theme(text = element_text(size = 24, face = ‚Äúbold‚Äù),</p>
<blockquote>
<div><p>axis.text = element_text(size = 20, face = ‚Äúbold‚Äù)) +</p>
</div></blockquote>
<p>stat_summary(fun = mean, col = ‚Äúblack‚Äù, geom = ‚Äúpoint‚Äù, size = 3) +  # Add mean points
scale_y_continuous(label = convert_in_to_ft,                          # Custom y-axis labels</p>
<blockquote>
<div><p>breaks = c(60, 65, 70, 75)) +</p>
</div></blockquote>
<p>xlab(‚Äú‚Äù) +                            # No x-axis label needed
ylab(‚ÄúHeight‚Äù)                        # y-axis label</p>
</div></blockquote>
</div></blockquote>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="3-4-measures-of-variability-IQR-and-5-number-summary.html" class="btn btn-neutral float-left" title="3.4. Measures of Variability - Interquartile Range and Five-Number Summary" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../chapter4/index.html" class="btn btn-neutral float-right" title="4. Probability" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>