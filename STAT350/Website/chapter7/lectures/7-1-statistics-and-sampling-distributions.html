

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>7.1. Statistics and Sampling Distributions &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=bac617f8" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter7/lectures/7-1-statistics-and-sampling-distributions.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7.2. Sampling Distribution for the Sample Mean" href="7-2-sampling-distribution-for-the-sample-mean.html" />
    <link rel="prev" title="7. Sampling Distributions" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Shape &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">7. Sampling Distributions</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-4-discret-rvs-and-clt.html">7.4. Discrete Random Variables and the CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">7. </span>Sampling Distributions</a></li>
      <li class="breadcrumb-item active"><span class="section-number">7.1. </span>Statistics and Sampling Distributions</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter7/lectures/7-1-statistics-and-sampling-distributions.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch7-1">
   <iframe
      id="video-ch7-1"
      title="STAT 350 – Chapter 7.1 Statistics and Sampling Distributions Video"
      src="https://www.youtube.com/embed/YLCUV0h1mRA?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="id1">
<h1><span class="section-number">7.1. </span>Statistics and Sampling Distributions<a class="headerlink" href="#id1" title="Link to this heading"></a></h1>
<p>We’ve spent considerable time building probability models that describe populations. Now we reach a pivotal
moment in our statistical journey: the bridge from probability theory to statistical inference.
Instead of knowing the population distribution, we’ll work backward from sample data to make conclusions
about unknown populations. This transition requires understanding <strong>how sample statistics themselves behave
as random variables</strong>.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p>Understand how <strong>sample statistics can be viewed as random variables</strong>.</p></li>
<li><p>Master the <strong>theoretical properties of sample statistics</strong> in relation to the population distribution.</p></li>
</ul>
</div>
<section id="parameters-statistics-and-the-bridge-to-inference">
<h2><span class="section-number">7.1.1. </span>Parameters, Statistics, and the Bridge to Inference<a class="headerlink" href="#parameters-statistics-and-the-bridge-to-inference" title="Link to this heading"></a></h2>
<p>Before diving into sampling distributions, let us review the fundamental vocabulary.</p>
<section id="population-parameters">
<h3>Population Parameters<a class="headerlink" href="#population-parameters" title="Link to this heading"></a></h3>
<p>A <strong>parameter</strong> is a number that describes some attribute of the population.
For example, the population mean <span class="math notranslate nohighlight">\(\mu\)</span> is a parameter that tells us the average value across <em>all units in
the population</em>. These parameters are often unknown in practice, but they always exist as <strong>fixed, non-random values</strong>.</p>
<p>When we study probability distributions, we often assume we know these parameters to
understand theoretical behavior. But in statistical inference, the tables turn—we
observe sample data and try to learn about these unknown population characteristics.</p>
</section>
<section id="sample-statistics-our-window-into-the-population">
<h3>Sample Statistics: Our Window Into the Population<a class="headerlink" href="#sample-statistics-our-window-into-the-population" title="Link to this heading"></a></h3>
<p>A <strong>statistic</strong> <span class="math notranslate nohighlight">\(T\)</span> is a function that maps each sample to a numerical summary <span class="math notranslate nohighlight">\(t\)</span>:</p>
<div class="math notranslate nohighlight">
\[T(x_1, x_2, \cdots, x_n) = t\]</div>
<p>One example is the sample mean <span class="math notranslate nohighlight">\(\bar{x} = \frac{1}{n}\sum_{i=1}^n x_i\)</span>, which summarizes the
center of an observed sample. Unlike parameters, we can calculate statistics directly
from the data.</p>
<p>The crucial insight is that <strong>statistics will change from sample to sample</strong>. If we collect a
new sample of the same size from the same population, we’ll almost certainly get <strong>different values for</strong>
<span class="math notranslate nohighlight">\(\bar{x}\)</span>.</p>
</section>
<section id="estimators-statistics-with-a-purpose">
<h3>Estimators: Statistics with a Purpose<a class="headerlink" href="#estimators-statistics-with-a-purpose" title="Link to this heading"></a></h3>
<p>An <strong>estimator</strong> is a statistic which <strong>targets a specific
population parameter</strong>. We use the sample mean <span class="math notranslate nohighlight">\(\bar{x}\)</span> as an estimator of the population mean <span class="math notranslate nohighlight">\(\mu\)</span>.
We use the sample standard deviation <span class="math notranslate nohighlight">\(s\)</span> as an estimator of the population standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p>The sample mean <span class="math notranslate nohighlight">\(\bar{x}\)</span> is both a statistic (it summarizes our sample)
and an estimator (it targets the population mean <span class="math notranslate nohighlight">\(\mu\)</span>). This dual role reflects the bridge between
describing what we observe and inferring what we cannot directly measure.</p>
<figure class="align-center" id="id2" style="width: 80%">
<img alt="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/pop-stat-est-inf.png" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/pop-stat-est-inf.png" />
<figcaption>
<p><span class="caption-number">Fig. 7.1 </span><span class="caption-text"><em>Parameters describe the population; statistics summarize the sample; estimators target the unknown parameters</em></span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
</section>
<section id="the-sampling-distribution">
<h2><span class="section-number">7.1.2. </span>The Sampling Distribution<a class="headerlink" href="#the-sampling-distribution" title="Link to this heading"></a></h2>
<p>To understand <strong>how estimators behave across many
possible samples</strong>, we must establish the concept of a sampling distribution.</p>
<section id="the-thought-experiment">
<h3>The Thought Experiment<a class="headerlink" href="#the-thought-experiment" title="Link to this heading"></a></h3>
<p>Imagine we could repeatedly sample from the same population, computing a statistic each
time. Suppose we’re studying the heights of college students and we take samples of size
<span class="math notranslate nohighlight">\(n = 25\)</span>. We collect our first sample, measure all <span class="math notranslate nohighlight">\(25\)</span> students, and compute <span class="math notranslate nohighlight">\(\bar{x}_1 = 67.2\)</span> inches.
We collect a second sample of <span class="math notranslate nohighlight">\(25\)</span> different students and get <span class="math notranslate nohighlight">\(\bar{x}_2 = 68.8\)</span> inches. A third sample
gives <span class="math notranslate nohighlight">\(\bar{x}_3 = 66.9\)</span> inches.</p>
<p>If we repeated this process thousands of times, we’d have thousands of different sample means:
<span class="math notranslate nohighlight">\(\bar{x}_1, \bar{x}_2, \cdots, \bar{x}_m\)</span>. These sample means would <strong>vary</strong>,
and that variation would follow a pattern.
The distribution of these sample means is called the <strong>sampling distribution of the sample mean</strong>.</p>
</section>
<section id="formal-definition">
<h3>Formal Definition<a class="headerlink" href="#formal-definition" title="Link to this heading"></a></h3>
<p>The <strong>sampling distribution</strong> of a statistic is the probability distribution of that statistic
across all possible samples of the same size from the same population. It tells us <strong>how the statistic
behaves as a random variable</strong>.</p>
<p>This concept applies to any statistic—sample means, sample standard deviations, sample medians,
sample correlations. Each has its own sampling distribution that describes how that particular
statistic varies from sample to sample.</p>
</section>
<section id="why-this-matters-for-inference">
<h3>Why This Matters for Inference<a class="headerlink" href="#why-this-matters-for-inference" title="Link to this heading"></a></h3>
<p>Understanding sampling distributions allows us to quantify the uncertainty in our estimates.
If we know how <span class="math notranslate nohighlight">\(\bar{X}\)</span> behaves across many samples, we can assess how reliable any single observed
<span class="math notranslate nohighlight">\(\bar{x}\)</span> might be as an estimate of <span class="math notranslate nohighlight">\(\mu\)</span>. This knowledge forms the foundation for
confidence intervals, hypothesis tests, and all other inferential procedures.</p>
<div class="important admonition">
<p class="admonition-title">The Capital <span class="math notranslate nohighlight">\(\bar{X}\)</span></p>
<p>We will now study the behavior of sample statistics as random variables.
To distinguish from contexts where they serve as realized values, we use
capital letters. <span class="math notranslate nohighlight">\(\bar{X}\)</span> denotes the random variable that
generates <span class="math notranslate nohighlight">\(\bar{x}\)</span>’s.
Similar distinctions apply to <span class="math notranslate nohighlight">\(S\)</span> vs. <span class="math notranslate nohighlight">\(s\)</span> and <span class="math notranslate nohighlight">\(S^2\)</span> vs. <span class="math notranslate nohighlight">\(s^2\)</span>.</p>
</div>
</section>
</section>
<section id="factors-affecting-sampling-distributions">
<h2><span class="section-number">7.1.3. </span>Factors Affecting Sampling Distributions<a class="headerlink" href="#factors-affecting-sampling-distributions" title="Link to this heading"></a></h2>
<ol class="arabic">
<li><p><strong>The population distribution</strong></p></li>
<li><p><strong>Sample size</strong>, <span class="math notranslate nohighlight">\(n\)</span></p></li>
<li><p><strong>The statistic itself</strong></p>
<p>For example, <span class="math notranslate nohighlight">\(S\)</span> can only take positive values, while <span class="math notranslate nohighlight">\(\bar{X}\)</span> has no such
restriction. This is due to differences in how the two statistics are computed.</p>
</li>
<li><p><strong>The sampling technique</strong></p>
<p>The sampling technique affects how well a sample represents the population and whether
key properties like independence are satisfied.</p>
</li>
</ol>
<p>We will examine how these factors influence inference in greater depth in the upcoming chapters.</p>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">7.1.4. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>Statistics are random variables</strong> that vary from sample to sample, creating sampling distributions
that describe this variability. Understanding how <strong>statistics behave as random variables</strong> lets us quantify
uncertainty and make conclusions about unknown populations.</p></li>
<li><p><strong>Multiple factors affect sampling distributions</strong>: population shape, sample size,
the choice of statistic, and independence all play important roles.</p></li>
</ol>
</div>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Conceptual Understanding</strong>: Explain the difference between a parameter, a statistic, and an estimator.
Give an example of each in the context of measuring the average commute time for workers in your city.</p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="7. Sampling Distributions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="7-2-sampling-distribution-for-the-sample-mean.html" class="btn btn-neutral float-right" title="7.2. Sampling Distribution for the Sample Mean" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>