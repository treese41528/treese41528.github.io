

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>7.2. Sampling Distribution for the Sample Mean &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=9c3e77be" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=2f168d12" />
      <link rel="stylesheet" type="text/css" href="../../_static/credits.css?v=f7efa099" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/Website/chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=1ae7504c"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=7e0058eb"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7.3. The Central Limit Theorem (CLT)" href="7-3-clt.html" />
    <link rel="prev" title="7.1. Statistics and Sampling Distributions" href="7-1-statistics-and-sampling-distributions.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#office-hours">Office Hours</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#troubleshooting-guide">Troubleshooting Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-and-binomial-distributions">Part 1: The Bernoulli and Binomial Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#the-binomial-distribution">The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-poisson-distribution">Part 2: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-other-named-discrete-distributions">Part 3: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-standard-normal-table">Part 2: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-z-score-transformation">Part 3: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html">Worksheet 11: The Central Limit Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#tutorial-generating-the-sampling-distribution-of-bar-x">Tutorial: Generating the Sampling Distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-1-exploring-clt-with-skewed-distributions">Part 1: Exploring CLT with Skewed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-2-application-of-the-clt">Part 2: Application of the CLT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-3-beyond-mean-and-sum">Part 3: Beyond Mean and Sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-4-exploring-clt-generalizability-with-ai-assistance-exploration">Part 4: Exploring CLT Generalizability with AI Assistance (Exploration)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html">Worksheet 12: Point Estimators and Unbiased Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-1-estimating-parameters-of-the-exponential-distribution">Part 1: Estimating Parameters of the Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-2-estimating-the-maximum-of-a-uniform-distribution">Part 2: Estimating the Maximum of a Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-3-minimum-variance-unbiased-estimators-mvue">Part 3: Minimum Variance Unbiased Estimators (MVUE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html">Worksheet 13: Introduction to Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-1-pivotal-quantities-and-deriving-confidence-intervals">Part 1: Pivotal Quantities and Deriving Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-2-sample-size-determination">Part 2: Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-3-one-sided-confidence-bounds">Part 3: One-Sided Confidence Bounds</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-4-confidence-intervals-when-is-unknown">Part 4: Confidence Intervals When σ is Unknown</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html">Worksheet 14: Student’s t-Distribution and Statistical Power</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#assumptions-for-t-distribution-inference">Assumptions for t-Distribution Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-1-analyzing-chick-growth-with-confidence-intervals">Part 1: Analyzing Chick Growth with Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-2-introduction-to-hypothesis-testing">Part 2: Introduction to Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-3-sample-size-determination-and-power-analysis">Part 3: Sample Size Determination and Power Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html">Worksheet 15: Hypothesis Testing for a Single Mean</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-hypothesis-testing-framework">The Hypothesis Testing Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-test-statistic-known">The Test Statistic (Known σ)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#distribution-of-the-test-statistic">Distribution of the Test Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-p-value">The p-value</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1a-simulation-when-null-hypothesis-is-true">Question 1a: Simulation When Null Hypothesis is True</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1b-simulation-when-null-hypothesis-is-false">Question 1b: Simulation When Null Hypothesis is False</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1c-comparing-the-two-scenarios">Question 1c: Comparing the Two Scenarios</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-t-test-statistic">The t-Test Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#properties-of-the-t-distribution">Properties of the t-Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2a-assumptions-and-exploratory-analysis">Question 2a: Assumptions and Exploratory Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2b-full-hypothesis-testing-procedure">Question 2b: Full Hypothesis Testing Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2c-manual-verification">Question 2c: Manual Verification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2d-confidence-bound">Question 2d: Confidence Bound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2e-power-calculation">Question 2e: Power Calculation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html">Worksheet 16: Two-Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-1-independent-vs-paired-designs">Part 1: Independent vs. Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-2-independent-samples-with-known-variances">Part 2: Independent Samples with Known Variances</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-3-pooled-two-sample-t-test-equal-variances">Part 3: Pooled Two-Sample t-Test (Equal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-4-welch-s-two-sample-t-test-unequal-variances">Part 4: Welch’s Two-Sample t-Test (Unequal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html">Worksheet 17: Paired Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-1-theory-and-procedure-for-paired-samples">Part 1: Theory and Procedure for Paired Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-2-sleep-study-analysis">Part 2: Sleep Study Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-3-sample-size-calculation-for-paired-designs">Part 3: Sample Size Calculation for Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html">Worksheet 18: One-Way ANOVA (Analysis of Variance)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#why-use-one-way-anova">Why Use One-Way ANOVA?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#one-way-anova-assumptions">One-Way ANOVA Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#one-way-anova-f-test-statistic-and-sources-of-variation">One-Way ANOVA F-test Statistic and Sources of Variation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#notation-and-setup">Notation and Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-1-computing-the-overall-sample-mean">Part 1: Computing the Overall Sample Mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-2-checking-the-equal-variance-assumption">Part 2: Checking the Equal Variance Assumption</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-3-pooled-variance-estimator">Part 3: Pooled Variance Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-4-within-group-variability-sum-of-squares-within-sse">Part 4: Within-Group Variability (Sum of Squares Within, SSE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-5-between-group-variability-sum-of-squares-among-ssa">Part 5: Between-Group Variability (Sum of Squares Among, SSA)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-6-total-variability-and-partitioning">Part 6: Total Variability and Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-7-degrees-of-freedom">Part 7: Degrees of Freedom</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-8-mean-squares">Part 8: Mean Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-9-the-f-test-statistic">Part 9: The F-Test Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-10-computing-the-p-value-and-making-a-decision">Part 10: Computing the P-Value and Making a Decision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-11-completing-the-anova-table">Part 11: Completing the ANOVA Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-12-limitations-and-follow-up-questions">Part 12: Limitations and Follow-Up Questions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html">Worksheet 19: Multiple Comparisons and Post-Hoc Testing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#the-multiple-comparisons-problem">The Multiple Comparisons Problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#methods-to-control-the-family-wise-error-rate">Methods to Control the Family-Wise Error Rate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-1-simulation-study-type-i-error-with-multiple-comparison-methods">Part 1: Simulation Study - Type I Error with Multiple Comparison Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-2-applying-tukey-s-hsd-to-worksheet-18-data">Part 2: Applying Tukey’s HSD to Worksheet 18 Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-3-comprehensive-anova-analysis-toothgrowth-dataset">Part 3: Comprehensive ANOVA Analysis - ToothGrowth Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html">Worksheet 20: Introduction to Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#from-anova-to-regression-same-core-ideas-new-application">From ANOVA to Regression: Same Core Ideas, New Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#the-simple-linear-regression-model">The Simple Linear Regression Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#least-squares">Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-1-deriving-least-squares-estimators">Part 1: Deriving Least Squares Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-2-the-general-simple-linear-regression-estimators">Part 2: The General Simple Linear Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-3-sampling-distributions-of-regression-estimators">Part 3: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-4-practice-problems">Part 4: Practice Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html">Worksheet 21: Inference for Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-1-sampling-distributions-of-regression-estimators">Part 1: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-2-checking-regression-assumptions">Part 2: Checking Regression Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-3-bird-data-analysis">Part 3: Bird Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-4-regression-anova">Part 4: Regression ANOVA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html">Worksheet 22: Model Assessment and Prediction in Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-1-the-coefficient-of-determination">Part 1: The Coefficient of Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-2-confidence-intervals-vs-prediction-intervals">Part 2: Confidence Intervals vs. Prediction Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-3-simulation-study-ci-vs-pi-coverage">Part 3: Simulation Study — CI vs. PI Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-4-prediction-with-the-bird-data">Part 4: Prediction with the Bird Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-5-diamonds-data-analysis">Part 5: Diamonds Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html">Getting Started with R and RStudio</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#getting-started-with-swirl">Getting Started with swirl</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#setup-and-use-swirl">Setup and Use swirl</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html">Course Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#primary-course-dataset-apprating">Primary Course Dataset - AppRating</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#tutorial-support-datasets">Tutorial Support Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#loading-datasets-in-r">Loading Datasets in R</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#built-in-r-datasets-used-in-course">Built-in R Datasets Used in Course</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#data-download-and-organization">Data Download and Organization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html">Computer Assignments and Tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-structure">Assignment Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#more-help-and-reference-pages">More Help and Reference Pages</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#data-import-validation">Data Import &amp; Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#statistical-assumptions">Statistical Assumptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#common-errors-to-avoid">Common Errors to Avoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#workflow-template">Workflow Template</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html">Graphics (ggplot2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#tables-reporting">Tables &amp; Reporting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html">Function Reference Part 1</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#simulation-functions">Simulation Functions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html">Function Reference Part 2: Inference Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html#diagnostic-plots-for-assumptions">Diagnostic Plots for Assumptions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html">Alternative Resources (Tutorials)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#general-r-data-science">General R &amp; Data Science</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#ggplot2-visualization">ggplot2 Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#tidyverse">Tidyverse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#video-content">Video Content</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#quick-reference">Quick Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#base-r">Base R</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Sequential Bayesian Updating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. The Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">7. Sampling Distributions</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. The Foundation of Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Connecting CI and HT; <em>t</em>-Test for μ When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. The Four Steps to Hypothesis Testing and Understanding the Result</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Statistical Inference for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Independent Two-Sample Analysis When Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Independent Two-Sample Analysis - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Independent Two-Sample Analysis - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Paired Two-Sample Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. ANOVA F-Test and Its Relationship to Two-Sample <em>t</em>-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction and Robustness</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">7. </span>Sampling Distributions</a></li>
      <li class="breadcrumb-item active"><span class="section-number">7.2. </span>Sampling Distribution for the Sample Mean</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch7-2">
   <iframe
      id="video-ch7-2"
      title="STAT 350 – Chapter 7.2 Sampling Distribution for the Sample Mean Video"
      src="https://www.youtube.com/embed/TIOCX2hjXqw?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><div class="tip admonition">
<p class="admonition-title">Slides 📊</p>
<p><a class="reference external" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%207%20Sampling%20Distributions/Sampling%20Distributions%20%28Chapter7%29_AC.pptx">Download Chapter 7 slides (PPTX)</a></p>
</div>
<section id="id1">
<h1><span class="section-number">7.2. </span>Sampling Distribution for the Sample Mean<a class="headerlink" href="#id1" title="Link to this heading"></a></h1>
<p>Having established that statistics are random variables with their own distributions, we now focus on the most
important statistic in all of statistical inference: the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span>.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p>View the <strong>sample mean</strong> <span class="math notranslate nohighlight">\(\bar{X}\)</span> as a function of <span class="math notranslate nohighlight">\(n\)</span> independent and identically distributed
random variables. Establish <span class="math notranslate nohighlight">\(E[\bar{X}]\)</span> and <span class="math notranslate nohighlight">\(\text{Var}(\bar{X})\)</span> in relation to the distributional properties of
these building blocks.</p></li>
<li><p>Define the standard deviation <span class="math notranslate nohighlight">\(\sigma_{\bar{X}}\)</span> of the sample mean as the <strong>standard error</strong> and understand
how it is influenced by the population standard deviation and sample size.</p></li>
</ul>
</div>
<section id="a-new-perspective-on-the-data-generating-procedure">
<h2><span class="section-number">7.2.1. </span>A New Perspective on the Data-Generating Procedure<a class="headerlink" href="#a-new-perspective-on-the-data-generating-procedure" title="Link to this heading"></a></h2>
<p>So far, we’ve pictured the sampling procedure as drawing
individual datapoints <span class="math notranslate nohighlight">\(n\)</span> different times from a single random variable <span class="math notranslate nohighlight">\(X\)</span> (left of
<a class="reference internal" href="#new-sampling-framework"><span class="std std-numref">Fig. 7.3</span></a>).</p>
<figure class="align-center" id="id2" style="width: 70%">
<span id="new-sampling-framework"></span><img alt="A new perspective of understanding how data points are sampled" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/new-sampling-framework.png" />
<figcaption>
<p><span class="caption-number">Fig. 7.3 </span><span class="caption-text">Left represents how we used to think of the sampling procedure;
we now think in the perspective on the right</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>For the formal understanding of the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span>, we need to
begin with a new perspective. Imagine that there are <span class="math notranslate nohighlight">\(n\)</span> <strong>independent and identically distributed (iid)
copies of the population</strong>, <span class="math notranslate nohighlight">\(X_1, X_2, \cdots, X_n\)</span>, and a sample
is constructed by taking one data point from each copy (right of <a class="reference internal" href="#new-sampling-framework"><span class="std std-numref">Fig. 7.3</span></a>).</p>
<p>Through this shift, we can now express the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> as a function of <span class="math notranslate nohighlight">\(n\)</span> random variables:</p>
<div class="math notranslate nohighlight">
\[\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i\]</div>
<p>This allows us to break down the properties of the random variable <span class="math notranslate nohighlight">\(\bar{X}\)</span> in terms of its building blocks
<span class="math notranslate nohighlight">\(X_1, X_2, \cdots, X_n\)</span>, with which we are more familiar.</p>
</section>
<section id="visualizing-sampling-distributions">
<h2><span class="section-number">7.2.2. </span>Visualizing Sampling Distributions<a class="headerlink" href="#visualizing-sampling-distributions" title="Link to this heading"></a></h2>
<p>Let’s get a feel for how sampling distributions behave with a concrete visual example.</p>
<section id="the-population-exponential-distribution">
<h3>The Population: Exponential Distribution<a class="headerlink" href="#the-population-exponential-distribution" title="Link to this heading"></a></h3>
<p>Consider a population that follows an exponential distribution with parameter <span class="math notranslate nohighlight">\(\lambda = 1\)</span>.
Recall that this distribution is highly right-skewed, with most values bunched near 0 and a
long tail extending to the right. The population mean is <span class="math notranslate nohighlight">\(\mu = 1/\lambda = 1\)</span>, and the population
standard deviation is <span class="math notranslate nohighlight">\(\sigma = 1/\lambda = 1\)</span>.</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/exponential-pdf.png"><img alt="The pdf of exponential distribution" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/exponential-pdf.png" style="width: 70%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 7.4 </span><span class="caption-text">The exponential population: highly right-skewed with mean <span class="math notranslate nohighlight">\(\mu=1\)</span></span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>When we conduct statistical inference in practice, we won’t know the population follows an
exponential distribution or what its parameter value is. For now, we’ll assume this knowledge
so we can compare our sample results to the known truth.</p>
</section>
<section id="sampling-with-n-5">
<h3>Sampling with n = 5<a class="headerlink" href="#sampling-with-n-5" title="Link to this heading"></a></h3>
<p>Let’s start by taking one sample of size <span class="math notranslate nohighlight">\(n = 5\)</span> from this population. The code below
samples five numbers from the population and computes the average:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Take one sample of size 5</span>
<span class="n">sample1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rexp</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">rate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
<span class="n">sample_mean1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">sample1</span><span class="p">)</span>
<span class="c1"># Result: 0.39</span>
</pre></div>
</div>
<p>We repeat this process many times (<code class="docutils literal notranslate"><span class="pre">num_samples</span></code>). Each repetition samples a different set of
five numbers and thus produces a different sample mean.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simulate the sampling distribution</span>
<span class="n">num_samples</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1000000</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5</span>
<span class="n">sample_means</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">replicate</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="nf">rexp</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">rate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)))</span>
</pre></div>
</div>
<p>When we plot the distribution of these million sample means, we see something remarkable.
The distribution no longer looks like the original exponential distribution. It’s still somewhat right-skewed,
but the degree of skewness has diminished. The sample means cluster more tightly around the true
population mean <span class="math notranslate nohighlight">\(\mu=1\)</span>.</p>
<figure class="align-center">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/sampling-dist-n5.png"><img alt="Histogram of sample means when :math:`n=5`" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/sampling-dist-n5.png" style="width: 70%;" />
</a>
</figure>
</section>
<section id="the-effect-of-increasing-sample-size">
<h3>The Effect of Increasing Sample Size<a class="headerlink" href="#the-effect-of-increasing-sample-size" title="Link to this heading"></a></h3>
<p>Now let’s see what happens when we increase the sample size to <span class="math notranslate nohighlight">\(n = 25\)</span>:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/sampling-dist-n25.png"><img alt="Histogram of sample means when :math:`n=25`" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/sampling-dist-n25.png" style="width: 70%;" />
</a>
</figure>
<p>The transformation is dramatic. The sampling distribution is now roughly symmetric and centered around <span class="math notranslate nohighlight">\(\mu = 1\)</span>.
It bears little resemblance to the original exponential population. The sample means are much more concentrated
around the true value—most fall between 0.5 and 1.5.</p>
<p>With <span class="math notranslate nohighlight">\(n = 65\)</span>, the pattern becomes even more pronounced:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/sampling-dist-n65.png"><img alt="Histogram of sample means when :math:`n=65`" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/sampling-dist-n65.png" style="width: 70%;" />
</a>
</figure>
<p>Now the distribution is highly concentrated around <span class="math notranslate nohighlight">\(\mu = 1\)</span> and appears very symmetric.
The sample means rarely stray far from the true population mean.</p>
</section>
<section id="key-insights">
<h3>Key Insights<a class="headerlink" href="#key-insights" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>The sample mean targets the population mean</strong>: All sampling distributions center around <span class="math notranslate nohighlight">\(\mu = 1\)</span>,
regardless of sample size.</p></li>
<li><p><strong>Larger samples produce more precise estimates</strong>: As <span class="math notranslate nohighlight">\(n\)</span> increases, the sampling distribution becomes
more concentrated around <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p><strong>Shape changes with sample size</strong>: Even though the population is highly skewed, the sampling distribution
becomes more symmetric as <span class="math notranslate nohighlight">\(n\)</span> increases.</p></li>
<li><p><strong>The magic of averaging</strong>: By averaging multiple observations, we reduce the impact of extreme values and
create estimators that behave better than individual observations.</p></li>
</ol>
</section>
</section>
<section id="deriving-the-mathematical-properties">
<h2><span class="section-number">7.2.3. </span>Deriving the Mathematical Properties<a class="headerlink" href="#deriving-the-mathematical-properties" title="Link to this heading"></a></h2>
<p>To deepen our understanding of the sample mean’s behavior, we derive its key distributional properties:
the mean, variance, and standard deviation. For clarity,
all population parameters are written with a subscript <span class="math notranslate nohighlight">\(X\)</span> and all
sampling distribution parameters with a subscript <span class="math notranslate nohighlight">\(\bar{X}\)</span>.</p>
<section id="a-expected-value-of-the-sample-mean">
<h3>A. Expected Value of the Sample Mean<a class="headerlink" href="#a-expected-value-of-the-sample-mean" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight">
\[\mu_{\bar{X}} = E[\bar{X}] = E\left[\frac{1}{n}\sum_{i=1}^n X_i\right]
= \frac{1}{n} E\left[\sum_{i=1}^n X_i\right] = \frac{1}{n} \sum_{i=1}^n E[X_i]\]</div>
<p>Since all <span class="math notranslate nohighlight">\(X_i\)</span>’s come from the same distribution with <span class="math notranslate nohighlight">\(E[X_i] = \mu_X\)</span>,</p>
<div class="math notranslate nohighlight">
\[E[\bar{X}] = \frac{1}{n} \sum_{i=1}^n \mu_X = \frac{1}{n} \cdot n\mu_X = \mu_X\]</div>
<section id="unbiasedness-of-sample-mean">
<h4>Unbiasedness of Sample Mean<a class="headerlink" href="#unbiasedness-of-sample-mean" title="Link to this heading"></a></h4>
<p>The <strong>expected value of the sample mean equals the population mean</strong> (<span class="math notranslate nohighlight">\(\mu_{\bar{X}} = \mu_X\)</span>).
When an estimator equals its target on average, we call it an <strong>unbiased</strong> estimator.
Individual sample means may be too high or too low, but they center around the correct target.</p>
</section>
</section>
<section id="b-variance-and-standard-error-of-the-sample-mean">
<h3>B. Variance and Standard Error of the Sample Mean<a class="headerlink" href="#b-variance-and-standard-error-of-the-sample-mean" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight">
\[\sigma^2_{\bar{X}}=\text{Var}(\bar{X}) =\text{Var}\left(\frac{1}{n}\sum_{i=1}^n X_i\right)
= \frac{1}{n^2} \text{Var}\left(\sum_{i=1}^n X_i\right)\]</div>
<p>Since the <span class="math notranslate nohighlight">\(X_i\)</span>’s are independent, the variance of the sum equals the sum of the variances.
Also, all <span class="math notranslate nohighlight">\(X_i\)</span>’s have the same variance <span class="math notranslate nohighlight">\(\sigma_X^2\)</span>:</p>
<div class="math notranslate nohighlight">
\[\text{Var}(\bar{X}) = \frac{1}{n^2} \sum_{i=1}^n\text{Var}(X_i)
= \frac{1}{n^2} \cdot n\sigma^2_X = \frac{\sigma^2_X}{n}\]</div>
<p>We call the standard deviation of the sample mean the <strong>standard error</strong>. It is the positive square root
of the variance of <span class="math notranslate nohighlight">\(\bar{X}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \sqrt{\text{Var}(\bar{X})} = \frac{\sigma_X}{\sqrt{n}}\]</div>
<section id="understanding-the-standard-error">
<h4>Understanding the Standard Error<a class="headerlink" href="#understanding-the-standard-error" title="Link to this heading"></a></h4>
<p>For even modest sample sizes, <strong>sample means are much less variable</strong> than individual observations.
With <span class="math notranslate nohighlight">\(n = 25\)</span>, for example, the sample mean has standard error <span class="math notranslate nohighlight">\(\frac{\sigma}{5}\)</span>, making it five times
more precise than any single observation with standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p>This concentration effect explains why averaging is such a powerful statistical technique
and why larger samples are usually better. By combining information from multiple observations, we create estimators that are more
reliable than an individual measurement.</p>
</section>
</section>
<section id="c-summary-of-basic-distributional-properties-of-bar-x">
<h3>C. Summary of Basic Distributional Properties of <span class="math notranslate nohighlight">\(\bar{X}\)</span><a class="headerlink" href="#c-summary-of-basic-distributional-properties-of-bar-x" title="Link to this heading"></a></h3>
<table class="docutils align-center" style="width: 90%">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Notation</p></th>
<th class="head"><p>Formula</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Expected Value</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(E[\bar{X}]\)</span> or <span class="math notranslate nohighlight">\(\mu_{\bar{X}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu_X\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Variance</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\text{Var}(\bar{X})\)</span> or <span class="math notranslate nohighlight">\(\sigma_{\bar{X}}^2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\sigma_X^2}{n}\)</span></p></td>
</tr>
<tr class="row-even"><td><p><strong>Standard Error</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\sigma_{\bar{X}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\sigma_X}{\sqrt{n}}\)</span></p></td>
</tr>
</tbody>
</table>
<div class="note admonition">
<p class="admonition-title">Example💡: Maze Navigation Times</p>
<p>Researchers study how long it takes rats of a certain subspecies to navigate through a maze.
Previous research suggests that navigation times have a mean <span class="math notranslate nohighlight">\(\mu_X = 1.5\)</span> minutes and a
standard deviation <span class="math notranslate nohighlight">\(\sigma_X=0.35\)</span> minutes.</p>
<p>The researchers select five rats at random and want to understand the <strong>behavior of the average navigation
time for their sample</strong>. What are the mean and the standard error of the sampling distribution for the
sample mean?</p>
<p><strong>Setting Up the Problem</strong></p>
<p>We have:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X_i\)</span> are <em>iid</em> with <span class="math notranslate nohighlight">\(E[X_i]=1.5\)</span> and <span class="math notranslate nohighlight">\(\text{Var}(X_i)=0.35^2\)</span>
for each <span class="math notranslate nohighlight">\(i \in \{1,2,3,4,5\}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(n = 5\)</span></p></li>
</ul>
<p><strong>Mean of the Sample Mean</strong></p>
<div class="math notranslate nohighlight">
\[\mu_{\bar{X}} = \mu_X = 1.5 \text{ minutes}\]</div>
<p><strong>Standard Error of the Sample Mean</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{0.35}{\sqrt{5}} = \frac{0.35}{2.236} = 0.1565 \text{ minutes}\]</div>
</div>
</section>
</section>
<section id="the-special-case-normal-populations">
<h2><span class="section-number">7.2.4. </span>The Special Case: Normal Populations<a class="headerlink" href="#the-special-case-normal-populations" title="Link to this heading"></a></h2>
<p>While our mathematical results <strong>apply to any population with finite mean and variance</strong>,
there’s <strong>one special case where we can say much more</strong> about the shape of the sampling
distribution: when the population follows a normal distribution.</p>
<section id="linear-combinations-of-normal-random-variables">
<h3>Linear Combinations of Normal Random Variables<a class="headerlink" href="#linear-combinations-of-normal-random-variables" title="Link to this heading"></a></h3>
<p>A key property of normal distributions is that <strong>linear combinations of normal random
variables are themselves normal</strong>. That is, if <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are
normal random variables, then any linear combination of the form <span class="math notranslate nohighlight">\(aX + bY + c\)</span> is also normal.</p>
<p>The sample mean is exactly such a linear combination:</p>
<div class="math notranslate nohighlight">
\[\bar{X} = \frac{1}{n}X_1 + \frac{1}{n}X_2 + \cdots + \frac{1}{n}X_n\]</div>
</section>
<section id="the-exact-distribution-of-bar-x-from-normal-population">
<h3>The Exact Distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> from Normal Population<a class="headerlink" href="#the-exact-distribution-of-bar-x-from-normal-population" title="Link to this heading"></a></h3>
<p>If <span class="math notranslate nohighlight">\(X_1, X_2, \cdots, X_n\)</span> are iid from a normal distribution with mean
<span class="math notranslate nohighlight">\(\mu_X\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma_X\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \sim N\left(\mu_X, \frac{\sigma_X^2}{n}\right) \quad \text{ or equivalently,} \quad
\bar{X} \sim N\left(\mu_X, \frac{\sigma_X}{\sqrt{n}}\right)\]</div>
<p>This result is remarkable because it tells us the <strong>exact</strong> sampling distribution,
not just its mean and variance.</p>
<div class="note admonition">
<p class="admonition-title">Example💡: Maze Navigation Times, Continued</p>
<p>Researchers study how long it takes rats of a certain subspecies to navigate through a maze.
In addition to the parameters  <span class="math notranslate nohighlight">\(\mu = 1.5\)</span> minutes and  <span class="math notranslate nohighlight">\(\sigma = 0.35\)</span> minutes,
it is known that <strong>the population of navigation times follow normal distribution</strong>.</p>
<p><strong>Setting Up the Problem</strong></p>
<p>From the previous example, we have</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu_{\bar{X}} = 1.5\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = 0.1565\)</span></p></li>
</ul>
<p>Since the population follows normal distribution, the sampling distribution for
the sample mean must also be normal. We have:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \sim N(\mu_{\bar{X}} = 1.5, \sigma^2_{\bar{X}} = 0.1565^2)\]</div>
<p><strong>Computing Probabilities</strong></p>
<p>What’s the probability that the average navigation time for five rats exceeds 1.75 minutes?</p>
<p>We need to find <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 1.75)\)</span>. Since <span class="math notranslate nohighlight">\(\bar{X} \sim N(1.5, 0.1565^2)\)</span>, we use
the standardization technique and the Z-table (or a statistical software) to compute:</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;P(\bar{X} &gt; 1.75) = P\left(\frac{\bar{X} - 1.5}{0.1565} &gt; \frac{1.75 - 1.5}{0.1565}\right)\\
&amp;= P(Z &gt; 1.60) = 1 - \Phi(1.60) = 1 - 0.9452 = 0.0548\end{split}\]</div>
<p>There’s 0.0548 probability that the average navigation time for five randomly selected
rats will exceed 1.75 minutes.</p>
</div>
</section>
</section>
<section id="additional-example-quality-control-in-manufacturing">
<h2><span class="section-number">7.2.5. </span>Additional Example: Quality Control in Manufacturing<a class="headerlink" href="#additional-example-quality-control-in-manufacturing" title="Link to this heading"></a></h2>
<p>Let us conclude this section by solving a problem applying the CLT to decision-making in
in quality control.</p>
<div class="note admonition">
<p class="admonition-title">Example 💡: Quality Control in Manufacturing</p>
<p>The Bulls Eye Production company manufactures a number of high precision tools.
Under the usual production process, one of these tools has a <strong>mean diameter of 5mm</strong>.
The measurement varies <strong>normally</strong> aroud this mean, with <strong>standard deviation of 0.5mm</strong>.</p>
<p>However, the machine will need to be frequently recalibrated due to the strenuous operating conditions.
Recalibration is required anytime the difference between
the <strong>observed sample mean diameter</strong> and <strong>the ideal diameter</strong> is too large. “Large” is
measured probabilistically; if the probability of the deviation is <em>rarer</em>
than 0.05, then the difference is considered too large.</p>
<p>A <strong>random sample of size 64</strong> is taken to assess the need for recalibration. It is found that the average diameter of
the sample is <strong>4.85mm</strong>. Is recalibration necessary?</p>
<p><strong>Setting Up the Problem</strong></p>
<p>It is given that</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n=64\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mu_X = 5\)</span> and <span class="math notranslate nohighlight">\(\sigma_X = 0.5\)</span></p></li>
<li><p>The population is normally distributed.</p></li>
<li><p>The sample is randomly collected from the same population, which allows us to assume the iid condition.</p></li>
<li><p>A single realization from <span class="math notranslate nohighlight">\(\bar{X}\)</span> has value <span class="math notranslate nohighlight">\(\bar{x} = 4.85\)</span>.</p></li>
</ul>
<p><strong>Solving the Problem</strong></p>
<p>We must compute a probability representing how <em>rare</em> the current difference <span class="math notranslate nohighlight">\(|\bar{x}-\mu_X|\)</span> is
when compared with the general behavior of <span class="math notranslate nohighlight">\(|\bar{X}-\mu_X|\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;P(|\bar{X}-\mu_X| &gt; |\bar{x}-\mu_X|)\\
&amp;= P(|\bar{X}-\mu_X| &gt; |4.85-5|)\\
&amp;=P(\Bigg|\frac{\bar{X}-\mu_X}{\sigma_X/\sqrt{n}}\Bigg| &gt; \frac{|4.85-5|}{0.5/\sqrt{64}})\\
&amp;=P(|Z| &gt; 2.4) = P(Z &gt; 2.4) + P(Z &lt; -2.4)\\
&amp;=\underbrace{2P(Z &lt; -2.4)}_{\text{by symmetry around } 0} = 0.0164\end{split}\]</div>
<p>The probability of seeing an even larger difference than the current observation is only 0.0164,
which is smaller than 0.05. Therefore, the machine must be recalibrated.</p>
</div>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">7.2.6. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p>The sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> is a random variable. Its probability distribution is
called the sampling distribution of the sample mean.</p></li>
<li><p>If the population has mean <span class="math notranslate nohighlight">\(\mu_X\)</span> and variance <span class="math notranslate nohighlight">\(\sigma_X^2\)</span>, then
<span class="math notranslate nohighlight">\(\mu_{\bar{X}} = E[\bar{X}] = \mu_X\)</span> and <span class="math notranslate nohighlight">\(\sigma^2_{\bar{X}} = Var(\bar{X}) = \sigma_X^2/n\)</span>.</p></li>
<li><p>If the population has a distribution <span class="math notranslate nohighlight">\(N(\mu_X, \sigma_X^2)\)</span>,
then the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is completely known: <span class="math notranslate nohighlight">\(\bar{X} \sim N(\mu_X, \sigma_X^2/n)\)</span>.</p></li>
</ol>
</div>
</section>
<section id="exercises">
<h2><span class="section-number">7.2.7. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h2>
<p>These exercises develop your skills in working with the sampling distribution of the sample mean, including computing the expected value and standard error, finding probabilities when the population is normal, and determining sample sizes for desired precision.</p>
<div class="tip admonition">
<p class="admonition-title">Key Formulas</p>
<p>For a random sample of size <span class="math notranslate nohighlight">\(n\)</span> from a population with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>:</p>
<ul class="simple">
<li><p><strong>Expected Value</strong>: <span class="math notranslate nohighlight">\(E[\bar{X}] = \mu_{\bar{X}} = \mu\)</span></p></li>
<li><p><strong>Variance</strong>: <span class="math notranslate nohighlight">\(\text{Var}(\bar{X}) = \sigma^2_{\bar{X}} = \frac{\sigma^2}{n}\)</span></p></li>
<li><p><strong>Standard Error</strong>: <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}\)</span></p></li>
</ul>
<p><strong>Special Case — Normal Population</strong>: If the population is <span class="math notranslate nohighlight">\(N(\mu, \sigma^2)\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)\]</div>
</div>
<div class="tip admonition">
<p class="admonition-title">R Functions for Normal Probabilities and Quantiles</p>
<p>For <span class="math notranslate nohighlight">\(\bar{X} \sim N(\mu_{\bar{X}}, \sigma_{\bar{X}})\)</span>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Probability calculations</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sigma_xbar</span><span class="p">)</span><span class="w">               </span><span class="c1"># P(X̄ ≤ x)</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sigma_xbar</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">  </span><span class="c1"># P(X̄ &gt; x)</span>

<span class="c1"># Quantile (inverse CDF) - find x such that P(X̄ ≤ x) = p</span>
<span class="nf">qnorm</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sigma_xbar</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Example</strong>: For <span class="math notranslate nohighlight">\(\bar{X} \sim N(100, 4)\)</span> (mean 100, SD 2):</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">pnorm</span><span class="p">(</span><span class="m">102</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w">                </span><span class="c1"># P(X̄ ≤ 102) = 0.8413</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">102</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">  </span><span class="c1"># P(X̄ &gt; 102) = 0.1587</span>
<span class="nf">qnorm</span><span class="p">(</span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w">              </span><span class="c1"># 95th percentile = 103.29</span>
</pre></div>
</div>
</div>
<div class="warning admonition">
<p class="admonition-title">Important Note</p>
<p>The formulas for <span class="math notranslate nohighlight">\(E[\bar{X}]\)</span> and <span class="math notranslate nohighlight">\(\text{Var}(\bar{X})\)</span> hold for <strong>any</strong> population with finite mean and variance. However, we can only determine the <strong>exact shape</strong> of the sampling distribution when the population is normal. For non-normal populations, the Central Limit Theorem (Section 7.3) provides an approximation for large samples.</p>
</div>
<div class="note admonition">
<p class="admonition-title">Exercise 1: Basic Properties of the Sampling Distribution</p>
<p>The tensile strength of a certain type of steel cable is normally distributed with mean <span class="math notranslate nohighlight">\(\mu = 850\)</span> pounds and standard deviation <span class="math notranslate nohighlight">\(\sigma = 40\)</span> pounds. A quality control engineer selects a random sample of <span class="math notranslate nohighlight">\(n = 16\)</span> cables for testing.</p>
<ol class="loweralpha simple">
<li><p>What is the expected value of the sample mean tensile strength?</p></li>
<li><p>What is the standard error of the sample mean?</p></li>
<li><p>What is the complete sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span>?</p></li>
<li><p>Compare the standard error to the population standard deviation. What does this tell you about the precision of the sample mean versus a single observation?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X\)</span> = tensile strength (pounds), where <span class="math notranslate nohighlight">\(X \sim N(\mu = 850, \sigma = 40)\)</span> and <span class="math notranslate nohighlight">\(n = 16\)</span>.</p>
<p class="sd-card-text"><strong>Part (a): Expected value of X̄</strong></p>
<div class="math notranslate nohighlight">
\[E[\bar{X}] = \mu = 850 \text{ pounds}\]</div>
<p class="sd-card-text">The sample mean is centered at the population mean.</p>
<p class="sd-card-text"><strong>Part (b): Standard error</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{40}{\sqrt{16}} = \frac{40}{4} = 10 \text{ pounds}\]</div>
<p class="sd-card-text"><strong>Part (c): Complete sampling distribution</strong></p>
<p class="sd-card-text">Since the population is normal, the sampling distribution is also normal:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \sim N\left(850, 10^2\right) \quad \text{or equivalently} \quad \bar{X} \sim N(850, 100)\]</div>
<p class="sd-card-text"><strong>Part (d): Precision comparison</strong></p>
<p class="sd-card-text">The standard error (10 pounds) is one-fourth of the population standard deviation (40 pounds). This means the sample mean of 16 cables is <strong>4 times more precise</strong> than a single cable measurement. Averaging reduces variability by a factor of <span class="math notranslate nohighlight">\(\sqrt{n} = \sqrt{16} = 4\)</span>.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 2: Probability Calculations with Normal Population</p>
<p>The diameter of ball bearings produced by a machine is normally distributed with mean <span class="math notranslate nohighlight">\(\mu = 5.00\)</span> mm and standard deviation <span class="math notranslate nohighlight">\(\sigma = 0.10\)</span> mm. A random sample of <span class="math notranslate nohighlight">\(n = 25\)</span> ball bearings is selected.</p>
<ol class="loweralpha simple">
<li><p>Find <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 5.03)\)</span>.</p></li>
<li><p>Find <span class="math notranslate nohighlight">\(P(\bar{X} &lt; 4.96)\)</span>.</p></li>
<li><p>Find <span class="math notranslate nohighlight">\(P(4.97 &lt; \bar{X} &lt; 5.03)\)</span>.</p></li>
<li><p>Find the value <span class="math notranslate nohighlight">\(c\)</span> such that <span class="math notranslate nohighlight">\(P(\bar{X} &gt; c) = 0.10\)</span>.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X\)</span> = diameter (mm), where <span class="math notranslate nohighlight">\(X \sim N(5.00, 0.10^2)\)</span> and <span class="math notranslate nohighlight">\(n = 25\)</span>.</p>
<p class="sd-card-text">First, find the sampling distribution parameters:</p>
<ul class="simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(E[\bar{X}] = 5.00\)</span> mm</p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{0.10}{\sqrt{25}} = \frac{0.10}{5} = 0.02\)</span> mm</p></li>
</ul>
<p class="sd-card-text">Since the population is normal: <span class="math notranslate nohighlight">\(\bar{X} \sim N(5.00, 0.02^2)\)</span>.</p>
<p class="sd-card-text"><strong>Part (a): P(X̄ &gt; 5.03)</strong></p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &gt; 5.03) = P\left(Z &gt; \frac{5.03 - 5.00}{0.02}\right) = P(Z &gt; 1.50)\]</div>
<div class="math notranslate nohighlight">
\[= 1 - \Phi(1.50) = 1 - 0.9332 = 0.0668\]</div>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">pnorm</span><span class="p">(</span><span class="m">5.03</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5.00</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.02</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.0668</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): P(X̄ &lt; 4.96)</strong></p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &lt; 4.96) = P\left(Z &lt; \frac{4.96 - 5.00}{0.02}\right) = P(Z &lt; -2.00)\]</div>
<div class="math notranslate nohighlight">
\[= \Phi(-2.00) = 0.0228\]</div>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">pnorm</span><span class="p">(</span><span class="m">4.96</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5.00</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.02</span><span class="p">)</span>
<span class="c1"># [1] 0.0228</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (c): P(4.97 &lt; X̄ &lt; 5.03)</strong></p>
<div class="math notranslate nohighlight">
\[P(4.97 &lt; \bar{X} &lt; 5.03) = P\left(\frac{4.97 - 5.00}{0.02} &lt; Z &lt; \frac{5.03 - 5.00}{0.02}\right)\]</div>
<div class="math notranslate nohighlight">
\[= P(-1.50 &lt; Z &lt; 1.50) = \Phi(1.50) - \Phi(-1.50) = 0.9332 - 0.0668 = 0.8664\]</div>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">pnorm</span><span class="p">(</span><span class="m">5.03</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5.00</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.02</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">4.97</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5.00</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.02</span><span class="p">)</span>
<span class="c1"># [1] 0.8664</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Find c such that P(X̄ &gt; c) = 0.10</strong></p>
<p class="sd-card-text">We need the 90th percentile of <span class="math notranslate nohighlight">\(\bar{X}\)</span>.</p>
<p class="sd-card-text">From the Z-table: <span class="math notranslate nohighlight">\(\Phi(1.28) = 0.8997 \approx 0.90\)</span>, so <span class="math notranslate nohighlight">\(z_{0.90} \approx 1.28\)</span>.</p>
<div class="math notranslate nohighlight">
\[c = \mu + z_{0.90} \cdot \sigma_{\bar{X}} = 5.00 + 1.28(0.02) = 5.00 + 0.0256 = 5.026 \text{ mm}\]</div>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">qnorm</span><span class="p">(</span><span class="m">0.90</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5.00</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.02</span><span class="p">)</span>
<span class="c1"># [1] 5.0256</span>
</pre></div>
</div>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 3: Standard Error and Sample Size</p>
<p>A biomedical engineer is measuring the response time of a neural sensor. The population standard deviation is known to be <span class="math notranslate nohighlight">\(\sigma = 8\)</span> milliseconds.</p>
<ol class="loweralpha simple">
<li><p>If a sample of <span class="math notranslate nohighlight">\(n = 16\)</span> measurements is taken, what is the standard error of <span class="math notranslate nohighlight">\(\bar{X}\)</span>?</p></li>
<li><p>If the sample size is increased to <span class="math notranslate nohighlight">\(n = 64\)</span>, what is the new standard error?</p></li>
<li><p>By what factor did the standard error decrease when the sample size was quadrupled?</p></li>
<li><p>What sample size is needed to achieve a standard error of at most 1 millisecond?</p></li>
<li><p>A colleague claims that doubling the sample size will cut the standard error in half. Is this correct? Explain.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Given: <span class="math notranslate nohighlight">\(\sigma = 8\)</span> ms.</p>
<p class="sd-card-text"><strong>Part (a): SE with n = 16</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{8}{\sqrt{16}} = \frac{8}{4} = 2 \text{ ms}\]</div>
<p class="sd-card-text"><strong>Part (b): SE with n = 64</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{8}{\sqrt{64}} = \frac{8}{8} = 1 \text{ ms}\]</div>
<p class="sd-card-text"><strong>Part (c): Factor of decrease</strong></p>
<p class="sd-card-text">The standard error decreased from 2 ms to 1 ms, a factor of <strong>2</strong>.</p>
<p class="sd-card-text">When sample size quadruples (×4), the standard error decreases by <span class="math notranslate nohighlight">\(\sqrt{4} = 2\)</span>.</p>
<p class="sd-card-text">In general: <span class="math notranslate nohighlight">\(\frac{\text{SE}_{\text{old}}}{\text{SE}_{\text{new}}} = \frac{\sigma/\sqrt{n_{\text{old}}}}{\sigma/\sqrt{n_{\text{new}}}} = \sqrt{\frac{n_{\text{new}}}{n_{\text{old}}}} = \sqrt{\frac{64}{16}} = 2\)</span>.</p>
<p class="sd-card-text"><strong>Part (d): Sample size for SE ≤ 1 ms</strong></p>
<p class="sd-card-text">We need <span class="math notranslate nohighlight">\(\frac{\sigma}{\sqrt{n}} \leq 1\)</span>, which gives <span class="math notranslate nohighlight">\(\sqrt{n} \geq \sigma = 8\)</span>, so <span class="math notranslate nohighlight">\(n \geq 64\)</span>.</p>
<p class="sd-card-text">Minimum sample size: <strong>n = 64</strong>.</p>
<p class="sd-card-text"><strong>Part (e): Does doubling n halve the SE?</strong></p>
<p class="sd-card-text"><strong>No, this is incorrect.</strong> Doubling the sample size reduces the standard error by a factor of <span class="math notranslate nohighlight">\(\sqrt{2} \approx 1.41\)</span>, not 2.</p>
<p class="sd-card-text">If <span class="math notranslate nohighlight">\(n \to 2n\)</span>, then <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} \to \frac{\sigma}{\sqrt{2n}} = \frac{\sigma}{\sqrt{2}\sqrt{n}}\)</span>.</p>
<p class="sd-card-text">To <strong>halve</strong> the standard error, you must <strong>quadruple</strong> the sample size.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 4: Comparing Individual Observations to Sample Means</p>
<p>CPU processing times for a certain task are normally distributed with mean <span class="math notranslate nohighlight">\(\mu = 120\)</span> ms and standard deviation <span class="math notranslate nohighlight">\(\sigma = 15\)</span> ms.</p>
<ol class="loweralpha simple">
<li><p>What is the probability that a <strong>single</strong> randomly selected task takes more than 130 ms?</p></li>
<li><p>What is the probability that the <strong>average</strong> of <span class="math notranslate nohighlight">\(n = 9\)</span> randomly selected tasks exceeds 130 ms?</p></li>
<li><p>What is the probability that the <strong>average</strong> of <span class="math notranslate nohighlight">\(n = 36\)</span> randomly selected tasks exceeds 130 ms?</p></li>
<li><p>Explain why the probabilities in (a), (b), and (c) are different.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X\)</span> = processing time (ms), where <span class="math notranslate nohighlight">\(X \sim N(120, 15^2)\)</span>.</p>
<p class="sd-card-text"><strong>Part (a): Single observation, P(X &gt; 130)</strong></p>
<p class="sd-card-text">For a single observation, we use the population distribution directly:</p>
<div class="math notranslate nohighlight">
\[P(X &gt; 130) = P\left(Z &gt; \frac{130 - 120}{15}\right) = P(Z &gt; 0.67)\]</div>
<div class="math notranslate nohighlight">
\[= 1 - \Phi(0.67) = 1 - 0.7486 = 0.2514\]</div>
<p class="sd-card-text"><strong>Part (b): Sample mean with n = 9</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{15}{\sqrt{9}} = 5\)</span> ms, and <span class="math notranslate nohighlight">\(\bar{X} \sim N(120, 5^2)\)</span>.</p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &gt; 130) = P\left(Z &gt; \frac{130 - 120}{5}\right) = P(Z &gt; 2.00)\]</div>
<div class="math notranslate nohighlight">
\[= 1 - \Phi(2.00) = 1 - 0.9772 = 0.0228\]</div>
<p class="sd-card-text"><strong>Part (c): Sample mean with n = 36</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{15}{\sqrt{36}} = 2.5\)</span> ms, and <span class="math notranslate nohighlight">\(\bar{X} \sim N(120, 2.5^2)\)</span>.</p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &gt; 130) = P\left(Z &gt; \frac{130 - 120}{2.5}\right) = P(Z &gt; 4.00)\]</div>
<div class="math notranslate nohighlight">
\[= 1 - \Phi(4.00) \approx 1 - 0.99997 \approx 0.00003\]</div>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Part (a): Single observation</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">130</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">120</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">15</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.2525</span>

<span class="c1"># Part (b): Sample mean, n = 9</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">130</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">120</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">15</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="m">9</span><span class="p">),</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.0228</span>

<span class="c1"># Part (c): Sample mean, n = 36</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">130</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">120</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">15</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="m">36</span><span class="p">),</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 3.167e-05</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Explanation</strong></p>
<p class="sd-card-text">The probabilities decrease dramatically as sample size increases because:</p>
<ul class="simple">
<li><p class="sd-card-text">Individual observations have high variability (<span class="math notranslate nohighlight">\(\sigma = 15\)</span> ms)</p></li>
<li><p class="sd-card-text">Sample means have reduced variability (<span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \sigma/\sqrt{n}\)</span>)</p></li>
<li><p class="sd-card-text">Larger samples produce means that cluster more tightly around <span class="math notranslate nohighlight">\(\mu = 120\)</span></p></li>
</ul>
<p class="sd-card-text">A single observation exceeding 130 ms is fairly common (25% chance), but a sample mean of 36 observations exceeding 130 ms is extremely rare (0.003% chance) because extreme values in individual observations tend to cancel out when averaging.</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch7-2/fig4_sampling_distributions.png"><img alt="Comparison of distributions for n=1, 9, and 36" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch7-2/fig4_sampling_distributions.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 7.5 </span><span class="caption-text">As sample size increases, the sampling distribution becomes more concentrated around μ = 120.</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 5: Quality Control Application</p>
<p>A pharmaceutical company fills capsules with an active ingredient. The filling process is normally distributed with a target mean of <span class="math notranslate nohighlight">\(\mu = 500\)</span> mg and standard deviation <span class="math notranslate nohighlight">\(\sigma = 12\)</span> mg. To monitor quality, a random sample of <span class="math notranslate nohighlight">\(n = 9\)</span> capsules is tested each hour.</p>
<ol class="loweralpha simple">
<li><p>What is the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span>?</p></li>
<li><p>If the process is operating correctly (at <span class="math notranslate nohighlight">\(\mu = 500\)</span>), what is the probability that the sample mean falls between 492 mg and 508 mg?</p></li>
<li><p>The quality control protocol triggers an investigation if <span class="math notranslate nohighlight">\(\bar{X}\)</span> falls outside the interval <span class="math notranslate nohighlight">\([492, 508]\)</span>. What is the probability of triggering an investigation when the process is operating correctly? (This is called a “false alarm” rate.)</p></li>
<li><p>Suppose the process drifts so that <span class="math notranslate nohighlight">\(\mu = 506\)</span> mg (but <span class="math notranslate nohighlight">\(\sigma\)</span> remains 12 mg). What is the probability that <span class="math notranslate nohighlight">\(\bar{X}\)</span> falls within <span class="math notranslate nohighlight">\([492, 508]\)</span>? (This represents failing to detect a problem.)</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Given: Target <span class="math notranslate nohighlight">\(\mu = 500\)</span> mg, <span class="math notranslate nohighlight">\(\sigma = 12\)</span> mg, <span class="math notranslate nohighlight">\(n = 9\)</span>.</p>
<p class="sd-card-text"><strong>Part (a): Sampling distribution</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{12}{\sqrt{9}} = 4 \text{ mg}\]</div>
<p class="sd-card-text">Since the population is normal:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \sim N(500, 4^2) \quad \text{or} \quad \bar{X} \sim N(500, 16)\]</div>
<p class="sd-card-text"><strong>Part (b): P(492 &lt; X̄ &lt; 508) when μ = 500</strong></p>
<div class="math notranslate nohighlight">
\[P(492 &lt; \bar{X} &lt; 508) = P\left(\frac{492 - 500}{4} &lt; Z &lt; \frac{508 - 500}{4}\right)\]</div>
<div class="math notranslate nohighlight">
\[= P(-2.00 &lt; Z &lt; 2.00) = \Phi(2.00) - \Phi(-2.00) = 0.9772 - 0.0228 = 0.9544\]</div>
<p class="sd-card-text"><strong>Part (c): False alarm rate</strong></p>
<p class="sd-card-text">The probability of triggering an investigation when the process is correct:</p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &lt; 492 \text{ or } \bar{X} &gt; 508) = 1 - P(492 &lt; \bar{X} &lt; 508) = 1 - 0.9544 = 0.0456\]</div>
<p class="sd-card-text">About <strong>4.56%</strong> of the time, an investigation will be triggered even when the process is operating correctly.</p>
<p class="sd-card-text"><strong>Part (d): P(492 &lt; X̄ &lt; 508) when μ = 506 (process drift)</strong></p>
<p class="sd-card-text">Now <span class="math notranslate nohighlight">\(\bar{X} \sim N(506, 4^2)\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(492 &lt; \bar{X} &lt; 508) = P\left(\frac{492 - 506}{4} &lt; Z &lt; \frac{508 - 506}{4}\right)\]</div>
<div class="math notranslate nohighlight">
\[= P(-3.50 &lt; Z &lt; 0.50) = \Phi(0.50) - \Phi(-3.50)\]</div>
<div class="math notranslate nohighlight">
\[= 0.6915 - 0.0002 = 0.6913\]</div>
<p class="sd-card-text">There is about a <strong>69%</strong> probability that the sample mean falls in the acceptable range even though the process has drifted. This means the protocol fails to detect the problem about 69% of the time—a concern for quality control effectiveness.</p>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">se</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">12</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="m">9</span><span class="p">)</span><span class="w">  </span><span class="c1"># Standard error = 4</span>

<span class="c1"># Part (b): P(492 &lt; X̄ &lt; 508) when μ = 500</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">508</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">492</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span>
<span class="c1"># [1] 0.9545</span>

<span class="c1"># Part (c): False alarm rate</span>
<span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="nf">pnorm</span><span class="p">(</span><span class="m">508</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">492</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">))</span>
<span class="c1"># [1] 0.0455</span>

<span class="c1"># Part (d): P(492 &lt; X̄ &lt; 508) when μ = 506</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">508</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">506</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">492</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">506</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span>
<span class="c1"># [1] 0.6915</span>
</pre></div>
</div>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 6: Working Backward — Finding Population Parameters</p>
<p>For a normally distributed population, a sample of size <span class="math notranslate nohighlight">\(n = 25\)</span> yields a sampling distribution for <span class="math notranslate nohighlight">\(\bar{X}\)</span> with standard error <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = 3\)</span>.</p>
<ol class="loweralpha simple">
<li><p>What is the population standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>?</p></li>
<li><p>If the sample size were increased to <span class="math notranslate nohighlight">\(n = 100\)</span>, what would be the new standard error?</p></li>
<li><p>If the population standard deviation were actually <span class="math notranslate nohighlight">\(\sigma = 20\)</span>, what sample size would be needed to achieve the original standard error of 3?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Find σ from SE</strong></p>
<p class="sd-card-text">Given: <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = 3\)</span> and <span class="math notranslate nohighlight">\(n = 25\)</span>.</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} \implies 3 = \frac{\sigma}{\sqrt{25}} = \frac{\sigma}{5}\]</div>
<div class="math notranslate nohighlight">
\[\sigma = 3 \times 5 = 15\]</div>
<p class="sd-card-text"><strong>Part (b): New SE with n = 100</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{15}{\sqrt{100}} = \frac{15}{10} = 1.5\]</div>
<p class="sd-card-text"><strong>Part (c): Sample size for SE = 3 when σ = 20</strong></p>
<div class="math notranslate nohighlight">
\[3 = \frac{20}{\sqrt{n}} \implies \sqrt{n} = \frac{20}{3} \implies n = \left(\frac{20}{3}\right)^2 = \frac{400}{9} = 44.44\]</div>
<p class="sd-card-text">Since sample size must be a whole number, we need <span class="math notranslate nohighlight">\(n \geq 45\)</span> to achieve a standard error of at most 3.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 7: Symmetric Probability Bounds</p>
<p>The weight of packages shipped by an e-commerce company is normally distributed with mean <span class="math notranslate nohighlight">\(\mu = 2.5\)</span> kg and standard deviation <span class="math notranslate nohighlight">\(\sigma = 0.4\)</span> kg. For a random sample of <span class="math notranslate nohighlight">\(n = 16\)</span> packages:</p>
<ol class="loweralpha simple">
<li><p>Find the value <span class="math notranslate nohighlight">\(d\)</span> such that <span class="math notranslate nohighlight">\(P(|\bar{X} - \mu| &lt; d) = 0.95\)</span>.</p></li>
<li><p>Interpret this result in context.</p></li>
<li><p>How would <span class="math notranslate nohighlight">\(d\)</span> change if the sample size were increased to <span class="math notranslate nohighlight">\(n = 64\)</span>?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Given: <span class="math notranslate nohighlight">\(\mu = 2.5\)</span> kg, <span class="math notranslate nohighlight">\(\sigma = 0.4\)</span> kg, <span class="math notranslate nohighlight">\(n = 16\)</span>.</p>
<p class="sd-card-text">First, find the standard error:</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{0.4}{\sqrt{16}} = 0.1 \text{ kg}\]</div>
<p class="sd-card-text"><strong>Part (a): Find d such that P(|X̄ − μ| &lt; d) = 0.95</strong></p>
<p class="sd-card-text">We need <span class="math notranslate nohighlight">\(P(-d &lt; \bar{X} - \mu &lt; d) = 0.95\)</span>.</p>
<p class="sd-card-text">Standardizing:</p>
<div class="math notranslate nohighlight">
\[P\left(-\frac{d}{\sigma_{\bar{X}}} &lt; Z &lt; \frac{d}{\sigma_{\bar{X}}}\right) = 0.95\]</div>
<p class="sd-card-text">For this symmetric interval around 0, we need <span class="math notranslate nohighlight">\(\frac{d}{\sigma_{\bar{X}}} = z_{0.975}\)</span>.</p>
<p class="sd-card-text">From the Z-table: <span class="math notranslate nohighlight">\(z_{0.975} = 1.96\)</span>.</p>
<div class="math notranslate nohighlight">
\[d = 1.96 \times \sigma_{\bar{X}} = 1.96 \times 0.1 = 0.196 \text{ kg}\]</div>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find z_{0.975}</span>
<span class="nf">qnorm</span><span class="p">(</span><span class="m">0.975</span><span class="p">)</span>
<span class="c1"># [1] 1.96</span>

<span class="c1"># Calculate d</span>
<span class="m">1.96</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">0.1</span>
<span class="c1"># [1] 0.196</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (b): Interpretation</strong></p>
<p class="sd-card-text">There is a 95% probability that the sample mean weight of 16 packages will be within <strong>0.196 kg</strong> (about 196 grams) of the true population mean. In other words, 95% of all possible sample means will fall in the interval <span class="math notranslate nohighlight">\([2.304, 2.696]\)</span> kg.</p>
<p class="sd-card-text"><strong>Part (c): Effect of increasing n to 64</strong></p>
<p class="sd-card-text">New standard error:</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{0.4}{\sqrt{64}} = 0.05 \text{ kg}\]</div>
<p class="sd-card-text">New <span class="math notranslate nohighlight">\(d\)</span>:</p>
<div class="math notranslate nohighlight">
\[d = 1.96 \times 0.05 = 0.098 \text{ kg}\]</div>
<p class="sd-card-text">The bound <strong>halves</strong> (from 0.196 to 0.098 kg) when sample size quadruples. Larger samples produce sample means that stay closer to the population mean.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 8: The iid Framework</p>
<p>Consider the sampling framework where <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> are independent and identically distributed (iid) random variables, each with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<ol class="loweralpha simple">
<li><p>Explain in your own words what “independent” means in this context.</p></li>
<li><p>Explain what “identically distributed” means in this context.</p></li>
<li><p>Why is the iid assumption important for deriving the variance formula <span class="math notranslate nohighlight">\(\text{Var}(\bar{X}) = \sigma^2/n\)</span>?</p></li>
<li><p>Give an example of a sampling scenario where the iid assumption might be violated.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Independence</strong></p>
<p class="sd-card-text">“Independent” means that the value of one observation does not affect or provide information about the values of other observations. Mathematically, knowing <span class="math notranslate nohighlight">\(X_1 = x_1\)</span> does not change the probability distribution of <span class="math notranslate nohighlight">\(X_2, X_3, \ldots, X_n\)</span>.</p>
<p class="sd-card-text">In practice, this typically requires random sampling where each unit is selected without regard to other selected units.</p>
<p class="sd-card-text"><strong>Part (b): Identically distributed</strong></p>
<p class="sd-card-text">“Identically distributed” means all observations come from the same probability distribution—they have the same mean <span class="math notranslate nohighlight">\(\mu\)</span>, same variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>, and same distributional shape. This ensures we’re sampling from a single, well-defined population.</p>
<p class="sd-card-text"><strong>Part (c): Importance of iid for variance formula</strong></p>
<p class="sd-card-text">The derivation of <span class="math notranslate nohighlight">\(\text{Var}(\bar{X}) = \sigma^2/n\)</span> relies on:</p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>Independence</strong>: This allows us to write <span class="math notranslate nohighlight">\(\text{Var}(X_1 + X_2 + \cdots + X_n) = \text{Var}(X_1) + \text{Var}(X_2) + \cdots + \text{Var}(X_n)\)</span>. Without independence, we would need to include covariance terms.</p></li>
<li><p class="sd-card-text"><strong>Identical distribution</strong>: This ensures each <span class="math notranslate nohighlight">\(\text{Var}(X_i) = \sigma^2\)</span>, so the sum of variances equals <span class="math notranslate nohighlight">\(n\sigma^2\)</span>.</p></li>
</ol>
<p class="sd-card-text">Together, these give <span class="math notranslate nohighlight">\(\text{Var}(\bar{X}) = \frac{1}{n^2} \cdot n\sigma^2 = \frac{\sigma^2}{n}\)</span>.</p>
<p class="sd-card-text"><strong>Part (d): Violation example</strong></p>
<p class="sd-card-text"><em>Cluster sampling</em>: If we sample households and then measure all individuals within each household, observations within the same household are likely correlated (not independent)—family members may share similar characteristics.</p>
<p class="sd-card-text"><em>Time series data</em>: Measurements taken over time (e.g., daily stock prices) often exhibit dependence, where today’s value is related to yesterday’s value.</p>
<p class="sd-card-text"><em>Sampling without replacement from a small population</em>: If the population is small relative to the sample, observations are not truly independent because removing one unit changes the composition of remaining units.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 9: Comprehensive Application — Engine Performance</p>
<p>A mechanical engineer is testing fuel efficiency of a new engine design. Based on extensive prior testing, fuel efficiency (in miles per gallon) is known to be normally distributed with mean <span class="math notranslate nohighlight">\(\mu = 32\)</span> mpg and standard deviation <span class="math notranslate nohighlight">\(\sigma = 3\)</span> mpg.</p>
<ol class="loweralpha simple">
<li><p>For a single test run, what is the probability of observing fuel efficiency above 35 mpg?</p></li>
<li><p>The engineer conducts <span class="math notranslate nohighlight">\(n = 12\)</span> test runs and computes the sample mean. What is the distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span>?</p></li>
<li><p>Find <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 33)\)</span> for the sample of 12 runs.</p></li>
<li><p>Find the 5th and 95th percentiles of the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span>.</p></li>
<li><p>The engineer wants the standard error to be at most 0.5 mpg. How many test runs are needed?</p></li>
<li><p>If the engineer observes <span class="math notranslate nohighlight">\(\bar{x} = 34.2\)</span> mpg from 12 test runs, should this be considered unusual? Calculate the probability of observing a sample mean at least this far from <span class="math notranslate nohighlight">\(\mu = 32\)</span>.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Given: <span class="math notranslate nohighlight">\(X \sim N(\mu = 32, \sigma = 3)\)</span> mpg.</p>
<p class="sd-card-text"><strong>Part (a): P(X &gt; 35) for single observation</strong></p>
<div class="math notranslate nohighlight">
\[P(X &gt; 35) = P\left(Z &gt; \frac{35 - 32}{3}\right) = P(Z &gt; 1.00) = 1 - 0.8413 = 0.1587\]</div>
<p class="sd-card-text"><strong>Part (b): Distribution of X̄ with n = 12</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{3}{\sqrt{12}} = \frac{3}{3.464} = 0.866 \text{ mpg}\]</div>
<div class="math notranslate nohighlight">
\[\bar{X} \sim N(32, 0.866^2) \quad \text{or} \quad \bar{X} \sim N(32, 0.75)\]</div>
<p class="sd-card-text"><strong>Part (c): P(X̄ &gt; 33)</strong></p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &gt; 33) = P\left(Z &gt; \frac{33 - 32}{0.866}\right) = P(Z &gt; 1.15)\]</div>
<div class="math notranslate nohighlight">
\[= 1 - \Phi(1.15) = 1 - 0.8749 = 0.1251\]</div>
<p class="sd-card-text"><strong>Part (d): 5th and 95th percentiles</strong></p>
<p class="sd-card-text">From Z-table: <span class="math notranslate nohighlight">\(z_{0.05} = -1.645\)</span> and <span class="math notranslate nohighlight">\(z_{0.95} = 1.645\)</span>.</p>
<p class="sd-card-text">5th percentile:</p>
<div class="math notranslate nohighlight">
\[\bar{x}_{0.05} = \mu + z_{0.05} \cdot \sigma_{\bar{X}} = 32 + (-1.645)(0.866) = 32 - 1.42 = 30.58 \text{ mpg}\]</div>
<p class="sd-card-text">95th percentile:</p>
<div class="math notranslate nohighlight">
\[\bar{x}_{0.95} = 32 + (1.645)(0.866) = 32 + 1.42 = 33.42 \text{ mpg}\]</div>
<p class="sd-card-text">90% of sample means will fall between <strong>30.58 and 33.42 mpg</strong>.</p>
<p class="sd-card-text"><strong>Part (e): Sample size for SE ≤ 0.5 mpg</strong></p>
<div class="math notranslate nohighlight">
\[\frac{\sigma}{\sqrt{n}} \leq 0.5 \implies \frac{3}{\sqrt{n}} \leq 0.5 \implies \sqrt{n} \geq 6 \implies n \geq 36\]</div>
<p class="sd-card-text">At least <strong>36 test runs</strong> are needed.</p>
<p class="sd-card-text"><strong>Part (f): Is x̄ = 34.2 unusual?</strong></p>
<p class="sd-card-text">The observed sample mean is 34.2 − 32 = 2.2 mpg away from <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p class="sd-card-text">We compute <span class="math notranslate nohighlight">\(P(|\bar{X} - 32| \geq 2.2)\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(|\bar{X} - 32| \geq 2.2) = P(\bar{X} \leq 29.8) + P(\bar{X} \geq 34.2)\]</div>
<div class="math notranslate nohighlight">
\[= P\left(Z \leq \frac{29.8 - 32}{0.866}\right) + P\left(Z \geq \frac{34.2 - 32}{0.866}\right)\]</div>
<div class="math notranslate nohighlight">
\[= P(Z \leq -2.54) + P(Z \geq 2.54) = 2 \times P(Z \leq -2.54)\]</div>
<div class="math notranslate nohighlight">
\[= 2 \times 0.0055 = 0.011\]</div>
<p class="sd-card-text"><strong>Yes, this is unusual.</strong> There is only about a <strong>1.1%</strong> probability of observing a sample mean at least 2.2 mpg away from the true mean if <span class="math notranslate nohighlight">\(\mu = 32\)</span>. This result suggests the engine may actually have different fuel efficiency than assumed, or something unusual occurred during testing.</p>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">32</span>
<span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">3</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">12</span>
<span class="n">se</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w">  </span><span class="c1"># 0.866</span>

<span class="c1"># Part (a): Single observation P(X &gt; 35)</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">35</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sigma</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.1587</span>

<span class="c1"># Part (c): P(X̄ &gt; 33)</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">33</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.1241</span>

<span class="c1"># Part (d): 5th and 95th percentiles</span>
<span class="nf">qnorm</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span>
<span class="c1"># [1] 30.58</span>
<span class="nf">qnorm</span><span class="p">(</span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span>
<span class="c1"># [1] 33.42</span>

<span class="c1"># Part (f): Two-tailed probability</span>
<span class="m">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">29.8</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span>
<span class="c1"># [1] 0.0110</span>
</pre></div>
</div>
</div>
</details></div>
</section>
<hr class="docutils" />
<section id="additional-practice-problems">
<h2><span class="section-number">7.2.8. </span>Additional Practice Problems<a class="headerlink" href="#additional-practice-problems" title="Link to this heading"></a></h2>
<p><strong>True/False Questions</strong> (1 point each)</p>
<ol class="arabic">
<li><p>The expected value of the sample mean equals the population mean for any sample size.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>The standard error of <span class="math notranslate nohighlight">\(\bar{X}\)</span> increases as sample size increases.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>If the population is normally distributed, then <span class="math notranslate nohighlight">\(\bar{X}\)</span> is exactly normally distributed regardless of sample size.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>Doubling the sample size will cut the standard error in half.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>The variance of the sample mean is <span class="math notranslate nohighlight">\(\sigma^2/n\)</span>, where <span class="math notranslate nohighlight">\(\sigma^2\)</span> is the population variance.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>The sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> has the same standard deviation as the population.</p>
<p>Ⓣ or Ⓕ</p>
</li>
</ol>
<p><strong>Multiple Choice Questions</strong> (2 points each)</p>
<ol class="arabic" start="7">
<li><p>A population has <span class="math notranslate nohighlight">\(\mu = 100\)</span> and <span class="math notranslate nohighlight">\(\sigma = 20\)</span>. For samples of size <span class="math notranslate nohighlight">\(n = 25\)</span>, the standard error of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is:</p>
<p>Ⓐ 0.8</p>
<p>Ⓑ 4</p>
<p>Ⓒ 20</p>
<p>Ⓓ 100</p>
</li>
<li><p>If the population is normal with <span class="math notranslate nohighlight">\(\mu = 50\)</span> and <span class="math notranslate nohighlight">\(\sigma = 10\)</span>, and <span class="math notranslate nohighlight">\(n = 4\)</span>, then <span class="math notranslate nohighlight">\(\bar{X}\)</span> follows:</p>
<p>Ⓐ <span class="math notranslate nohighlight">\(N(50, 100)\)</span></p>
<p>Ⓑ <span class="math notranslate nohighlight">\(N(50, 25)\)</span></p>
<p>Ⓒ <span class="math notranslate nohighlight">\(N(50, 10)\)</span></p>
<p>Ⓓ <span class="math notranslate nohighlight">\(N(12.5, 2.5)\)</span></p>
</li>
<li><p>To reduce the standard error by half, you must:</p>
<p>Ⓐ Double the sample size</p>
<p>Ⓑ Triple the sample size</p>
<p>Ⓒ Quadruple the sample size</p>
<p>Ⓓ Halve the population standard deviation</p>
</li>
<li><p>For a normal population with <span class="math notranslate nohighlight">\(\sigma = 12\)</span>, what sample size gives <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = 2\)</span>?</p>
<p>Ⓐ 6</p>
<p>Ⓑ 24</p>
<p>Ⓒ 36</p>
<p>Ⓓ 144</p>
</li>
<li><p>If <span class="math notranslate nohighlight">\(X \sim N(80, 16)\)</span> (variance = 16), and <span class="math notranslate nohighlight">\(n = 4\)</span>, then <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 82)\)</span> equals:</p>
<p>Ⓐ <span class="math notranslate nohighlight">\(P(Z &gt; 0.5)\)</span></p>
<p>Ⓑ <span class="math notranslate nohighlight">\(P(Z &gt; 1)\)</span></p>
<p>Ⓒ <span class="math notranslate nohighlight">\(P(Z &gt; 2)\)</span></p>
<p>Ⓓ <span class="math notranslate nohighlight">\(P(Z &gt; 4)\)</span></p>
</li>
<li><p>The formula <span class="math notranslate nohighlight">\(\text{Var}(\bar{X}) = \sigma^2/n\)</span> requires which assumption?</p>
<p>Ⓐ The population must be normal</p>
<p>Ⓑ The sample size must be at least 30</p>
<p>Ⓒ The observations must be independent</p>
<p>Ⓓ The population mean must be known</p>
</li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Answers to Practice Problems</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>True/False Answers:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>True</strong> — <span class="math notranslate nohighlight">\(E[\bar{X}] = \mu\)</span> always holds when sampling from a population with mean <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p class="sd-card-text"><strong>False</strong> — The standard error <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span> <strong>decreases</strong> as <span class="math notranslate nohighlight">\(n\)</span> increases.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — Linear combinations of normal random variables are normal, so <span class="math notranslate nohighlight">\(\bar{X}\)</span> is exactly normal when the population is normal.</p></li>
<li><p class="sd-card-text"><strong>False</strong> — Doubling <span class="math notranslate nohighlight">\(n\)</span> reduces SE by factor of <span class="math notranslate nohighlight">\(\sqrt{2} \approx 1.41\)</span>, not 2. To halve SE, you must quadruple <span class="math notranslate nohighlight">\(n\)</span>.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — This is the variance formula for the sample mean.</p></li>
<li><p class="sd-card-text"><strong>False</strong> — The sampling distribution has standard deviation <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span>, which is smaller than <span class="math notranslate nohighlight">\(\sigma\)</span> when <span class="math notranslate nohighlight">\(n &gt; 1\)</span>.</p></li>
</ol>
<p class="sd-card-text"><strong>Multiple Choice Answers:</strong></p>
<ol class="arabic simple" start="7">
<li><p class="sd-card-text"><strong>Ⓑ</strong> — <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = 20/\sqrt{25} = 20/5 = 4\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — <span class="math notranslate nohighlight">\(\bar{X} \sim N(\mu, \sigma^2/n) = N(50, 100/4) = N(50, 25)\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓒ</strong> — To halve SE, multiply <span class="math notranslate nohighlight">\(n\)</span> by 4 (since <span class="math notranslate nohighlight">\(\sqrt{4} = 2\)</span>).</p></li>
<li><p class="sd-card-text"><strong>Ⓒ</strong> — <span class="math notranslate nohighlight">\(2 = 12/\sqrt{n} \implies \sqrt{n} = 6 \implies n = 36\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — <span class="math notranslate nohighlight">\(\sigma = 4\)</span>, so <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = 4/\sqrt{4} = 2\)</span>. Then <span class="math notranslate nohighlight">\(z = (82-80)/2 = 1\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓒ</strong> — Independence allows <span class="math notranslate nohighlight">\(\text{Var}(\sum X_i) = \sum \text{Var}(X_i)\)</span>. Normality is not required for this formula.</p></li>
</ol>
</div>
</details></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="7-1-statistics-and-sampling-distributions.html" class="btn btn-neutral float-left" title="7.1. Statistics and Sampling Distributions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="7-3-clt.html" class="btn btn-neutral float-right" title="7.3. The Central Limit Theorem (CLT)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
  <p class="footer-credits-inline">
    <strong>Website Credits:</strong>
    Website development by Dr. Timothy Reese and Halin Shin.
    Generative AI tools were used to draft and refine some prose, code, and documentation; all content was reviewed by the instructors.
    Models: OpenAI o3 (2025-04-16 release) and Anthropic Claude Opus 4.1 (2025-08-05).
  </p>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 

<!-- Floating Chat Button -->
<button id="chatbot-toggle" class="chatbot-fab" aria-label="Open AI Course Assistant" aria-expanded="false">
  <span class="chatbot-fab-badge">BETA</span>
  <svg class="chatbot-fab-icon chatbot-icon-open" fill="none" stroke="currentColor" viewBox="0 0 24 24">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
          d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"/>
  </svg>
  <svg class="chatbot-fab-icon chatbot-icon-close" fill="none" stroke="currentColor" viewBox="0 0 24 24" style="display:none;">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
  </svg>
  <span class="chatbot-fab-text">Ask AI Assistant</span>
</button>

<!-- Chat Panel - Fullscreen -->
<div id="chatbot-panel" class="chatbot-panel" aria-hidden="true">
  <div class="chatbot-panel-topbar">
    <button id="chatbot-close" class="chatbot-panel-close-minimal" aria-label="Close chat">
      <svg width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
      </svg>
    </button>
    <a href="https://advert-cingular-employer-humor.trycloudflare.com/" 
       target="_blank" 
       rel="noopener noreferrer" 
       class="chatbot-newtab">
      <svg width="16" height="16" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
              d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"/>
      </svg>
      Open in new tab
    </a>
  </div>
  <iframe id="chatbot-iframe" class="chatbot-iframe" title="STAT 350 AI Course Assistant"></iframe>
</div>

<script>
(function() {
  const CHATBOT_BASE_URL = 'https://advert-cingular-employer-humor.trycloudflare.com/';
  
  const toggle = document.getElementById('chatbot-toggle');
  const panel = document.getElementById('chatbot-panel');
  const closeBtn = document.getElementById('chatbot-close');
  const iframe = document.getElementById('chatbot-iframe');
  const iconOpen = toggle.querySelector('.chatbot-icon-open');
  const iconClose = toggle.querySelector('.chatbot-icon-close');
  
  let isOpen = false;
  let iframeLoaded = false;
  
  function getPageContext() {
    const pageTitle = document.title || '';
    const pageUrl = window.location.href;
    const pagePath = window.location.pathname;
    
    const h1 = document.querySelector('.rst-content h1, h1');
    const heading = h1 ? h1.textContent.replace(/[¶#]/g, '').trim() : '';
    
    const breadcrumbs = document.querySelectorAll('.wy-breadcrumbs li a');
    const breadcrumbPath = Array.from(breadcrumbs).map(a => a.textContent.trim()).join(' > ');
    
    const chapterMatch = pagePath.match(/chapter(\d+)/i);
    const chapter = chapterMatch ? 'Chapter ' + chapterMatch[1] : '';
    
    return {
      title: heading || pageTitle,
      url: pageUrl,
      path: pagePath,
      breadcrumbs: breadcrumbPath,
      chapter: chapter
    };
  }
  
  function buildChatbotUrl(context) {
    const params = new URLSearchParams();
    if (context.title) params.set('page_title', context.title);
    if (context.url) params.set('page_url', context.url);
    if (context.chapter) params.set('chapter', context.chapter);
    if (context.breadcrumbs) params.set('breadcrumbs', context.breadcrumbs);
    
    const queryString = params.toString();
    return queryString ? CHATBOT_BASE_URL + '?' + queryString : CHATBOT_BASE_URL;
  }
  
  function openChat() {
    const context = getPageContext();
    
    const newUrl = buildChatbotUrl(context);
    if (!iframeLoaded || iframe.dataset.lastUrl !== context.url) {
      iframe.src = newUrl;
      iframe.dataset.lastUrl = context.url;
      iframeLoaded = true;
    }
    
    panel.classList.add('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'false');
    toggle.setAttribute('aria-expanded', 'true');
    iconOpen.style.display = 'none';
    iconClose.style.display = 'block';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Close';
    isOpen = true;
    
    toggle.classList.add('chatbot-fab-opened');
    
    // Prevent body scroll when panel is open
    document.body.style.overflow = 'hidden';
  }
  
  function closeChat() {
    panel.classList.remove('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'true');
    toggle.setAttribute('aria-expanded', 'false');
    iconOpen.style.display = 'block';
    iconClose.style.display = 'none';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Ask AI Assistant';
    isOpen = false;
    
    // Restore body scroll
    document.body.style.overflow = '';
  }
  
  function toggleChat() {
    if (isOpen) {
      closeChat();
    } else {
      openChat();
    }
  }
  
  toggle.addEventListener('click', toggleChat);
  closeBtn.addEventListener('click', closeChat);
  
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape' && isOpen) {
      closeChat();
    }
  });
})();
</script>


</body>
</html>