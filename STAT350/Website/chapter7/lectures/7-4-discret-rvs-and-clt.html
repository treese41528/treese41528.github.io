

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>7.4. Discrete Random Variables and the CLT &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=3c686048" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter7/lectures/7-4-discret-rvs-and-clt.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=8512422d"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8. Experimental Design" href="../../chapter8/index.html" />
    <link rel="prev" title="7.3. The Central Limit Theorem (CLT)" href="7-3-clt.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#simulation-exercise">Simulation Exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Shape &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">7. Sampling Distributions</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">7.4. Discrete Random Variables and the CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">7. </span>Sampling Distributions</a></li>
      <li class="breadcrumb-item active"><span class="section-number">7.4. </span>Discrete Random Variables and the CLT</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter7/lectures/7-4-discret-rvs-and-clt.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch7-4">
   <iframe
      id="video-ch7-4"
      title="STAT 350 – Chapter 7.4 Discrete Random Variables and the CLT Video"
      src="https://www.youtube.com/embed/U98siSK61oY?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="discrete-random-variables-and-the-clt">
<h1><span class="section-number">7.4. </span>Discrete Random Variables and the CLT<a class="headerlink" href="#discrete-random-variables-and-the-clt" title="Link to this heading"></a></h1>
<p>We’ve explored how the Central Limit Theorem applies to continuous distributions, showing that the
sampling distribution of the sample mean approaches a normal distribution as the sample size increases.
But what about discrete random variables? Can we apply the CLT to distributions that count things rather
than measure them?</p>
<p>In this chapter, we’ll examine how the CLT applies to discrete distributions like the binomial and Poisson,
and explore when and how to use normal approximations for these discrete outcomes.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p><strong>Problem</strong>: How do we apply the CLT to discrete random variables that count successes or events?</p></li>
<li><p><strong>Tool</strong>: Normal approximations to binomial and Poisson distributions with appropriate conditions and corrections</p></li>
<li><p><strong>Pipeline</strong>: This extends our ability to use normal-based inference methods to discrete data contexts</p></li>
</ul>
</div>
<section id="the-clt-for-discrete-random-variables">
<h2><span class="section-number">7.4.1. </span>The CLT for Discrete Random Variables<a class="headerlink" href="#the-clt-for-discrete-random-variables" title="Link to this heading"></a></h2>
<p>The Central Limit Theorem isn’t limited to continuous distributions. It also applies to discrete random variables
like those from binomial and Poisson distributions, provided certain conditions are met.</p>
<p>When we use the CLT to approximate discrete distributions with the normal distribution, we’re using a continuous
distribution to model discrete outcomes. This requires special consideration because discrete variables can only
take specific values with gaps between them, while normal distributions are continuous across their range.</p>
</section>
<section id="binomial-distribution-and-the-clt">
<h2><span class="section-number">7.4.2. </span>Binomial Distribution and the CLT<a class="headerlink" href="#binomial-distribution-and-the-clt" title="Link to this heading"></a></h2>
<p>The binomial distribution B(n,p) counts the number of successes in n independent trials, each with probability of success p. A binomial random variable can be expressed as a sum of n independent Bernoulli random variables:</p>
<div class="math notranslate nohighlight">
\[X = \sum_{i=1}^n X_i\]</div>
<p>where each <span class="math notranslate nohighlight">\(X_i\)</span> is a Bernoulli random variable that equals 1 with probability p and 0 with probability (1-p).</p>
<p>Since the binomial random variable is a sum of independent and identically distributed random variables, the CLT applies as n increases. For sufficiently large n, the distribution of X can be approximated by:</p>
<div class="math notranslate nohighlight">
\[X \approx N(np, \sqrt{np(1-p)})\]</div>
<p>The rule of thumb for when this approximation is valid includes two common criteria:</p>
<ol class="arabic simple">
<li><p>Both <span class="math notranslate nohighlight">\(np ≥ 10\)</span> and <span class="math notranslate nohighlight">\(n(1-p) ≥ 10\)</span>, ensuring enough expected successes and failures</p></li>
<li><p>Alternatively, <span class="math notranslate nohighlight">\(np(1-p) ≥ 10\)</span>, focusing on the variance of the distribution</p></li>
</ol>
<p>These conditions ensure that the discrete binomial distribution is well-approximated by the continuous normal distribution.</p>
</section>
<section id="poisson-distribution-and-the-clt">
<h2><span class="section-number">7.4.3. </span>Poisson Distribution and the CLT<a class="headerlink" href="#poisson-distribution-and-the-clt" title="Link to this heading"></a></h2>
<p>The Poisson distribution with parameter λ counts the number of events occurring in a fixed interval, where events happen at a constant average rate and independently of each other.</p>
<p>An interesting property of the Poisson distribution is that the sum of independent Poisson random variables is also Poisson distributed. If X ~ Poisson(λ₁) and Y ~ Poisson(λ₂) are independent, then X + Y ~ Poisson(λ₁ + λ₂).</p>
<p>By extension, if X₁, X₂, …, Xₙ are independent Poisson random variables with the same parameter λ, then:</p>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^n X_i \sim \text{Poisson}(n\lambda)\]</div>
<p>The CLT tells us that for large λ, a Poisson random variable can be approximated by a normal distribution:</p>
<div class="math notranslate nohighlight">
\[X \sim \text{Poisson}(\lambda) \approx N(\lambda, \sqrt{\lambda})\]</div>
<p>This approximation works well when λ is sufficiently large (typically λ ≥ 10), as the Poisson distribution becomes more symmetric and bell-shaped.</p>
</section>
<section id="continuity-correction-for-discrete-distributions">
<h2><span class="section-number">7.4.4. </span>Continuity Correction for Discrete Distributions<a class="headerlink" href="#continuity-correction-for-discrete-distributions" title="Link to this heading"></a></h2>
<p>When using the normal distribution to approximate discrete distributions like the binomial or Poisson, we need to account for the difference between discrete and continuous variables. This is done through a continuity correction.</p>
<section id="continuity-correction-for-binomial-distribution">
<h3>Continuity Correction for Binomial Distribution<a class="headerlink" href="#continuity-correction-for-binomial-distribution" title="Link to this heading"></a></h3>
<p>Consider calculating a probability for a binomial random variable <span class="math notranslate nohighlight">\(X ~ B(n,p)\)</span> using the normal approximation <span class="math notranslate nohighlight">\(X* ~ N(np, np(1-p))\)</span>. When computing <span class="math notranslate nohighlight">\(P(X = k)\)</span>, we need to recognize that X can only take integer values, while <span class="math notranslate nohighlight">\(X*\)</span> is continuous.</p>
<p>The probability <span class="math notranslate nohighlight">\(P(X = k)\)</span> is approximated by the area under the normal curve between <span class="math notranslate nohighlight">\(k-0.5\)</span> and <span class="math notranslate nohighlight">\(k+0.5\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(X = k) \approx P(k-0.5 &lt; X^* &lt; k+0.5)\]</div>
<p>Similarly, for range probabilities:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}P(X \leq k) \approx P(X^* \leq k+0.5)\\P(X \geq k) \approx P(X^* \geq k-0.5)\end{aligned}\end{align} \]</div>
<p>For example, to calculate <span class="math notranslate nohighlight">\(P(X = 48)\)</span> for <span class="math notranslate nohighlight">\(X ~ B(100, 0.5)\)</span>:</p>
<ul class="simple">
<li><p>Without continuity correction: <span class="math notranslate nohighlight">\(P(X* = 48) = 0\)</span> (as the probability of any exact value in a continuous distribution is zero)</p></li>
<li><p>With continuity correction: <span class="math notranslate nohighlight">\(P(X = 48) ≈ P(47.5 &lt; X* &lt; 48.5)\)</span></p></li>
</ul>
</section>
<section id="continuity-correction-for-poisson-distribution">
<h3>Continuity Correction for Poisson Distribution<a class="headerlink" href="#continuity-correction-for-poisson-distribution" title="Link to this heading"></a></h3>
<p>Similar principles apply to the Poisson distribution. For a Poisson random variable <span class="math notranslate nohighlight">\(X ~ Poisson(λ)\)</span> approximated by <span class="math notranslate nohighlight">\(X* ~ N(λ, √λ)\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}P(X = k) \approx P(k-0.5 &lt; X^* &lt; k+0.5)\\P(X \leq k) \approx P(X^* \leq k+0.5)\\P(X \geq k) \approx P(X^* \geq k-0.5)\end{aligned}\end{align} \]</div>
<p>These corrections significantly improve the accuracy of normal approximations to discrete distributions, especially when calculating probabilities for specific values rather than ranges.</p>
</section>
</section>
<section id="applications-of-the-clt-for-discrete-variables">
<h2><span class="section-number">7.4.5. </span>Applications of the CLT for Discrete Variables<a class="headerlink" href="#applications-of-the-clt-for-discrete-variables" title="Link to this heading"></a></h2>
<p>The normal approximation to discrete distributions has numerous practical applications in statistics, making calculations more straightforward for large samples.</p>
<section id="quality-control-and-manufacturing">
<h3>Quality Control and Manufacturing<a class="headerlink" href="#quality-control-and-manufacturing" title="Link to this heading"></a></h3>
<p>In manufacturing processes, defective items often follow a binomial distribution. When large batches are produced, the CLT allows quality control engineers to efficiently calculate probabilities related to defect rates using the normal approximation.</p>
<p>For example, if the probability of a defect is 0.05 and 1000 items are produced, the normal approximation can be used to calculate the probability of observing more than 60 defective items:</p>
<div class="math notranslate nohighlight">
\[X \sim \text{Binomial}(1000, 0.05) \approx N(50, \sqrt{47.5})\]</div>
<p>With continuity correction:</p>
<div class="math notranslate nohighlight">
\[P(X &gt; 60) \approx P(X^* &gt; 59.5) = P\left(Z &gt; \frac{59.5 - 50}{\sqrt{47.5}}\right) = P(Z &gt; 1.38) \approx 0.0838\]</div>
</section>
<section id="medical-research-and-clinical-trials">
<h3>Medical Research and Clinical Trials<a class="headerlink" href="#medical-research-and-clinical-trials" title="Link to this heading"></a></h3>
<p>In large clinical trials, the number of patients who respond to a treatment often follows a binomial distribution. The CLT enables researchers to efficiently calculate confidence intervals and perform hypothesis tests for treatment efficacy.</p>
</section>
<section id="network-traffic-and-server-loads">
<h3>Network Traffic and Server Loads<a class="headerlink" href="#network-traffic-and-server-loads" title="Link to this heading"></a></h3>
<p>The number of requests arriving at a server in a fixed time interval often follows a Poisson distribution. For high-traffic systems, the CLT allows network engineers to use the normal approximation to calculate probabilities related to server load and capacity planning.</p>
</section>
<section id="practical-example-machine-calibration">
<h3>Practical Example: Machine Calibration<a class="headerlink" href="#practical-example-machine-calibration" title="Link to this heading"></a></h3>
<p>Consider a manufacturing process producing components with a target diameter of 5mm. The diameters follow a normal distribution with mean 5mm and standard deviation 0.5mm. A sample of 64 components is taken to assess whether the machine needs recalibration.</p>
<p>If the sample mean is 4.85mm, we can use the CLT to determine if this deviation is statistically significant:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \sim N\left(5, \frac{0.5}{\sqrt{64}}\right) = N(5, 0.0625)\]</div>
<p>The probability of observing a deviation this large or larger is:</p>
<div class="math notranslate nohighlight">
\[P(|\bar{X} - 5| \geq |4.85 - 5|) = P\left(\left|\frac{\bar{X} - 5}{0.5/\sqrt{64}}\right| \geq \frac{0.15}{0.0625}\right) = P(|Z| \geq 2.4) \approx 0.0164\]</div>
<p>If the company policy requires recalibration when this probability is less than 0.05, then recalibration is necessary because 0.0164 &lt; 0.05.</p>
<p>This application uses the normal distribution directly since the sample mean has a normal distribution by the CLT, even though the individual measurements follow a normal distribution as well.</p>
</section>
</section>
<section id="limitations-and-considerations">
<h2><span class="section-number">7.4.6. </span>Limitations and Considerations<a class="headerlink" href="#limitations-and-considerations" title="Link to this heading"></a></h2>
<p>While the normal approximation to discrete distributions is powerful, there are important limitations and considerations to keep in mind:</p>
<section id="sample-size-requirements">
<h3>Sample Size Requirements<a class="headerlink" href="#sample-size-requirements" title="Link to this heading"></a></h3>
<p>The required sample size or parameter value depends on the specific discrete distribution and its parameters:</p>
<ul class="simple">
<li><p>For binomial distributions, both np and n(1-p) should be at least 10 for the approximation to be reliable</p></li>
<li><p>For Poisson distributions, λ should be at least 10</p></li>
<li><p>When p is very small or very large in the binomial distribution, larger sample sizes are needed</p></li>
</ul>
</section>
<section id="alternative-methods">
<h3>Alternative Methods<a class="headerlink" href="#alternative-methods" title="Link to this heading"></a></h3>
<p>In some cases, other approaches may be more appropriate than using the normal approximation:</p>
<ul class="simple">
<li><p>For small samples, exact methods using the probability mass functions of the discrete distributions are more accurate</p></li>
<li><p>For binomial distributions with small n, direct calculation using the binomial formula or binomial tables may be preferable</p></li>
<li><p>For Poisson distributions with small λ, direct calculation using the Poisson formula is more accurate</p></li>
<li><p>Statistical software often provides exact methods that don’t require the normal approximation</p></li>
</ul>
</section>
<section id="importance-of-continuity-correction">
<h3>Importance of Continuity Correction<a class="headerlink" href="#importance-of-continuity-correction" title="Link to this heading"></a></h3>
<p>The continuity correction is crucial when calculating probabilities for specific values or narrow ranges. Without it, the normal approximation can produce significant errors, especially for:</p>
<ul class="simple">
<li><p>Probabilities of exact values (e.g., :math:` P(X = k)`)</p></li>
<li><p>Probabilities near the tails of the distribution</p></li>
<li><p>Distributions with smaller parameter values that barely meet the criteria for normal approximation</p></li>
</ul>
</section>
<section id="visual-assessment">
<h3>Visual Assessment<a class="headerlink" href="#visual-assessment" title="Link to this heading"></a></h3>
<p>Visually comparing the discrete distribution with its normal approximation can help assess the quality of the approximation:</p>
<ul class="simple">
<li><p>For binomial distributions with <span class="math notranslate nohighlight">\(p = 0.5\)</span>, the approximation is typically good even for moderate n</p></li>
<li><p>For binomial distributions with p far from 0.5 (e.g., p = 0.1 or p = 0.9), the approximation requires larger n</p></li>
<li><p>For Poisson distributions, as λ increases, the distribution becomes more symmetric and the normal approximation improves</p></li>
</ul>
</section>
</section>
<section id="concluding-the-chapter-the-universal-power-of-the-central-limit-theorem">
<h2><span class="section-number">7.4.7. </span>Concluding the Chapter: The Universal Power of the Central Limit Theorem<a class="headerlink" href="#concluding-the-chapter-the-universal-power-of-the-central-limit-theorem" title="Link to this heading"></a></h2>
<p>Throughout these chapters, we’ve explored the Central Limit Theorem in various contexts - from continuous to discrete distributions, from measuring to counting, from theoretical foundations to practical applications.</p>
<p>The CLT stands as one of the most remarkable and powerful results in all of statistics, providing a mathematical bridge that connects diverse random phenomena through a common distributional form: the normal distribution.</p>
<section id="what-we-ve-learned">
<h3>What We’ve Learned<a class="headerlink" href="#what-we-ve-learned" title="Link to this heading"></a></h3>
<p>We began by examining how sample means from continuous distributions approach normality as sample size increases, regardless of the shape of the original population distribution. We saw through simulations and mathematical derivations that this convergence happens more quickly for some distributions than others, but the pattern remains universal for distributions with finite mean and variance.</p>
<p>We then extended these principles to discrete distributions, showing how the binomial and Poisson distributions can be approximated by the normal distribution when certain conditions are met. We learned about continuity corrections and how to handle the transition from discrete to continuous probability models.</p>
<p>Throughout, we’ve seen that the CLT has broad applications across numerous fields - from quality control and manufacturing to medical research, from environmental science to finance, and from network engineering to pharmaceutical development.</p>
</section>
<section id="the-foundation-for-statistical-inference">
<h3>The Foundation for Statistical Inference<a class="headerlink" href="#the-foundation-for-statistical-inference" title="Link to this heading"></a></h3>
<p>The CLT doesn’t just provide convenient computational shortcuts; it forms the theoretical foundation for many statistical inference procedures. By understanding how sample statistics behave across repeated samples, we can:</p>
<ol class="arabic simple">
<li><p>Construct confidence intervals that capture population parameters with specified reliability</p></li>
<li><p>Develop hypothesis tests that control error rates at predetermined levels</p></li>
<li><p>Make probability statements about sample statistics that quantify uncertainty</p></li>
<li><p>Compare different populations using samples of reasonable size</p></li>
</ol>
<p>Without the CLT, statistical inference would be far more complex and likely require different procedures for different types of data. The theorem’s universality provides the common mathematical language that unifies statistical methodology.</p>
</section>
<section id="beyond-the-sample-mean">
<h3>Beyond the Sample Mean<a class="headerlink" href="#beyond-the-sample-mean" title="Link to this heading"></a></h3>
<p>While our focus has been primarily on the sample mean, we’ve noted that the CLT extends to other statistics as well - sample sums, weighted averages, linear combinations, and under certain conditions, to statistics like the sample variance. This broad applicability explains why the normal distribution appears so frequently in statistical analyses and why understanding its properties is essential for statistical practice.</p>
<p>As we move forward to topics in statistical inference in subsequent chapters, the CLT will serve as our theoretical bedrock, enabling us to make reliable inferences from sample data to population parameters across a wide range of scenarios.</p>
<p>The elegant simplicity of the theorem belies its profound implications: regardless of the complexity and diversity of random phenomena in our world, their averages tend toward a common, predictable pattern. This insight not only simplifies statistical computations but provides a deeper understanding of the underlying order in seemingly chaotic processes.</p>
</section>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">7.4.8. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<p>The Central Limit Theorem extends beyond continuous distributions to discrete random variables,
allowing us to use the normal distribution to approximate binomial and Poisson probabilities under
appropriate conditions. By understanding when these approximations are valid and applying continuity corrections,
we can leverage the mathematical convenience of the normal distribution while maintaining reasonable accuracy.</p>
<p>This capability is especially valuable when:</p>
<ul class="simple">
<li><p>Manual calculations of exact probabilities would be cumbersome</p></li>
<li><p>Working with large sample sizes or parameter values</p></li>
<li><p>Creating confidence intervals or conducting hypothesis tests based on discrete data</p></li>
</ul>
<p>The application of the CLT to discrete distributions further demonstrates its power and versatility as a
foundational concept in statistical inference, building a bridge between discrete counting processes and
continuous measurement models.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>The CLT applies to discrete distributions</strong> like the binomial and Poisson when certain conditions are met.</p></li>
<li><p><strong>For binomial distributions</strong>, the normal approximation is valid when np ≥ 10 and n(1-p) ≥ 10 (or alternatively when np(1-p) ≥ 10).</p></li>
<li><p><strong>For Poisson distributions</strong>, the normal approximation is valid when λ ≥ 10.</p></li>
<li><p><strong>Continuity corrections are necessary</strong> when using a continuous distribution to approximate a discrete one.</p></li>
<li><p><strong>The probability of a discrete outcome k</strong> is approximated by the area under the normal curve between k-0.5 and k+0.5.</p></li>
<li><p><strong>Probabilities involving ranges</strong> (≤, ≥, &lt;, &gt;) require appropriate continuity corrections at the boundaries.</p></li>
<li><p><strong>The quality of approximation</strong> depends on the sample size, parameter values, and the specific probability being calculated.</p></li>
</ol>
</div>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Binomial Approximation</strong>: A fair coin is tossed 100 times.</p>
<ol class="loweralpha simple">
<li><p>Use the binomial formula to calculate the exact probability of obtaining exactly 55 heads</p></li>
<li><p>Use the normal approximation with continuity correction to approximate this probability</p></li>
<li><p>Calculate the percent error in the approximation</p></li>
</ol>
</li>
<li><p><strong>Poisson Approximation</strong>: A call center receives an average of 15 calls per hour.</p>
<ol class="loweralpha simple">
<li><p>What is the exact probability of receiving exactly 20 calls in an hour?</p></li>
<li><p>Approximate this probability using the normal distribution with continuity correction</p></li>
<li><p>What is the approximate probability of receiving between 10 and 20 calls (inclusive) in an hour?</p></li>
</ol>
</li>
<li><p><strong>Quality Control</strong>: A manufacturing process produces items with a 3% defect rate. In a batch of 500 items:</p>
<ol class="loweralpha simple">
<li><p>Use the normal approximation to calculate the probability of finding more than 20 defective items</p></li>
<li><p>Calculate the probability that the number of defective items is within 5 of the expected number</p></li>
<li><p>How large should the batch be to have a 90% probability that the number of defects is within 1% of the total batch size?</p></li>
</ol>
</li>
<li><p><strong>Binomial vs. Poisson</strong>: Under what circumstances can a binomial distribution be approximated by a Poisson distribution? When would you choose to use a normal approximation instead?</p></li>
<li><p><strong>Comparing Approaches</strong>: For X ~ Binomial(20, 0.4):</p>
<ol class="loweralpha simple">
<li><p>Calculate P(X ≤ 5) using the exact binomial formula</p></li>
<li><p>Approximate the probability using the normal distribution with continuity correction</p></li>
<li><p>Would you recommend using the normal approximation in this case? Why or why not?</p></li>
</ol>
</li>
<li><p><strong>Simulation Exercise</strong>: Design a simulation to demonstrate how the quality of the normal approximation to the binomial distribution improves as n increases while p remains fixed at 0.3.</p></li>
<li><p><strong>Comprehensive Review</strong>: For each of the following distributions, indicate whether the CLT can be applied, what conditions need to be met, and what the resulting normal approximation would be:</p>
<ol class="loweralpha simple">
<li><p>A population with unknown shape but finite mean μ = 100 and standard deviation σ = 20</p></li>
<li><p>A binomial distribution with n = 25 and p = 0.4</p></li>
<li><p>A Poisson distribution with λ = 8</p></li>
<li><p>A heavily right-skewed distribution with infinite variance</p></li>
<li><p>A binomial distribution with n = 1000 and p = 0.002</p></li>
</ol>
</li>
<li><p><strong>CLT Application Across Chapters</strong>: Reflect on how the CLT connects the material in this chapter to previous probability concepts and how it will serve as a foundation for upcoming inference methods. Provide specific examples of how the CLT bridges these topics.</p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="7-3-clt.html" class="btn btn-neutral float-left" title="7.3. The Central Limit Theorem (CLT)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../chapter8/index.html" class="btn btn-neutral float-right" title="8. Experimental Design" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>