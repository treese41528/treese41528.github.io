

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>7.3. The Central Limit Theorem (CLT) &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=2f168d12" />
      <link rel="stylesheet" type="text/css" href="../../_static/credits.css?v=f7efa099" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/Website/chapter7/lectures/7-3-clt.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=7e0058eb"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7.4. Understanding Binomial and Poisson Distributions through CLT" href="7-4-discret-rvs-and-clt.html" />
    <link rel="prev" title="7.2. Sampling Distribution for the Sample Mean" href="7-2-sampling-distribution-for-the-sample-mean.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#exam-2-preparation-materials-not-comprensive-for-final">Exam 2 Preparation Materials (Not comprensive for final)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#troubleshooting-guide">Troubleshooting Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-and-binomial-distributions">Part 1: The Bernoulli and Binomial Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#the-binomial-distribution">The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-poisson-distribution">Part 2: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-other-named-discrete-distributions">Part 3: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-standard-normal-table">Part 2: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-z-score-transformation">Part 3: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html">Worksheet 11: The Central Limit Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#tutorial-generating-the-sampling-distribution-of-bar-x">Tutorial: Generating the Sampling Distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-1-exploring-clt-with-skewed-distributions">Part 1: Exploring CLT with Skewed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-2-application-of-the-clt">Part 2: Application of the CLT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-3-beyond-mean-and-sum">Part 3: Beyond Mean and Sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-4-exploring-clt-generalizability-with-ai-assistance-exploration">Part 4: Exploring CLT Generalizability with AI Assistance (Exploration)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html">Worksheet 12: Point Estimators and Unbiased Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-1-estimating-parameters-of-the-exponential-distribution">Part 1: Estimating Parameters of the Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-2-estimating-the-maximum-of-a-uniform-distribution">Part 2: Estimating the Maximum of a Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-3-minimum-variance-unbiased-estimators-mvue">Part 3: Minimum Variance Unbiased Estimators (MVUE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html">Worksheet 13: Introduction to Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-1-pivotal-quantities-and-deriving-confidence-intervals">Part 1: Pivotal Quantities and Deriving Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-2-sample-size-determination">Part 2: Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-3-one-sided-confidence-bounds">Part 3: One-Sided Confidence Bounds</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-4-confidence-intervals-when-is-unknown">Part 4: Confidence Intervals When σ is Unknown</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html">Worksheet 14: Student’s t-Distribution and Statistical Power</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#assumptions-for-t-distribution-inference">Assumptions for t-Distribution Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-1-analyzing-chick-growth-with-confidence-intervals">Part 1: Analyzing Chick Growth with Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-2-introduction-to-hypothesis-testing">Part 2: Introduction to Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-3-sample-size-determination-and-power-analysis">Part 3: Sample Size Determination and Power Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html">The Hypothesis Testing Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-test-statistic-known">The Test Statistic (Known σ)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#distribution-of-the-test-statistic">Distribution of the Test Statistic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-p-value">The p-value</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#part-1-simulating-test-statistics-and-p-values">Part 1: Simulating Test Statistics and P-values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1a-simulation-when-null-hypothesis-is-true">Question 1a: Simulation When Null Hypothesis is True</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1b-simulation-when-null-hypothesis-is-false">Question 1b: Simulation When Null Hypothesis is False</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1c-comparing-the-two-scenarios">Question 1c: Comparing the Two Scenarios</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-t-test-when-is-unknown">The t-Test When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-t-test-statistic">The t-Test Statistic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#properties-of-the-t-distribution">Properties of the t-Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#relationship-between-confidence-intervals-and-hypothesis-tests">Relationship Between Confidence Intervals and Hypothesis Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#part-2-epa-ozone-concentration-analysis">Part 2: EPA Ozone Concentration Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2a-assumptions-and-exploratory-analysis">Question 2a: Assumptions and Exploratory Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2b-full-hypothesis-testing-procedure">Question 2b: Full Hypothesis Testing Procedure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2c-manual-verification">Question 2c: Manual Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2d-confidence-bound">Question 2d: Confidence Bound</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2e-power-calculation">Question 2e: Power Calculation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html">Worksheet 16: Two-Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-1-independent-vs-paired-designs">Part 1: Independent vs. Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-2-independent-samples-with-known-variances">Part 2: Independent Samples with Known Variances</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-3-pooled-two-sample-t-test-equal-variances">Part 3: Pooled Two-Sample t-Test (Equal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-4-welch-s-two-sample-t-test-unequal-variances">Part 4: Welch’s Two-Sample t-Test (Unequal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html">Worksheet 17: Paired Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-1-theory-and-procedure-for-paired-samples">Part 1: Theory and Procedure for Paired Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-2-sleep-study-analysis">Part 2: Sleep Study Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-3-sample-size-calculation-for-paired-designs">Part 3: Sample Size Calculation for Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html">Worksheet 18: One-Way ANOVA (Analysis of Variance)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#why-use-one-way-anova">Why Use One-Way ANOVA?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#one-way-anova-assumptions">One-Way ANOVA Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#one-way-anova-f-test-statistic-and-sources-of-variation">One-Way ANOVA F-test Statistic and Sources of Variation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#notation-and-setup">Notation and Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-1-computing-the-overall-sample-mean">Part 1: Computing the Overall Sample Mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-2-checking-the-equal-variance-assumption">Part 2: Checking the Equal Variance Assumption</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-3-pooled-variance-estimator">Part 3: Pooled Variance Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-4-within-group-variability-sum-of-squares-within-sse">Part 4: Within-Group Variability (Sum of Squares Within, SSE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-5-between-group-variability-sum-of-squares-among-ssa">Part 5: Between-Group Variability (Sum of Squares Among, SSA)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-6-total-variability-and-partitioning">Part 6: Total Variability and Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-7-degrees-of-freedom">Part 7: Degrees of Freedom</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-8-mean-squares">Part 8: Mean Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-9-the-f-test-statistic">Part 9: The F-Test Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-10-computing-the-p-value-and-making-a-decision">Part 10: Computing the P-Value and Making a Decision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-11-completing-the-anova-table">Part 11: Completing the ANOVA Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-12-limitations-and-follow-up-questions">Part 12: Limitations and Follow-Up Questions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html">Worksheet 19: Multiple Comparisons and Post-Hoc Testing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#the-multiple-comparisons-problem">The Multiple Comparisons Problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#methods-to-control-the-family-wise-error-rate">Methods to Control the Family-Wise Error Rate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-1-simulation-study-type-i-error-with-multiple-comparison-methods">Part 1: Simulation Study - Type I Error with Multiple Comparison Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-2-applying-tukey-s-hsd-to-worksheet-18-data">Part 2: Applying Tukey’s HSD to Worksheet 18 Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-3-comprehensive-anova-analysis-toothgrowth-dataset">Part 3: Comprehensive ANOVA Analysis - ToothGrowth Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html">Worksheet 20: Introduction to Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#from-anova-to-regression-same-core-ideas-new-application">From ANOVA to Regression: Same Core Ideas, New Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#the-simple-linear-regression-model">The Simple Linear Regression Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#least-squares">Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-1-deriving-least-squares-estimators">Part 1: Deriving Least Squares Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-2-the-general-simple-linear-regression-estimators">Part 2: The General Simple Linear Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-3-sampling-distributions-of-regression-estimators">Part 3: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-4-practice-problems">Part 4: Practice Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html">Worksheet 21: Inference for Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-1-sampling-distributions-of-regression-estimators">Part 1: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-2-checking-regression-assumptions">Part 2: Checking Regression Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-3-bird-data-analysis">Part 3: Bird Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-4-regression-anova">Part 4: Regression ANOVA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html">Worksheet 22: Model Assessment and Prediction in Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-1-the-coefficient-of-determination">Part 1: The Coefficient of Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-2-confidence-intervals-vs-prediction-intervals">Part 2: Confidence Intervals vs. Prediction Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-3-simulation-study-ci-vs-pi-coverage">Part 3: Simulation Study — CI vs. PI Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-4-prediction-with-the-bird-data">Part 4: Prediction with the Bird Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-5-diamonds-data-analysis">Part 5: Diamonds Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html">Getting Started with R and RStudio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#getting-started-with-swirl">Getting Started with swirl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#alternative-r-learning-resources">Alternative R Learning Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_quick_reference.html">Quick Reference Table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html">Computer Assignments and Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-structure">Assignment Structure</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html">Function Reference Part 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#simulation-functions">Simulation Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html">Function Reference Part 2: Inference Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html#diagnostic-plots-for-assumptions">Diagnostic Plots for Assumptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#tables-reporting">Tables &amp; Reporting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#data-import-validation">Data Import &amp; Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#statistical-assumptions">Statistical Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#common-errors-to-avoid">Common Errors to Avoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#workflow-template">Workflow Template</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html">Course Datasets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#primary-course-dataset-apprating">Primary Course Dataset - AppRating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#tutorial-support-datasets">Tutorial Support Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#loading-datasets-in-r">Loading Datasets in R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#built-in-r-datasets-used-in-course">Built-in R Datasets Used in Course</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#data-download-and-organization">Data Download and Organization</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Sequential Bayesian Updating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. The Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">7. Sampling Distributions</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. The Foundation of Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Connecting CI and HT; <em>t</em>-Test for μ When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. The Four Steps to Hypothesis Testing and Understanding the Result</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Statistical Inference for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Independent Two-Sample Analysis When Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Independent Two-Sample Analysis - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Independent Two-Sample Analysis - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Paired Two-Sample Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. ANOVA F-Test and Its Relationship to Two-Sample <em>t</em>-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction and Robustness</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">7. </span>Sampling Distributions</a></li>
      <li class="breadcrumb-item active"><span class="section-number">7.3. </span>The Central Limit Theorem (CLT)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter7/lectures/7-3-clt.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch7-3">
   <iframe
      id="video-ch7-3"
      title="STAT 350 – Chapter 7.3 Central Limit Theorem Video"
      src="https://www.youtube.com/embed/l1vhy86sIVU?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><div class="tip admonition">
<p class="admonition-title">Slides 📊</p>
<p><a class="reference external" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%207%20Sampling%20Distributions/Sampling%20Distributions%20%28Chapter7%29_AC.pptx">Download Chapter 7 slides (PPTX)</a></p>
</div>
<section id="the-central-limit-theorem-clt">
<h1><span class="section-number">7.3. </span>The Central Limit Theorem (CLT)<a class="headerlink" href="#the-central-limit-theorem-clt" title="Link to this heading"></a></h1>
<p>We’ve established that the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is normal when the population is normal.
Then what about cases where the <strong>population is not normally distributed</strong>?
The Central Limit Theorem (CLT) is a pivotal concept in statistics that addresses this question.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p>Learn the formal statement of the Central Limit Theorem (CLT).</p></li>
<li><p>Recognize the experimental settings where the CLT applies.</p></li>
<li><p>Apply the CLT to compute approximate probabilities of the sample mean.</p></li>
</ul>
</div>
<section id="the-formal-statement-of-the-clt">
<h2><span class="section-number">7.3.1. </span>The Formal Statement of the CLT<a class="headerlink" href="#the-formal-statement-of-the-clt" title="Link to this heading"></a></h2>
<p>For an <em>independent and identically distributed (iid)</em> random sample <span class="math notranslate nohighlight">\(X_1, X_2, ..., X_n\)</span>
from a population with a finite mean <span class="math notranslate nohighlight">\(μ\)</span> and finite standard deviation <span class="math notranslate nohighlight">\(σ\)</span>,</p>
<div class="math notranslate nohighlight">
\[\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \xrightarrow{d} N(0,1) \text{ as } n \rightarrow \infty\]</div>
<div class="important admonition">
<p class="admonition-title">What does this all mean? 🔎</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\frac{\bar{X} - \mu}{\sigma/\sqrt{n}}\)</span> is the <em>standardized sample mean</em>.
<span class="math notranslate nohighlight">\(\bar{X}\)</span> is subtracted by its own mean <span class="math notranslate nohighlight">\(\mu_{\bar{X}} = \mu\)</span>,
then divided by its own standard deviation <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}\)</span> (the standard error).</p></li>
<li><p><span class="math notranslate nohighlight">\(\xrightarrow{d}\)</span> indicates <em>convergence in distribution</em>.</p></li>
<li><p>Putting together, the mathematical statement reads: “The distribution of the standardized sample mean
approaches standard normal as the sample size <span class="math notranslate nohighlight">\(n\)</span> goes to infinity.”</p></li>
</ul>
</div>
<section id="practical-implications-of-the-clt">
<h3>Practical Implications of the CLT<a class="headerlink" href="#practical-implications-of-the-clt" title="Link to this heading"></a></h3>
<p>When</p>
<ol class="arabic simple">
<li><p>the population has a <strong>finite mean</strong> <span class="math notranslate nohighlight">\(\mu\)</span> and a <strong>finite standard deviation</strong> <span class="math notranslate nohighlight">\(\sigma\)</span>,</p></li>
<li><p>the observations are <strong>independent and identically distributed (iid)</strong>, and</p></li>
<li><p>the sample size <span class="math notranslate nohighlight">\(n\)</span> is <strong>sufficiently large</strong>,</p></li>
</ol>
<p>we have</p>
<div class="math notranslate nohighlight">
\[\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \stackrel{d}{\approx} Z,\]</div>
<p>where <span class="math notranslate nohighlight">\(\stackrel{d}{\approx}\)</span> indicates that the two random variables have <strong>similar</strong> distributions.
By applying the same linear operations on both sides, we can
equivalently write:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \stackrel{d}{\approx} \frac{\sigma}{\sqrt{n}} Z + \mu.\]</div>
<p>The right-hand side is a linear transformation of a standard normal random variable
with the distribution <span class="math notranslate nohighlight">\(N(\mu, \sigma/\sqrt{n})\)</span>. It follows that:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \stackrel{\text{approx}}{\sim} N\left(\mu, \frac{\sigma}{\sqrt{n}}\right).\]</div>
</section>
</section>
<section id="visual-demonstrations">
<h2><span class="section-number">7.3.2. </span>Visual Demonstrations<a class="headerlink" href="#visual-demonstrations" title="Link to this heading"></a></h2>
<p>The Central Limit Theorem (CLT) states that the sampling distribution of the sample mean approaches a
normal distribution as the sample size increases, <strong>regardless of the shape of the population distribution</strong>,
as long as certain conditions are met. Let us use a visual tool to build intuition for this somewhat surprising result.</p>
<section id="how-to-use-the-simulation-tool">
<h3>How to Use the Simulation Tool<a class="headerlink" href="#how-to-use-the-simulation-tool" title="Link to this heading"></a></h3>
<p>The simulation tool requires a few inputs.</p>
<table class="docutils align-default" style="width: 100%">
<thead>
<tr class="row-odd"><th class="head"><p>Argument</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>How to use</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Population Distribution</strong></p></td>
<td><p>Normal, uniform, exponential, etc.</p></td>
<td><p>Select the family of distributions from which samples will be generated</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Population Parameters</strong></p></td>
<td><p>Different for each population family (e.g., <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> for normal, <span class="math notranslate nohighlight">\(\lambda\)</span> for exponential)</p></td>
<td><p>Select the specific distribution belonging to the chosen family</p></td>
</tr>
<tr class="row-even"><td><p><strong>Sample Size</strong> <span class="math notranslate nohighlight">\(n\)</span></p></td>
<td><p>The number of data points used to compute one sample mean</p></td>
<td><p>Increase from small to large. Observe the change in the sampling distribution</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Number of Samples</strong></p></td>
<td><p>The number of different sample means used to construct a histogram of the sampling distribution</p></td>
<td><p>Fix at a large number (10000, for example) so the sampling distribution of of sample means is
sufficiently described.</p></td>
</tr>
</tbody>
</table>
<p>Once all values are set as desired, click <strong>simulate</strong>. Two plots will display:</p>
<ul class="simple">
<li><p>A pdf/pmf plot of the population distribution</p></li>
<li><p>A histogram of sample means drawn from the population</p></li>
</ul>
<div class="interactive admonition">
<p class="admonition-title">Interactive Visualization 🎮</p>
<p><strong>Central Limit Theorem Simulation</strong></p>
<p>Visualize how sample means converge to a normal distribution as sample size
increases, regardless of the underlying population distribution.</p>
<p><a class="reference external" href="https://treese41528.github.io/STAT350/ShinyApps/CLT.html">🔗 Launch Interactive Demo</a> |
<a class="reference external" href="https://treese41528.github.io/STAT350/ShinyApps/CLT_Shiny.R">📄 View R Code</a></p>
</div>
</section>
<section id="a-checklist">
<h3>A Checklist<a class="headerlink" href="#a-checklist" title="Link to this heading"></a></h3>
<p>By experimenting with different settings, confirm the following:</p>
<table class="docutils align-default" style="width: 100%">
<thead>
<tr class="row-odd"><th class="head"><p>✔❓</p></th>
<th class="head"><p>To confirm</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
<td><p>The CLT indeed holds. That is, the histogram of sample means approaches a normal shape
as <span class="math notranslate nohighlight">\(n\)</span> grows.</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>A <em>large enough</em> <span class="math notranslate nohighlight">\(n\)</span>, which makes the histogram look sufficiently normal, is different
for each population distribution. In general, a population requires a larger <span class="math notranslate nohighlight">\(n\)</span> if
it has strong non-normal characteristics (asymetry, multimodality, etc.).</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>the center of the histogram remains around <span class="math notranslate nohighlight">\(\mu\)</span> while the spread (<span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span>) narrows around
<span class="math notranslate nohighlight">\(\mu\)</span> as <span class="math notranslate nohighlight">\(n\)</span> increases.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="how-large-is-sufficiently-large">
<h3>How Large is “Sufficiently Large”?<a class="headerlink" href="#how-large-is-sufficiently-large" title="Link to this heading"></a></h3>
<p>The common rule of thumb that n &gt; 30 is sufficient should not be blindly applied.
As we saw through simulations, the appropriate sample size depends entirely on the underlying population distribution.
The farther the population distribution is from normal, the larger the sample size needed for the CLT to apply effectively.</p>
<p>In practice, <strong>we only observe a single sample from a population</strong>. Our understanding of the
population depends on the sample we observe and our background knowledge. We must explore our sample carefully
to determine if the sample size is likely sufficient for the CLT to apply.</p>
</section>
</section>
<section id="step-by-step-problem-solving-with-the-clt">
<h2><span class="section-number">7.3.3. </span>Step-by-Step Problem Solving with the CLT<a class="headerlink" href="#step-by-step-problem-solving-with-the-clt" title="Link to this heading"></a></h2>
<p>Problems using the CLT follow the general steps below:</p>
<ol class="arabic simple">
<li><p>Verify that the prerequisites for the CLT are met.</p></li>
<li><p>Identify the population mean <span class="math notranslate nohighlight">\(\mu_X\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma_X\)</span>, and
use them to calculate the mean <span class="math notranslate nohighlight">\(\mu_{\bar{X}} = \mu_X\)</span> and
the standard error <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \sigma_X/\sqrt{n}\)</span> of the sampling distribution.</p></li>
<li><p>Establish the approximate sampling distribution of the sample mean: <span class="math notranslate nohighlight">\(\bar{X} \stackrel{\text{approx}}{\sim} N(\mu_{\bar{X}}, \sigma_{\bar{X}})\)</span>.</p></li>
<li><p>Use a standard normal table or software to find the required probability.</p></li>
</ol>
<div class="note admonition">
<p class="admonition-title">Example💡: Another Maze Navigation Example</p>
<p>The same subspecies of rat from the previous experiment will be forced to navigate a more complex maze in which
a wrong turn early on can drastically increase the time to completion. The true mean completion time for
the whole population of the subspecies is known to be 10 minutes. The true standard deviation is 3 minutes.
It is also known that the distribution is slightly right skewed.</p>
<p>Suppose that 60 rats are randomly selected from the population to navigate the maze.</p>
<ol class="loweralpha simple">
<li><p>What is the mean of the <strong>average time</strong> it takes 60 rats to navigate the maze?</p></li>
<li><p>What is the standard deviation of the <strong>average time</strong>?</p></li>
<li><p>What is the probability that the <strong>average maze navigation time</strong> for the 60 rats is greater than 11 minutes?</p></li>
</ol>
<p><strong>Organize the Given Information</strong></p>
<p>We know that the distribution of the population <span class="math notranslate nohighlight">\(X\)</span> is slightly right skewed. Further, <span class="math notranslate nohighlight">\(\mu_X=10\)</span> and <span class="math notranslate nohighlight">\(\sigma_X=3\)</span>.</p>
<p><strong>Solve the Problems</strong></p>
<ol class="loweralpha">
<li><p><span class="math notranslate nohighlight">\(\mu_{\bar{X}} = \mu_{X} = 10\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{\sigma_X}{\sqrt{n}} = \frac{3}{\sqrt{60}}=0.3878\)</span></p></li>
<li><p>We do not know the population distribution, so we hope to use the CLT to compute the probability. We must first confirm that
all the conditions are met for the CLT to hold:</p>
<ol class="arabic simple">
<li><p>The population mean and standard deviation are finite. ✔</p></li>
<li><p>The sample was formed by taking random samples from the same population. The randmonness ensures that
the selection of one rat does not influence others (independence). Since they come from the same population,
their distributions are identical. ✔</p></li>
<li><p>For a <em>slightly</em> skewed distribution, <span class="math notranslate nohighlight">\(n=60\)</span> is large enough. (To confirm, try plotting a left-skewed beta case with
<span class="math notranslate nohighlight">\(\alpha=3, \beta=2\)</span> using the simulation tool above). ✔</p></li>
</ol>
<p>Therefore, <span class="math notranslate nohighlight">\(\bar{X} \stackrel{\text{approx}}{\sim} N(\mu_{X}=10, \sigma_{\bar{X}}=0.3878)\)</span> by the CLT. Then</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(\bar{X} &gt; 11) &amp;= 1 - P(\bar{X} \leq 11) \\
&amp;= 1 - P\left(Z \leq \frac{11-10}{3/\sqrt{60}}\right) \\
&amp;= 1-\Phi(2.58) = 0.0049\end{split}\]</div>
</li>
</ol>
</div>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">7.3.4. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>The Central Limit Theorem states</strong> that for an iid sample from a population with finite mean and variance,
the distribution of the standardized sample mean approaches standard normal as the sample size increases.</p></li>
<li><p><strong>The CLT can be used to approximate the sampling distribution of</strong> <span class="math notranslate nohighlight">\(\bar{X}\)</span>,
but the sample size needed depends on how far the population distribution deviates from normality.</p></li>
</ol>
</div>
<p>The Central Limit Theorem represents one of the most powerful and remarkable results in statistics.
It allows us to use the normal distribution as a foundation for statistical inference across a wide
range of real-world situations, even when the underlying population distributions are unknown or non-normal.</p>
</section>
<section id="exercises">
<h2><span class="section-number">7.3.5. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h2>
<p>These exercises develop your skills in applying the Central Limit Theorem to approximate the sampling distribution of the sample mean when the population is not normally distributed.</p>
<div class="tip admonition">
<p class="admonition-title">Key Concepts</p>
<p><strong>Central Limit Theorem (CLT)</strong>: For an iid random sample from a population with finite mean <span class="math notranslate nohighlight">\(\mu\)</span> and finite standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>, as <span class="math notranslate nohighlight">\(n \to \infty\)</span>:</p>
<div class="math notranslate nohighlight">
\[\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \xrightarrow{d} N(0,1)\]</div>
<p><strong>Practical implication</strong>: When <span class="math notranslate nohighlight">\(n\)</span> is sufficiently large,</p>
<div class="math notranslate nohighlight">
\[\bar{X} \stackrel{\text{approx}}{\sim} N\left(\mu, \sigma_{\bar{X}}^2\right) \quad \text{where } \sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}\]</div>
<p>Throughout these exercises, <span class="math notranslate nohighlight">\(N(\mu, \sigma^2)\)</span> denotes a normal distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and <strong>variance</strong> <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
</div>
<div class="info admonition">
<p class="admonition-title">CLT Conditions Checklist</p>
<p>Before applying the CLT, verify:</p>
<ol class="arabic simple">
<li><p>✓ Population has <strong>finite mean</strong> <span class="math notranslate nohighlight">\(\mu\)</span> and <strong>finite standard deviation</strong> <span class="math notranslate nohighlight">\(\sigma\)</span></p></li>
<li><p>✓ Observations are <strong>independent and identically distributed (iid)</strong></p></li>
<li><p>✓ Sample size <span class="math notranslate nohighlight">\(n\)</span> is <strong>sufficiently large</strong> (depends on population shape)</p></li>
</ol>
<p><strong>Important</strong>: The required sample size depends heavily on how far the population deviates from normality. Symmetric populations may need only <span class="math notranslate nohighlight">\(n \geq 15\)</span>, while heavily skewed or heavy-tailed distributions may require <span class="math notranslate nohighlight">\(n \geq 50\)</span> or more. The common “<span class="math notranslate nohighlight">\(n \geq 30\)</span>” rule is a rough guideline, not a guarantee.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">R Functions for CLT Calculations</p>
<p>Once the CLT applies, use normal distribution functions with <span class="math notranslate nohighlight">\(\mu_{\bar{X}} = \mu\)</span> and <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \sigma/\sqrt{n}\)</span>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define parameters</span>
<span class="n">mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">...</span><span class="w">           </span><span class="c1"># Population mean</span>
<span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">...</span><span class="w">        </span><span class="c1"># Population SD</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">...</span><span class="w">            </span><span class="c1"># Sample size</span>
<span class="n">se</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w">  </span><span class="c1"># Standard error</span>

<span class="c1"># Probability calculations for X̄</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span><span class="w">                     </span><span class="c1"># P(X̄ ≤ x)</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w"> </span><span class="c1"># P(X̄ &gt; x)</span>

<span class="c1"># Quantiles of X̄</span>
<span class="nf">qnorm</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span><span class="w">                     </span><span class="c1"># Find x such that P(X̄ ≤ x) = p</span>
</pre></div>
</div>
</div>
<div class="note admonition">
<p class="admonition-title">Exercise 1: CLT with Uniform Population</p>
<p>The time (in seconds) for a random number generator to complete a cryptographic operation follows a uniform distribution on the interval <span class="math notranslate nohighlight">\([2, 6]\)</span>.</p>
<ol class="loweralpha simple">
<li><p>Find the population mean <span class="math notranslate nohighlight">\(\mu\)</span> and population standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>.</p></li>
<li><p>For a sample of <span class="math notranslate nohighlight">\(n = 49\)</span> operations, find the mean and standard error of <span class="math notranslate nohighlight">\(\bar{X}\)</span>.</p></li>
<li><p>Verify that the CLT conditions are satisfied.</p></li>
<li><p>Use the CLT to approximate <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 4.2)\)</span>.</p></li>
<li><p>Find <span class="math notranslate nohighlight">\(P(3.7 &lt; \bar{X} &lt; 4.3)\)</span>.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X\)</span> = time for one operation (seconds), where <span class="math notranslate nohighlight">\(X \sim \text{Uniform}(2, 6)\)</span>.</p>
<p class="sd-card-text"><strong>Part (a): Population parameters</strong></p>
<p class="sd-card-text">For a uniform distribution on <span class="math notranslate nohighlight">\([a, b]\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mu = \frac{a + b}{2} = \frac{2 + 6}{2} = 4 \text{ seconds}\]</div>
<div class="math notranslate nohighlight">
\[\sigma = \frac{b - a}{\sqrt{12}} = \frac{6 - 2}{\sqrt{12}} = \frac{4}{3.464} = 1.155 \text{ seconds}\]</div>
<p class="sd-card-text"><strong>Part (b): Sampling distribution parameters</strong></p>
<div class="math notranslate nohighlight">
\[\mu_{\bar{X}} = \mu = 4 \text{ seconds}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{1.155}{\sqrt{49}} = \frac{1.155}{7} = 0.165 \text{ seconds}\]</div>
<p class="sd-card-text"><strong>Part (c): CLT conditions</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text">✓ Finite mean and SD: <span class="math notranslate nohighlight">\(\mu = 4\)</span> and <span class="math notranslate nohighlight">\(\sigma = 1.155\)</span> are both finite.</p></li>
<li><p class="sd-card-text">✓ iid: Operations are randomly selected and independent of each other under stable conditions.</p></li>
<li><p class="sd-card-text">✓ Sample size: The uniform distribution is symmetric and bounded, so the CLT converges quickly. With <span class="math notranslate nohighlight">\(n = 49\)</span>, the normal approximation is excellent.</p></li>
</ol>
<p class="sd-card-text"><strong>Part (d): P(X̄ &gt; 4.2) using CLT</strong></p>
<p class="sd-card-text">By CLT: <span class="math notranslate nohighlight">\(\bar{X} \stackrel{\text{approx}}{\sim} N(4, 0.165^2)\)</span>.</p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &gt; 4.2) = P\left(Z &gt; \frac{4.2 - 4}{0.165}\right) = P(Z &gt; 1.21)\]</div>
<div class="math notranslate nohighlight">
\[= 1 - \Phi(1.21) = 1 - 0.8869 = 0.1131\]</div>
<p class="sd-card-text"><strong>Part (e): P(3.7 &lt; X̄ &lt; 4.3)</strong></p>
<div class="math notranslate nohighlight">
\[P(3.7 &lt; \bar{X} &lt; 4.3) = P\left(\frac{3.7 - 4}{0.165} &lt; Z &lt; \frac{4.3 - 4}{0.165}\right)\]</div>
<div class="math notranslate nohighlight">
\[= P(-1.82 &lt; Z &lt; 1.82) = \Phi(1.82) - \Phi(-1.82)\]</div>
<div class="math notranslate nohighlight">
\[= 0.9656 - 0.0344 = 0.9312\]</div>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">4</span>
<span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">4</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="m">12</span><span class="p">)</span><span class="w">  </span><span class="c1"># 1.1547</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">49</span>
<span class="n">se</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w">  </span><span class="c1"># 0.1650</span>

<span class="c1"># Part (d): P(X̄ &gt; 4.2)</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">4.2</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.1127</span>

<span class="c1"># Part (e): P(3.7 &lt; X̄ &lt; 4.3)</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">4.3</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">3.7</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span>
<span class="c1"># [1] 0.9310</span>
</pre></div>
</div>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 2: CLT with Exponential Population</p>
<p>The time between customer arrivals at a help desk follows an exponential distribution with mean <span class="math notranslate nohighlight">\(\mu = 5\)</span> minutes.</p>
<ol class="loweralpha simple">
<li><p>What is the population standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>?</p></li>
<li><p>A manager records <span class="math notranslate nohighlight">\(n = 40\)</span> inter-arrival times and computes the sample mean. What is the approximate distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span>?</p></li>
<li><p>Find the probability that the sample mean inter-arrival time is less than 4 minutes.</p></li>
<li><p>Find the probability that the sample mean is within 1 minute of the population mean.</p></li>
<li><p>The exponential distribution is right-skewed. Why is <span class="math notranslate nohighlight">\(n = 40\)</span> likely sufficient for the CLT approximation?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X\)</span> = inter-arrival time (minutes), where <span class="math notranslate nohighlight">\(X \sim \text{Exp}(\mu = 5)\)</span>.</p>
<p class="sd-card-text"><strong>Part (a): Population standard deviation</strong></p>
<p class="sd-card-text">For an exponential distribution, <span class="math notranslate nohighlight">\(\sigma = \mu\)</span> (a unique property of this distribution).</p>
<div class="math notranslate nohighlight">
\[\sigma = 5 \text{ minutes}\]</div>
<p class="sd-card-text"><strong>Part (b): Approximate distribution of X̄</strong></p>
<p class="sd-card-text">First, calculate the standard error:</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{5}{\sqrt{40}} = \frac{5}{6.325} = 0.791 \text{ minutes}\]</div>
<p class="sd-card-text"><strong>CLT conditions check:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text">✓ Finite mean (<span class="math notranslate nohighlight">\(\mu = 5\)</span>) and SD (<span class="math notranslate nohighlight">\(\sigma = 5\)</span>)</p></li>
<li><p class="sd-card-text">✓ iid: Inter-arrival times are independent and from the same process</p></li>
<li><p class="sd-card-text">✓ <span class="math notranslate nohighlight">\(n = 40\)</span> is reasonably large for moderately skewed exponential</p></li>
</ol>
<p class="sd-card-text">By CLT:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \stackrel{\text{approx}}{\sim} N(5, 0.791^2)\]</div>
<p class="sd-card-text"><strong>Part (c): P(X̄ &lt; 4)</strong></p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &lt; 4) = P\left(Z &lt; \frac{4 - 5}{0.791}\right) = P(Z &lt; -1.26)\]</div>
<div class="math notranslate nohighlight">
\[= \Phi(-1.26) = 0.1038\]</div>
<p class="sd-card-text"><strong>Part (d): P(|X̄ − μ| &lt; 1) = P(4 &lt; X̄ &lt; 6)</strong></p>
<div class="math notranslate nohighlight">
\[P(4 &lt; \bar{X} &lt; 6) = P\left(\frac{4 - 5}{0.791} &lt; Z &lt; \frac{6 - 5}{0.791}\right)\]</div>
<div class="math notranslate nohighlight">
\[= P(-1.26 &lt; Z &lt; 1.26) = \Phi(1.26) - \Phi(-1.26)\]</div>
<div class="math notranslate nohighlight">
\[= 0.8962 - 0.1038 = 0.7924\]</div>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5</span>
<span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5</span><span class="w">  </span><span class="c1"># For exponential, σ = μ</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">40</span>
<span class="n">se</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w">  </span><span class="c1"># 0.7906</span>

<span class="c1"># Part (c): P(X̄ &lt; 4)</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span>
<span class="c1"># [1] 0.1034</span>

<span class="c1"># Part (d): P(4 &lt; X̄ &lt; 6)</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">6</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span>
<span class="c1"># [1] 0.7932</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (e): Why n = 40 is likely sufficient</strong></p>
<p class="sd-card-text">Although the exponential distribution is right-skewed, it has moderate skewness (skewness coefficient = 2 for all exponential distributions). The CLT converges reasonably quickly for such distributions. With <span class="math notranslate nohighlight">\(n = 40\)</span>, the averaging process is often adequate for many practical probability calculations involving the exponential distribution. However, for populations with more extreme skewness or heavier tails, larger samples may be needed.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 3: Effect of Sample Size on CLT Approximation</p>
<p>A manufacturing process produces components with weights that follow a right-skewed distribution with <span class="math notranslate nohighlight">\(\mu = 50\)</span> grams and <span class="math notranslate nohighlight">\(\sigma = 8\)</span> grams.</p>
<ol class="loweralpha simple">
<li><p>For <span class="math notranslate nohighlight">\(n = 16\)</span>, find <span class="math notranslate nohighlight">\(\sigma_{\bar{X}}\)</span> and use the CLT to approximate <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 52)\)</span>.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(n = 64\)</span>, find <span class="math notranslate nohighlight">\(\sigma_{\bar{X}}\)</span> and approximate <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 52)\)</span>.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(n = 256\)</span>, find <span class="math notranslate nohighlight">\(\sigma_{\bar{X}}\)</span> and approximate <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 52)\)</span>.</p></li>
<li><p>Explain the pattern in your answers. Why does <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 52)\)</span> decrease as <span class="math notranslate nohighlight">\(n\)</span> increases?</p></li>
<li><p>A quality engineer questions whether the CLT approximation is valid for <span class="math notranslate nohighlight">\(n = 16\)</span> given the skewed population. Is this concern reasonable?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Given: <span class="math notranslate nohighlight">\(\mu = 50\)</span> g, <span class="math notranslate nohighlight">\(\sigma = 8\)</span> g, population is right-skewed.</p>
<p class="sd-card-text"><strong>Part (a): n = 16</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{8}{\sqrt{16}} = 2 \text{ g}\]</div>
<p class="sd-card-text">By CLT: <span class="math notranslate nohighlight">\(\bar{X} \stackrel{\text{approx}}{\sim} N(50, 2^2)\)</span>.</p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &gt; 52) \approx P\left(Z &gt; \frac{52 - 50}{2}\right) = P(Z &gt; 1.00) = 1 - 0.8413 = 0.1587\]</div>
<p class="sd-card-text"><strong>Part (b): n = 64</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{8}{\sqrt{64}} = 1 \text{ g}\]</div>
<div class="math notranslate nohighlight">
\[P(\bar{X} &gt; 52) \approx P\left(Z &gt; \frac{52 - 50}{1}\right) = P(Z &gt; 2.00) = 1 - 0.9772 = 0.0228\]</div>
<p class="sd-card-text"><strong>Part (c): n = 256</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{8}{\sqrt{256}} = 0.5 \text{ g}\]</div>
<div class="math notranslate nohighlight">
\[P(\bar{X} &gt; 52) \approx P\left(Z &gt; \frac{52 - 50}{0.5}\right) = P(Z &gt; 4.00) \approx 0.00003\]</div>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">50</span>
<span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">8</span>

<span class="c1"># Part (a): n = 16</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">52</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sigma</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="m">16</span><span class="p">),</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.1587</span>

<span class="c1"># Part (b): n = 64</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">52</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sigma</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="m">64</span><span class="p">),</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.02275</span>

<span class="c1"># Part (c): n = 256</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">52</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sigma</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="m">256</span><span class="p">),</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 3.167e-05</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Pattern explanation</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 25.0%" />
<col style="width: 37.5%" />
<col style="width: 37.5%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p class="sd-card-text"><span class="math notranslate nohighlight">\(n\)</span></p></th>
<th class="head"><p class="sd-card-text"><span class="math notranslate nohighlight">\(\sigma_{\bar{X}}\)</span></p></th>
<th class="head"><p class="sd-card-text"><span class="math notranslate nohighlight">\(P(\bar{X} &gt; 52)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p class="sd-card-text">16</p></td>
<td><p class="sd-card-text">2.0 g</p></td>
<td><p class="sd-card-text">0.1587</p></td>
</tr>
<tr class="row-odd"><td><p class="sd-card-text">64</p></td>
<td><p class="sd-card-text">1.0 g</p></td>
<td><p class="sd-card-text">0.0228</p></td>
</tr>
<tr class="row-even"><td><p class="sd-card-text">256</p></td>
<td><p class="sd-card-text">0.5 g</p></td>
<td><p class="sd-card-text">0.00003</p></td>
</tr>
</tbody>
</table>
<p class="sd-card-text">As <span class="math notranslate nohighlight">\(n\)</span> increases, the standard error decreases, making the sampling distribution more concentrated around <span class="math notranslate nohighlight">\(\mu = 50\)</span>. A value of 52 (which is 2 grams above the mean) becomes increasingly “extreme” in terms of standard errors: 1.0 SE for <span class="math notranslate nohighlight">\(n = 16\)</span>, 2.0 SE for <span class="math notranslate nohighlight">\(n = 64\)</span>, and 4.0 SE for <span class="math notranslate nohighlight">\(n = 256\)</span>.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch7-3/fig3_sample_size_effect.png"><img alt="Sampling distributions for different sample sizes" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch7-3/fig3_sample_size_effect.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 7.6 </span><span class="caption-text">Larger samples produce more concentrated sampling distributions, making P(X̄ &gt; 52) decrease dramatically.</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
<p class="sd-card-text"><strong>Part (e): Validity concern for n = 16</strong></p>
<p class="sd-card-text"><strong>Yes, this concern is reasonable.</strong> For skewed populations, <span class="math notranslate nohighlight">\(n = 16\)</span> may not be large enough for the CLT approximation to be accurate. The approximation for <span class="math notranslate nohighlight">\(n = 16\)</span> should be treated as rough—directionally correct but potentially inaccurate depending on the degree of skewness and presence of outliers.</p>
<p class="sd-card-text">The results for <span class="math notranslate nohighlight">\(n = 64\)</span> and <span class="math notranslate nohighlight">\(n = 256\)</span> are more reliable. If high precision is needed with small samples from skewed populations, alternative methods (like bootstrapping) or larger sample sizes should be considered.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 4: Verifying CLT Conditions</p>
<p>For each scenario, determine whether the CLT can be appropriately applied. If not, explain which condition is violated.</p>
<ol class="loweralpha simple">
<li><p>Sample of 50 household incomes from a city, used to estimate mean income. Income distributions are typically right-skewed.</p></li>
<li><p>Sample of 25 measurements from a symmetric, bell-shaped population.</p></li>
<li><p>Sample of 100 observations from a manufacturing process, where each observation is the maximum of 10 temperature readings from the same set of correlated sensors taken in overlapping time windows.</p></li>
<li><p>Sample of 40 waiting times from a process that occasionally produces extreme outliers (heavy-tailed distribution with infinite variance).</p></li>
<li><p>Sample of 35 reaction times from a mildly skewed distribution with <span class="math notranslate nohighlight">\(\mu = 250\)</span> ms and <span class="math notranslate nohighlight">\(\sigma = 40\)</span> ms.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Household incomes, n = 50, right-skewed</strong></p>
<p class="sd-card-text">✓ <strong>CLT can be applied.</strong> Income distributions have finite mean and variance. With <span class="math notranslate nohighlight">\(n = 50\)</span>, the sample size is large enough to handle right-skewness. The CLT approximation should be reasonably accurate.</p>
<p class="sd-card-text"><strong>Part (b): Bell-shaped population, n = 25</strong></p>
<p class="sd-card-text">✓ <strong>CLT is valid, but not necessary.</strong> Since the population is symmetric and bell-shaped (approximately normal), the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is already approximately normal even for small <span class="math notranslate nohighlight">\(n\)</span>. The exact normal result from Section 7.2 applies if the population is truly normal; otherwise, the CLT provides additional justification.</p>
<p class="sd-card-text"><strong>Part (c): Maximum of correlated sensors with overlapping windows, n = 100</strong></p>
<p class="sd-card-text">✗ <strong>CLT cannot be applied.</strong> The observations are not independent—each observation is derived from the same set of correlated sensors, and overlapping time windows introduce temporal dependence between consecutive observations. The <strong>independence</strong> condition is violated. Even with <span class="math notranslate nohighlight">\(n = 100\)</span>, the CLT does not apply because the variance formula <span class="math notranslate nohighlight">\(\text{Var}(\bar{X}) = \sigma^2/n\)</span> assumes independence; with dependent observations, the true variance of <span class="math notranslate nohighlight">\(\bar{X}\)</span> may be much larger.</p>
<p class="sd-card-text"><strong>Part (d): Heavy-tailed distribution with infinite variance, n = 40</strong></p>
<p class="sd-card-text">✗ <strong>CLT cannot be applied.</strong> The CLT requires <strong>finite variance</strong>. If the population variance is infinite (as with some heavy-tailed distributions like the Cauchy distribution), the CLT does not hold regardless of sample size. The sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> will not approach normality.</p>
<p class="sd-card-text"><strong>Part (e): Mildly skewed reaction times, n = 35</strong></p>
<p class="sd-card-text">✓ <strong>CLT can be applied.</strong> The population has finite <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, observations can be assumed iid if properly sampled, and <span class="math notranslate nohighlight">\(n = 35\)</span> is reasonable for a mildly skewed distribution. With <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = 40/\sqrt{35} = 6.76\)</span> ms, the approximation <span class="math notranslate nohighlight">\(\bar{X} \stackrel{\text{approx}}{\sim} N(250, 6.76^2)\)</span> is reasonable.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 5: Comparing CLT to Normal Population Result</p>
<p>Consider two populations, both with <span class="math notranslate nohighlight">\(\mu = 100\)</span> and <span class="math notranslate nohighlight">\(\sigma = 20\)</span>:</p>
<ul class="simple">
<li><p><strong>Population A</strong>: Normally distributed</p></li>
<li><p><strong>Population B</strong>: Uniformly distributed on <span class="math notranslate nohighlight">\([100 - 20\sqrt{3}, 100 + 20\sqrt{3}]\)</span></p></li>
</ul>
<p>For samples of size <span class="math notranslate nohighlight">\(n = 36\)</span> from each population:</p>
<ol class="loweralpha simple">
<li><p>What is the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> for Population A? (Use exact result.)</p></li>
<li><p>What is the approximate sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> for Population B? (Use CLT.)</p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(P(\bar{X} &lt; 95)\)</span> for each population.</p></li>
<li><p>Why are the answers to part (c) similar?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Both populations have <span class="math notranslate nohighlight">\(\mu = 100\)</span>, <span class="math notranslate nohighlight">\(\sigma = 20\)</span>, and <span class="math notranslate nohighlight">\(n = 36\)</span>.</p>
<p class="sd-card-text">Standard error: <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{20}{\sqrt{36}} = \frac{20}{6} = 3.333\)</span>.</p>
<p class="sd-card-text"><strong>Part (a): Population A (Normal) — Exact result</strong></p>
<p class="sd-card-text">Since Population A is normal, by the exact result from Section 7.2:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \sim N(100, 3.333^2) \quad \text{(exactly)}\]</div>
<p class="sd-card-text"><strong>Part (b): Population B (Uniform) — CLT approximation</strong></p>
<p class="sd-card-text">The uniform distribution is symmetric with finite mean and variance, and <span class="math notranslate nohighlight">\(n = 36\)</span> is large. By CLT:</p>
<div class="math notranslate nohighlight">
\[\bar{X} \stackrel{\text{approx}}{\sim} N(100, 3.333^2)\]</div>
<p class="sd-card-text"><strong>Part (c): P(X̄ &lt; 95) for each population</strong></p>
<p class="sd-card-text"><em>Population A (exact):</em></p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &lt; 95) = P\left(Z &lt; \frac{95 - 100}{3.333}\right) = P(Z &lt; -1.50) = 0.0668\]</div>
<p class="sd-card-text"><em>Population B (CLT approximation):</em></p>
<div class="math notranslate nohighlight">
\[P(\bar{X} &lt; 95) \approx P\left(Z &lt; \frac{95 - 100}{3.333}\right) = P(Z &lt; -1.50) \approx 0.0668\]</div>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">100</span>
<span class="n">se</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">36</span><span class="p">)</span><span class="w">  </span><span class="c1"># 3.333</span>

<span class="c1"># Both populations give the same result</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">95</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se</span><span class="p">)</span>
<span class="c1"># [1] 0.0668</span>
</pre></div>
</div>
<p class="sd-card-text"><strong>Part (d): Why are the answers similar?</strong></p>
<p class="sd-card-text">The answers are nearly identical because:</p>
<ol class="arabic simple">
<li><p class="sd-card-text">Both sampling distributions have the same mean (<span class="math notranslate nohighlight">\(\mu_{\bar{X}} = 100\)</span>) and standard error (<span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = 3.333\)</span>)</p></li>
<li><p class="sd-card-text">For Population A, normality is exact; for Population B, the CLT approximation is very accurate because the uniform distribution is symmetric and bounded, causing rapid convergence to normality</p></li>
<li><p class="sd-card-text">The CLT tells us that the shape of the population matters less and less as <span class="math notranslate nohighlight">\(n\)</span> increases—all sampling distributions converge to normal</p></li>
</ol>
<p class="sd-card-text">This illustrates the power of the CLT: regardless of the original population shape, sample means behave similarly for large <span class="math notranslate nohighlight">\(n\)</span>.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 6: Sample Size Determination</p>
<p>A quality control engineer needs to estimate the mean fill volume of bottles. The filling process has <span class="math notranslate nohighlight">\(\sigma = 2.4\)</span> mL, and the distribution is slightly right-skewed.</p>
<ol class="loweralpha simple">
<li><p>The engineer wants <span class="math notranslate nohighlight">\(P(|\bar{X} - \mu| &lt; 0.5) \geq 0.95\)</span>. Using the CLT approximation, find the minimum sample size needed.</p></li>
<li><p>Given that the population is skewed, should the engineer use a sample size larger than the minimum calculated in part (a)? Explain.</p></li>
<li><p>If the engineer uses <span class="math notranslate nohighlight">\(n = 100\)</span>, find <span class="math notranslate nohighlight">\(P(|\bar{X} - \mu| &lt; 0.5)\)</span>.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Given: <span class="math notranslate nohighlight">\(\sigma = 2.4\)</span> mL, population slightly right-skewed.</p>
<p class="sd-card-text"><strong>Part (a): Minimum sample size for P(|X̄ − μ| &lt; 0.5) ≥ 0.95</strong></p>
<p class="sd-card-text">We need:</p>
<div class="math notranslate nohighlight">
\[P\left(-0.5 &lt; \bar{X} - \mu &lt; 0.5\right) \geq 0.95\]</div>
<p class="sd-card-text">Standardizing:</p>
<div class="math notranslate nohighlight">
\[P\left(-\frac{0.5}{\sigma_{\bar{X}}} &lt; Z &lt; \frac{0.5}{\sigma_{\bar{X}}}\right) \geq 0.95\]</div>
<p class="sd-card-text">For a symmetric interval, we need <span class="math notranslate nohighlight">\(\frac{0.5}{\sigma_{\bar{X}}} \geq z_{0.975} = 1.96\)</span>.</p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} \leq \frac{0.5}{1.96} = 0.2551\]</div>
<div class="math notranslate nohighlight">
\[\frac{2.4}{\sqrt{n}} \leq 0.2551 \implies \sqrt{n} \geq \frac{2.4}{0.2551} = 9.408 \implies n \geq 88.5\]</div>
<p class="sd-card-text">Minimum sample size: <strong>n = 89</strong>.</p>
<p class="sd-card-text"><strong>Part (b): Should a larger sample be used?</strong></p>
<p class="sd-card-text"><strong>Yes, a larger sample is advisable</strong> for two reasons:</p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>CLT accuracy</strong>: The calculation assumes the CLT approximation is accurate. For a skewed population, using a sample size larger than the theoretical minimum (e.g., <span class="math notranslate nohighlight">\(n = 100\)</span> or more) helps ensure the normal approximation is valid.</p></li>
<li><p class="sd-card-text"><strong>Safety margin</strong>: The minimum of 89 achieves <em>exactly</em> 95% probability under ideal conditions. Real-world variability and the approximation nature of the CLT suggest building in a buffer.</p></li>
</ol>
<p class="sd-card-text"><strong>Part (c): P(|X̄ − μ| &lt; 0.5) with n = 100</strong></p>
<div class="math notranslate nohighlight">
\[\sigma_{\bar{X}} = \frac{2.4}{\sqrt{100}} = 0.24 \text{ mL}\]</div>
<div class="math notranslate nohighlight">
\[P(|\bar{X} - \mu| &lt; 0.5) = P\left(-\frac{0.5}{0.24} &lt; Z &lt; \frac{0.5}{0.24}\right)\]</div>
<div class="math notranslate nohighlight">
\[= P(-2.08 &lt; Z &lt; 2.08) = \Phi(2.08) - \Phi(-2.08)\]</div>
<div class="math notranslate nohighlight">
\[= 0.9812 - 0.0188 = 0.9624\]</div>
<p class="sd-card-text">With <span class="math notranslate nohighlight">\(n = 100\)</span>, there is about a <strong>96.2%</strong> probability that the sample mean is within 0.5 mL of the true mean—exceeding the 95% target.</p>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2.4</span>

<span class="c1"># Part (a): Find minimum n for P(|X̄ - μ| &lt; 0.5) ≥ 0.95</span>
<span class="c1"># Need SE ≤ 0.5/1.96</span>
<span class="p">(</span><span class="m">2.4</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="m">0.5</span><span class="o">/</span><span class="nf">qnorm</span><span class="p">(</span><span class="m">0.975</span><span class="p">)))</span><span class="o">^</span><span class="m">2</span>
<span class="c1"># [1] 88.5 → round up to 89</span>

<span class="c1"># Part (c): P(|X̄ - μ| &lt; 0.5) with n = 100</span>
<span class="n">se</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">100</span><span class="p">)</span><span class="w">  </span><span class="c1"># 0.24</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">0.5</span><span class="o">/</span><span class="n">se</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">-0.5</span><span class="o">/</span><span class="n">se</span><span class="p">)</span>
<span class="c1"># [1] 0.9625</span>
</pre></div>
</div>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 7: Process Monitoring Application</p>
<p>A chemical reactor operates with a temperature that fluctuates according to a distribution with <span class="math notranslate nohighlight">\(\mu = 350°C\)</span> and <span class="math notranslate nohighlight">\(\sigma = 12°C\)</span>. The distribution is symmetric but has heavier tails than normal. Every hour, an automated system records <span class="math notranslate nohighlight">\(n = 36\)</span> temperature readings and computes the average.</p>
<ol class="loweralpha simple">
<li><p>Using the CLT, what is the approximate distribution of the hourly average temperature <span class="math notranslate nohighlight">\(\bar{X}\)</span>?</p></li>
<li><p>The system triggers an alert if <span class="math notranslate nohighlight">\(\bar{X}\)</span> falls outside the interval <span class="math notranslate nohighlight">\([346, 354]\)</span>. What is the probability of a false alarm (alert when the process is operating normally)?</p></li>
<li><p>Suppose the reactor drifts so that <span class="math notranslate nohighlight">\(\mu = 355°C\)</span>. What is the probability that the monitoring system detects this drift (i.e., <span class="math notranslate nohighlight">\(\bar{X}\)</span> falls outside <span class="math notranslate nohighlight">\([346, 354]\)</span>)?</p></li>
<li><p>How would increasing <span class="math notranslate nohighlight">\(n\)</span> to 64 affect the false alarm rate and detection probability?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Given: <span class="math notranslate nohighlight">\(\mu = 350°C\)</span>, <span class="math notranslate nohighlight">\(\sigma = 12°C\)</span>, <span class="math notranslate nohighlight">\(n = 36\)</span>, symmetric heavy-tailed distribution.</p>
<p class="sd-card-text"><strong>Part (a): Approximate distribution of X̄</strong></p>
<p class="sd-card-text">Standard error: <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{12}{\sqrt{36}} = 2°C\)</span>.</p>
<p class="sd-card-text">CLT conditions: ✓ Finite <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, ✓ iid readings, ✓ <span class="math notranslate nohighlight">\(n = 36\)</span> is sufficient for a symmetric distribution (even with heavy tails, symmetry helps).</p>
<div class="math notranslate nohighlight">
\[\bar{X} \stackrel{\text{approx}}{\sim} N(350, 2^2)\]</div>
<p class="sd-card-text"><strong>Part (b): False alarm probability when μ = 350</strong></p>
<div class="math notranslate nohighlight">
\[P(\text{false alarm}) = P(\bar{X} &lt; 346 \text{ or } \bar{X} &gt; 354)\]</div>
<div class="math notranslate nohighlight">
\[= P\left(Z &lt; \frac{346 - 350}{2}\right) + P\left(Z &gt; \frac{354 - 350}{2}\right)\]</div>
<div class="math notranslate nohighlight">
\[= P(Z &lt; -2) + P(Z &gt; 2) = 0.0228 + 0.0228 = 0.0456\]</div>
<p class="sd-card-text">About <strong>4.56%</strong> false alarm rate.</p>
<p class="sd-card-text"><strong>Part (c): Detection probability when μ = 355</strong></p>
<p class="sd-card-text">Now <span class="math notranslate nohighlight">\(\bar{X} \stackrel{\text{approx}}{\sim} N(355, 2^2)\)</span>.</p>
<div class="math notranslate nohighlight">
\[P(\text{detection}) = P(\bar{X} &lt; 346 \text{ or } \bar{X} &gt; 354)\]</div>
<div class="math notranslate nohighlight">
\[= P\left(Z &lt; \frac{346 - 355}{2}\right) + P\left(Z &gt; \frac{354 - 355}{2}\right)\]</div>
<div class="math notranslate nohighlight">
\[= P(Z &lt; -4.5) + P(Z &gt; -0.5)\]</div>
<div class="math notranslate nohighlight">
\[\approx 0 + (1 - 0.3085) = 0.6915\]</div>
<p class="sd-card-text">About <strong>69%</strong> detection rate—the system will catch the drift about 69% of the time.</p>
<p class="sd-card-text"><strong>Part (d): Effect of increasing n to 64</strong></p>
<p class="sd-card-text">New standard error: <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{12}{\sqrt{64}} = 1.5°C\)</span>.</p>
<p class="sd-card-text"><em>False alarm rate (μ = 350):</em></p>
<div class="math notranslate nohighlight">
\[P(Z &lt; -2.67 \text{ or } Z &gt; 2.67) = 2 \times 0.0038 = 0.0076 \approx 0.76\%\]</div>
<p class="sd-card-text"><em>Detection rate (μ = 355):</em></p>
<div class="math notranslate nohighlight">
\[P\left(Z &lt; \frac{346-355}{1.5}\right) + P\left(Z &gt; \frac{354-355}{1.5}\right) = P(Z &lt; -6) + P(Z &gt; -0.67)\]</div>
<div class="math notranslate nohighlight">
\[\approx 0 + 0.7486 = 0.749 \approx 75\%\]</div>
<p class="sd-card-text"><strong>Summary</strong>: Increasing <span class="math notranslate nohighlight">\(n\)</span> from 36 to 64 decreases the false alarm rate (4.56% → 0.76%) while increasing the detection rate (69% → 75%). Larger samples make the monitoring system both more reliable and more sensitive.</p>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">12</span>

<span class="c1"># With n = 36</span>
<span class="n">se36</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">36</span><span class="p">)</span><span class="w">  </span><span class="c1"># 2</span>
<span class="c1"># Part (b): False alarm rate when μ = 350</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">346</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">350</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se36</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">354</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">350</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se36</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.0455</span>

<span class="c1"># Part (c): Detection rate when μ = 355</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">346</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">355</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se36</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">354</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">355</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se36</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.6915</span>

<span class="c1"># Part (d): With n = 64</span>
<span class="n">se64</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">64</span><span class="p">)</span><span class="w">  </span><span class="c1"># 1.5</span>
<span class="c1"># False alarm rate</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">346</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">350</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se64</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">354</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">350</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se64</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.0076</span>
<span class="c1"># Detection rate</span>
<span class="nf">pnorm</span><span class="p">(</span><span class="m">346</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">355</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se64</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">pnorm</span><span class="p">(</span><span class="m">354</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">355</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">se64</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>
<span class="c1"># [1] 0.7475</span>
</pre></div>
</div>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 8: Exploring the CLT with Simulation 🎮</p>
<p>Use the interactive CLT simulation to explore how the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> changes with different populations and sample sizes.</p>
<p><strong>Access the simulation</strong>: <a class="reference external" href="https://treese41528.github.io/STAT350/ShinyApps/CLT.html">CLT Interactive Demo</a></p>
<p><strong>Setup</strong>: Set “Number of Samples (SRS)” to 10000 for all explorations (this ensures smooth histograms).</p>
<p><strong>Part A: Effect of Sample Size on Convergence</strong></p>
<ol class="arabic simple">
<li><p>Select <strong>Exponential</strong> distribution. Set <span class="math notranslate nohighlight">\(n = 5\)</span>. Click Simulate.</p>
<ul class="simple">
<li><p>Describe the shape of the sampling distribution histogram. Is it symmetric or skewed?</p></li>
<li><p>Compare the experimental mean and SD to the theoretical values.</p></li>
</ul>
</li>
<li><p>Increase to <span class="math notranslate nohighlight">\(n = 15\)</span>, then <span class="math notranslate nohighlight">\(n = 30\)</span>, then <span class="math notranslate nohighlight">\(n = 60\)</span>. For each:</p>
<ul class="simple">
<li><p>How does the histogram shape change?</p></li>
<li><p>How does the QQ plot change? (Points closer to the line indicate better normality.)</p></li>
</ul>
</li>
<li><p>At what sample size does the sampling distribution appear approximately normal for the exponential population?</p></li>
</ol>
<p><strong>Part B: Comparing Population Shapes</strong></p>
<p>Using <span class="math notranslate nohighlight">\(n = 30\)</span> for each, compare the sampling distributions for:</p>
<ol class="arabic simple">
<li><p><strong>Uniform</strong> — symmetric, bounded</p></li>
<li><p><strong>Exponential</strong> — right-skewed, unbounded</p></li>
<li><p><strong>Beta</strong> (try different α, β values) — can be skewed or symmetric</p></li>
<li><p><strong>Bimodal</strong> — two peaks</p></li>
</ol>
<p>For which population(s) does <span class="math notranslate nohighlight">\(n = 30\)</span> seem sufficient for normality? For which might you want a larger sample?</p>
<p><strong>Part C: When CLT Fails</strong></p>
<ol class="arabic simple">
<li><p>Select <strong>Cauchy (CLT Failure!)</strong> distribution with <span class="math notranslate nohighlight">\(n = 30\)</span>. Simulate.</p>
<ul class="simple">
<li><p>Does the sampling distribution look normal?</p></li>
<li><p>What happens to the experimental mean and SD across different simulations? (Click Simulate several times.)</p></li>
</ul>
</li>
<li><p>Increase to <span class="math notranslate nohighlight">\(n = 100\)</span>, then <span class="math notranslate nohighlight">\(n = 500\)</span>. Does the sampling distribution become more normal?</p></li>
<li><p>Explain why the CLT fails for the Cauchy distribution.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part A: Effect of Sample Size</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><em>n = 5 (Exponential)</em>: The histogram is noticeably right-skewed, similar to the population. The QQ plot shows curvature, indicating departure from normality. Experimental mean and SD should be close to theoretical values.</p></li>
<li><p class="sd-card-text"><em>As n increases</em>:</p>
<ul class="simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(n = 15\)</span>: Still somewhat skewed but less pronounced</p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(n = 30\)</span>: Approximately symmetric, QQ plot mostly linear</p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(n = 60\)</span>: Very close to normal, QQ plot nearly perfect line</p></li>
</ul>
</li>
<li><p class="sd-card-text">For the exponential distribution, <span class="math notranslate nohighlight">\(n \approx 30\text{--}40\)</span> typically produces an approximately normal sampling distribution. This aligns with the common rule of thumb.</p></li>
</ol>
<p class="sd-card-text"><strong>Part B: Comparing Population Shapes</strong></p>
<p class="sd-card-text">With <span class="math notranslate nohighlight">\(n = 30\)</span>:</p>
<ul class="simple">
<li><p class="sd-card-text"><strong>Uniform</strong>: Sampling distribution is very close to normal. The uniform distribution is symmetric and bounded, so convergence is rapid. Even <span class="math notranslate nohighlight">\(n = 10\text{--}15\)</span> often suffices.</p></li>
<li><p class="sd-card-text"><strong>Exponential</strong>: Approximately normal at <span class="math notranslate nohighlight">\(n = 30\)</span> for many practical calculations, though slight right skewness may still be visible in the QQ plot.</p></li>
<li><p class="sd-card-text"><strong>Beta</strong>: Depends on parameters. Symmetric beta (<span class="math notranslate nohighlight">\(\alpha = \beta\)</span>) converges quickly; highly skewed beta (e.g., <span class="math notranslate nohighlight">\(\alpha = 1, \beta = 5\)</span>) may benefit from <span class="math notranslate nohighlight">\(n &gt; 30\text{--}40\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Bimodal</strong>: Often converges reasonably well by <span class="math notranslate nohighlight">\(n = 30\)</span> because averaging smooths out the two modes.</p></li>
</ul>
<p class="sd-card-text"><strong>Key insight</strong>: The more the population deviates from normality (especially skewness and heavy tails), the larger the sample size needed for an accurate approximation.</p>
<p class="sd-card-text"><strong>Part C: When CLT Fails (Cauchy)</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><em>n = 30</em>: The sampling distribution does NOT look normal. It has heavy tails and extreme outliers. The histogram may look erratic.</p></li>
<li><p class="sd-card-text"><em>n = 100, 500</em>: The distribution still does not become normal. You may see extreme sample means far from 0.</p></li>
<li><p class="sd-card-text"><em>Experimental mean/SD instability</em>: Each time you simulate, the experimental mean and SD change dramatically—they don’t stabilize.</p></li>
</ol>
<p class="sd-card-text"><strong>Why CLT fails for Cauchy</strong>: The Cauchy distribution has <strong>no finite mean or variance</strong> (both are undefined/infinite). The CLT requires finite mean and variance. Without these, the sample mean does not converge to any distribution—it remains unstable and heavy-tailed regardless of sample size.</p>
<p class="sd-card-text">This demonstrates that the CLT conditions are not just technicalities—they are essential requirements.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 9: Conceptual Understanding</p>
<p>Answer the following conceptual questions about the Central Limit Theorem.</p>
<ol class="loweralpha simple">
<li><p>The CLT says the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> approaches normal as <span class="math notranslate nohighlight">\(n \to \infty\)</span>. Does this mean that individual observations <span class="math notranslate nohighlight">\(X_i\)</span> become more normal as we collect more data? Explain.</p></li>
<li><p>Two populations have the same mean and variance, but Population A is symmetric while Population B is heavily right-skewed. For which population would you need a larger sample size for the CLT approximation to be accurate? Why?</p></li>
<li><p>If a population is already normally distributed, is the CLT still useful? Explain.</p></li>
<li><p>A student claims: “The CLT guarantees that <span class="math notranslate nohighlight">\(\bar{X}\)</span> is normally distributed for any sample size as long as <span class="math notranslate nohighlight">\(n \geq 30\)</span>.” Is this statement accurate? Critique it.</p></li>
<li><p>Based on the simulation in Exercise 8, explain why the Cauchy distribution is a counterexample to the CLT.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Do individual observations become more normal?</strong></p>
<p class="sd-card-text"><strong>No.</strong> The CLT describes the behavior of the <em>sample mean</em> <span class="math notranslate nohighlight">\(\bar{X}\)</span>, not individual observations. The population distribution (and hence each <span class="math notranslate nohighlight">\(X_i\)</span>) remains unchanged regardless of sample size. The “magic” of the CLT is that <em>averaging</em> many observations produces a quantity that is approximately normal, even though the individual observations may be far from normal.</p>
<p class="sd-card-text"><strong>Part (b): Which population needs larger n?</strong></p>
<p class="sd-card-text"><strong>Population B (heavily right-skewed)</strong> requires a larger sample size. The CLT converges faster for distributions that are closer to normal. Symmetric distributions converge quickly (often <span class="math notranslate nohighlight">\(n \geq 15\text{--}20\)</span> suffices), while heavily skewed distributions may need <span class="math notranslate nohighlight">\(n \geq 50\)</span> or more. The greater the departure from normality, the larger the <span class="math notranslate nohighlight">\(n\)</span> needed.</p>
<p class="sd-card-text"><strong>Part (c): Is the CLT useful for normal populations?</strong></p>
<p class="sd-card-text">When the population is normal, we have the <strong>exact result</strong> from Section 7.2: <span class="math notranslate nohighlight">\(\bar{X} \sim N(\mu, \sigma^2/n)\)</span> for any sample size. The CLT is not needed in this case because we already know the exact distribution.</p>
<p class="sd-card-text">However, the CLT provides reassurance that our inference methods remain valid even if our normality assumption is slightly wrong—the procedures are robust to mild departures from normality.</p>
<p class="sd-card-text"><strong>Part (d): Critique of the “n ≥ 30” claim</strong></p>
<p class="sd-card-text">This statement is <strong>not accurate</strong>. Issues include:</p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>“Guarantees”</strong> is too strong—the CLT provides an <em>approximation</em>, not an exact result. The quality of the approximation depends on the population shape.</p></li>
<li><p class="sd-card-text"><strong>“n ≥ 30”</strong> is an oversimplified rule of thumb, not a universal threshold. Symmetric, bounded populations may need much less (even <span class="math notranslate nohighlight">\(n = 10\text{--}15\)</span>); heavily skewed or heavy-tailed populations may need <span class="math notranslate nohighlight">\(n \geq 50\)</span> or more.</p></li>
<li><p class="sd-card-text">The CLT describes what happens as <span class="math notranslate nohighlight">\(n \to \infty\)</span>. For finite <span class="math notranslate nohighlight">\(n\)</span>, we only have an approximation, and we should assess whether that approximation is adequate for our purposes.</p></li>
</ol>
<p class="sd-card-text">A more accurate statement: “The required sample size for an adequate CLT approximation depends on the population’s departure from normality. Symmetric populations converge quickly; skewed or heavy-tailed populations require larger samples.”</p>
<p class="sd-card-text"><strong>Part (e): Cauchy as CLT counterexample</strong></p>
<p class="sd-card-text">The Cauchy distribution has <strong>undefined (infinite) mean and variance</strong>. In Exercise 8’s simulation, we observed that:</p>
<ul class="simple">
<li><p class="sd-card-text">The sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> does not become more normal as <span class="math notranslate nohighlight">\(n\)</span> increases</p></li>
<li><p class="sd-card-text">The experimental mean and SD are unstable across simulations</p></li>
<li><p class="sd-card-text">Extreme outliers persist even with large samples</p></li>
</ul>
<p class="sd-card-text">This occurs because the CLT requires finite mean and variance. The Cauchy distribution violates both conditions, so the theorem simply does not apply. This is not a matter of needing a “larger n”—the CLT will never work for Cauchy regardless of sample size.</p>
</div>
</details></div>
</section>
<hr class="docutils" />
<section id="additional-practice-problems">
<h2><span class="section-number">7.3.6. </span>Additional Practice Problems<a class="headerlink" href="#additional-practice-problems" title="Link to this heading"></a></h2>
<p><strong>True/False Questions</strong> (1 point each)</p>
<ol class="arabic">
<li><p>The Central Limit Theorem requires the population to be normally distributed.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>As sample size increases, the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> becomes more concentrated around <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>The CLT can be applied when the population has infinite variance.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>For a symmetric population, a smaller sample size is typically needed for the CLT approximation to be accurate compared to a skewed population.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>The CLT tells us that individual observations become approximately normal when the sample size is large.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>If observations are not independent, the CLT does not apply.</p>
<p>Ⓣ or Ⓕ</p>
</li>
</ol>
<p><strong>Multiple Choice Questions</strong> (2 points each)</p>
<ol class="arabic" start="7">
<li><p>The CLT states that as <span class="math notranslate nohighlight">\(n \to \infty\)</span>, which quantity approaches a standard normal distribution?</p>
<p>Ⓐ <span class="math notranslate nohighlight">\(\bar{X}\)</span></p>
<p>Ⓑ <span class="math notranslate nohighlight">\(\frac{\bar{X} - \mu}{\sigma}\)</span></p>
<p>Ⓒ <span class="math notranslate nohighlight">\(\frac{\bar{X} - \mu}{\sigma/\sqrt{n}}\)</span></p>
<p>Ⓓ <span class="math notranslate nohighlight">\(\frac{X_i - \mu}{\sigma}\)</span></p>
</li>
<li><p>A population has <span class="math notranslate nohighlight">\(\mu = 80\)</span> and <span class="math notranslate nohighlight">\(\sigma = 15\)</span>. For <span class="math notranslate nohighlight">\(n = 25\)</span>, the CLT approximation gives <span class="math notranslate nohighlight">\(\bar{X} \stackrel{\text{approx}}{\sim}\)</span>:</p>
<p>Ⓐ <span class="math notranslate nohighlight">\(N(80, 15^2)\)</span></p>
<p>Ⓑ <span class="math notranslate nohighlight">\(N(80, 3^2)\)</span></p>
<p>Ⓒ <span class="math notranslate nohighlight">\(N(80, 0.6^2)\)</span></p>
<p>Ⓓ <span class="math notranslate nohighlight">\(N(3.2, 80)\)</span></p>
</li>
<li><p>Which condition is NOT required for the CLT to apply?</p>
<p>Ⓐ Population has finite mean</p>
<p>Ⓑ Population has finite variance</p>
<p>Ⓒ Population is normally distributed</p>
<p>Ⓓ Observations are independent</p>
</li>
<li><p>For a heavily right-skewed population, which sample size is most likely to give an accurate CLT approximation?</p>
<p>Ⓐ <span class="math notranslate nohighlight">\(n = 10\)</span></p>
<p>Ⓑ <span class="math notranslate nohighlight">\(n = 25\)</span></p>
<p>Ⓒ <span class="math notranslate nohighlight">\(n = 50\)</span></p>
<p>Ⓓ <span class="math notranslate nohighlight">\(n = 100\)</span></p>
</li>
<li><p>If <span class="math notranslate nohighlight">\(X \sim \text{Uniform}(0, 12)\)</span>, then <span class="math notranslate nohighlight">\(\sigma =\)</span>:</p>
<p>Ⓐ 6</p>
<p>Ⓑ <span class="math notranslate nohighlight">\(12/\sqrt{12} \approx 3.46\)</span></p>
<p>Ⓒ 12</p>
<p>Ⓓ 4</p>
</li>
<li><p>Using the CLT with <span class="math notranslate nohighlight">\(\mu = 50\)</span>, <span class="math notranslate nohighlight">\(\sigma = 10\)</span>, and <span class="math notranslate nohighlight">\(n = 100\)</span>, find <span class="math notranslate nohighlight">\(P(\bar{X} &gt; 52)\)</span>:</p>
<p>Ⓐ <span class="math notranslate nohighlight">\(P(Z &gt; 0.2)\)</span></p>
<p>Ⓑ <span class="math notranslate nohighlight">\(P(Z &gt; 2)\)</span></p>
<p>Ⓒ <span class="math notranslate nohighlight">\(P(Z &gt; 20)\)</span></p>
<p>Ⓓ <span class="math notranslate nohighlight">\(P(Z &gt; 0.02)\)</span></p>
</li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Answers to Practice Problems</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>True/False Answers:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>False</strong> — The CLT applies to any population with finite mean and variance, regardless of its distribution shape.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — The standard error <span class="math notranslate nohighlight">\(\sigma/\sqrt{n}\)</span> decreases as <span class="math notranslate nohighlight">\(n\)</span> increases, concentrating the distribution around <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p class="sd-card-text"><strong>False</strong> — The CLT requires <strong>finite variance</strong>. For populations with infinite variance (like Cauchy), the CLT does not apply.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — Symmetric distributions are “closer” to normal, so the CLT approximation converges faster.</p></li>
<li><p class="sd-card-text"><strong>False</strong> — The CLT applies to the <strong>sample mean</strong> <span class="math notranslate nohighlight">\(\bar{X}\)</span>, not to individual observations. Individual observations retain their original (non-normal) distribution.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — Independence is a key requirement. Without it, the variance formula <span class="math notranslate nohighlight">\(\sigma^2/n\)</span> and the CLT both fail.</p></li>
</ol>
<p class="sd-card-text"><strong>Multiple Choice Answers:</strong></p>
<ol class="arabic simple" start="7">
<li><p class="sd-card-text"><strong>Ⓒ</strong> — The CLT states that the <strong>standardized sample mean</strong> <span class="math notranslate nohighlight">\(\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \xrightarrow{d} N(0,1)\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = 15/\sqrt{25} = 3\)</span>, so <span class="math notranslate nohighlight">\(\bar{X} \stackrel{\text{approx}}{\sim} N(80, 3^2)\)</span>. Remember: <span class="math notranslate nohighlight">\(N(\mu, \sigma^2)\)</span> uses variance as the second parameter.</p></li>
<li><p class="sd-card-text"><strong>Ⓒ</strong> — Normality of the population is NOT required. The CLT works for any population shape (given finite mean and variance).</p></li>
<li><p class="sd-card-text"><strong>Ⓓ</strong> — Heavily skewed populations require larger samples. <span class="math notranslate nohighlight">\(n = 100\)</span> is most likely to give an accurate approximation.</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — For Uniform(a, b): <span class="math notranslate nohighlight">\(\sigma = \frac{b-a}{\sqrt{12}} = \frac{12}{\sqrt{12}} = \sqrt{12} \approx 3.46\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — <span class="math notranslate nohighlight">\(z = \frac{52 - 50}{10/\sqrt{100}} = \frac{2}{1} = 2\)</span>, so the answer is <span class="math notranslate nohighlight">\(P(Z &gt; 2)\)</span>.</p></li>
</ol>
</div>
</details></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="7-2-sampling-distribution-for-the-sample-mean.html" class="btn btn-neutral float-left" title="7.2. Sampling Distribution for the Sample Mean" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="7-4-discret-rvs-and-clt.html" class="btn btn-neutral float-right" title="7.4. Understanding Binomial and Poisson Distributions through CLT" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
  <p class="footer-credits-inline">
    <strong>Website Credits:</strong>
    Website development by Dr. Timothy Reese and Halin Shin.
    Generative AI tools were used to draft and refine some prose, code, and documentation; all content was reviewed by the instructors.
    Models: OpenAI o3 (2025-04-16 release) and Anthropic Claude Opus 4.1 (2025-08-05).
  </p>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 

<!-- Floating Chat Button -->
<button id="chatbot-toggle" class="chatbot-fab" aria-label="Open AI Course Assistant" aria-expanded="false">
  <span class="chatbot-fab-badge">BETA</span>
  <svg class="chatbot-fab-icon chatbot-icon-open" fill="none" stroke="currentColor" viewBox="0 0 24 24">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
          d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"/>
  </svg>
  <svg class="chatbot-fab-icon chatbot-icon-close" fill="none" stroke="currentColor" viewBox="0 0 24 24" style="display:none;">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
  </svg>
  <span class="chatbot-fab-text">Ask AI Assistant</span>
</button>

<!-- Chat Panel - Fullscreen -->
<div id="chatbot-panel" class="chatbot-panel" aria-hidden="true">
  <div class="chatbot-panel-topbar">
    <button id="chatbot-close" class="chatbot-panel-close-minimal" aria-label="Close chat">
      <svg width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
      </svg>
    </button>
    <a href="https://advert-cingular-employer-humor.trycloudflare.com/" 
       target="_blank" 
       rel="noopener noreferrer" 
       class="chatbot-newtab">
      <svg width="16" height="16" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
              d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"/>
      </svg>
      Open in new tab
    </a>
  </div>
  <iframe id="chatbot-iframe" class="chatbot-iframe" title="STAT 350 AI Course Assistant"></iframe>
</div>

<script>
(function() {
  const CHATBOT_BASE_URL = 'https://advert-cingular-employer-humor.trycloudflare.com/';
  
  const toggle = document.getElementById('chatbot-toggle');
  const panel = document.getElementById('chatbot-panel');
  const closeBtn = document.getElementById('chatbot-close');
  const iframe = document.getElementById('chatbot-iframe');
  const iconOpen = toggle.querySelector('.chatbot-icon-open');
  const iconClose = toggle.querySelector('.chatbot-icon-close');
  
  let isOpen = false;
  let iframeLoaded = false;
  
  function getPageContext() {
    const pageTitle = document.title || '';
    const pageUrl = window.location.href;
    const pagePath = window.location.pathname;
    
    const h1 = document.querySelector('.rst-content h1, h1');
    const heading = h1 ? h1.textContent.replace(/[¶#]/g, '').trim() : '';
    
    const breadcrumbs = document.querySelectorAll('.wy-breadcrumbs li a');
    const breadcrumbPath = Array.from(breadcrumbs).map(a => a.textContent.trim()).join(' > ');
    
    const chapterMatch = pagePath.match(/chapter(\d+)/i);
    const chapter = chapterMatch ? 'Chapter ' + chapterMatch[1] : '';
    
    return {
      title: heading || pageTitle,
      url: pageUrl,
      path: pagePath,
      breadcrumbs: breadcrumbPath,
      chapter: chapter
    };
  }
  
  function buildChatbotUrl(context) {
    const params = new URLSearchParams();
    if (context.title) params.set('page_title', context.title);
    if (context.url) params.set('page_url', context.url);
    if (context.chapter) params.set('chapter', context.chapter);
    if (context.breadcrumbs) params.set('breadcrumbs', context.breadcrumbs);
    
    const queryString = params.toString();
    return queryString ? CHATBOT_BASE_URL + '?' + queryString : CHATBOT_BASE_URL;
  }
  
  function openChat() {
    const context = getPageContext();
    
    const newUrl = buildChatbotUrl(context);
    if (!iframeLoaded || iframe.dataset.lastUrl !== context.url) {
      iframe.src = newUrl;
      iframe.dataset.lastUrl = context.url;
      iframeLoaded = true;
    }
    
    panel.classList.add('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'false');
    toggle.setAttribute('aria-expanded', 'true');
    iconOpen.style.display = 'none';
    iconClose.style.display = 'block';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Close';
    isOpen = true;
    
    toggle.classList.add('chatbot-fab-opened');
    
    // Prevent body scroll when panel is open
    document.body.style.overflow = 'hidden';
  }
  
  function closeChat() {
    panel.classList.remove('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'true');
    toggle.setAttribute('aria-expanded', 'false');
    iconOpen.style.display = 'block';
    iconClose.style.display = 'none';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Ask AI Assistant';
    isOpen = false;
    
    // Restore body scroll
    document.body.style.overflow = '';
  }
  
  function toggleChat() {
    if (isOpen) {
      closeChat();
    } else {
      openChat();
    }
  }
  
  toggle.addEventListener('click', toggleChat);
  closeBtn.addEventListener('click', closeChat);
  
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape' && isOpen) {
      closeChat();
    }
  });
})();
</script>


</body>
</html>