

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>7.3. The Central Limit Theorem (CLT) &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=3c686048" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter7/lectures/7-3-clt.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=8512422d"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7.4. Discrete Random Variables and the CLT" href="7-4-discret-rvs-and-clt.html" />
    <link rel="prev" title="7.2. Sampling Distribution for the Sample Mean" href="7-2-sampling-distribution-for-the-sample-mean.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#simulation-exercise">Simulation Exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Shape &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">7. Sampling Distributions</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="7-4-discret-rvs-and-clt.html">7.4. Discrete Random Variables and the CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">7. </span>Sampling Distributions</a></li>
      <li class="breadcrumb-item active"><span class="section-number">7.3. </span>The Central Limit Theorem (CLT)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter7/lectures/7-3-clt.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch7-3">
   <iframe
      id="video-ch7-3"
      title="STAT 350 – Chapter 7.3 Central Limit Theorem Video"
      src="https://www.youtube.com/embed/l1vhy86sIVU?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="the-central-limit-theorem-clt">
<h1><span class="section-number">7.3. </span>The Central Limit Theorem (CLT)<a class="headerlink" href="#the-central-limit-theorem-clt" title="Link to this heading"></a></h1>
<p>We’ve established that the sampling distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is normal when the population is normal.
Then what about cases where the <strong>population is not normally distributed</strong>?
The Central Limit Theorem (CLT) is a pivotal concept in statistics that addresses this questions.
It states that regardless of the shape of the original population distribution, the sampling distribution
of the sample mean will approach a normal distribution as the sample size increases, provided certain conditions
are met.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p>Learn the formal statement of the Central Limit Theorem (CLT).</p></li>
<li><p>Recognize the experimental settings to which the CLT applies. Apply the CLT to
compute approximate probabilities of the sample mean.</p></li>
</ul>
</div>
<section id="the-formal-statement-of-the-clt">
<h2><span class="section-number">7.3.1. </span>The Formal Statement of the CLT<a class="headerlink" href="#the-formal-statement-of-the-clt" title="Link to this heading"></a></h2>
<p>For an independent and identically distributed (<em>iid</em>) random sample <span class="math notranslate nohighlight">\(X_1, X_2, ..., X_n\)</span>
from a population with a finite mean <span class="math notranslate nohighlight">\(μ\)</span> and finite standard deviation <span class="math notranslate nohighlight">\(σ\)</span>,</p>
<div class="math notranslate nohighlight">
\[\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \xrightarrow{d} N(0,1) \text{ as } n \rightarrow \infty\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\frac{\bar{X} - \mu}{\sigma/\sqrt{n}}\)</span> is the <em>standardized sample mean</em>.
<span class="math notranslate nohighlight">\(\bar{X}\)</span> is subtracted by its own mean <span class="math notranslate nohighlight">\(\mu_{\bar{X}} = \mu\)</span>,
then divided by its own standard deviation <span class="math notranslate nohighlight">\(\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}\)</span> (the standard error).</p></li>
<li><p><span class="math notranslate nohighlight">\(\xrightarrow{d}\)</span> indicates <em>convergence in distribution</em>.</p></li>
<li><p>Putting together, the mathematical statement reads: “The distribution of the standardized sample mean
approaches standard normal as the sample size <span class="math notranslate nohighlight">\(n\)</span> grows larger.”</p></li>
</ul>
<ul class="simple">
<li><p>Mean: <span class="math notranslate nohighlight">\(\mu_{\bar{X}} = \mu\)</span></p></li>
<li><p>Standard deviation:</p></li>
</ul>
<p>Importantly, the CLT also applies to the sample sum <span class="math notranslate nohighlight">\(S_n = X_1 + X_2 + \ldots + X_n\)</span>. The standardized sample sum:</p>
<div class="math notranslate nohighlight">
\[\frac{S_n - n\mu}{\sigma\sqrt{n}} \xrightarrow{d} N(0,1) \text{ as } n \rightarrow \infty\]</div>
<p>This means that for sufficiently large n, the sample sum is approximately normally distributed:</p>
<div class="math notranslate nohighlight">
\[S_n \approx N(n\mu, \sigma\sqrt{n})\]</div>
<section id="key-conditions-for-the-clt">
<h3>Key Conditions for the CLT<a class="headerlink" href="#key-conditions-for-the-clt" title="Link to this heading"></a></h3>
<p>For the Central Limit Theorem to apply:</p>
<ol class="arabic simple">
<li><p>The population must have a finite mean (μ) and finite standard deviation (σ)</p></li>
<li><p>The observations must be independent and identically distributed (i.i.d.)</p></li>
<li><p>The sample size must be “sufficiently large”</p></li>
</ol>
<p>The presence of large outliers in your data may indicate that the population variance is not finite, which would violate a key assumption of the CLT. It’s important to note that there are distributions, such as the Cauchy distribution, that do not have a finite mean or variance. For such distributions, the CLT does not apply, and the sample mean does not converge to a normal distribution regardless of sample size.</p>
</section>
<section id="visual-demonstration-of-the-clt">
<h3>Visual Demonstration of the CLT<a class="headerlink" href="#visual-demonstration-of-the-clt" title="Link to this heading"></a></h3>
<p>We can observe the CLT in action through simulations. When we draw samples from different population distributions and compute the sample means, we see a remarkable pattern emerge as the sample size increases.</p>
<p>Regardless of the population distribution we start with—uniform, exponential, left-skewed, or even bimodal—the sampling distribution of the sample mean starts to resemble a normal distribution as we increase the sample size.</p>
<p>For example, when sampling from a uniform distribution (a flat distribution with constant height), the distribution of sample means starts to become more bell-shaped even with small sample sizes. By the time we reach sample sizes around 25, the sampling distribution appears approximately normal.</p>
<p>For a right-skewed distribution like the exponential distribution, even with samples of size 10, the sampling distribution of the mean remains noticeably right-skewed. However, as sample size increases to around 100, the sampling distribution becomes approximately symmetric and normal.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/clt_demonstration.png"><img alt="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/clt_demonstration.png" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/clt_demonstration.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 7.4 </span><span class="caption-text"><em>As sample size increases, the sampling distribution of the mean approaches a normal distribution regardless of the original population shape</em></span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
</section>
<section id="how-large-is-sufficiently-large">
<h2><span class="section-number">7.3.2. </span>How Large is “Sufficiently Large”?<a class="headerlink" href="#how-large-is-sufficiently-large" title="Link to this heading"></a></h2>
<p>The required sample size depends on how far the original population distribution deviates from normality:</p>
<ul class="simple">
<li><p>For symmetric distributions like the uniform distribution, even small sample sizes (n ≈ 10) may be sufficient</p></li>
<li><p>For moderately skewed distributions, sample sizes of n ≈ 30-50 might be needed</p></li>
<li><p>For heavily skewed distributions, sample sizes of n ≈ 100 or more may be required</p></li>
<li><p>For extremely skewed or bimodal distributions, even larger samples may be necessary</p></li>
</ul>
<p><strong>Important:</strong> The common rule of thumb that n &gt; 30 is sufficient is misleading and should not be blindly applied. The appropriate sample size depends entirely on the underlying population distribution. The farther the population distribution is from normal, the larger the sample size needed for the CLT to apply effectively.</p>
<p>For instance, when sampling from a heavily right-skewed Gamma distribution with small shape parameter (e.g., Gamma(0.5, 5)), it might take sample sizes as large as n = 80 or even n = 165 for the sampling distribution to appear reasonably normal, especially in the tails.</p>
<p>In practice, we only observe a single sample from a population. We can’t know for certain if we’re sampling from a heavily right-skewed distribution or not. It depends on the sample we observe and our understanding of what distribution it likely came from. We must explore our sample and possibly conduct simulations to determine if the sample size is likely sufficient for the CLT to apply.</p>
</section>
<section id="detailed-examples-of-the-clt-in-action">
<h2><span class="section-number">7.3.3. </span>Detailed Examples of the CLT in Action<a class="headerlink" href="#detailed-examples-of-the-clt-in-action" title="Link to this heading"></a></h2>
<p>Let’s examine what happens to the sampling distribution of the sample mean for different population distributions as we increase the sample size:</p>
<section id="example-1-normal-population">
<h3>Example 1: Normal Population<a class="headerlink" href="#example-1-normal-population" title="Link to this heading"></a></h3>
<p>When sampling from a normal population, the sampling distribution of the mean is also normal, regardless of sample size. As sample size increases, the sampling distribution becomes more concentrated around the true population mean.</p>
</section>
<section id="example-2-uniform-population">
<h3>Example 2: Uniform Population<a class="headerlink" href="#example-2-uniform-population" title="Link to this heading"></a></h3>
<p>When sampling from a uniform distribution (a flat distribution with constant height), even with small sample sizes like n=2, the distribution of sample means starts to change shape. By the time we reach sample sizes around 25, the sampling distribution appears approximately normal.</p>
</section>
<section id="example-3-right-skewed-exponential-population">
<h3>Example 3: Right-Skewed (Exponential) Population<a class="headerlink" href="#example-3-right-skewed-exponential-population" title="Link to this heading"></a></h3>
<p>For a right-skewed distribution like the exponential distribution, even with samples of size 10, the sampling distribution of the mean remains noticeably right-skewed. However, as sample size increases to around 100, the sampling distribution becomes approximately symmetric and normal.</p>
</section>
<section id="example-4-left-skewed-population">
<h3>Example 4: Left-Skewed Population<a class="headerlink" href="#example-4-left-skewed-population" title="Link to this heading"></a></h3>
<p>For a left-skewed distribution (like a beta distribution with appropriate parameters), samples of size 50 may be sufficient to achieve approximate normality in the sampling distribution.</p>
</section>
<section id="example-5-bimodal-distribution">
<h3>Example 5: Bimodal Distribution<a class="headerlink" href="#example-5-bimodal-distribution" title="Link to this heading"></a></h3>
<p>For bimodal distributions (distributions with two peaks), the CLT still applies mathematically, but caution is needed. If the bimodal pattern represents two distinct populations, it may be more appropriate to analyze each population separately rather than combining them.</p>
<p>In all these cases, we observe that regardless of the original population distribution, the sample means tend to follow a normal distribution as the sample size increases. However, the required sample size varies depending on how far the original distribution deviates from normality.</p>
</section>
</section>
<section id="practical-applications-of-the-clt">
<h2><span class="section-number">7.3.4. </span>Practical Applications of the CLT<a class="headerlink" href="#practical-applications-of-the-clt" title="Link to this heading"></a></h2>
<p>The Central Limit Theorem allows us to:</p>
<ol class="arabic simple">
<li><p>Quantify uncertainty in our sample mean estimates</p></li>
<li><p>Calculate probabilities related to sample means</p></li>
<li><p>Construct confidence intervals for population means</p></li>
<li><p>Develop hypothesis tests for means</p></li>
<li><p>Make statistical inferences about populations using sample data</p></li>
</ol>
<p>The CLT is particularly powerful because it allows us to use the normal distribution to quantify uncertainty in our sample mean estimates even when the underlying population is not normal. This means we can use the normal distribution to compute probabilities, create confidence intervals, and perform hypothesis tests across a wide range of real-world situations.</p>
<section id="real-world-applications">
<h3>Real-World Applications<a class="headerlink" href="#real-world-applications" title="Link to this heading"></a></h3>
<p>The CLT has important applications in many fields:</p>
</section>
<section id="quality-control">
<h3>Quality Control<a class="headerlink" href="#quality-control" title="Link to this heading"></a></h3>
<p>In manufacturing, the CLT allows engineers to reliably predict defect rates in large batches based on smaller samples, even when individual defect occurrences may not follow a normal distribution.</p>
</section>
<section id="medical-research">
<h3>Medical Research<a class="headerlink" href="#medical-research" title="Link to this heading"></a></h3>
<p>When assessing the effectiveness of treatments or medical devices, researchers can use the CLT to analyze average outcomes, even when individual patient responses vary widely.</p>
</section>
<section id="finance">
<h3>Finance<a class="headerlink" href="#finance" title="Link to this heading"></a></h3>
<p>Although daily stock returns may be non-normal with extreme values, average returns over longer periods tend toward normality, allowing for more reliable risk assessments.</p>
</section>
<section id="environmental-science">
<h3>Environmental Science<a class="headerlink" href="#environmental-science" title="Link to this heading"></a></h3>
<p>When measuring pollutant levels that may have skewed distributions, the CLT enables scientists to make reliable inferences about mean pollution levels using sample averages.</p>
<p>In all these cases, the CLT provides a theoretical foundation for making reliable inferences despite the non-normal nature of the underlying data.</p>
</section>
</section>
<section id="beyond-the-sample-mean-other-statistics">
<h2><span class="section-number">7.3.5. </span>Beyond the Sample Mean: Other Statistics<a class="headerlink" href="#beyond-the-sample-mean-other-statistics" title="Link to this heading"></a></h2>
<p>While the Central Limit Theorem is most commonly applied to the sample mean, it’s worth noting that similar convergence to normality can occur for other statistics under appropriate conditions:</p>
<section id="sample-sum">
<h3>Sample Sum<a class="headerlink" href="#sample-sum" title="Link to this heading"></a></h3>
<p>As mentioned earlier, the CLT applies directly to the sample sum <span class="math notranslate nohighlight">\(S_n = X_1 + X_2 + \ldots + X_n\)</span>. For large n, the sample sum is approximately normally distributed with mean n·μ and standard deviation σ·√n.</p>
</section>
<section id="weighted-averages-and-linear-combinations">
<h3>Weighted Averages and Linear Combinations<a class="headerlink" href="#weighted-averages-and-linear-combinations" title="Link to this heading"></a></h3>
<p>The CLT also applies to weighted averages and other linear combinations of random variables. This is particularly important in regression analysis, where estimators like the least squares slope and intercept are weighted averages of the response variable. As we’ll see later in simple linear regression, these estimators also follow normal distributions asymptotically under appropriate conditions, which is crucial for constructing confidence intervals and conducting hypothesis tests for regression coefficients.</p>
</section>
<section id="sample-variance">
<h3>Sample Variance<a class="headerlink" href="#sample-variance" title="Link to this heading"></a></h3>
<p>The sample variance can also approach a normal distribution as sample size increases, but it typically requires much larger sample sizes than the sample mean to achieve a good normal approximation. For statistics like the sample variance, specialized distributions (like the chi-squared distribution) often provide better approximations than relying on the CLT, especially for smaller sample sizes.</p>
</section>
<section id="other-statistics">
<h3>Other Statistics<a class="headerlink" href="#other-statistics" title="Link to this heading"></a></h3>
<p>Many other statistics that involve weighted averages or sums of random variables can also converge to a normal distribution as sample size increases, but the rate of convergence varies considerably depending on the specific statistic. This is why simulation studies are often valuable to determine when normal approximations are reasonable.</p>
</section>
<section id="discrete-data-and-continuity-corrections">
<h3>Discrete Data and Continuity Corrections<a class="headerlink" href="#discrete-data-and-continuity-corrections" title="Link to this heading"></a></h3>
<p>For discrete distributions, the CLT still applies, but when approximating a discrete sampling distribution with a continuous normal distribution, a continuity correction is sometimes necessary for greater accuracy. The correction involves adjusting probability bounds by ±0.5 when using the normal approximation. This is particularly important when applying the CLT to binomial or Poisson data. Which are discussed in more detail in the next section.</p>
</section>
<section id="step-by-step-problem-solving-with-the-clt">
<h3>Step-by-Step Problem Solving with the CLT<a class="headerlink" href="#step-by-step-problem-solving-with-the-clt" title="Link to this heading"></a></h3>
<p>When solving problems using the CLT:</p>
<ol class="arabic simple">
<li><p>Verify that the CLT conditions are met (finite mean and variance, i.i.d. observations, sufficient sample size)</p></li>
<li><p>Identify the population mean (μ) and standard deviation (σ)</p></li>
<li><p>Calculate the mean of the sampling distribution: μₓ̄ = μ</p></li>
<li><p>Calculate the standard deviation of the sampling distribution: σₓ̄ = σ/√n</p></li>
<li><p>Standardize the problem to use the standard normal distribution (Z):
Z = (x̄ - μₓ̄)/σₓ̄</p></li>
<li><p>Use normal distribution tables or calculators to find the required probability</p></li>
</ol>
</section>
<section id="interactive-exploration">
<h3>Interactive Exploration<a class="headerlink" href="#interactive-exploration" title="Link to this heading"></a></h3>
<p>To better understand how the Central Limit Theorem works with different population distributions and sample sizes,
you can explore an interactive simulation at:</p>
<div class="interactive admonition">
<p class="admonition-title">Interactive Visualization 🎮</p>
<p><strong>Central Limit Theorem Simulation</strong></p>
<p>Visualize how sample means converge to a normal distribution as sample size
increases, regardless of the underlying population distribution.</p>
<p><a class="reference external" href="https://treese41528.github.io/STAT350/ShinyApps/CLT.html">🔗 Launch Interactive Demo</a> |
<a class="reference external" href="https://treese41528.github.io/STAT350/ShinyApps/CLT_Shiny.R">📄 View R Code</a></p>
</div>
<p>This interactive tool allows you to:</p>
<ul class="simple">
<li><p>Select different population distributions (Normal, Uniform, Exponential, etc.)</p></li>
<li><p>Adjust sample sizes</p></li>
<li><p>Generate thousands of samples</p></li>
<li><p>Visualize both the population distribution and the resulting sampling distribution of means</p></li>
</ul>
</section>
</section>
<section id="code-implementation-example">
<h2><span class="section-number">7.3.6. </span>Code Implementation Example<a class="headerlink" href="#code-implementation-example" title="Link to this heading"></a></h2>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Central Limit Theorem Demonstration</span>
<span class="c1"># This R code simulates the Central Limit Theorem for different distributions</span>

<span class="c1"># Parameters</span>
<span class="n">n_samples</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10000</span><span class="w">  </span><span class="c1"># Number of samples to generate</span>
<span class="n">sample_sizes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">)</span><span class="w">  </span><span class="c1"># Different sample sizes to try</span>
<span class="n">population_type</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&quot;exponential&quot;</span><span class="w">  </span><span class="c1"># Options: &quot;normal&quot;, &quot;uniform&quot;, &quot;exponential&quot;, &quot;beta&quot;</span>

<span class="c1"># Function to generate samples and calculate means</span>
<span class="n">simulate_sampling_distribution</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">pop_type</span><span class="p">,</span><span class="w"> </span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">n_samples</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sample_means</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">numeric</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

<span class="w">  </span><span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n_samples</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1"># Generate sample based on population type</span>
<span class="w">    </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">pop_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;normal&quot;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">pop_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;uniform&quot;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">-5</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">)</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">pop_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;exponential&quot;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rexp</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">rate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">pop_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;beta&quot;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">sample</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rbeta</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">shape1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">shape2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">)</span><span class="w">  </span><span class="c1"># Left-skewed</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1"># Calculate and store the sample mean</span>
<span class="w">    </span><span class="n">sample_means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kr">return</span><span class="p">(</span><span class="n">sample_means</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Generate and plot sampling distributions for different sample sizes</span>
<span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">),</span><span class="w"> </span><span class="m">1</span><span class="p">))</span>
<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="n">sample_sizes</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">means</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">simulate_sampling_distribution</span><span class="p">(</span><span class="n">population_type</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">n_samples</span><span class="p">)</span>
<span class="w">  </span><span class="nf">hist</span><span class="p">(</span><span class="n">means</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Sample Size =&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">),</span>
<span class="w">       </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Sample Mean&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">freq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span>

<span class="w">  </span><span class="c1"># Add normal curve with parameters predicted by CLT</span>
<span class="w">  </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">population_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;normal&quot;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nf">curve</span><span class="p">(</span><span class="nf">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">size</span><span class="p">)),</span><span class="w"> </span><span class="n">add</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">population_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;uniform&quot;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1"># Uniform(-5,5) has mean 0 and variance (10^2)/12 = 8.33</span>
<span class="w">    </span><span class="nf">curve</span><span class="p">(</span><span class="nf">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">8.33</span><span class="p">)</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">size</span><span class="p">)),</span><span class="w"> </span><span class="n">add</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">population_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;exponential&quot;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1"># Exponential(1) has mean 1 and variance 1</span>
<span class="w">    </span><span class="nf">curve</span><span class="p">(</span><span class="nf">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">size</span><span class="p">)),</span><span class="w"> </span><span class="n">add</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="kr">else</span><span class="w"> </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">population_type</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;beta&quot;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1"># Beta(2,5) has mean 2/(2+5) = 2/7 and variance specific to this distribution</span>
<span class="w">    </span><span class="n">beta_var</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="m">2</span><span class="o">*</span><span class="m">5</span><span class="p">)</span><span class="o">/</span><span class="p">((</span><span class="m">2+5</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="m">2+5+1</span><span class="p">))</span>
<span class="w">    </span><span class="nf">curve</span><span class="p">(</span><span class="nf">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="o">/</span><span class="m">7</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">beta_var</span><span class="p">)</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">size</span><span class="p">)),</span><span class="w"> </span><span class="n">add</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This code demonstrates how to simulate the Central Limit Theorem across different population distributions and sample sizes. By running this simulation, you can observe firsthand how the sampling distribution of the sample mean changes shape and becomes more normal as the sample size increases.</p>
</section>
<section id="important-considerations">
<h2><span class="section-number">7.3.7. </span>Important Considerations<a class="headerlink" href="#important-considerations" title="Link to this heading"></a></h2>
<p>In practice, we typically observe only a single sample from a population. We cannot directly observe the sampling distribution of the mean. Instead, we must rely on understanding the properties of the original population to determine if the CLT can be reasonably applied.</p>
<p>When working with real data, consider:</p>
<ol class="arabic simple">
<li><p>Examining your sample for extreme skewness or outliers</p></li>
<li><p>Assessing whether your sample size is adequate given the apparent distribution</p></li>
<li><p>Using simulations to explore how the CLT might apply in your specific context</p></li>
</ol>
<p>Remember that while the CLT is a powerful tool, it is not applicable in all situations, particularly when dealing with distributions that have infinite variance or when sample sizes are inadequate relative to the population’s deviation from normality.</p>
<section id="limitations-of-the-clt">
<h3>Limitations of the CLT<a class="headerlink" href="#limitations-of-the-clt" title="Link to this heading"></a></h3>
<p>The CLT is not a universal solution for all statistical problems:</p>
</section>
<section id="distributions-without-finite-moments">
<h3>Distributions without finite moments<a class="headerlink" href="#distributions-without-finite-moments" title="Link to this heading"></a></h3>
<p>For distributions like the Cauchy distribution that lack finite mean or variance, the CLT does not apply. The sample mean of Cauchy random variables follows a Cauchy distribution regardless of sample size, never converging to normality.</p>
</section>
<section id="extremely-small-sample-sizes">
<h3>Extremely small sample sizes<a class="headerlink" href="#extremely-small-sample-sizes" title="Link to this heading"></a></h3>
<p>While the CLT is an asymptotic result (valid as n approaches infinity), practical applications require finite sample sizes. For highly non-normal distributions, the required sample size might be impractically large.</p>
</section>
<section id="dependent-observations">
<h3>Dependent observations<a class="headerlink" href="#dependent-observations" title="Link to this heading"></a></h3>
<p>The CLT assumes independent samples. When observations are correlated (like in time series data), specialized versions of the CLT that account for dependence are needed.</p>
</section>
<section id="mixtures-of-populations">
<h3>Mixtures of populations<a class="headerlink" href="#mixtures-of-populations" title="Link to this heading"></a></h3>
<p>When data come from multiple distinct populations (creating multimodal distributions), analyzing the combined data might be misleading. It’s often better to separate the populations for analysis.</p>
<p>Despite these limitations, the CLT remains one of the most powerful and widely applicable theorems in statistics, providing the theoretical foundation for many inferential procedures.</p>
</section>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">7.3.8. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<p>The Central Limit Theorem provides a theoretical foundation for many statistical procedures by allowing us to
approximate the sampling distribution of the sample mean with a normal distribution, regardless of the shape of
the original population distribution. However, the quality of this approximation depends critically on:</p>
<ol class="arabic simple">
<li><p>The sample size (n)</p></li>
<li><p>How far the original population distribution deviates from normality</p></li>
<li><p>Whether the population has finite mean and variance</p></li>
</ol>
<p>By understanding these factors, you can properly apply the CLT in statistical inference and avoid misusing it
in situations where its assumptions are violated.</p>
<p>The CLT forms a critical bridge between probability theory and statistical inference, making it possible to use
the well-understood properties of the normal distribution to analyze data from a wide variety of real-world processes.
It also connects to upcoming topics such as regression analysis, where we’ll see how the normal distribution underlies
our ability to make inferences about relationships between variables.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>The Central Limit Theorem states</strong> that for a properly taken i.i.d. sample from any population with finite mean and variance, the standardized sample mean approaches a standard normal distribution as the sample size increases.</p></li>
<li><p><strong>The CLT applies regardless of population shape</strong>, but the sample size needed depends on how far the population distribution deviates from normality.</p></li>
<li><p><strong>The commonly cited n ≥ 30 rule</strong> is not universally applicable and can be misleading. The required sample size depends entirely on the population distribution.</p></li>
<li><p><strong>When the CLT applies</strong>, we can use the normal distribution to compute probabilities, construct confidence intervals, and perform hypothesis tests.</p></li>
<li><p><strong>The CLT explains why the sample mean</strong> is such a widely used statistic—its sampling distribution becomes approximately normal even when the population isn’t.</p></li>
<li><p><strong>For the sample mean</strong> from an approximately normal sampling distribution: μₓ̄ = μ and σₓ̄ = σ/√n.</p></li>
<li><p><strong>The CLT also applies to sums and weighted averages</strong>, which becomes important in regression analysis and other advanced statistical methods.</p></li>
<li><p><strong>The CLT bridges the gap</strong> between probability theory and statistical inference by allowing us to understand how sample statistics behave across repeated sampling.</p></li>
</ol>
</div>
<p>The Central Limit Theorem represents one of the most powerful and remarkable results in statistics.
It allows us to use the normal distribution as a foundation for statistical inference across a wide
range of real-world situations, even when the underlying population distributions are unknown or non-normal.
By understanding the conditions under which the CLT applies and how to assess its applicability in specific contexts,
you gain a critical tool for making valid statistical inferences from sample data.</p>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>CLT Application</strong>: A population follows a uniform distribution between 0 and 100. For samples of size n = 36:</p>
<ol class="loweralpha simple">
<li><p>What are the mean and standard deviation of the sampling distribution of X̄?</p></li>
<li><p>Approximately what distribution does the sample mean follow?</p></li>
<li><p>Calculate P(X̄ &gt; 55)</p></li>
</ol>
</li>
<li><p><strong>Sample Size Requirements</strong>: For each of the following population distributions, estimate the minimum sample size likely needed for the CLT to provide a reasonable approximation:</p>
<ol class="loweralpha simple">
<li><p>A symmetric bimodal distribution</p></li>
<li><p>A moderately right-skewed distribution</p></li>
<li><p>A heavily right-skewed distribution</p></li>
<li><p>A slightly left-skewed distribution</p></li>
</ol>
</li>
<li><p><strong>Rat Maze Problem Extended</strong>: In the maze navigation example (μ = 10, σ = 3, slightly right-skewed):</p>
<ol class="loweralpha simple">
<li><p>If we use 25 rats instead of 60, would the CLT still provide a reasonable approximation? Explain.</p></li>
<li><p>Calculate P(9.5 &lt; X̄ &lt; 10.5) using the CLT with n = 25</p></li>
<li><p>How large should the sample size be to ensure that P(<a href="#id2"><span class="problematic" id="id3">|X̄ - μ|</span></a> &lt; 0.5) &gt; 0.95?</p></li>
</ol>
</li>
<li><p><strong>Comparing Distributions</strong>: A quality control engineer tests two methods for measuring impurities in a chemical compound. Method A yields measurements that are approximately normal, while Method B yields measurements that are right-skewed. Both methods have population means of 15 ppm and standard deviations of 3 ppm.</p>
<ol class="loweralpha simple">
<li><p>If samples of size n = 4 are taken, which method’s sample mean will have a sampling distribution closer to normal? Explain.</p></li>
<li><p>If samples of size n = 64 are taken instead, how would your answer to part (a) change?</p></li>
<li><p>For Method B with n = 16, is the sampling distribution of X̄ likely to be approximately normal? Why or why not?</p></li>
</ol>
</li>
<li><p><strong>Practical Implications</strong>: Explain why the CLT is so important for statistical inference. What practical problems would we face if the CLT didn’t exist?</p></li>
<li><p><strong>Simulation Exercise</strong>: Describe how you would design a simulation to demonstrate the CLT for an exponential distribution with rate parameter λ = 0.5. What sample sizes would you investigate, and what would you expect to observe?</p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="7-2-sampling-distribution-for-the-sample-mean.html" class="btn btn-neutral float-left" title="7.2. Sampling Distribution for the Sample Mean" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="7-4-discret-rvs-and-clt.html" class="btn btn-neutral float-right" title="7.4. Discrete Random Variables and the CLT" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>