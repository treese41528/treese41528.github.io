.. _5-2-joint-pmfs:

.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch5-2">
     <iframe
       id="video-ch5-2"
       title="STAT 350 ‚Äì Chapter 5.2 Joint Probability Mass Function Video"
       src="https://www.youtube.com/embed/eJa8C_Yg0dg?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
       allowfullscreen>
     </iframe>
   </div>

.. admonition:: Slides üìä
   :class: tip
   
   `Download Chapter 5 slides (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/
   slides/Chapter%205%20Discrete%20Distributions/L9-11-RandomVariables%20DiscreteProbabilityDistributions%28Chapter%205%29_AC.pptx>`_


Joint Probability Mass Functions
================================================

Many real-world scenarios involve multiple random quantities that interact with each other. 
To analyze such situations, we need to understand how random variables behave together. 
Joint probability mass functions provide the mathematical
foundation for analyzing multiple discrete random variables simultaneously.

.. admonition:: Road Map üß≠
   :class: important

   - Define **joint probability mass functions** for multiple discrete random variables.
   - Explore **tabular and functional representations** of joint PMFs.
   - Understand how to derive **marginal distributions** from joint distributions.
   - Identify when random variables are **independent** based on their joint PMF.

Joint Probability Mass Functions
--------------------------------------------

When dealing with a single discrete random variable, we used a probability mass 
function (PMF) to specify the probabilities associated with each possible value. 
We now extend this concept to multiple random variables.

Definition
~~~~~~~~~~~~~

The **joint probability mass function (joint PMF)** for two discrete random variables 
:math:`X` and :math:`Y` is denoted by :math:`p_{X,Y}`, and it gives the probability that 
:math:`X` equals some value :math:`x` **and** 
:math:`Y`  equals some value :math:`y` simultaneously:

.. math::

   p_{X,Y}(x,y) = P(\{X = x\} \cap \{Y = y\}).

Concisely, we also write :math:`p_{X,Y}(x,y) = P(X=x, Y=y).`

This definition extends naturally to more than two random variables. For example, 
the joint PMF for three random variables :math:`X`, :math:`Y`, and :math:`Z` would be 
denoted as :math:`p_{X,Y,Z}(x,y,z)`.

Support
~~~~~~~~

The **support** of a joint PMF is the set of all pairs :math:`(x,y)` for which the 
PMF assigns a positive probability:

.. math::

   \text{supp}(X,Y) = \{(x,y) \mid p_{X,Y}(x,y) > 0\}.


Representations of Joint PMFs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Joint probability mass functions can be represented in several ways.

**Tabular Form**  

For two discrete random variables with finite supports, we can represent 
the joint PMF as a table. Each cell contains the probability that 
:math:`X` equals the row value and :math:`Y` equals the column value.

.. admonition:: Exampleüí°: Joint PMF Table
  :class: note 

  Consider rolling a fair four-sided die and a fair six-sided die which are
  indepedent. Let :math:`X` represent the outcome of the four-sided die and :math:`Y` represent 
  the outcome of the six-sided die.

  .. flat-table:: 
    :header-rows: 2
    :width: 80%
    :align: center

    * - :cspan:`6` Joint PMF :math:`p_{X,Y}(x,y)` for the fair 4-sided and 6-sided dice

    * - :math:`x \backslash y`
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
    * - 1
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
    * - 2
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
    * - 3
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
    * - 4
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`


  Since the dice are fair and independent, each combination has the 
  same probability: :math:`1/24` (there are :math:`4 \times 6 = 24` possible outcomes).


**Functional Form**  

For certain pairs of random variables, it is possible to express their
joint PMF as a mathematical formula involving :math:`x` and :math:`y.`

.. admonition:: Exampleüí°: Joint PMF in functional form
  :class: note 

  For the dice example, we can express the joint PMF concisely as:

  .. math::

    p_{X,Y}(x,y) = \frac{1}{24}

  for :math:`x \in \{1, 2, 3, 4\}` and :math:`y \in \{1, 2, 3, 4, 5, 6\}.`

Validity of a Joint PMF
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Like single-variable PMFs, joint PMFs must satisfy the follwing two axioms.

1. **Non-negativity**
   
   For all values of :math:`x` and :math:`y`, :math:`0 \leq p_{X,Y}(x,y) \leq 1.`

2. **Total probability of 1**

   The sum of all probabilities in the joint PMF must equal 1:

.. math::

   \sum_{(x,y) \in \text{supp}(X,Y)} p_{X,Y}(x,y) = 1.



Marginal Distributions
-------------------------

Marginal PMF
~~~~~~~~~~~~~~

A **marginal PMF** is the individual probability mass function 
of a random variable that forms a joint PMF with others.

Deriving Marginal PMFs from a Joint PMF
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

One of the most important operations we can perform with a joint PMF is deriving 
marginal PMFs for individual random variables.

To find the marginal PMF :math:`p_X(x)`, we sum the joint PMF for each fixed value
:math:`x` over all possible values of :math:`Y`:

.. math::

   p_X(x) = \sum_{y: p_Y(y) > 0} p_{X,Y}(x,y)

Similarly, to find the marginal PMF :math:`p_Y(y)`, we sum the joint PMF for each fixed 
value :math:`y` over all possible values of :math:`X`:

.. math::

   p_Y(y) = \sum_{x: p_X(x) > 0} p_{X,Y}(x,y)

In tabular form, the marginal PMF values are computed as row-wise or column-wise sums 
of the joint PMF and are
often recorded in the *margins* of the table--hence the name *marginal* PMF.

.. admonition:: Marginal PMFs and the Law of Partitions
  :class: important 

  Deriving a marginal PMF is a direct application of
  the Law of Partitions. In the case of :math:`p_X(x)`, 
  we treat the support of :math:`Y` as a partition of the sample space
  and sum the probabilities of small sections of :math:`\{X=x\}` created by
  its overlap with different events in the partition.

  .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter5/marginal-partitions.png
     :align: center
     :figwidth: 50%
     :alt: marginal PMF derivation explained through the Law of Partitions

     Marginal PMF explained through the Law of Partitions


.. admonition:: Exampleüí°: Calculating marginal PMFs from a Joint PMF
  :class: note 

  Let's calculate the marginal distributions for the independent fair dice example.

  .. flat-table:: 
    :header-rows: 2
    :width: 90%
    :align: center

    * - :cspan:`7` Marginal PMFs from the Joint PMF of for the fair 4-sided and 6-sided dice

    * - :math:`x \backslash y`
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
      - :math:`p_X(x)`

    * - **1**
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{6}{24}=\tfrac14`
    * - **2**
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{6}{24}=\tfrac14`
    * - **3**
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{6}{24}=\tfrac14`
    * - **4**
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{1}{24}`
      - :math:`\tfrac{6}{24}=\tfrac14`
    * - :math:`p_Y(y)`
      - :math:`\tfrac{4}{24} =\tfrac16`
      - :math:`\tfrac{4}{24} =\tfrac16`
      - :math:`\tfrac{4}{24} =\tfrac16`
      - :math:`\tfrac{4}{24} =\tfrac16`
      - :math:`\tfrac{4}{24} =\tfrac16`
      - :math:`\tfrac{4}{24} =\tfrac16`
      -


Independence of Random Variables
------------------------------------

Definition
~~~~~~~~~~~~~

Two discrete random variables :math:`X` and :math:`Y` are **independent** if and only if 
their joint PMF factors as the product of their marginal PMFs for all values in the support.
Mathematically, they are independent if and only if

.. math::

   p_{X,Y}(x,y) = p_X(x) p_Y(y) \text{ for all } (x,y) \in \text{supp}(X,Y).

What Does It Mean?
~~~~~~~~~~~~~~~~~~~~~

Independence of random variables :math:`X` and :math:`Y` means that knowing the value of 
one provides no information about the value of the other. 

With respect to the previously learned concept of independence of two **events**, 
this means that *any* event
written in terms of :math:`X` is independent of *any* event expressed in terms of :math:`Y`.

.. admonition:: Exampleüí°: Independence of Two Dice Shown Mathematically
  :class: note 

  In our dice example, :math:`X` and :math:`Y` are independent because

  .. math::

    p_{X,Y}(x,y) = \frac{1}{24} = \frac{1}{4} \times \frac{1}{6} = p_X(x) p_Y(y)

  for **all values** of :math:`x` and :math:`y` in the support.

.. admonition:: Be cautious üõë
   :class: danger 

   Independence is an important property that often simplifies probability calculations. 
   However, its convenient properties should only be used when 
   the idependence of :math:`X` and :math:`Y` is provided or
   shown mathematically.

.. admonition:: Exampleüí°: When the Dice Constrain Each Other
  :class: note 

  So far we have relied on independence to keep our calculations simple.  
  But real-world mechanisms often *couple* random quantities, 
  forcing their outcomes to move together. 

  Two ordinary **six-sided dice** are altered so that any roll whose 
  **sum is less than 3 or greater than 9 is physically impossible**.  
  
  Let :math:`X` represent the outcome of the first die and :math:`Y` the outcome of the second die.
  The rule :math:`3 \le X+Y \le 9` prunes the sample space, but
  among the *allowed* pairs, every combination is still equally likely.
  The table below shows the pruned outcomes as ‚ùå as well as the
  probabilities of the possible pairs. Since there are 29 unpruned entries in the table,
  each possible pair :math:`(x,y)` gets :math:`p_{X,Y} (x,y)= 1/29.` 
  
  .. flat-table:: 
    :header-rows: 2
    :width: 90%
    :align: center

    * - :cspan:`7` Joint and marginal PMFs of two dice constraining each other

    * - :math:`x \backslash y`
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
      - :math:`p_X(x)`

    * - **1**
      - ‚ùå
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{5}{29}`
    * - **2**
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{6}{29}`
    * - **3**
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{6}{29}`
    * - **4**
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - ‚ùå
      - :math:`\tfrac{5}{29}`
    * - **5**
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - ‚ùå
      - ‚ùå
      - :math:`\tfrac{4}{29}`
    * - **6**
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - :math:`\tfrac{1}{29}`
      - ‚ùå
      - ‚ùå
      - ‚ùå
      - :math:`\tfrac{3}{29}`
    * - :math:`p_Y(y)`
      - :math:`\tfrac{5}{29}`
      - :math:`\tfrac{6}{29}`
      - :math:`\tfrac{6}{29}`
      - :math:`\tfrac{5}{29}`
      - :math:`\tfrac{4}{29}`
      - :math:`\tfrac{3}{29}`
      -

  Both dice are now biased toward lower numbers‚Äîa direct result of our sum constraint.
  
  Let us now **prove or disprove the independence** of :math:`X` and :math:`Y`. 
  If we suspect dependence, it suffices to show that
  the equation :math:`p_{X,Y}(x,y) = p_X(x)p_Y(y)` fails for any single pair.
  Pick the pair :math:`(x=6,\; y=1)`:

  .. math::

    p_{X,Y}(6,1) \;=\; \frac{1}{29}
    \quad\text{but}\quad
    p_X(6)\,p_Y(1)
      \;=\;
      \frac{3}{29} \times \frac{5}{29}
      \;=\;
      \frac{15}{29^{2}}
      \;\neq\;
      \frac{1}{29}.

  Since the requirement for independence is :math:`p_{X,Y}(x,y) = p_X(x)p_Y(y)` for *all* possible
  pairs, :math:`X` and :math:`Y` has already failed the criterion. Therefore, they are dependent.

A joint distribution can encode constraints (a bounded sum in the previous example) that never appear in the marginals alone.  
Whenever the joint PMF doesn't factor, dependence is at play.

Bringing It All Together
---------------------------

.. admonition:: Key Takeaways üìù
  :class: important
  
  1. A **joint probability mass function** specifies the probability of two or more discrete random 
     variables taking on specific values simultaneously.
   
  2. Joint PMFs must satisfy the basic probability axioms: non-negativity and summing to 1 over the entire support.
   
  3. **Marginal distributions** can be derived from a joint PMF by summing over all possible values of the other variable(s).
   
  4. Random variables are **independent** if and only if their joint PMF equals the product of their marginal PMFs for all values in the support.
   
  5. When random variables are **dependent**, their joint distribution contains important information about how they relate to 
     each other that isn't captured by their marginal distributions alone.


Exercises
---------

These exercises develop your skills in working with joint probability mass functions, deriving marginal distributions, and testing for independence of random variables.

.. admonition:: Exercise 1: Extracting Marginal PMFs from a Joint PMF
   :class: note

   A software company tracks two metrics for their mobile app: :math:`X` = number of crashes per user session (0, 1, or 2) and :math:`Y` = user satisfaction rating (1 = low, 2 = medium, 3 = high). Based on data from 1000 sessions, they constructed the following joint PMF:

   .. flat-table:: Joint PMF for App Performance
      :header-rows: 2
      :widths: 20 20 20 20 20

      * - :cspan:`4` Joint PMF :math:`p_{X,Y}(x,y)`
      * - :math:`x \backslash y`
        - 1 (Low)
        - 2 (Med)
        - 3 (High)
        - :math:`p_X(x)`
      * - 0
        - 0.05
        - 0.15
        - 0.40
        - 
      * - 1
        - 0.10
        - 0.12
        - 0.08
        - 
      * - 2
        - 0.06
        - 0.03
        - 0.01
        - 
      * - :math:`p_Y(y)`
        - 
        - 
        - 
        - 

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch5-2/fig1_joint_pmf_heatmap.png
      :alt: Heatmap showing joint PMF of app crashes vs user satisfaction
      :align: center
      :width: 80%

      Heatmap visualization of the joint PMF

   a. Complete the table by finding the marginal PMFs :math:`p_X(x)` and :math:`p_Y(y)`.

   b. Verify that both marginal PMFs are valid.

   c. What is the probability that a session has no crashes?

   d. What is the probability that a user gives a high satisfaction rating?

   e. What is the most likely combination of (crashes, rating)?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Marginal PMFs**

      *Marginal PMF for X* (sum across each row):

      - :math:`p_X(0) = 0.05 + 0.15 + 0.40 = 0.60`
      - :math:`p_X(1) = 0.10 + 0.12 + 0.08 = 0.30`
      - :math:`p_X(2) = 0.06 + 0.03 + 0.01 = 0.10`

      *Marginal PMF for Y* (sum down each column):

      - :math:`p_Y(1) = 0.05 + 0.10 + 0.06 = 0.21`
      - :math:`p_Y(2) = 0.15 + 0.12 + 0.03 = 0.30`
      - :math:`p_Y(3) = 0.40 + 0.08 + 0.01 = 0.49`

      **Completed Table:**

      .. flat-table::
         :header-rows: 2
         :widths: 20 20 20 20 20

         * - :cspan:`4` Joint PMF :math:`p_{X,Y}(x,y)`
         * - :math:`x \backslash y`
           - 1 (Low)
           - 2 (Med)
           - 3 (High)
           - :math:`p_X(x)`
         * - 0
           - 0.05
           - 0.15
           - 0.40
           - **0.60**
         * - 1
           - 0.10
           - 0.12
           - 0.08
           - **0.30**
         * - 2
           - 0.06
           - 0.03
           - 0.01
           - **0.10**
         * - :math:`p_Y(y)`
           - **0.21**
           - **0.30**
           - **0.49**
           - **1.00**

      **Part (b): Validity Check**

      For :math:`p_X(x)`:
      
      - Non-negativity: All values (0.60, 0.30, 0.10) are between 0 and 1 ‚úì
      - Sum: :math:`0.60 + 0.30 + 0.10 = 1.00` ‚úì

      For :math:`p_Y(y)`:
      
      - Non-negativity: All values (0.21, 0.30, 0.49) are between 0 and 1 ‚úì
      - Sum: :math:`0.21 + 0.30 + 0.49 = 1.00` ‚úì

      **Part (c): P(no crashes)**

      :math:`P(X = 0) = p_X(0) = 0.60`

      **Part (d): P(high rating)**

      :math:`P(Y = 3) = p_Y(3) = 0.49`

      **Part (e): Most likely combination**

      The cell with the highest probability is :math:`p_{X,Y}(0, 3) = 0.40`.

      The most likely combination is **(0 crashes, high satisfaction)**.

----

.. admonition:: Exercise 2: Validating a Joint PMF
   :class: note

   A network engineer proposes the following joint PMF for two random variables: :math:`X` = number of packet errors and :math:`Y` = network congestion level.

   .. flat-table:: Proposed Joint PMF
      :header-rows: 2
      :widths: 25 25 25 25

      * - :cspan:`3` Joint PMF :math:`p_{X,Y}(x,y)`
      * - :math:`x \backslash y`
        - 0 (Low)
        - 1 (Med)
        - 2 (High)
      * - 0
        - 0.25
        - 0.15
        - 0.05
      * - 1
        - 0.10
        - 0.20
        - 0.10
      * - 2
        - 0.02
        - 0.08
        - 0.10

   a. Verify whether this is a valid joint PMF.

   b. If valid, find the marginal PMFs :math:`p_X(x)` and :math:`p_Y(y)`.

   c. Calculate :math:`P(X \leq 1)`.

   d. Calculate :math:`P(X + Y \leq 2)`.

   e. Calculate :math:`P(X = Y)`.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Validity Check**

      1. **Non-negativity**: All entries are between 0 and 1 ‚úì

      2. **Sum to 1**: 
      
         .. math::

            \sum_{x,y} p_{X,Y}(x,y) = 0.25 + 0.15 + 0.05 + 0.10 + 0.20 + 0.10 + 0.02 + 0.08 + 0.10 = 1.05

         Sum = 1.05 ‚â† 1 ‚úó

      **This is NOT a valid joint PMF** ‚Äî the probabilities sum to more than 1.

      **Parts (b)-(e)**: Since this is not a valid PMF, we cannot meaningfully compute marginal distributions or probabilities. The table would need to be adjusted (e.g., by normalizing) before being used.

      **Note**: In practice, if this arose from data, it might indicate rounding errors. To fix it, we could divide each entry by 1.05 to normalize.

----

.. admonition:: Exercise 3: Testing Independence
   :class: note

   A quality control process inspects circuit boards on two criteria: :math:`X` = number of soldering defects (0 or 1) and :math:`Y` = number of component misalignments (0 or 1). The joint PMF is:

   .. flat-table:: Joint PMF for Circuit Board Defects
      :header-rows: 2
      :widths: 25 25 25 25

      * - :cspan:`3` Joint PMF :math:`p_{X,Y}(x,y)`
      * - :math:`x \backslash y`
        - 0
        - 1
        - :math:`p_X(x)`
      * - 0
        - 0.70
        - 0.10
        - 
      * - 1
        - 0.05
        - 0.15
        - 
      * - :math:`p_Y(y)`
        - 
        - 
        - 

   a. Find the marginal PMFs :math:`p_X(x)` and :math:`p_Y(y)`.

   b. Determine whether :math:`X` and :math:`Y` are independent. Show your work.

   c. Calculate :math:`P(X = 1 | Y = 1)`.

   d. Compare :math:`P(X = 1 | Y = 1)` with :math:`P(X = 1)`. What does this tell you about the relationship between soldering defects and misalignments?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Marginal PMFs**

      *Marginal for X:*
      
      - :math:`p_X(0) = 0.70 + 0.10 = 0.80`
      - :math:`p_X(1) = 0.05 + 0.15 = 0.20`

      *Marginal for Y:*
      
      - :math:`p_Y(0) = 0.70 + 0.05 = 0.75`
      - :math:`p_Y(1) = 0.10 + 0.15 = 0.25`

      **Part (b): Independence Test**

      For independence, we need :math:`p_{X,Y}(x,y) = p_X(x) \cdot p_Y(y)` for ALL (x,y).

      Check each cell:

      - :math:`p_{X,Y}(0,0) = 0.70` vs :math:`p_X(0) \cdot p_Y(0) = 0.80 \times 0.75 = 0.60` ‚Üí **NOT EQUAL**

      Since the condition fails for (0,0), we can stop here.

      **X and Y are NOT independent.**

      .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch5-2/fig2_independence_comparison.png
         :alt: Side-by-side comparison of actual joint PMF vs expected under independence
         :align: center
         :width: 90%

         Visual comparison: Actual joint PMF (left) vs. what it would be if X and Y were independent (right)

      Verification of other cells (for completeness):
      
      - :math:`p_{X,Y}(0,1) = 0.10` vs :math:`0.80 \times 0.25 = 0.20` ‚úó
      - :math:`p_{X,Y}(1,0) = 0.05` vs :math:`0.20 \times 0.75 = 0.15` ‚úó
      - :math:`p_{X,Y}(1,1) = 0.15` vs :math:`0.20 \times 0.25 = 0.05` ‚úó

      **Part (c): Conditional Probability**

      .. math::

         P(X = 1 | Y = 1) = \frac{P(X = 1, Y = 1)}{P(Y = 1)} = \frac{0.15}{0.25} = 0.60

      **Part (d): Interpretation**

      - :math:`P(X = 1 | Y = 1) = 0.60`
      - :math:`P(X = 1) = 0.20`

      When there's a misalignment (Y = 1), the probability of a soldering defect jumps from 20% to 60%. This strong increase suggests that **the two types of defects are positively associated** ‚Äî boards with one type of defect are more likely to have the other.

      This could indicate a common cause (e.g., a malfunctioning machine causing both problems) or that one defect makes the other more likely.

----

.. admonition:: Exercise 4: Constructing a Joint PMF
   :class: note

   A data center monitors two servers. Let :math:`X` = number of Server A failures in a day (0 or 1) and :math:`Y` = number of Server B failures in a day (0 or 1). Historical data shows:

   - Server A fails on 10% of days
   - Server B fails on 15% of days
   - The servers fail independently of each other

   a. Use independence to construct the joint PMF :math:`p_{X,Y}(x,y)`.

   b. What is the probability that at least one server fails on a given day?

   c. What is the probability that exactly one server fails?

   d. Given that at least one server failed, what is the probability that both failed?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Construct Joint PMF Using Independence**

      Given:
      
      - :math:`P(X = 1) = 0.10`, so :math:`P(X = 0) = 0.90`
      - :math:`P(Y = 1) = 0.15`, so :math:`P(Y = 0) = 0.85`

      Since X and Y are independent: :math:`p_{X,Y}(x,y) = p_X(x) \cdot p_Y(y)`

      .. math::

         p_{X,Y}(0,0) = 0.90 \times 0.85 = 0.765

      .. math::

         p_{X,Y}(0,1) = 0.90 \times 0.15 = 0.135

      .. math::

         p_{X,Y}(1,0) = 0.10 \times 0.85 = 0.085

      .. math::

         p_{X,Y}(1,1) = 0.10 \times 0.15 = 0.015

      **Joint PMF Table:**

      .. flat-table::
         :header-rows: 2
         :widths: 25 25 25 25

         * - :cspan:`3` Joint PMF :math:`p_{X,Y}(x,y)`
         * - :math:`x \backslash y`
           - 0
           - 1
           - :math:`p_X(x)`
         * - 0
           - 0.765
           - 0.135
           - 0.90
         * - 1
           - 0.085
           - 0.015
           - 0.10
         * - :math:`p_Y(y)`
           - 0.85
           - 0.15
           - 1.00

      **Part (b): P(at least one fails)**

      "At least one fails" = NOT(both work) = :math:`1 - P(X=0, Y=0)`

      .. math::

         P(X \geq 1 \text{ or } Y \geq 1) = 1 - p_{X,Y}(0,0) = 1 - 0.765 = 0.235

      **Part (c): P(exactly one fails)**

      "Exactly one" = (A fails, B works) OR (A works, B fails)

      .. math::

         P(\text{exactly one}) = p_{X,Y}(1,0) + p_{X,Y}(0,1) = 0.085 + 0.135 = 0.220

      **Part (d): P(both failed | at least one failed)**

      .. math::

         P(X=1, Y=1 | X \geq 1 \text{ or } Y \geq 1) = \frac{P(X=1, Y=1)}{P(\text{at least one})} = \frac{0.015}{0.235} \approx 0.0638

      Given that at least one server failed, there's about a 6.4% chance both failed.

----

.. admonition:: Exercise 5: Joint PMF with Constraints
   :class: note

   A manufacturing process produces items that are inspected for defects. Let :math:`X` = number of surface defects and :math:`Y` = number of internal defects. Due to the inspection process, the total number of detected defects :math:`X + Y` is always at most 3.

   The joint PMF is given by:

   .. math::

      p_{X,Y}(x,y) = \frac{c}{(x+y+1)} \quad \text{for } x, y \in \{0, 1, 2\} \text{ and } x + y \leq 3

   where :math:`c` is a normalizing constant.

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch5-2/fig3_constrained_support.png
      :alt: Joint PMF with constrained support showing X+Y <= 3
      :align: center
      :width: 70%

      The constraint X + Y ‚â§ 3 creates an irregular support (green = valid, gray = excluded)

   a. List all pairs (x, y) in the support of this joint PMF.

   b. Find the value of :math:`c` that makes this a valid PMF.

   c. Construct the joint PMF table.

   d. Find the marginal PMF :math:`p_X(x)`.

   e. Are X and Y independent? Justify your answer.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Support**

      We need :math:`x, y \in \{0, 1, 2\}` and :math:`x + y \leq 3`.

      Valid pairs:
      
      - x = 0: (0,0), (0,1), (0,2) ‚Äî all satisfy x + y ‚â§ 3
      - x = 1: (1,0), (1,1), (1,2) ‚Äî all satisfy x + y ‚â§ 3
      - x = 2: (2,0), (2,1) ‚Äî (2,2) would give x + y = 4 > 3, excluded

      **Support**: {(0,0), (0,1), (0,2), (1,0), (1,1), (1,2), (2,0), (2,1)}

      **Part (b): Finding c**

      Sum over all pairs in support:

      .. math::

         \sum_{(x,y)} \frac{c}{x+y+1} = c\left(\frac{1}{1} + \frac{1}{2} + \frac{1}{3} + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \frac{1}{3} + \frac{1}{4}\right)

      .. math::

         = c\left(1 + \frac{1}{2} + \frac{1}{2} + \frac{1}{3} + \frac{1}{3} + \frac{1}{3} + \frac{1}{4} + \frac{1}{4}\right)

      .. math::

         = c\left(1 + 1 + 1 + \frac{1}{2}\right) = c \times \frac{7}{2} = \frac{7c}{2}

      For validity: :math:`\frac{7c}{2} = 1 \implies c = \frac{2}{7}`

      **Part (c): Joint PMF Table**

      Using :math:`p_{X,Y}(x,y) = \frac{2}{7(x+y+1)}`:

      .. flat-table::
         :header-rows: 2
         :widths: 20 20 20 20 20

         * - :cspan:`4` Joint PMF :math:`p_{X,Y}(x,y)`
         * - :math:`x \backslash y`
           - 0
           - 1
           - 2
           - :math:`p_X(x)`
         * - 0
           - :math:`\frac{2}{7}`
           - :math:`\frac{1}{7}`
           - :math:`\frac{2}{21}`
           - :math:`\frac{11}{21}`
         * - 1
           - :math:`\frac{1}{7}`
           - :math:`\frac{2}{21}`
           - :math:`\frac{1}{14}`
           - :math:`\frac{13}{42}`
         * - 2
           - :math:`\frac{2}{21}`
           - :math:`\frac{1}{14}`
           - ‚Äî
           - :math:`\frac{7}{42} = \frac{1}{6}`
         * - :math:`p_Y(y)`
           - :math:`\frac{11}{21}`
           - :math:`\frac{13}{42}`
           - :math:`\frac{1}{6}`
           - 1

      **Part (d): Marginal PMF for X**

      - :math:`p_X(0) = \frac{2}{7} + \frac{1}{7} + \frac{2}{21} = \frac{6}{21} + \frac{3}{21} + \frac{2}{21} = \frac{11}{21}`
      - :math:`p_X(1) = \frac{1}{7} + \frac{2}{21} + \frac{1}{14} = \frac{6}{42} + \frac{4}{42} + \frac{3}{42} = \frac{13}{42}` 
      - :math:`p_X(2) = \frac{2}{21} + \frac{1}{14} = \frac{4}{42} + \frac{3}{42} = \frac{7}{42} = \frac{1}{6}`

      Check: :math:`\frac{11}{21} + \frac{13}{42} + \frac{1}{6} = \frac{22}{42} + \frac{13}{42} + \frac{7}{42} = \frac{42}{42} = 1` ‚úì

      **Part (e): Independence Test**

      Check if :math:`p_{X,Y}(0,0) = p_X(0) \cdot p_Y(0)`:

      - :math:`p_{X,Y}(0,0) = \frac{2}{7}`
      - :math:`p_X(0) \cdot p_Y(0) = \frac{11}{21} \times \frac{11}{21} = \frac{121}{441}`

      Convert :math:`\frac{2}{7} = \frac{126}{441}`

      Since :math:`\frac{126}{441} \neq \frac{121}{441}`, **X and Y are NOT independent**.

      The constraint :math:`x + y \leq 3` creates dependence ‚Äî knowing X limits the possible values of Y.

----

.. admonition:: Exercise 6: Working with a Given Joint PMF
   :class: note

   Two sensors monitor temperature (X) and humidity (Y) in a data center, where both are discretized into levels 1, 2, or 3. The joint PMF is:

   .. flat-table:: Joint PMF for Sensor Readings
      :header-rows: 2
      :widths: 20 20 20 20 20

      * - :cspan:`4` Joint PMF :math:`p_{X,Y}(x,y)`
      * - :math:`x \backslash y`
        - 1
        - 2
        - 3
        - :math:`p_X(x)`
      * - 1
        - 0.15
        - 0.10
        - 0.05
        - 0.30
      * - 2
        - 0.10
        - 0.25
        - 0.10
        - 0.45
      * - 3
        - 0.05
        - 0.10
        - 0.10
        - 0.25
      * - :math:`p_Y(y)`
        - 0.30
        - 0.45
        - 0.25
        - 1.00

   a. Calculate :math:`P(X \leq 2, Y \leq 2)`.

   b. Calculate :math:`P(X = Y)`.

   c. Calculate :math:`P(X < Y)`.

   d. Calculate :math:`P(Y = 2 | X = 2)`.

   e. Calculate :math:`P(X \geq 2 | Y \leq 2)`.

   f. Are X and Y independent?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): P(X ‚â§ 2, Y ‚â§ 2)**

      Sum all cells where x ‚â§ 2 AND y ‚â§ 2:

      .. math::

         P(X \leq 2, Y \leq 2) = p_{X,Y}(1,1) + p_{X,Y}(1,2) + p_{X,Y}(2,1) + p_{X,Y}(2,2)

      .. math::

         = 0.15 + 0.10 + 0.10 + 0.25 = 0.60

      **Part (b): P(X = Y)**

      Sum diagonal cells where x = y:

      .. math::

         P(X = Y) = p_{X,Y}(1,1) + p_{X,Y}(2,2) + p_{X,Y}(3,3)

      .. math::

         = 0.15 + 0.25 + 0.10 = 0.50

      **Part (c): P(X < Y)**

      Sum cells where x < y (below the diagonal):

      .. math::

         P(X < Y) = p_{X,Y}(1,2) + p_{X,Y}(1,3) + p_{X,Y}(2,3)

      .. math::

         = 0.10 + 0.05 + 0.10 = 0.25

      **Part (d): P(Y = 2 | X = 2)**

      .. math::

         P(Y = 2 | X = 2) = \frac{P(X = 2, Y = 2)}{P(X = 2)} = \frac{0.25}{0.45} = \frac{5}{9} \approx 0.556

      **Part (e): P(X ‚â• 2 | Y ‚â§ 2)**

      First, find :math:`P(X \geq 2, Y \leq 2)`:

      .. math::

         P(X \geq 2, Y \leq 2) = p_{X,Y}(2,1) + p_{X,Y}(2,2) + p_{X,Y}(3,1) + p_{X,Y}(3,2)

      .. math::

         = 0.10 + 0.25 + 0.05 + 0.10 = 0.50

      Then:

      .. math::

         P(Y \leq 2) = p_Y(1) + p_Y(2) = 0.30 + 0.45 = 0.75

      .. math::

         P(X \geq 2 | Y \leq 2) = \frac{P(X \geq 2, Y \leq 2)}{P(Y \leq 2)} = \frac{0.50}{0.75} = \frac{2}{3} \approx 0.667

      **Part (f): Independence Test**

      Check one cell: :math:`p_{X,Y}(1,1) = 0.15`

      :math:`p_X(1) \cdot p_Y(1) = 0.30 \times 0.30 = 0.09`

      Since :math:`0.15 \neq 0.09`, **X and Y are NOT independent**.

----

Additional Practice Problems
----------------------------

**True/False Questions** (1 point each)

1. A joint PMF :math:`p_{X,Y}(x,y)` gives the probability that X equals x OR Y equals y.

   ‚ìâ or ‚íª

2. The marginal PMF :math:`p_X(x)` is found by summing the joint PMF over all values of Y.

   ‚ìâ or ‚íª

3. If X and Y are independent, then :math:`p_{X,Y}(x,y) = p_X(x) + p_Y(y)`.

   ‚ìâ or ‚íª

4. All entries in a valid joint PMF must be non-negative.

   ‚ìâ or ‚íª

5. If :math:`p_{X,Y}(1,2) = p_X(1) \cdot p_Y(2)`, then X and Y are independent.

   ‚ìâ or ‚íª

6. The sum of all entries in a joint PMF table must equal 1.

   ‚ìâ or ‚íª

**Multiple Choice Questions** (2 points each)

7. Given the joint PMF below, what is :math:`p_X(1)`?

   .. flat-table::
      :header-rows: 1
      :widths: 25 25 25 25

      * - :math:`x \backslash y`
        - 0
        - 1
        - 2
      * - 0
        - 0.1
        - 0.2
        - 0.1
      * - 1
        - 0.15
        - 0.25
        - 0.2

   ‚í∂ 0.25
   
   ‚í∑ 0.45
   
   ‚í∏ 0.60
   
   ‚íπ 0.40

8. Using the joint PMF from Question 7, what is :math:`P(X = Y)`?

   ‚í∂ 0.10
   
   ‚í∑ 0.35
   
   ‚í∏ 0.45
   
   ‚íπ 0.55

9. If X and Y are independent with :math:`P(X = 0) = 0.6` and :math:`P(Y = 1) = 0.3`, what is :math:`P(X = 0, Y = 1)`?

   ‚í∂ 0.90
   
   ‚í∑ 0.30
   
   ‚í∏ 0.18
   
   ‚íπ 0.50

10. Which of the following is necessary for X and Y to be independent?

    ‚í∂ :math:`p_{X,Y}(x,y) = p_X(x) \cdot p_Y(y)` for at least one pair (x,y)
    
    ‚í∑ :math:`p_{X,Y}(x,y) = p_X(x) \cdot p_Y(y)` for all pairs (x,y) in the support
    
    ‚í∏ :math:`p_{X,Y}(x,y) = p_X(x) + p_Y(y)` for all pairs (x,y)
    
    ‚íπ :math:`P(X = Y) = 0`

.. dropdown:: Answers to Practice Problems
   :class-container: sd-border-success

   **True/False Answers:**

   1. **False** ‚Äî A joint PMF gives the probability that X equals x **AND** Y equals y simultaneously, not OR.

   2. **True** ‚Äî By definition, :math:`p_X(x) = \sum_y p_{X,Y}(x,y)`. This is summing over all possible values of Y for each fixed x.

   3. **False** ‚Äî If independent, :math:`p_{X,Y}(x,y) = p_X(x) \cdot p_Y(y)` (product, not sum).

   4. **True** ‚Äî Non-negativity is one of the two axioms for a valid joint PMF: :math:`0 \leq p_{X,Y}(x,y) \leq 1` for all (x,y).

   5. **False** ‚Äî Independence requires the product formula to hold for **ALL** pairs (x,y) in the support, not just one pair.

   6. **True** ‚Äî The second axiom for validity: :math:`\sum_{(x,y)} p_{X,Y}(x,y) = 1`.

   **Multiple Choice Answers:**

   7. **‚í∏** ‚Äî :math:`p_X(1) = 0.15 + 0.25 + 0.20 = 0.60` (sum of row where x = 1).

   8. **‚í∑** ‚Äî :math:`P(X = Y)` = :math:`p_{X,Y}(0,0) + p_{X,Y}(1,1) = 0.10 + 0.25 = 0.35`. Note: (0,0) is in the support; there's no (2,2) entry for x.

   9. **‚í∏** ‚Äî By independence: :math:`P(X = 0, Y = 1) = P(X = 0) \cdot P(Y = 1) = 0.6 \times 0.3 = 0.18`.

   10. **‚í∑** ‚Äî Independence requires the product formula to hold for **all** pairs in the support, not just some.