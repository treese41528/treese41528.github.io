.. _5-7-poisson-distribution:


.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch5-7">
     <iframe
       id="video-ch5-7"
       title="STAT 350 ‚Äì Chapter 5.7 The Poisson Distribution Video"
       src="https://www.youtube.com/embed/L9flxu2RCEc?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
       allowfullscreen>
     </iframe>
   </div>

.. admonition:: Slides üìä
   :class: tip
   
   `Download Chapter 5 slides (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/
   slides/Chapter%205%20Discrete%20Distributions/L9-11-RandomVariables%20DiscreteProbabilityDistributions%28Chapter%205%29_AC.pptx>`_
   
The Poisson Distribution
======================================

While the binomial distribution helps us count successes in a fixed number of trials, 
many real-world situations involve counting rare events that occur randomly over time or space. 
Think about counting phone calls to a help desk during an hour, defects in a length of computer tape, 
or radioactive particles emitted by a radioactive substance. These scenarios share a structure that 
leads us to another fundamental distribution in statistics: the Poisson distribution.

.. admonition:: Road Map üß≠
   :class: important

   ‚Ä¢ Identify situations where the **Poisson distribution** applies.
   ‚Ä¢ Master the **Poisson probability mass function** and its single parameter :math:`\lambda`.
   ‚Ä¢ Derive the Poisson **expected value and variance** using infinite series techniques.
   ‚Ä¢ Understand how the **interval length affects the parameter** :math:`\lambda`.

From Counting Events to Modeling Rates
--------------------------------------------

The Poisson distribution emerges when we count events that occur randomly over continuous 
intervals of time, space, or volume. Unlike a binomial experiment which involves a fixed 
number of trials, the number of events in a Poisson process is theoretically unlimited.

What Makes a Process Poisson?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A Poisson process has three essential properties:

**1. Stationary and Proportional**

* The probability that an event occurs in any interval depends only on the length of 
  that interval, not on where the interval occurs (**stationarity**). 
* Equal-sized intervals have the same probability distribution, and longer intervals have 
  **proportionally** higher probabilities of containing events.

For example, suppose we're counting phone calls to a help desk that has a constant call rate. The probability of 
receiving exactly one call should be the same whether we look at 9-10 AM or 2-3 PM. 
Furthermore, if we expect 3 calls per hour on average, we should expect 6 calls per two-hour period.

**2. Independent Events**

Individual events occur independently of each other. The occurrence of one event 
doesn't influence when the next event will happen. Additionally, the number of 
events in non-overlapping intervals are independent of each other.

In our phone call example, receiving three calls between 9-10 AM doesn't affect 
the number of calls received between 10-11 AM.

**3.Orderliness (no bunching)**

Events cannot occur simultaneously. In sufficiently small intervals,
the chance of two or more events occurring is negligible. Events effectively arrive **one at a time**.

Examples of Poisson Distributions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Several real-world scenarios approximately follow the rules of Poisson processes:

- **Radioactive decay**: The number of alpha particles emitted from uranium-238 in one minute
- **Call centers**: The number of calls received during busy hours on any given day
- **Quality control**: The number of flaws on a computer tape of fixed length
- **Ecology**: The number of dead trees in a square mile of forest
- **Traffic**: The number of accidents at an intersection per month

The Poisson Distribution
------------------------------------------------------

When events follow a Poisson process, we model the count of 
events using a Poisson distribution.

Definition
~~~~~~~~~~~~~~

A Poisson random variable :math:`X` counts the number of independently occurring 
events in a fixed interval, where events occur at some **average rate** :math:`\lambda` (lambda)
**per interval**.

When :math:`X` has a Poisson distribution, we write :math:`X \sim \text{Poisson}(\lambda)`.

Probability Mass Function
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The Poisson PMF gives the probability of observing exactly :math:`x` events:

.. math::

   p_X(x) = \frac{e^{-\lambda} \lambda^x}{x!}

for :math:`x \in \text{supp}(X) = \{0, 1, 2, 3, ...\}`.

Notice several key features of this distribution:

- **Single parameter**: Unlike the binomial distribution which has two parameters 
  (:math:`n` and :math:`p`), Poisson has only one parameter :math:`\lambda`.
- **Unbounded support**: A Poisson random variable can theoretically take any 
  non-negative integer value, unlike binomial whose support is bounded above by :math:`n`.

Expected Value and Variance: The Power of :math:`\lambda`
------------------------------------------------------------

One of the most elegant features of the Poisson distribution is that its parameter :math:`\lambda` 
completely determines both the center and spread of the distribution.

Expected Value
~~~~~~~~~~~~~~~~~~

To find :math:`E[X]` for a Poisson random variable, we use the definition of expected value:

.. math::

   E[X] = \sum_{x=0}^{\infty} x \cdot p_X(x) = \sum_{x=0}^{\infty} x \cdot \frac{e^{-\lambda} \lambda^x}{x!}

Since the first term equals zero with :math:`x = 0`, the summation effectively begins at :math:`x = 1`. 
Then in each term, we can cancel :math:`x` with the :math:`x` contained in :math:`x!` of the denominator.
Since :math:`e^\lambda` does not depend on :math:`x`, we can bring this outside the summation:

.. math::

   E[X] = \sum_{x=1}^{\infty} x \cdot \frac{e^{-\lambda} \lambda^x}{x!} = e^{-\lambda} \sum_{x=1}^{\infty} \frac{\lambda^x}{(x-1)!}

Substituting :math:`u = x - 1`, we get:

.. math::

   E[X] = e^{-\lambda} \lambda \sum_{u=0}^{\infty} \frac{\lambda^u}{u!}

The sum is the Taylor series for :math:`e^Œª`. Therefore:

.. math::

   E[X] = e^{-\lambda} \lambda \cdot e^{\lambda} = \lambda

Variance
~~~~~~~~~~~

For the variance, we use :math:`\text{Var}(X) = E[X^2] - (E[X])^2`. We already know :math:`E[X] = \lambda`, and
we need :math:`E[X^2]`:

.. math::

   E[X^2] = \sum_{x=0}^{\infty} x^2 \cdot \frac{e^{-\lambda} \lambda^x}{x!}

Through similar algebraic manipulation (starting at :math:`x = 1`, canceling factorials, and using substitutions), we can show:

.. math::

   E[X^2] = \lambda^2 + \lambda

Therefore:

.. math::

   \text{Var}(X) = E[X^2] - (E[X])^2 = (\lambda^2 + \lambda) - \lambda^2 = \lambda

Summary of Poisson Distribution Properties
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For :math:`X \sim Poisson(\lambda)`:

.. math::

   &\mu_X = E[X] = \lambda \\
   &\sigma_X^2 = \text{Var}(X) = \lambda \\
   &\sigma_X = \sqrt{\lambda}

The summary reveals a remarkable property of Poisson distribution; 
knowing :math:`\lambda` tells us everything about the distribution's location and spread.

Visualizing Poisson Distributions
----------------------------------

**Small** :math:`\lambda \, (\lambda=1)` 

When events are rare, most probability concentrates at 0 and 1, with a long right tail. 
The distribution is highly right-skewed.

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter5/lambda1.png
   :alt: Poisson distributions with Œª=1
   :align: center
   :width: 80%

   :math:`\lambda=1`

**Moderate** :math:`\lambda \, (\lambda=2.5)` 

As :math:`\lambda` increases, the mode shifts right and the distribution becomes less skewed. 
More probability spreads across multiple values.

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter5/lambda2.5.png
   :alt: Poisson distributions with Œª=2.5
   :align: center
   :width: 80%

   :math:`\lambda=2.5`

**Large** :math:`\lambda \, (\lambda=10)` 

For larger :math:`\lambda` values, the distribution approaches a symmetric, bell-shaped curve 
centered around :math:`\lambda`. The resemblance to a normal distribution becomes quite strong.

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter5/lambda10.png
   :alt: Poisson distributions with different Œª=10
   :align: center
   :width: 80%

   :math:`\lambda=10`

.. admonition:: Exampleüí°: IT Consultant Call Analysis
   :class: note

   An IT consultant receives **an average of 3 calls per hour**. We want to model 
   the number of calls using a Poisson distribution and answer several probability questions.

   **Setting Up the Model**

   Let :math:`X` count number of calls the consultant receives in the next hour.

   - **Stationary and Proportional**: Call rate is constant over time. ‚úì
   - **Independent**: One call doesn't influence when the next occurs. ‚úì  
   - **Orderliness**: Calls don't occur simultaneously. ‚úì

   Therefore: :math:`X \sim \text{Poisson}(\lambda = 3)`.

   **Solving Probability Problems**

   #. Find the probability of exactly one call.

      .. math::

         P(X = 1) = \frac{e^{-3} \cdot 3^1}{1!} = \frac{3e^{-3}}{1} ‚âà 0.1494


   #. Find the probability of more than one call.
      Using the complement rule:

      .. math::

         P(X > 1) = 1 - [P(X = 0) + P(X = 1)] = 1 - [e^{-3} + 3e^{-3}] ‚âà 0.8009

   #. Find the probability of exactly 5 calls in the next 
      **two hours**.

      Since the rate is 3 calls per hour, over two hours we expect 2 √ó 3 = 6 calls on average.
      Let :math:`Y` count the number of calls in the next two hours.
      Then :math:`Y \sim \text{Poisson}(\lambda = 6)`.

      .. math::

         P(Y = 5) = \frac{e^{-6} \cdot 6^5}{5!} ‚âà 0.1606

   #. Find the probability of 1 call in the next hour and 4 calls
      in the following hour.

      Let :math:`X_1` count the calls in the first hour and :math:`X_2`
      the calls in the second hour. Both have an average rate of 3,
      and since the two intervals are non-overlapping, :math:`X_1` and :math:`X_2` are
      **indepdendent**. This allows us to **use the special multiplication rule**:

      .. math::

         P(X_1=1 \cap X_2=4) &= P(X_1=1)P(X_2=4)\\
         &=(0.8009)\left(\frac{e^{-3}3^4}{4!}\right) \\
         &= (0.8009)(0.1680) \approx 0.1346

When to Use Poisson vs. Binomial
-----------------------------------------------

Understanding when to use Poisson versus binomial distributions is crucial for proper 
statistical modeling.

**Use Poisson When:**

- Counting events over continuous intervals (time, space, volume).
- Events are rare relative to opportunity.
- The number of potential events is very large or unlimited.
- You know the average rate but not the total number of trials.

**Use Binomial When:**

- The number of independent trials is fixed.
- Each trial has exactly two outcomes.
- Probability of success is constant across trials.
- You're counting successes among a known number of attempts.

**Poisson as Binomial Approximation**

Interestingly, Poisson can approximate binomial when :math:`n` is large and :math:`p` is small,
with :math:`np \approx \lambda`. This connection highlights how these distributions relate to different 
aspects of the same underlying counting process.

Bringing It All Together
---------------------------

The Poisson distribution serves as a fundamental model for understanding random processes in fields ranging 
from telecommunications and quality control to epidemiology and reliability engineering. 
As we've seen, the key to successful application lies in recognizing when events satisfy the Poisson 
assumptions and correctly interpreting the rate parameter :math:`Œª` in context.

.. admonition:: Key Takeaways üìù
   :class: important

   1. The **Poisson distribution** models counts of rare events occurring over fixed intervals of time, space, or volume.
   
   2. **Three key properties** that define Poisson processes are
      stationarity and proportional rates, independence of events, and unique event occurrences.
   
   3. The **PMF formula** :math:`p_X(x) = \frac{e^{-\lambda}\lambda^x}{x!}` applies to any 
      non-negative interger :math:`x`.

   4. The **single parameter** :math:`\lambda` represents both the mean and variance: :math:`E[X] = \text{Var}(X) = Œª`.
   
   5. The **shape of a Poisson distribution** evolves from highly right-skewed 
      to approximately symmetric as :math:`\lambda` becomes larger.


..
   Working with Poisson Distributions in R
   ----------------------------------------

   R provides comprehensive functions for working with Poisson distributions, following the same naming convention as other distributions.

   **The Four Essential R Functions**

   - **rpois()**: Generates random samples from a Poisson distribution
   - **dpois()**: Calculates the probability mass function (exact probabilities)  
   - **ppois()**: Calculates the cumulative distribution function (cumulative probabilities)
   - **qpois()**: Finds quantiles (the inverse of ppois)

   **Generating Random Samples with rpois()**

   .. code-block:: r

      # Generate 10 random values from Poisson(Œª = 3)
      # Each value represents count of events in one interval
      set.seed(123)
      random_counts <- rpois(n = 10, lambda = 3)
      print(random_counts)
      # Output: 1 4 5 3 1 1 4 5 4 2
      
      # Generate 1000 samples to see the distribution pattern
      large_sample <- rpois(n = 1000, lambda = 3)
      
      # Check that sample mean approximates theoretical mean
      sample_mean <- mean(large_sample)
      sample_var <- var(large_sample)
      theoretical_mean <- 3  # Œª = 3
      theoretical_var <- 3   # Œª = 3
      
      print(paste("Sample mean:", round(sample_mean, 2)))
      print(paste("Theoretical mean:", theoretical_mean))
      print(paste("Sample variance:", round(sample_var, 2)))
      print(paste("Theoretical variance:", theoretical_var))

   **Calculating Exact Probabilities with dpois()**

   .. code-block:: r

      # Calculate P(X = 2) when X ~ Poisson(Œª = 3)
      prob_exactly_2 <- dpois(x = 2, lambda = 3)
      print(paste("P(X = 2) =", round(prob_exactly_2, 4)))
      
      # Calculate probabilities for multiple values
      x_values <- 0:10
      probabilities <- dpois(x = x_values, lambda = 3)
      
      # Create a probability table
      prob_table <- data.frame(
      x = x_values,
      probability = round(probabilities, 4)
      )
      print(prob_table)
      
      # Verify probabilities sum close to 1 (they won't equal exactly 1 
      # because we're truncating the infinite support)
      total_prob <- sum(dpois(x = 0:20, lambda = 3))
      print(paste("Total probability (x = 0 to 20):", round(total_prob, 6)))

   **Calculating Cumulative Probabilities with ppois()**

   .. code-block:: r

      # Calculate P(X ‚â§ 5) when X ~ Poisson(Œª = 3)
      prob_at_most_5 <- ppois(q = 5, lambda = 3)
      print(paste("P(X ‚â§ 5) =", round(prob_at_most_5, 4)))
      
      # Calculate P(X > 5) = 1 - P(X ‚â§ 5)
      prob_more_than_5 <- 1 - ppois(q = 5, lambda = 3)
      # Alternative: use lower.tail = FALSE
      prob_more_than_5_alt <- ppois(q = 5, lambda = 3, lower.tail = FALSE)
      print(paste("P(X > 5) =", round(prob_more_than_5, 4)))
      
      # Calculate P(2 ‚â§ X ‚â§ 6) = P(X ‚â§ 6) - P(X ‚â§ 1)
      prob_between <- ppois(q = 6, lambda = 3) - ppois(q = 1, lambda = 3)
      print(paste("P(2 ‚â§ X ‚â§ 6) =", round(prob_between, 4)))

   .. code-block:: r

      # Method 1: Using complement rule with dpois
      prob_zero <- dpois(x = 0, lambda = 3)
      prob_one <- dpois(x = 1, lambda = 3)
      prob_more_than_one <- 1 - (prob_zero + prob_one)
      print(paste("P(X > 1) =", round(prob_more_than_one, 4)))
      
      # Method 2: Using ppois with lower.tail = FALSE
      prob_more_than_one_alt <- ppois(q = 1, lambda = 3, lower.tail = FALSE)
      print(paste("P(X > 1) using ppois =", round(prob_more_than_one_alt, 4)))
      
      # Method 3: Direct calculation
      prob_at_most_one <- ppois(q = 1, lambda = 3)
      prob_more_than_one_direct <- 1 - prob_at_most_one
      print(paste("P(X > 1) direct =", round(prob_more_than_one_direct, 4)))

      .. code-block:: r

   # New parameter for 2-hour interval
   lambda_2hours <- 2 * 3  # 2 hours √ó 3 calls/hour
   
   # Calculate P(Y = 5) for the 2-hour interval
   prob_five_calls_2hrs <- dpois(x = 5, lambda = lambda_2hours)
   print(paste("P(5 calls in 2 hours) =", round(prob_five_calls_2hrs, 4)))
   
   # Expected values for comparison
   print(paste("Expected calls in 1 hour:", 3))
   print(paste("Expected calls in 2 hours:", lambda_2hours))
   print(paste("Standard deviation in 1 hour:", round(sqrt(3), 3)))
   print(paste("Standard deviation in 2 hours:", round(sqrt(lambda_2hours), 3)))

   **Comprehensive Analysis with Visualization**

   .. code-block:: r

   # Create comprehensive analysis
   
   # 1-hour analysis
   lambda_1hr <- 3
   x_1hr <- 0:12
   probs_1hr <- dpois(x_1hr, lambda = lambda_1hr)
   
   # 2-hour analysis  
   lambda_2hr <- 6
   x_2hr <- 0:18
   probs_2hr <- dpois(x_2hr, lambda = lambda_2hr)
   
   par(mfrow = c(1, 1))
   
   # Summary statistics
   cat("\nSummary Statistics:\n")
   cat("1-hour interval: Mean =", lambda_1hr, ", SD =", round(sqrt(lambda_1hr), 3), "\n")
   cat("2-hour interval: Mean =", lambda_2hr, ", SD =", round(sqrt(lambda_2hr), 3), "\n")
   cat("P(exactly 1 call in 1 hour) =", round(dpois(1, lambda_1hr), 4), "\n")
   cat("P(exactly 5 calls in 2 hours) =", round(dpois(5, lambda_2hr), 4), "\n")
   cat("P(more than 3 calls in 1 hour) =", round(1 - ppois(3, lambda_1hr), 4), "\n")


   .. code-block:: r

      # Calculate P(X = 1) when Œª = 3
      prob_one_call <- dpois(x = 1, lambda = 3)
      print(paste("P(X = 1) =", round(prob_one_call, 4)))
      
      # Manual calculation for verification
      manual_calc <- exp(-3) * 3^1 / factorial(1)
      print(paste("Manual calculation =", round(manual_calc, 4)))


Exercises
---------

These exercises develop your skills in identifying Poisson processes, calculating Poisson probabilities, scaling the rate parameter for different intervals, and comparing Poisson to binomial distributions.

.. admonition:: Exercise 1: Identifying Poisson Processes
   :class: note

   For each scenario, determine whether a Poisson distribution is appropriate. If yes, identify the rate parameter :math:`\lambda` and the interval. If no, explain which Poisson assumption is violated.

   a. A network router experiences an average of 5 packet errors per hour. Let :math:`X` = number of packet errors in the next hour.

   b. A professor receives an average of 12 student emails per day. However, emails tend to cluster right before exams. Let :math:`X` = number of emails on a random day.

   c. Cars pass through a toll booth at an average rate of 20 per minute during rush hour. Let :math:`X` = number of cars in the next minute.

   d. A website receives an average of 100 visitors per hour. The site goes viral at noon, tripling traffic. Let :math:`X` = number of visitors between 11 AM and 1 PM.

   e. Typos occur in a manuscript at an average rate of 2.5 per page. Let :math:`X` = number of typos on a randomly selected page.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Packet errors ‚Äî YES, Poisson**

      - **Stationary**: Error rate is constant over time ‚úì
      - **Independent**: Errors occur independently ‚úì
      - **Orderly**: Errors happen one at a time ‚úì

      :math:`X \sim \text{Poisson}(\lambda = 5)` where the interval is 1 hour.

      **Part (b): Student emails ‚Äî NO, not Poisson**

      - **Stationary**: ‚ùå The rate is NOT constant ‚Äî emails cluster before exams.

      The non-constant rate violates stationarity. The Poisson model assumes the same average rate regardless of when we observe.

      **Part (c): Cars at toll booth ‚Äî YES, Poisson**

      - **Stationary**: Rate is constant during rush hour ‚úì
      - **Independent**: Car arrivals are independent ‚úì
      - **Orderly**: Cars pass one at a time ‚úì

      :math:`X \sim \text{Poisson}(\lambda = 20)` where the interval is 1 minute.

      **Part (d): Website visitors ‚Äî NO, not Poisson**

      - **Stationary**: ‚ùå The rate CHANGES at noon (triples).

      Since the rate isn't constant over the 2-hour interval, Poisson doesn't apply. You could model each hour separately with different Œª values.

      **Part (e): Typos per page ‚Äî YES, Poisson**

      - **Stationary**: Typo rate is constant per unit of text ‚úì
      - **Independent**: Typos occur independently ‚úì
      - **Orderly**: Typos happen at distinct locations ‚úì

      :math:`X \sim \text{Poisson}(\lambda = 2.5)` where the interval is 1 page.

----

.. admonition:: Exercise 2: Basic Poisson Probability Calculations
   :class: note

   A help desk receives an average of 4 support tickets per hour during business hours.

   Let :math:`X` = number of tickets received in the next hour.

   a. Write the distribution of :math:`X`.

   b. Calculate :math:`P(X = 3)`, the probability of exactly 3 tickets.

   c. Calculate :math:`P(X = 0)`, the probability of no tickets.

   d. Calculate :math:`P(X \leq 2)`, the probability of at most 2 tickets.

   e. Calculate :math:`P(X > 5)`, the probability of more than 5 tickets.

   f. Find :math:`E[X]`, :math:`\text{Var}(X)`, and :math:`\sigma_X`.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Distribution**

      :math:`X \sim \text{Poisson}(\lambda = 4)`

      **Part (b): P(X = 3)**

      .. math::

         P(X = 3) = \frac{e^{-4} \cdot 4^3}{3!} = \frac{e^{-4} \cdot 64}{6} = \frac{64 \cdot 0.0183}{6} = 0.1954

      **Part (c): P(X = 0)**

      .. math::

         P(X = 0) = \frac{e^{-4} \cdot 4^0}{0!} = e^{-4} = 0.0183

      **Part (d): P(X ‚â§ 2)**

      .. math::

         P(X \leq 2) = P(X=0) + P(X=1) + P(X=2)

      .. math::

         P(X = 1) = \frac{e^{-4} \cdot 4^1}{1!} = 4e^{-4} = 0.0733

      .. math::

         P(X = 2) = \frac{e^{-4} \cdot 4^2}{2!} = \frac{16e^{-4}}{2} = 8e^{-4} = 0.1465

      .. math::

         P(X \leq 2) = 0.0183 + 0.0733 + 0.1465 = 0.2381

      **Part (e): P(X > 5)**

      Using complement: :math:`P(X > 5) = 1 - P(X \leq 5)`

      .. math::

         P(X = 3) = 0.1954, \quad P(X = 4) = \frac{e^{-4} \cdot 4^4}{4!} = \frac{256e^{-4}}{24} = 0.1954

      .. math::

         P(X = 5) = \frac{e^{-4} \cdot 4^5}{5!} = \frac{1024e^{-4}}{120} = 0.1563

      .. math::

         P(X \leq 5) = 0.0183 + 0.0733 + 0.1465 + 0.1954 + 0.1954 + 0.1563 = 0.7852

      .. math::

         P(X > 5) = 1 - 0.7852 = 0.2148

      **Part (f): E[X], Var(X), œÉ_X**

      For Poisson, :math:`E[X] = \text{Var}(X) = \lambda`:

      .. math::

         E[X] = 4, \quad \text{Var}(X) = 4, \quad \sigma_X = \sqrt{4} = 2

----

.. admonition:: Exercise 3: Scaling the Rate Parameter
   :class: note

   A server logs an average of 6 security alerts per day (24 hours).

   a. What is the average rate of alerts per hour?

   b. Let :math:`X` = number of alerts in a 4-hour period. Find :math:`E[X]` and the distribution of :math:`X`.

   c. Calculate :math:`P(X = 0)` for the 4-hour period.

   d. Let :math:`Y` = number of alerts in a full week (7 days). Find :math:`E[Y]` and :math:`\sigma_Y`.

   e. A system administrator gets concerned if there are more than 2 alerts per hour. For a randomly selected hour, what is the probability of triggering concern?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Rate per hour**

      .. math::

         \lambda_{\text{hour}} = \frac{6 \text{ alerts}}{24 \text{ hours}} = 0.25 \text{ alerts per hour}

      **Part (b): 4-hour period**

      Scale the rate: :math:`\lambda_{4\text{hr}} = 4 \times 0.25 = 1`

      .. math::

         X \sim \text{Poisson}(\lambda = 1), \quad E[X] = 1

      **Part (c): P(X = 0) for 4-hour period**

      .. math::

         P(X = 0) = \frac{e^{-1} \cdot 1^0}{0!} = e^{-1} = 0.3679

      There's about a **36.8%** chance of no alerts in any 4-hour window.

      **Part (d): Full week**

      Scale the rate: :math:`\lambda_{\text{week}} = 7 \times 6 = 42`

      .. math::

         Y \sim \text{Poisson}(\lambda = 42)

      .. math::

         E[Y] = 42, \quad \text{Var}(Y) = 42, \quad \sigma_Y = \sqrt{42} \approx 6.48

      **Part (e): P(more than 2 per hour)**

      For one hour: :math:`H \sim \text{Poisson}(\lambda = 0.25)`

      .. math::

         P(H > 2) = 1 - P(H \leq 2)

      .. math::

         P(H = 0) = e^{-0.25} = 0.7788

      .. math::

         P(H = 1) = 0.25 \cdot e^{-0.25} = 0.1947

      .. math::

         P(H = 2) = \frac{(0.25)^2 \cdot e^{-0.25}}{2} = \frac{0.0625 \cdot 0.7788}{2} = 0.0243

      .. math::

         P(H \leq 2) = 0.7788 + 0.1947 + 0.0243 = 0.9978

      .. math::

         P(H > 2) = 1 - 0.9978 = 0.0022

      There's only about a **0.22%** chance of triggering concern in any given hour.

----

.. admonition:: Exercise 4: Independent Intervals
   :class: note

   Customers arrive at a coffee shop at an average rate of 10 per hour.

   a. What is the probability of exactly 5 customers arriving between 9:00-9:30 AM?

   b. What is the probability of exactly 3 customers between 9:00-9:30 AM AND exactly 7 customers between 9:30-10:00 AM?

   c. If :math:`X_1` = customers in the first half hour and :math:`X_2` = customers in the second half hour, explain why :math:`X_1` and :math:`X_2` are independent.

   d. Verify: :math:`P(X_1 + X_2 = 10)` using the distribution of the total.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): P(5 customers in 30 min)**

      Rate for 30 minutes: :math:`\lambda = 10 \times 0.5 = 5`

      Let :math:`X_1 \sim \text{Poisson}(5)`:

      .. math::

         P(X_1 = 5) = \frac{e^{-5} \cdot 5^5}{5!} = \frac{3125 \cdot e^{-5}}{120} = \frac{3125 \cdot 0.00674}{120} = 0.1755

      **Part (b): P(3 in first half hour AND 7 in second half hour)**

      Both :math:`X_1` and :math:`X_2` have :math:`\lambda = 5`.

      Since the intervals don't overlap, :math:`X_1` and :math:`X_2` are **independent**.

      Using the multiplication rule:

      .. math::

         P(X_1 = 3 \cap X_2 = 7) = P(X_1 = 3) \cdot P(X_2 = 7)

      .. math::

         P(X_1 = 3) = \frac{e^{-5} \cdot 5^3}{3!} = \frac{125 \cdot e^{-5}}{6} = 0.1404

      .. math::

         P(X_2 = 7) = \frac{e^{-5} \cdot 5^7}{7!} = \frac{78125 \cdot e^{-5}}{5040} = 0.1044

      .. math::

         P(X_1 = 3 \cap X_2 = 7) = 0.1404 \times 0.1044 = 0.0147

      **Part (c): Why independent?**

      By the Poisson process property, the number of events in **non-overlapping intervals** are independent. Since 9:00-9:30 and 9:30-10:00 don't overlap, :math:`X_1` and :math:`X_2` are independent random variables.

      **Part (d): Verify P(X‚ÇÅ + X‚ÇÇ = 10)**

      The sum of independent Poisson RVs is also Poisson:

      .. math::

         X_1 + X_2 \sim \text{Poisson}(\lambda_1 + \lambda_2) = \text{Poisson}(10)

      .. math::

         P(X_1 + X_2 = 10) = \frac{e^{-10} \cdot 10^{10}}{10!}

      .. math::

         = \frac{10^{10} \cdot e^{-10}}{3628800} = \frac{10000000000 \cdot 0.0000454}{3628800} = 0.1251

----

.. admonition:: Exercise 5: Poisson Mean and Variance
   :class: note

   Earthquakes of magnitude 4.0 or greater occur in a region at an average rate of 2 per month.

   a. What is the expected number of such earthquakes in a year?

   b. What is the standard deviation of the number of earthquakes per year?

   c. Using the empirical rule approximation (since Œª = 24 is fairly large), about 95% of years should have earthquake counts in what range?

   d. A seismologist observes 35 earthquakes in one year. How many standard deviations is this from the expected value?

   e. Based on your answer to (d), would 35 earthquakes be considered unusual?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Expected per year**

      .. math::

         E[X] = \lambda_{\text{year}} = 12 \times 2 = 24 \text{ earthquakes}

      **Part (b): Standard deviation per year**

      For Poisson: :math:`\text{Var}(X) = \lambda`, so:

      .. math::

         \sigma_X = \sqrt{24} \approx 4.90

      **Part (c): 95% range using empirical rule**

      For large Œª, Poisson is approximately normal. Using :math:`\mu \pm 2\sigma`:

      .. math::

         24 \pm 2(4.90) = 24 \pm 9.80

      About 95% of years should have between **14.2 and 33.8 earthquakes**, or roughly **14 to 34 earthquakes** (rounding to integers).

      **Part (d): How many SDs is 35?**

      .. math::

         z = \frac{x - \mu}{\sigma} = \frac{35 - 24}{4.90} = \frac{11}{4.90} \approx 2.24

      35 earthquakes is about **2.24 standard deviations** above the mean.

      **Part (e): Is 35 unusual?**

      Using the empirical rule, values beyond 2 standard deviations are somewhat unusual (roughly 5% of the time). At 2.24 SDs, this is on the edge of what we'd consider unusual.

      More precisely, for large Poisson (approximately normal), about 2.5% of values exceed Œº + 2œÉ ‚âà 33.8, so 35 earthquakes, while higher than typical, is not extremely rare ‚Äî it would occur in roughly **1-2.5%** of years.

----

.. admonition:: Exercise 6: Two Poisson Scenarios with Bayes' Rule
   :class: note

   A call center operates under two conditions:

   - **Condition A** (probability 0.6): Calls arrive at rate :math:`\lambda_A = 3` per hour
   - **Condition B** (probability 0.4): Calls arrive at rate :math:`\lambda_B = 8` per hour

   On any given hour, one condition applies (determined at random). Let :math:`X` = number of calls received.

   a. Find :math:`P(X = 5 \mid A)` and :math:`P(X = 5 \mid B)`.

   b. Use the Law of Total Probability to find :math:`P(X = 5)`.

   c. Use Bayes' Rule to find :math:`P(B \mid X = 5)`.

   d. Find :math:`P(X \geq 6 \mid A)` and :math:`P(X \geq 6 \mid B)`.

   e. Find :math:`P(B \mid X \geq 6)`. Interpret this result.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Conditional probabilities**

      .. math::

         P(X = 5 \mid A) = \frac{e^{-3} \cdot 3^5}{5!} = \frac{243 \cdot e^{-3}}{120} = 0.1008

      .. math::

         P(X = 5 \mid B) = \frac{e^{-8} \cdot 8^5}{5!} = \frac{32768 \cdot e^{-8}}{120} = 0.0916

      **Part (b): Law of Total Probability**

      .. math::

         P(X = 5) = P(X = 5 \mid A) \cdot P(A) + P(X = 5 \mid B) \cdot P(B)

      .. math::

         = (0.1008)(0.6) + (0.0916)(0.4) = 0.0605 + 0.0366 = 0.0971

      **Part (c): Bayes' Rule for P(B | X = 5)**

      .. math::

         P(B \mid X = 5) = \frac{P(X = 5 \mid B) \cdot P(B)}{P(X = 5)} = \frac{(0.0916)(0.4)}{0.0971} = \frac{0.0366}{0.0971} = 0.377

      **Part (d): P(X ‚â• 6) under each condition**

      For Condition A (:math:`\lambda = 3`):

      .. math::

         P(X \leq 5 \mid A) = \sum_{x=0}^{5} \frac{e^{-3} \cdot 3^x}{x!} = 0.9161

      .. math::

         P(X \geq 6 \mid A) = 1 - 0.9161 = 0.0839

      For Condition B (:math:`\lambda = 8`):

      .. math::

         P(X \leq 5 \mid B) = \sum_{x=0}^{5} \frac{e^{-8} \cdot 8^x}{x!} = 0.1912

      .. math::

         P(X \geq 6 \mid B) = 1 - 0.1912 = 0.8088

      **Part (e): Bayes' Rule for P(B | X ‚â• 6)**

      First, find :math:`P(X \geq 6)`:

      .. math::

         P(X \geq 6) = (0.0839)(0.6) + (0.8088)(0.4) = 0.0503 + 0.3235 = 0.3738

      Then apply Bayes' Rule:

      .. math::

         P(B \mid X \geq 6) = \frac{P(X \geq 6 \mid B) \cdot P(B)}{P(X \geq 6)} = \frac{(0.8088)(0.4)}{0.3738} = \frac{0.3235}{0.3738} = 0.865

      **Interpretation:** If we observe 6 or more calls, there's an **86.5%** chance we're in Condition B. The prior probability of B was only 40%, but observing high call volume strongly suggests the high-rate condition.

----

Additional Practice Problems
----------------------------

**True/False Questions** (1 point each)

1. For a Poisson distribution, :math:`E[X] = \text{Var}(X) = \lambda`.

   ‚ìâ or ‚íª

2. The Poisson distribution has a maximum possible value (like binomial's n).

   ‚ìâ or ‚íª

3. If events follow a Poisson process, events in non-overlapping intervals are independent.

   ‚ìâ or ‚íª

4. Doubling the observation interval doubles both the expected value AND the variance.

   ‚ìâ or ‚íª

5. Poisson distributions are always right-skewed regardless of Œª.

   ‚ìâ or ‚íª

6. The Poisson distribution can approximate the binomial when n is large and p is small.

   ‚ìâ or ‚íª

**Multiple Choice Questions** (2 points each)

7. If :math:`X \sim \text{Poisson}(3)`, what is :math:`P(X = 0)`?

   ‚í∂ 0
   
   ‚í∑ :math:`e^{-3}`
   
   ‚í∏ :math:`3e^{-3}`
   
   ‚íπ 0.5

8. If :math:`X \sim \text{Poisson}(5)`, what is :math:`\sigma_X`?

   ‚í∂ 5
   
   ‚í∑ :math:`\sqrt{5}`
   
   ‚í∏ 25
   
   ‚íπ 2.5

9. A store averages 8 customers per hour. What is Œª for a 15-minute interval?

   ‚í∂ 2
   
   ‚í∑ 4
   
   ‚í∏ 8
   
   ‚íπ 32

10. Which is NOT a requirement for a Poisson process?

    ‚í∂ Events occur independently
    
    ‚í∑ Events occur at a constant average rate
    
    ‚í∏ Events occur one at a time
    
    ‚íπ The number of trials is fixed in advance

.. dropdown:: Answers to Practice Problems
   :class-container: sd-border-success

   **True/False Answers:**

   1. **True** ‚Äî This is the defining property of Poisson: the single parameter Œª equals both the mean and variance.

   2. **False** ‚Äî Poisson has unbounded support: X ‚àà {0, 1, 2, 3, ...}. Unlike binomial (max = n), there's no upper limit.

   3. **True** ‚Äî Independence of non-overlapping intervals is a key Poisson process property.

   4. **True** ‚Äî If Œª‚ÇÅ is the rate for time t, then Œª‚ÇÇ = 2Œª‚ÇÅ for time 2t. Both E[X] = Œª and Var(X) = Œª double.

   5. **False** ‚Äî For small Œª, Poisson is right-skewed. But as Œª increases (Œª > 10 or so), it becomes approximately symmetric.

   6. **True** ‚Äî When n is large and p is small with np ‚âà Œª, Bin(n, p) ‚âà Poisson(np).

   **Multiple Choice Answers:**

   7. **‚í∑** ‚Äî :math:`P(X=0) = \frac{e^{-3} \cdot 3^0}{0!} = e^{-3}`.

   8. **‚í∑** ‚Äî For Poisson, Var(X) = Œª = 5, so œÉ = ‚àö5.

   9. **‚í∂** ‚Äî 15 minutes = 0.25 hours, so Œª = 8 √ó 0.25 = 2.

   10. **‚íπ** ‚Äî Poisson counts events over a continuous interval; there's no "fixed number of trials." That's a binomial requirement. Options A, B, C are all Poisson requirements (independence, stationarity, orderliness).