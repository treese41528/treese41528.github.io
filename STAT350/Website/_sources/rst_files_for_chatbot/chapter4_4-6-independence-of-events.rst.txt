.. _4-6-independence-of-events:



.. raw:: html

   <div class="video-placeholder">
     <iframe src="https://www.youtube.com/embed/_3Ukdl7pGPE?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6" allowfullscreen>
     </iframe>
   </div>

.. admonition:: Slides ğŸ“Š
   :class: tip
 
   `Download Chapter 4 slides (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/
   stat-350-assets/slides/Chapter%204%20Probability/L6-8-Probability%20%28Chapter%204%29_AC.pptx>`_
   
Independence of Events
====================================

In the previous sections, we explored how knowledge about an event
influences the probabilities involving another event. But do events
always influence each other? The answer is no, and we say that such events
are **idnependent**. In this section, we'll dive deeper into the 
concept of independence.

.. admonition:: Road map ğŸ§­
   :class: important

   * Understand what it means for events to be **independent**.
   * Distinguish between independence and mutually exclusive events.
   * See how independence simplifies probability calculations.
   * Explore different types of independence: pairwise vs. mutual.
   * Connect independence to the concepts covered in previous chapters.

Independence
------------------------------

We say two events :math:`A` and :math:`B` are **independent** if the occurrence of one event does not affect 
the probability of the other. Formally, events :math:`A` and :math:`B` are independent if

.. math::

   P(A|B) = P(A)  \text{ and }  P(B|A) = P(B).

The first equation means that knowing :math:`B` occurs provides no additional information about :math:`A`.
Likewise, the second equation says that knowing :math:`A` occurs does not provide any update on
the probability of :math:`B`.

Since independence is a symmetric relationship between events, the two conditions are equivalentâ€”one implies the other. 

.. admonition:: Additional Equivalent Expressions
   :class: important

   Independence of :math:`A` and :math:`B` also implies the pairwise independence of 
   :math:`A'` and :math:`B`, :math:`A` and :math:`B'`, and :math:`A'` and :math:`B'`.

Special Multiplication Rule
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When two events are independent, the **general multiplication rule simplifies** to:

.. math::

   P(A \cap B) = P(A) P(B).

Why Is This True?
^^^^^^^^^^^^^^^^^^^^^

The **general multiplication rule** says that for **any** pair of events :math:`A` and :math:`B`,

.. math::

   P(A \cap B) = P(A|B) P(B).

Independence of :math:`A` and :math:`B` implies :math:`P(A|B) = P(A)`, which allows
us to replace :math:`P(A|B)` with :math:`P(A)` in the general addition rule.

.. admonition:: â€¼ï¸ Avoid the common mistake â€¼ï¸
   :class: danger

   This is a special-case rule which can only be used when 
   **the independence of A and B has been mathematically shown**.
   When unsure, always begin with the **general** version (Revisit Section 4.3).


Independence vs. Mutual Exclusitivity
---------------------------------------------

It's important to distinguish between independence and mutual exclusivity, as these concepts are 
often confused but are fundamentally different. Recall their definitions:

* **Mutually exclusive** (or disjoint) events cannot occur simultaneously. 
  Their intersection is empty.
* **Independent** events provide no information about each other. 
  Knowing that one occurs does not change the probability of the other.

These concepts are in fact **incompatible** in general. 
Let us see why through two events :math:`A` and :math:`B`. For generality, assume
that their probabilities are **both non-zero**.

1. **If** :math:`A` **and** :math:`B` **are mutually exclusive, then they cannot be independent**.
   
   If :math:`A` and :math:`B` are mutually exclusive, then :math:`P(A \cap B) = 0`. 
   Using the conditional probability formula,
   
   .. math::

      P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{0}{P(B)} = 0.

   But :math:`P(A) > 0`, so :math:`P(A|B) = 0 \neq P(A)`. This means :math:`A` and :math:`B` are not independent.

2. **If** :math:`A` **and** :math:`B` **independent, then they cannot be mutually exclusive**.

   If :math:`A` and :math:`B` are independent, then

   .. math::

      P(A \cap B) = P(A)P(B) > 0

   since both :math:`P(A)` and :math:`P(B)` are non-zero.
   This means that :math:`A` and :math:`B` have a non-empty intersection. In other words, they are not mutually exclusive.

Pairwise Independence vs. Mutual Independence
------------------------------------------------

When dealing with more than two events, we can define different levels of independence.

**Pairwise Independence**

A collection of events :math:`\{A_1, A_2, \cdots, A_n\}` is pairwise independent 
if all pairs of events are independent. 

For example, four events :math:`\{A_1, A_2, A_3, A_4\}` are pairwise independent if

.. math::

   P(A_1|A_2) = P(A_1) \quad &\text{and} \quad P(A_1 \cap A_2) = P(A_1)P(A_2)\\
   P(A_1|A_3) = P(A_1) \quad &\text{and} \quad P(A_1 \cap A_3) = P(A_1)P(A_3)\\
   & \vdots

for all pairs.

**Mutual Independence**

Mutual indepdendence of events is a stronger condition where the special multiplication rule holds 
for all combinations of events, not just pairs. For four events to be mutually independent, 
they must be pairwise independent and satisfy

.. math::

   P(A_1 \cap A_2 \cap A_3) &= P(A_1)P(A_2)P(A_3)\\
   P(A_1 \cap A_2 \cap A_4) &= P(A_1)P(A_2)P(A_4)\\
   &\vdots

for all triplets, and

.. math::

   P(A_1 \cap A_2 \cap A_3 \cap A_4) = P(A_1)P(A_2)P(A_3)P(A_4).

There exist cases where events are pairwise independent but not mutually independent.

.. admonition:: ExampleğŸ’¡: Circuit Reliability
   :class: note

   Consider two electrical systems with different circuit configurations.

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter4/circuits.png
      :alt: Diagram of two circuits
      :align: center
      :figwidth: 70%

      Diagram of two circuit systems

   * System 1: Four parallel paths (labeled 1, 2, 3, 4) connect points A and B.
   * System 2: Three paths (labeled 1, 2, 3) connect points A and B, but with more 
     complex connectivity.

   Each path contains **mutually independent** switches that are 
   each activated **with probability 0.3**. 
   The system functions if current can flow from point A to point B. 
   We want to calculate the probability that each system will function.

   **System 1**

   * Let :math:`L_i` denote the event that the :math:`i` th line is on, for each :math:`i=1,2,3,4`.
   * We are given that :math:`P(L_i)=0.3` for all :math:`i`. This also implies
     :math:`P(L_i')=0.7` for all :math:`i`.
   * Let :math:`F_1^+` denote the event that system 1 is functioning.

   For the system to function, at least one path must be on. In other words,
   Line 1 **or** Line 2 **or** Line 3 **or** Line 4 must be on. This gives:

   .. math::

      P(F_1^+) = P(L_1 \cup L_2 \cup L_3 \cup L_4)

   Using the complement rule and De Morgan's law:

   .. math::

      P(F_1^+) &= 1 - P((L_1 \cup L_2 \cup L_3 \cup L_4)')\\
      &= 1 - P(L_1' \cap L_2' \cap L_3' \cap L_4')

   Since the **lines operate independently**, we can use the **special** multiplication rule:

   .. math::

      P(F_1^+) &= 1 - P(l_1') P(l_2') P(l_3') P(l_4')\\
      &= 1 - (0.7)^4 = 1 - 0.2401 = 0.7599.

   **System 2**

   * Let :math:`L_i` now denote the event that the :math:`i` th line is on
     in the second system, for each :math:`i=1,2,3`.
   
   * Let :math:`F_2^+` denote the event that system 1 is functioning.

   The first steps are identical to the first system.

   .. math::

      P(F_2^+) &= P(L_1 \cup L_2 \cup L_3) = 1 - P((L_1 \cup L_2 \cup L_3)')\\
      &= 1 - P(L_1' \cap L_2' \cap L_3') = 1- P(L_1')P(L_2')P(L_2')

   Now we need to calculate the probability that each line is not functioning.

   * :math:`P(L_1') = 1 - P(\text{both switches are on}) = 1-(0.3)^2 = 0.91`
   * :math:`P(L_2') = 1 - 0.3 = 0.7`
   * :math:`P(L_3') = 1 - P(\text{all three switches are on}) = 1-(0.3)^3 = 0.973`

   Putting it all together,

   .. math::

      P(F_2^+) = 1 - (0.91 \times 0.7 \times 0.973) \approx 0.3802.

   The difference in reliability between the two systems (76% vs. 38%) highlights how parallel paths increase reliability compared to series connections.


Bringing It All Together
---------------------------

.. admonition:: Key Takeaways ğŸ“
   :class: important

   1. **Independence** means that knowing one event occurs doesn't change the probability 
      of another event.
   
   2. Independence allows us to use the **special multiplication rule**: :math:`P(A \cap B) = P(A) P(B)`.
   
   3. **Mutually exclusivity** and **independence** generally do not occur simultaneously.
   
   4. **Pairwise independence** means all pairs of events are independent, while
      **mutual independence** requires that all combinations of events follow the special 
      multiplication rule.
   
   5. Independence often leads to powerful simplifications in computation, 
      but its should use should always follow mathematical justification.


Exercises
---------

These exercises develop your understanding of independence, how to test for it mathematically, and how it simplifies probability calculations.

.. admonition:: Exercise 1: Testing for Independence
   :class: note

   A software company tracks bug reports by severity and by the day of the week they are submitted. Data from 500 bug reports shows:

   .. flat-table:: Bug Reports by Severity and Day
      :header-rows: 1
      :widths: 25 25 25 25

      * - 
        - Critical
        - Non-Critical
        - Total
      * - Weekday
        - 80
        - 320
        - 400
      * - Weekend
        - 20
        - 80
        - 100
      * - Total
        - 100
        - 400
        - 500

   Let :math:`C` = "bug is critical" and :math:`W` = "bug submitted on a weekday."

   a. Calculate :math:`P(C)`, :math:`P(W)`, and :math:`P(C \cap W)`.

   b. If C and W were independent, what would :math:`P(C \cap W)` equal?

   c. Are events C and W independent? Justify mathematically.

   d. Calculate :math:`P(C|W)` and :math:`P(C|W')`. What do these tell you about the relationship between bug severity and submission day?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Basic Probabilities**

      - :math:`P(C) = \frac{100}{500} = 0.20`
      - :math:`P(W) = \frac{400}{500} = 0.80`
      - :math:`P(C \cap W) = \frac{80}{500} = 0.16`

      **Part (b): If Independent**

      If C and W were independent:

      .. math::

         P(C \cap W) = P(C) \cdot P(W) = (0.20)(0.80) = 0.16

      **Part (c): Independence Test**

      Compare the actual :math:`P(C \cap W)` with the product :math:`P(C) \cdot P(W)`:

      - Actual: :math:`P(C \cap W) = 0.16`
      - If independent: :math:`P(C) \cdot P(W) = 0.16`

      Since :math:`P(C \cap W) = P(C) \cdot P(W)`, **yes, C and W are independent**.

      **Part (d): Conditional Probabilities**

      .. math::

         P(C|W) = \frac{P(C \cap W)}{P(W)} = \frac{80/500}{400/500} = \frac{80}{400} = 0.20

      .. math::

         P(C|W') = \frac{P(C \cap W')}{P(W')} = \frac{20/500}{100/500} = \frac{20}{100} = 0.20

      Both equal :math:`P(C) = 0.20`, confirming independence.

      **Interpretation**: The severity of bugs is unrelated to whether they're submitted on weekdays or weekends. Critical bugs make up 20% of reports regardless of when they're submitted.

----

.. admonition:: Exercise 2: Independence vs Mutual Exclusivity
   :class: note

   Consider rolling a fair six-sided die once. Define the following events:

   - :math:`A` = "roll is even" = {2, 4, 6}
   - :math:`B` = "roll is greater than 4" = {5, 6}
   - :math:`C` = "roll is less than 3" = {1, 2}

   For each pair of events below, determine whether they are:
   
   (i) mutually exclusive, and
   (ii) independent.
   
   Justify each answer mathematically.

   a. Events A and B

   b. Events A and C

   c. Events B and C

   .. dropdown:: Solution
      :class-container: sd-border-success

      First, calculate individual probabilities:

      - :math:`P(A) = 3/6 = 1/2`
      - :math:`P(B) = 2/6 = 1/3`
      - :math:`P(C) = 2/6 = 1/3`

      **Part (a): Events A and B**

      *Mutual Exclusivity:*

      :math:`A \cap B = \{6\} \neq \emptyset`

      **Not mutually exclusive** â€” rolling a 6 satisfies both events.

      *Independence:*

      - :math:`P(A \cap B) = 1/6`
      - :math:`P(A) \cdot P(B) = (1/2)(1/3) = 1/6`

      Since :math:`P(A \cap B) = P(A) \cdot P(B)`, **A and B are independent**.

      **Part (b): Events A and C**

      *Mutual Exclusivity:*

      :math:`A \cap C = \{2\} \neq \emptyset`

      **Not mutually exclusive** â€” rolling a 2 satisfies both events.

      *Independence:*

      - :math:`P(A \cap C) = 1/6`
      - :math:`P(A) \cdot P(C) = (1/2)(1/3) = 1/6`

      Since :math:`P(A \cap C) = P(A) \cdot P(C)`, **A and C are independent**.

      **Part (c): Events B and C**

      *Mutual Exclusivity:*

      :math:`B \cap C = \emptyset` (no number is both > 4 and < 3)

      **B and C are mutually exclusive**.

      *Independence:*

      - :math:`P(B \cap C) = 0`
      - :math:`P(B) \cdot P(C) = (1/3)(1/3) = 1/9 \neq 0`

      Since :math:`P(B \cap C) \neq P(B) \cdot P(C)`, **B and C are NOT independent**.

      **Key Insight**: Events B and C illustrate that **mutually exclusive events with non-zero probabilities cannot be independent**. Knowing one occurs tells you the other definitely didn't occur.

----

.. admonition:: Exercise 3: System Reliability â€” Series Configuration
   :class: note

   A data pipeline has three processing stages that operate independently:

   - Stage 1 (Data Ingestion): 98% reliability
   - Stage 2 (Data Transformation): 95% reliability
   - Stage 3 (Data Storage): 99% reliability

   The pipeline functions only if **all three stages** work (series configuration).

   a. What is the probability that the entire pipeline functions?

   b. Which stage contributes most to pipeline failures? Justify your answer.

   c. If the company wants the overall pipeline reliability to be at least 95%, and they can only improve one stage, which stage should they focus on and what reliability would that stage need?

   d. If they add a fourth stage with 97% reliability, what is the new pipeline reliability?

   .. dropdown:: Solution
      :class-container: sd-border-success

      Let :math:`S_1, S_2, S_3` denote the events that stages 1, 2, 3 work, respectively.

      Given: :math:`P(S_1) = 0.98`, :math:`P(S_2) = 0.95`, :math:`P(S_3) = 0.99`

      **Part (a): Pipeline Reliability**

      For a series system, all components must work. Since stages operate independently:

      .. math::

         P(\text{Pipeline works}) = P(S_1 \cap S_2 \cap S_3) = P(S_1) \cdot P(S_2) \cdot P(S_3)

      .. math::

         P(\text{Pipeline works}) = (0.98)(0.95)(0.99) = 0.9216

      The pipeline has **92.16% reliability**.

      **Part (b): Identifying the Bottleneck**

      The stage with the **lowest reliability** contributes most to failures.

      - Stage 1: 2% failure rate
      - Stage 2: 5% failure rate â† **Highest failure rate**
      - Stage 3: 1% failure rate

      **Stage 2 (Data Transformation)** is the bottleneck with a 5% failure rate.

      **Part (c): Achieving 95% Overall Reliability**

      Current: :math:`(0.98)(0.95)(0.99) = 0.9216`

      Target: 0.95

      Focus on Stage 2 (the bottleneck). Let :math:`p` be the new Stage 2 reliability.

      .. math::

         (0.98)(p)(0.99) \geq 0.95

      .. math::

         p \geq \frac{0.95}{(0.98)(0.99)} = \frac{0.95}{0.9702} \approx 0.9792

      Stage 2 needs **at least 97.92% reliability** (up from 95%).

      **Part (d): Adding a Fourth Stage**

      Let :math:`P(S_4) = 0.97`

      .. math::

         P(\text{Pipeline works}) = (0.98)(0.95)(0.99)(0.97) = 0.8940

      Adding a fourth stage **reduces** overall reliability to **89.4%**. In series systems, more components generally decrease reliability.

----

.. admonition:: Exercise 4: System Reliability â€” Parallel Configuration
   :class: note

   A web application uses redundant servers for high availability. Three servers are configured in parallel â€” the system functions if **at least one server** is operational.

   Each server has a 90% probability of being operational (servers fail independently).

   a. What is the probability that the system functions?

   b. What is the probability that exactly two servers are operational?

   c. If the company adds a fourth server (also 90% reliable), what is the new system reliability?

   d. How many 90%-reliable servers would be needed to achieve 99.99% system reliability?

   .. dropdown:: Solution
      :class-container: sd-border-success

      Let :math:`S_i` = "server :math:`i` is operational" with :math:`P(S_i) = 0.90` and :math:`P(S_i') = 0.10`.

      **Part (a): System Reliability (At Least One Server)**

      Use the complement: P(system works) = 1 âˆ’ P(all servers fail)

      .. math::

         P(\text{System works}) = 1 - P(S_1' \cap S_2' \cap S_3')

      By independence:

      .. math::

         P(\text{System works}) = 1 - P(S_1') \cdot P(S_2') \cdot P(S_3') = 1 - (0.10)^3 = 1 - 0.001 = 0.999

      **System reliability: 99.9%**

      **Part (b): Exactly Two Servers Operational**

      "Exactly two" means one fails and two work. There are :math:`\binom{3}{2} = 3` ways to choose which two work.

      .. math::

         P(\text{exactly 2}) = 3 \times (0.90)^2 \times (0.10)^1 = 3 \times 0.81 \times 0.10 = 0.243

      **24.3% probability of exactly two servers operational.**

      **Part (c): Adding a Fourth Server**

      .. math::

         P(\text{System works}) = 1 - (0.10)^4 = 1 - 0.0001 = 0.9999

      With four servers, reliability increases to **99.99%**.

      **Part (d): Achieving 99.99% Reliability**

      We need: :math:`1 - (0.10)^n \geq 0.9999`

      .. math::

         (0.10)^n \leq 0.0001

      .. math::

         (0.10)^n \leq (0.10)^4

      .. math::

         n \geq 4

      **Four servers** are needed for 99.99% reliability.

      **Key Insight**: Parallel configurations dramatically improve reliability. Three 90%-reliable servers give 99.9% system reliability, while three such servers in *series* would give only :math:`(0.90)^3 = 72.9\%`.

----

.. admonition:: Exercise 5: Pairwise vs Mutual Independence
   :class: note

   A fair coin is flipped twice. Define the following events:

   - :math:`A` = "first flip is heads"
   - :math:`B` = "second flip is heads"
   - :math:`C` = "both flips show the same result" (both heads or both tails)

   a. List the sample space and identify which outcomes belong to each event.

   b. Calculate :math:`P(A)`, :math:`P(B)`, :math:`P(C)`, :math:`P(A \cap B)`, :math:`P(A \cap C)`, and :math:`P(B \cap C)`.

   c. Check whether each pair of events is independent:
      
      - Are A and B independent?
      - Are A and C independent?
      - Are B and C independent?

   d. Calculate :math:`P(A \cap B \cap C)`. Is it equal to :math:`P(A) \cdot P(B) \cdot P(C)`?

   e. Are A, B, and C mutually independent? Explain.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Sample Space**

      :math:`\Omega = \{HH, HT, TH, TT\}`, each with probability 1/4.

      - :math:`A = \{HH, HT\}` â€” first flip is H
      - :math:`B = \{HH, TH\}` â€” second flip is H
      - :math:`C = \{HH, TT\}` â€” both same

      **Part (b): Probabilities**

      - :math:`P(A) = 2/4 = 1/2`
      - :math:`P(B) = 2/4 = 1/2`
      - :math:`P(C) = 2/4 = 1/2`
      - :math:`P(A \cap B) = P(\{HH\}) = 1/4`
      - :math:`P(A \cap C) = P(\{HH\}) = 1/4`
      - :math:`P(B \cap C) = P(\{HH\}) = 1/4`

      **Part (c): Pairwise Independence**

      *A and B:*

      - :math:`P(A \cap B) = 1/4`
      - :math:`P(A) \cdot P(B) = (1/2)(1/2) = 1/4` âœ“

      **A and B are independent.**

      *A and C:*

      - :math:`P(A \cap C) = 1/4`
      - :math:`P(A) \cdot P(C) = (1/2)(1/2) = 1/4` âœ“

      **A and C are independent.**

      *B and C:*

      - :math:`P(B \cap C) = 1/4`
      - :math:`P(B) \cdot P(C) = (1/2)(1/2) = 1/4` âœ“

      **B and C are independent.**

      **All pairs are independent â€” the events are pairwise independent.**

      **Part (d): Triple Intersection**

      :math:`A \cap B \cap C = \{HH\}` (first H, second H, both same)

      - :math:`P(A \cap B \cap C) = 1/4`
      - :math:`P(A) \cdot P(B) \cdot P(C) = (1/2)(1/2)(1/2) = 1/8`

      :math:`P(A \cap B \cap C) = 1/4 \neq 1/8 = P(A) \cdot P(B) \cdot P(C)`

      **Part (e): Mutual Independence**

      **No, A, B, and C are NOT mutually independent.**

      Although all pairs are independent (pairwise independence), the triple product rule fails. This is a classic example showing that **pairwise independence does not imply mutual independence**.

      **Intuition**: If you know A occurred (first flip H) AND B occurred (second flip H), then C *must* occur (both same). So knowing A and B together completely determines C, even though knowing A alone or B alone doesn't help predict C.

----

.. admonition:: Exercise 6: Independent Events and Complements
   :class: note

   Network packets are transmitted through two independent routers. Router 1 successfully forwards a packet with probability 0.95, and Router 2 successfully forwards with probability 0.92.

   Let :math:`R_1` = "Router 1 succeeds" and :math:`R_2` = "Router 2 succeeds."

   a. Verify that :math:`R_1` and :math:`R_2` being independent implies :math:`R_1'` and :math:`R_2` are also independent.

   b. Calculate the probability that both routers fail.

   c. Calculate the probability that exactly one router succeeds.

   d. A packet is successfully delivered if **both** routers succeed (series). What is P(delivered)?

   e. If the routers were configured in **parallel** (packet delivered if **at least one** succeeds), what would P(delivered) be?

   .. dropdown:: Solution
      :class-container: sd-border-success

      Given: :math:`P(R_1) = 0.95`, :math:`P(R_2) = 0.92`, and :math:`R_1 \perp R_2` (independent).

      **Part (a): Complement Independence**

      If :math:`R_1` and :math:`R_2` are independent, we need to show :math:`P(R_1' \cap R_2) = P(R_1') \cdot P(R_2)`.

      .. math::

         P(R_1' \cap R_2) &= P(R_2) - P(R_1 \cap R_2) \\
         &= P(R_2) - P(R_1) \cdot P(R_2) \quad \text{(by independence of } R_1, R_2\text{)} \\
         &= P(R_2)(1 - P(R_1)) \\
         &= P(R_2) \cdot P(R_1')

      This confirms **:math:`R_1'` and :math:`R_2` are independent** âœ“

      Similarly, :math:`R_1` and :math:`R_2'`, and :math:`R_1'` and :math:`R_2'` are all independent.

      **Part (b): Both Routers Fail**

      By independence of complements:

      .. math::

         P(R_1' \cap R_2') = P(R_1') \cdot P(R_2') = (0.05)(0.08) = 0.004

      **0.4% probability both fail.**

      **Part (c): Exactly One Succeeds**

      "Exactly one" = (:math:`R_1` and not :math:`R_2`) OR (not :math:`R_1` and :math:`R_2`)

      .. math::

         P(\text{exactly one}) &= P(R_1 \cap R_2') + P(R_1' \cap R_2) \\
         &= P(R_1) \cdot P(R_2') + P(R_1') \cdot P(R_2) \\
         &= (0.95)(0.08) + (0.05)(0.92) \\
         &= 0.076 + 0.046 = 0.122

      **12.2% probability exactly one succeeds.**

      **Part (d): Series Configuration (Both Must Succeed)**

      .. math::

         P(\text{delivered}) = P(R_1 \cap R_2) = P(R_1) \cdot P(R_2) = (0.95)(0.92) = 0.874

      **87.4% delivery rate in series.**

      **Part (e): Parallel Configuration (At Least One Succeeds)**

      .. math::

         P(\text{delivered}) = 1 - P(R_1' \cap R_2') = 1 - 0.004 = 0.996

      **99.6% delivery rate in parallel.**

      **Comparison**: Parallel configuration (99.6%) is much more reliable than series (87.4%) for the same components.

----

Additional Practice Problems
----------------------------

**True/False Questions** (1 point each)

1. If events A and B are independent, then :math:`P(A \cap B) = P(A) \cdot P(B)`.

   â“‰ or â’»

2. If events A and B are mutually exclusive with :math:`P(A) > 0` and :math:`P(B) > 0`, then they are independent.

   â“‰ or â’»

3. If A and B are independent, then A and B' are also independent.

   â“‰ or â’»

4. Pairwise independence of three events implies mutual independence.

   â“‰ or â’»

5. In a series system, adding more independent components always decreases system reliability.

   â“‰ or â’»

6. If :math:`P(A|B) = P(A)`, then A and B are independent.

   â“‰ or â’»

**Multiple Choice Questions** (2 points each)

7. Two events A and B have :math:`P(A) = 0.4`, :math:`P(B) = 0.5`, and :math:`P(A \cap B) = 0.2`. Are A and B independent?

   â’¶ Yes, because :math:`P(A \cap B) = P(A) \cdot P(B)`
   
   â’· No, because :math:`P(A \cap B) \neq P(A) \cdot P(B)`
   
   â’¸ Yes, because they are not mutually exclusive
   
   â’¹ Cannot be determined

8. Three independent components each have 80% reliability. What is the reliability of a system where all three must work (series)?

   â’¶ 0.512
   
   â’· 0.800
   
   â’¸ 0.992
   
   â’¹ 2.400

9. For the same three components in parallel (at least one must work), the system reliability is:

   â’¶ 0.512
   
   â’· 0.800
   
   â’¸ 0.992
   
   â’¹ 0.008

10. If P(A) = 0.3 and P(B) = 0.4, and A and B are mutually exclusive, what is :math:`P(A \cap B)`?

    â’¶ 0.00
    
    â’· 0.12
    
    â’¸ 0.70
    
    â’¹ Cannot be determined without more information

.. dropdown:: Answers to Practice Problems
   :class-container: sd-border-success

   **True/False Answers:**

   1. **True** â€” This is the special multiplication rule, which defines independence.

   2. **False** â€” Mutually exclusive events with non-zero probabilities are NEVER independent. If A occurs, B definitely doesn't (P(B|A) = 0 â‰  P(B)).

   3. **True** â€” Independence of A and B implies independence of A and B', B and A', and A' and B'.

   4. **False** â€” Pairwise independence does NOT imply mutual independence. The coin flip example (Exercise 5) shows three pairwise independent events that are not mutually independent.

   5. **True** â€” In series, P(system) = P(Câ‚) Ã— P(Câ‚‚) Ã— ... Each additional component (with P < 1) multiplies by a value less than 1, decreasing reliability.

   6. **True** â€” This is an equivalent definition of independence. P(A|B) = P(A) means knowing B doesn't change the probability of A.

   **Multiple Choice Answers:**

   7. **â’¶** â€” Check: P(A) Ã— P(B) = 0.4 Ã— 0.5 = 0.2 = P(A âˆ© B). Since the products match, A and B are independent.

   8. **â’¶** â€” Series reliability = (0.8)Â³ = 0.512

   9. **â’¸** â€” Parallel reliability = 1 âˆ’ P(all fail) = 1 âˆ’ (0.2)Â³ = 1 âˆ’ 0.008 = 0.992

   10. **â’¶** â€” Mutually exclusive events have no overlap, so P(A âˆ© B) = 0 by definition.