.. _12-1-intro-one-way-anova:

.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch12-1">
      <iframe
         id="video-ch12-1"
         title="STAT 350 ‚Äì Chapter 12.1 One-Way ANOVA Video"
         src="https://www.youtube.com/embed/FYgP2E9lre4?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

.. admonition:: Slides üìä
   :class: tip

   `Download Chapter 12 slides (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/
   Chapter%2012%20ANOVA/OneWayANOVA_AC.pptx>`_

Introduction to One-Way ANOVA
==========================================================

Many important research questions involve comparing two or more 
populations simultaneously. We now need a new approach that can handle the complexity of 
simultaneous comparisons while controlling the overall error rates.

.. admonition:: Road Map üß≠
   :class: important

   * Identify the **experimental conditions** that call for the use of ANOVA.
   * Explain why a comparison of multiple means is called an Analysis of "**Variance**."
   * Define the **notations** and formulate the **hypotheses** for ANOVA.
   * List the **assumptions** required for validity of ANOVA.

The Fundamental ANOVA Question
---------------------------------

Many controlled experiments involve dividing subjects into two or more groups, applying a
distinct treatment to each group, and then analyzing their quantitative responses to see if any systematic
difference exists among the groups. See the example below for concrete scenarios.

.. admonition:: Examples üí°: Experiments That Require Multiple Comparisons 
   :class: note
      
   **Example 1: Bacterial Growth Study**

   A research group studies bacteria growth rates in different sugar solutions.

   - **Factor variable**: Type of sugar solution
   - **Levels**: Glucose, Sucrose, Fructose, Lactose (4 groups)
   - **Quantitative response variable**: Bacterial growth rate

   **Example 2: Gasoline Brand Efficiency**

   Researchers want to determine if five different gasoline brands affect automobile fuel efficiency.

   - **Factor variable**: Gasoline brand
   - **Levels**: Brand A, Brand B, Brand C, Brand D, Brand E (5 groups)
   - **Quantitative response variable**: Miles per gallon

The Research Question and Our Strategy
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In all the examples above, the researchers aim to determine whether any difference
exists among the true means of the response groups. 

A naive approach to would be to perform two-sample comparisons for all possible pairs of levels. 
However, there are two critical drawbacks to this approach.

1. Let :math:`k` be the number of levels. The total number of
   pairwise comparisons is :math:`k \choose 2`, which grows quickly with :math:`k`‚Äîfor example,
   :math:`10`  for :math:`k=5` and :math:`45` for :math:`k=10`. 

2. When many inferences are performed simultaneously at significance level :math:`\alpha`, 
   the probability of making at least one Type I error becomes substantially larger than :math:`\alpha`.

To avoid unncessary efforts and potential errors, we would like to first perform a single screening hypothesis test 
which determines whether *any* difference exists among the population means. Only when we reject the null hypothesis
that all means are equal do we proceed to pairwise comparisons, taking special care to
control the overall Type I error rate.

The preliminary screening test is called the **Analysis of Variance, or ANOVA**.

Why Analysis of "Variance"?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

At first glance, it seems strange that a procedure designed to compare means is called an
analysis of "variance." This is because the perceived difference among means 
depend on the relative variances within and between groups. See :numref:`ANOVA-intro`
for a graphical illustration.

.. _ANOVA-intro:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter12/ANOVA-intro.png 
   :figwidth: 90%
   :align: center 
   :alt: Graphical illustration of need for ANOVA

   Left: Distributions with large within-group variances; Right: Distributions with
   small within-group variances

Suppose we obtain samples from Case (a). Most likely, the data points will be spread
over a wide range within each group. The within-group variability is wide enough to obscure
the distinction created by the difference in central values. 

On the other hand, samples from Case (b) will bunch closely arount their respective means,
providing a stronger evidence that the true means are indeed distinct.

Note that the **true means are identical in both cases**‚Äîthe absolute locations of the
true means did not have a significant role in our visual analysis. Instead, the key difference arose
from **the relative size of the within-group spread in comparison with the spread of the true means**.

1. If the within-group variation is comparable or larger than the between-group variation,
   we do not have enough evidence to reject the baseline belief that all means are equal.

2. If the within-group variation is smaller than the spread of the group means, 
   there is a strong evidence that at least one true mean is different than the rest.

..
   .. _within-vs-between:
   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter12/within-vs-between.png 
      :figwidth: 40%
      :align: center 
      :alt: Comparison of within-group and between-group variation

      Comparison of within-group and between-group variation

Why "One-Way"?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We use the term **one-way** ANOVA to indicate an experimental design in which 
groups are formed based on different levels of a single factor.

When analyzing the joint impact of two factors on a response, 
we use a **two-way** ANOVA. While the foundational ideas are the same as in
one-way ANOVA, an additional feature must be considered‚Äîthe 
**interaction effect** between the two factors, which may 
amplify or offset their respective **main effects**. ANOVA models involving more than two factors also exist.

In this course, we focus exclusively on **one-way** ANOVA. 

Formalizing ANOVA
--------------------

Notation
~~~~~~~~~~

Suppose we have :math:`k` different groups, where :math:`k \geq 2`.

.. flat-table::
   :header-rows: 1
   :widths: 1 1

   * - :cspan:`1` ANOVA Notations for Group :math:`i`

   * - Group Index
     - .. math:: 
         i \in \{1, 2, \ldots, k\}

   * - Observation Index
     - .. math:: 
         j \in \{1, 2, \ldots, n_i\}
   * - Population Mean and Variance
     - .. math:: 
         \mu_i \text{ and } \sigma^2_i

   * - Group Sample Size
     - .. math:: 
         n_i
   
   * - Group Sample
     - .. math:: 
         X_{i1}, X_{i2}, \cdots, X_{in_i}

   * - Group Sample Mean
     - .. math:: 
         \bar{X}_{i\cdot} = \frac{1}{n_i}\sum_{j=1}^{n_i} X_{ij}

   * - Group Sample Variance
     - .. math:: 
         S_{i\cdot}^2 = \frac{1}{n_{i}-1}\sum_{j=1}^{n_i}(X_{ij} - \bar{X}_{i\cdot})^2

   * - :cspan:`1` **ANOVA Notation for Overall Summary**
   
   * - Overall Sample Size
     - .. math::
         n = n_1 + n_2 + \cdots + n_k

   * - Overall Sample Mean
     - .. math:: 
         \bar{X}_{\cdot \cdot} = \frac{1}{n} \sum_{i=1}^{k} \sum_{j=1}^{n_i} X_{ij} 
         = \frac{1}{n} \sum_{i=1}^{k} n_i \bar{X}_{i \cdot} 

Each random variable in a sample is now indexed with double subscripts. 

* The first subscript :math:`i` specifies the group to which the data point belongs.
* The second subscript :math:`j` indicates the observeration index
  within the group.

In addition, we use :math:`\cdot` in the place of an index to indicate that a summary statistic is 
computed over all values of the corresponding index.

* For example, the notation :math:`\bar{X}_{i\cdot}` indiates that the statistic is
  computed using data points for all values of the second index, while keeping 
  the group index fixed at :math:`i`. 
* Likewise, :math:`\bar{X}_{\cdot \cdot}` means that
  data points for *all* indices are used to compute the summary.


Hypothesis Formulation
~~~~~~~~~~~~~~~~~~~~~~~~~

There is only one type of dual hypothesis for one-way ANOVA.
The **null hypothesis** states that all true means are equal:

* :math:`H_0: \mu_1 = \mu_2 = \mu_3 = \cdots = \mu_k.`

The **alternative hypothesis** states that at least one population mean is different from the others. 
This can be expressed in several equivalent ways:

* :math:`H_a:` At least one :math:`\mu_i` is different from the others.
* :math:`H_a:` Not all population means are equal.
* :math:`H_a: \mu_i \neq \mu_j \text{ for some } i \neq j`

.. admonition:: Important Note About the Alternative
   :class: danger

   ‚ùå It is **incorrect** to write the alternative hypothesis as

   .. math::
      H_0: \mu_1 \neq \mu_2 \neq \mu_3 \neq \cdots \neq \mu_k.

   The alternative hypothesis does **not** state that all means are different from each other. It only requires 
   that at least one mean differs from the others. This could mean:

   - Only :math:`\mu_1` differs from :math:`\mu_2 = \mu_3 = \mu_4`
   - Two groups differ: :math:`\mu_1 = \mu_2 \neq \mu_3 = \mu_4`
   - All groups differ: :math:`\mu_1 \neq \mu_2 \neq \mu_3 \neq \mu_4`



.. admonition:: Example üí°: Coffeehouse Demographics Study ‚òïÔ∏è
   :class: note

   A student reporter wants to study the demographics of coffeehouses around campus. Specifically, 
   she's interested in whether different coffeehouses attract customers of different ages. 
   The reporter randomly selects 50 customers at each of five coffeehouses using a systematic sampling 
   approach. Due to non-response, the final sample sizes vary slightly across coffeehouses 
   but remain close to 50 per location.

   **Component Identification**

   - **Factor variable**: Coffeehouse location (5 levels)
   - **Response variable**: Customer age (quantitative, measured in years)
   - **Research question**: Are there statistically significant differences between the average ages of 
     customers at the different coffeehouses?

   **ANOVA Setup**

   Let :math:`\mu_i` represent the true mean age of customers at Coffeehouse :math:`i`, for each
   :math:`i = 1, 2, \cdots , 5`. The hypotheses are:

   .. math::
      &H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4 = \mu_5 \\
      &H_a: \mu_i \neq \mu_j \text{ for some } i \neq j


Assumptions
~~~~~~~~~~~~

Like all statistical procedures, ANOVA relies on certain assumptions for validity. These assumptions extend 
the familiar requirements from two-sample procedures to the multi-group setting.

**Assumption 1: Independent Simple Random Samples**

The observations in each of the :math:`k` groups must form a simple random sample. That is, within each group :math:`i`, 
the observations :math:`X_{i1}, X_{i2}, \ldots, X_{in_i}` must be independent and identically distributed.

**Assumption 2: Independence Between Groups**

Samples from different populations must be independent of each other.

**Assumption 3: Normality of the Sample Means**

Each population must either be normally distributed or have a large enough sample size for the CLT to hold, so
that the sample mean is approximately normally distributed.

**Assumption 4: Equal Variances**

All populations must have equal variances:

.. math::

   \sigma^2_1 = \sigma^2_2 = \cdots = \sigma^2_k = \sigma^2

This assumption allows us to pool information across groups when estimating the common variance, 
leading to more efficient procedures. 

We discuss how to verify Assumption 4 through observed data in the following section. 
Alternative approaches must be used when the equal variance assumption fails, 
which is beyond the scope of this course.

.. _visual_analysis:

Preliminary Visual Analysis
------------------------------

Before conducting formal ANOVA procedures, it is standard practice to gain insights 
about the populations and the samples through graphical analysis. We pay special attention to 
two aspects:

1. Signs of significant differences among population means
2. Any violation of the assumptions

Signs of Differences Among True Means
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Note that the sample means alone do not give us any sense of whether
the *true* means are different‚Äîthe sample means will almost always be different from each another
due to the randomness in the population distributions. Instead, we pay attention to the **spread** of the samples
through their side-by-side boxlpots. :numref:`side-by-side` shows the side-by-side boxplots for the coffeehouse example. 

.. _side-by-side:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter12/side-by-side-boxplot.png
   :width: 90%
   :align: center
   :alt: Side-by-side boxplots of the five samples in the coffeehouse example
   
   Side-by-side boxplots of the five samples in the coffeehouse example

We assess the strength of visual evidence by **how much the boxplots overlap in their spans**.
If all the boxplots span similar regions,there is little visual evidence of
distinct means. If at least one group partially overlaps with the rest,
there is a higher chance of eventually rejecting the null hypothesis in ANOVA.

Note that no formal conclusion should be drawn from visual evidence alone. Boxplots 
serve only as a tool to gain insight into the dataset.

Identifying Violation of Assumptions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This stage involves examining **all available visual resources**, including the
boxplots, the histograms, and the normal probability plot.

(a) Boxplots
^^^^^^^^^^^^^^^^^^

To confirm the equal variance assumption visually,
ensure that the range and IQR of the samples are similar on the sid-by-side boxplots.
The assumption must also be checked numerically. As a rule of thumb,
we say that the sign of violation is not strong if:

.. math:: 
   \frac{\max{s_i}}{\min{s_i}} \leq 2.

Boxplots are also used to check if any potential outliers exist.

(b) Histograms and Normal Probability Plot
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To check whether the samples show any signs of non-normality,
use group-wise histograms.

.. _histograms:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter12/histograms.png
   :width: 90%
   :align: center
   :alt: Group-wise histograms for the coffeehouse example
   
   Group-wise histograms for the coffeehouse example

A combined normal probability plot of :math:`x_{ij}-\bar{x}_{i\cdot}` 
(data points re-centered to have zero-mean; also called the *residuals*) can be used together.

.. _QQplot:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter12/QQplot.png
   :width: 70%
   :align: center
   :alt: normal probability plot for the coffeehouse example
   
   Normal probability plot for the coffeehouse example

.. admonition:: Example üí°: Coffeehouse Demographics Study ‚òïÔ∏è
   :class: note
   
   Use :numref:`side-by-side`, :numref:`histograms`, :numref:`QQplot`, and the numerical summary
   below to perform a preliminary assessment of the coffeehouse dataset.

   üìä `Download the coffeehouse dataset (CSV) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Data/AgeCoffee.csv>`_

   .. list-table:: Sample Statistics
      :header-rows: 1
      :widths: 30 20 25 25
      :align: center

      * - Sample (Levels of Factor Variable)
        - Sample Size
        - Mean
        - Variance
      * - Population 1
        - :math:`n_1 = 39`
        - :math:`\bar{x}_{1.} = 39.13`
        - :math:`s_1^2 = 62.43`
      * - Population 2
        - :math:`n_2 = 38`
        - :math:`\bar{x}_{2.} = 46.66`
        - :math:`s_2^2 = 168.34`
      * - Population 3
        - :math:`n_3 = 42`
        - :math:`\bar{x}_{3.} = 40.50`
        - :math:`s_3^2 = 119.62`
      * - Population 4
        - :math:`n_4 = 38`
        - :math:`\bar{x}_{4.} = 26.42`
        - :math:`s_4^2 = 48.90`
      * - Population 5
        - :math:`n_5 = 43`
        - :math:`\bar{x}_{5.} = 34.07`
        - :math:`s_5^2 = 98.50`
      * - **Combined**
        - :math:`n = 200`
        - :math:`\bar{x}_{..} = 37.35`
        - :math:`s^2 = 142.14`

   **1. Do the graphs show signs of distinct means?**

   From the boxplots, we observe that the customer age sample from Coffeehouse 4 spans a
   notably lower region than others. Its difference with Coffeehouse 2 is most evident‚Äîthe mean age at 
   Coffeehouse 2 appears higher than even the maximum observed at Coffeehouse 4.
   Other coffeehouses show larger overlaps.

   **2. Any violation of assumptions?**

     **Equal variance**
     
     From the boxplots, the variability of Sample 2 and Sample 4 appear to be different. We need to make sure that 
     the largest ratio between two sample standard deviations is less than or equal to 2:
     
     .. math:: 
        \frac{\max{s_i}}{\min{s_i}} = \frac{\sqrt{168.34}}{\sqrt{48.90}} = 1.855 < 2 \checkmark

     So we consider the sample variances to be *similar enough* for the equal population variance assumption.

     **Normality** 
     
     The histogram of Coffeehouse 4 and the overall QQ plot show a sign of skewness. Since the dataset is
     sufficiently large, this moderate departure from normality is okay.

   **3. Summary** 

   Since the assumptions are reasonably met and the boxplots show signs of difference in means,
   we predict that ANOVA will yield a statistically significant result. We will perform the formal test
   in the upcoming sections and find out whether our prediction is correct.


.. admonition:: Key Takeaways üìù
   :class: important

   1. ANOVA is a statistical analysis that **simultaneously compares two or more population means**.

   2. **Double subscript notation** :math:`X_{ij}` systematically handles multiple groups, with **dot notation** 
      indicating which indices are averaged over.
   
   3. Four key assumptions must be satisfied for validity of ANOVA: 
      **independent simple random samples, independence between groups, normality, and equal variances**.

   4. Perform preliminary graphical and numerical assessments to check the assumptions and
      spot signs of statistical significance.


Exercises
---------

.. admonition:: Notation and Rounding Policy
   :class: tip

   **Notation**: In ANOVA, we use :math:`x_{i,j}` where :math:`i` indexes the group (1 to k) and :math:`j` indexes the observation within that group. Always use a comma between subscripts to avoid ambiguity.

   **Rounding**: Carry at least 3‚Äì4 decimal places in intermediate calculations; round final answers to 2 decimal places (or 3 significant figures for very small values like p-values).

----

.. admonition:: Exercise 1: Identifying ANOVA Scenarios
   :class: note

   For each scenario, determine whether one-way ANOVA is the appropriate analysis method. If not, suggest an alternative.

   a. A software company compares bug detection rates of 4 different code review tools, testing each tool on 15 independent projects.

   b. A researcher measures blood pressure before and after a meditation intervention for 30 participants.

   c. An engineer compares the tensile strength of steel samples from 5 different suppliers, with 20 samples from each supplier.

   d. A data scientist wants to determine if there's a relationship between hours of sleep and exam scores.

   e. A quality control team compares the precision of 3 measurement instruments by having each instrument measure the same 25 reference objects.

   f. A marketing team tests whether click-through rates differ among 6 different ad designs, randomly showing each design to 500 users.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): One-way ANOVA is appropriate** ‚úì

      - Factor: Code review tool (4 levels)
      - Response: Bug detection rate (quantitative)
      - Independent samples from each tool
      - Compares k = 4 population means

      **Part (b): One-way ANOVA is NOT appropriate**

      This is a **paired design** (before/after on same individuals). Use a **paired t-test** instead. The measurements are not independent‚Äîeach participant provides both measurements.

      **Part (c): One-way ANOVA is appropriate** ‚úì

      - Factor: Supplier (5 levels)
      - Response: Tensile strength (quantitative)
      - Independent samples from each supplier
      - Compares k = 5 population means

      **Part (d): One-way ANOVA is NOT appropriate**

      This describes a relationship between two quantitative variables. Use **simple linear regression** or **correlation analysis** instead. ANOVA requires a categorical factor variable.

      **Part (e): One-way ANOVA is NOT appropriate**

      The same objects are measured by all instruments, creating a **repeated measures** or **blocked design**. The measurements are not independent across instruments. This would require **repeated measures ANOVA** or treating objects as blocks (beyond STAT 350).

      **Part (f): One-way ANOVA is appropriate** ‚úì

      - Factor: Ad design (6 levels)
      - Response: Click-through rate (quantitative)
      - Independent random samples for each design
      - Compares k = 6 population means

----

.. admonition:: Exercise 2: Notation Practice
   :class: note

   A materials engineer tests the hardness of ceramic samples produced using three different sintering temperatures. The following data are collected:

   .. list-table::
      :header-rows: 1
      :widths: 25 15 20 20

      * - Temperature
        - Sample Size
        - Mean Hardness
        - Std Dev
      * - 1200¬∞C (Group 1)
        - 8
        - 72.5
        - 4.2
      * - 1350¬∞C (Group 2)
        - 10
        - 78.3
        - 3.8
      * - 1500¬∞C (Group 3)
        - 7
        - 85.1
        - 5.1

   **Notation convention**: In ANOVA, we use double subscripts :math:`x_{i,j}` where :math:`i` indexes the **group** (1 to k) and :math:`j` indexes the **observation within that group** (1 to :math:`n_i`).

   a. Using proper ANOVA notation, identify: :math:`k`, :math:`n_1, n_2, n_3`, :math:`n`, :math:`\bar{x}_{1.}, \bar{x}_{2.}, \bar{x}_{3.}`, :math:`s_1, s_2, s_3`.

   b. Compute the overall (grand) mean :math:`\bar{x}_{..}` using the formula:

      .. math::
         \bar{x}_{..} = \frac{1}{n}\sum_{i=1}^{k} n_i \bar{x}_{i.}

   c. What does the notation :math:`x_{2,5}` represent in this context?

   d. Write an expression for "the sum of all observations in Group 1" in two equivalent forms.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Notation identification**

      - :math:`k = 3` (number of groups/temperature levels)
      - :math:`n_1 = 8, n_2 = 10, n_3 = 7` (sample sizes per group)
      - :math:`n = n_1 + n_2 + n_3 = 8 + 10 + 7 = 25` (total sample size)
      - :math:`\bar{x}_{1.} = 72.5, \bar{x}_{2.} = 78.3, \bar{x}_{3.} = 85.1` (group means)
      - :math:`s_1 = 4.2, s_2 = 3.8, s_3 = 5.1` (group standard deviations)

      **Part (b): Overall mean**

      .. math::
         \bar{x}_{..} = \frac{1}{25}(8 \times 72.5 + 10 \times 78.3 + 7 \times 85.1)

      .. math::
         = \frac{580 + 783 + 595.7}{25} = \frac{1958.7}{25} = 78.35

      **Part (c): Interpretation of** :math:`x_{2,5}`

      The notation :math:`x_{2,5}` represents the **5th observation in Group 2** (the 1350¬∞C temperature group). 
      
      - The first subscript (2) identifies the **group** (:math:`i = 2`)
      - The second subscript (5) identifies the **observation within that group** (:math:`j = 5`)

      **Important**: Always use a comma between subscripts (e.g., :math:`x_{2,5}` not :math:`x_{25}`) to avoid ambiguity when group or observation indices exceed 9.

      **Part (d): Sum of observations in Group 1**

      Two equivalent forms:

      .. math::
         \sum_{j=1}^{n_1} x_{1,j} = \sum_{j=1}^{8} x_{1,j} \quad \text{(summation notation)}

      .. math::
         = n_1 \bar{x}_{1.} = 8 \times 72.5 = 580 \quad \text{(using definition of sample mean)}

      The second form, :math:`n_1 \bar{x}_{1.}`, is a useful shortcut that follows directly from the definition of the sample mean: :math:`\bar{x}_{1.} = \frac{1}{n_1}\sum_{j=1}^{n_1} x_{1,j}`, which rearranges to :math:`\sum_{j=1}^{n_1} x_{1,j} = n_1 \bar{x}_{1.}`.

----

.. admonition:: Exercise 3: Hypothesis Formulation
   :class: note

   For each research scenario, write the null and alternative hypotheses using proper notation. Define the parameters clearly.

   a. A network engineer tests whether mean packet latency differs among 4 different router configurations.

   b. A pharmaceutical company compares the mean efficacy scores of 5 different drug dosages.

   c. An agricultural researcher investigates whether mean crop yield differs among 3 fertilizer types.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Router configurations**

      *Parameter definitions:*
      
      - :math:`\mu_1` = true mean packet latency (ms) for Configuration 1
      - :math:`\mu_2` = true mean packet latency (ms) for Configuration 2
      - :math:`\mu_3` = true mean packet latency (ms) for Configuration 3
      - :math:`\mu_4` = true mean packet latency (ms) for Configuration 4

      *Hypotheses:*

      .. math::
         &H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4\\
         &H_a: \text{At least one } \mu_i \text{ is different from the others}

      **Part (b): Drug dosages**

      *Parameter definitions:*
      
      - :math:`\mu_i` = true mean efficacy score for dosage level :math:`i`, for :math:`i = 1, 2, 3, 4, 5`

      *Hypotheses:*

      .. math::
         &H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4 = \mu_5\\
         &H_a: \text{At least one } \mu_i \text{ is different from the others}

      **Part (c): Fertilizer types**

      *Parameter definitions:*
      
      - :math:`\mu_A` = true mean crop yield (bushels/acre) with Fertilizer A
      - :math:`\mu_B` = true mean crop yield (bushels/acre) with Fertilizer B
      - :math:`\mu_C` = true mean crop yield (bushels/acre) with Fertilizer C

      *Hypotheses:*

      .. math::
         &H_0: \mu_A = \mu_B = \mu_C\\
         &H_a: \text{At least one } \mu_i \text{ is different from the others}

      **Note**: The ANOVA alternative hypothesis is a **composite alternative**: it states that at least one mean differs from the others, but does not specify which means differ or in what direction. This is different from a simple "two-sided" test‚Äîwe are testing one null against many possible alternatives.

----

.. admonition:: Exercise 4: Checking the Equal Variance Assumption
   :class: note

   The equal variance assumption is critical for valid ANOVA results. Use the rule of thumb: the assumption is reasonable if the ratio of the largest to smallest sample standard deviation is at most 2.

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch12-1/fig3_variance_check.png
      :alt: Equal vs unequal variance scenarios
      :align: center
      :width: 95%

      **Figure**: Side-by-side boxplots illustrating equal variances (left), borderline case (center), and unequal variances (right).

   For each scenario, determine whether the equal variance assumption is satisfied.

   a. Four treatment groups with sample standard deviations: :math:`s_1 = 12.4`, :math:`s_2 = 15.8`, :math:`s_3 = 11.2`, :math:`s_4 = 18.6`

   b. Three groups with sample variances: :math:`s_1^2 = 25`, :math:`s_2^2 = 81`, :math:`s_3^2 = 36`

   c. Five groups with the following summary:

      .. list-table::
         :header-rows: 1

         * - Group
           - n
           - Mean
           - Variance
         * - 1
           - 15
           - 45.2
           - 28.5
         * - 2
           - 18
           - 52.1
           - 31.2
         * - 3
           - 12
           - 48.7
           - 42.8
         * - 4
           - 20
           - 39.8
           - 25.1
         * - 5
           - 16
           - 55.3
           - 38.4

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Four treatment groups**

      Standard deviations: 12.4, 15.8, 11.2, 18.6

      .. math::
         \frac{\max(s_i)}{\min(s_i)} = \frac{18.6}{11.2} = 1.66

      Since 1.66 ‚â§ 2, **the equal variance assumption is satisfied** ‚úì

      **Part (b): Three groups (given variances)**

      First convert variances to standard deviations:
      
      - :math:`s_1 = \sqrt{25} = 5`
      - :math:`s_2 = \sqrt{81} = 9`
      - :math:`s_3 = \sqrt{36} = 6`

      .. math::
         \frac{\max(s_i)}{\min(s_i)} = \frac{9}{5} = 1.8

      Since 1.8 ‚â§ 2, **the equal variance assumption is satisfied** ‚úì

      **Part (c): Five groups**

      Convert variances to standard deviations:
      
      - :math:`s_1 = \sqrt{28.5} = 5.34`
      - :math:`s_2 = \sqrt{31.2} = 5.59`
      - :math:`s_3 = \sqrt{42.8} = 6.54`
      - :math:`s_4 = \sqrt{25.1} = 5.01`
      - :math:`s_5 = \sqrt{38.4} = 6.20`

      .. math::
         \frac{\max(s_i)}{\min(s_i)} = \frac{6.54}{5.01} = 1.31

      Since 1.31 ‚â§ 2, **the equal variance assumption is satisfied** ‚úì

      **R verification:**

      .. code-block:: r

         # Part (a)
         s_a <- c(12.4, 15.8, 11.2, 18.6)
         max(s_a) / min(s_a)  # 1.661

         # Part (b)
         s2_b <- c(25, 81, 36)
         s_b <- sqrt(s2_b)
         max(s_b) / min(s_b)  # 1.8

         # Part (c)
         s2_c <- c(28.5, 31.2, 42.8, 25.1, 38.4)
         s_c <- sqrt(s2_c)
         max(s_c) / min(s_c)  # 1.306

      .. warning::
         
         **Do not apply the "‚â§ 2" rule to variances!** The rule of thumb uses the ratio of **standard deviations**, not variances. If you're given variances, you must first take square roots to get standard deviations before computing the ratio. For example, in Part (b), the variance ratio is 81/25 = 3.24, but the SD ratio is 9/5 = 1.8.

----

.. admonition:: Exercise 5: Complete Assumption Checking with Plots
   :class: note

   Before performing ANOVA inference, we must verify three key assumptions:

   1. **Independence** (usually justified by study design)
   2. **Normality** within each group (histograms, QQ-plots)
   3. **Equal variances** across groups (boxplots, SD ratio)

   A quality engineer collects tensile strength measurements (in MPa) from steel samples produced by three different manufacturing processes. The data is stored in a data frame called ``steel`` with variables ``Strength`` and ``Process`` (levels: A, B, C).

   a. Write R code to create **side-by-side boxplots** with mean points to visually compare the three processes.

   b. Write R code to create an **effects plot** showing the group means connected by lines.

   c. Write R code to compute the sample size, mean, and standard deviation for each process using ``tapply()``.

   d. Write R code to create **faceted histograms** by process with kernel density curves (red) and normal density overlays (blue).

   e. Write R code to create **faceted QQ-plots** by process to assess normality within each group.

   f. Check the equal variance assumption using the SD ratio rule of thumb.

   g. Based on typical output from these plots, describe what you would look for to verify each assumption.

   **Example Output (for reference):**

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch12-1/fig4_effects_plot.png
      :alt: Example effects plot
      :align: center
      :width: 70%

      Effects plot showing group means connected by lines

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch12-1/fig5_faceted_histograms.png
      :alt: Example faceted histograms
      :align: center
      :width: 95%

      Faceted histograms with kernel density (red) and normal overlay (blue)

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch12-1/fig6_faceted_qqplots.png
      :alt: Example faceted QQ-plots
      :align: center
      :width: 95%

      Faceted QQ-plots for assessing normality within each group

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Side-by-side boxplots with mean points**

      .. code-block:: r

         library(ggplot2)

         # Side-by-side boxplots
         ggplot(steel, aes(x = Process, y = Strength)) +
           stat_boxplot(geom = "errorbar", width = 0.3) +
           geom_boxplot(fill = "lightblue") +
           stat_summary(fun = mean, geom = "point", 
                        color = "black", size = 3) +
           ggtitle("Tensile Strength by Manufacturing Process") +
           xlab("Process") +
           ylab("Tensile Strength (MPa)") +
           theme_minimal()

      **Part (b): Effects plot**

      .. code-block:: r

         # Effects plot - shows group means connected by lines
         ggplot(steel, aes(x = Process, y = Strength)) +
           stat_summary(fun = mean, geom = "point", size = 3) +
           stat_summary(fun = mean, geom = "line", aes(group = 1)) +
           ggtitle("Effects Plot of Tensile Strength by Process") +
           xlab("Process") +
           ylab("Mean Tensile Strength (MPa)") +
           theme_minimal()

      **Part (c): Summary statistics using tapply()**

      .. code-block:: r

         # Sample sizes
         n <- tapply(steel$Strength, steel$Process, length)

         # Sample means
         xbar <- tapply(steel$Strength, steel$Process, mean)

         # Sample standard deviations
         s <- tapply(steel$Strength, steel$Process, sd)

         # Create summary table
         summary_table <- data.frame(
           Process = names(n),
           n = as.numeric(n),
           Mean = round(xbar, 2),
           SD = round(s, 2)
         )
         print(summary_table)

      **Part (d): Faceted histograms with density overlays**

      .. code-block:: r

         # Calculate group statistics for normal density overlay
         xbar <- tapply(steel$Strength, steel$Process, mean)
         s <- tapply(steel$Strength, steel$Process, sd)

         # Add normal density column to data frame
         steel$normal.density <- mapply(function(value, group) {
           dnorm(value, mean = xbar[group], sd = s[group])
         }, steel$Strength, steel$Process)

         # Determine number of bins
         n_bins <- max(round(sqrt(nrow(steel))) + 2, 5)

         # Faceted histograms
         ggplot(steel, aes(x = Strength)) +
           geom_histogram(aes(y = after_stat(density)), 
                          bins = n_bins, fill = "grey", col = "black") +
           geom_density(col = "red", linewidth = 1) +
           geom_line(aes(y = normal.density), col = "blue", linewidth = 1) +
           facet_wrap(~ Process) +
           ggtitle("Histograms of Tensile Strength by Process") +
           xlab("Tensile Strength (MPa)") +
           ylab("Density") +
           theme_minimal()

      **Part (e): Faceted QQ-plots**

      .. code-block:: r

         # Add intercept and slope for QQ line (group-specific)
         steel$intercept <- xbar[steel$Process]
         steel$slope <- s[steel$Process]

         # Faceted QQ-plots
         ggplot(steel, aes(sample = Strength)) +
           stat_qq() +
           geom_abline(aes(intercept = intercept, slope = slope), 
                       color = "red", linewidth = 1) +
           facet_wrap(~ Process) +
           ggtitle("QQ Plots of Tensile Strength by Process") +
           xlab("Theoretical Quantiles") +
           ylab("Sample Quantiles") +
           theme_minimal()

      **Part (f): Equal variance check**

      .. code-block:: r

         # SD ratio rule of thumb
         sd_ratio <- max(s) / min(s)
         cat("SD ratio:", round(sd_ratio, 4), "\n")
         cat("Equal variance assumption satisfied?", 
             ifelse(sd_ratio <= 2, "Yes", "No"), "\n")

      **Part (g): What to look for in each plot**

      *Side-by-side boxplots:*
      
      - **Equal variances**: Boxes should have similar heights (IQRs) and whisker lengths
      - **Separation of means**: Look for overlap/separation between groups to predict ANOVA outcome
      - **Outliers**: Identify potential outliers (points beyond whiskers)

      *Effects plot:*
      
      - Shows the **pattern of group means** clearly
      - Useful for predicting whether ANOVA will be significant
      - Large differences in height suggest group means differ

      *Faceted histograms:*
      
      - **Normality**: Each histogram should be approximately bell-shaped
      - **Kernel density (red)** should roughly follow the **normal density (blue)**
      - Look for severe skewness or multimodality within groups

      *Faceted QQ-plots:*
      
      - **Normality**: Points should fall approximately along the diagonal reference line
      - **Deviations at tails**: Suggest heavy or light tails
      - **S-shaped pattern**: Suggests skewness
      - **Systematic curvature**: Suggests non-normality

      *SD ratio:*
      
      - If max(s)/min(s) ‚â§ 2, the equal variance assumption is reasonable
      - If ratio > 2, consider alternative methods (Welch's ANOVA, beyond STAT 350)

----

.. admonition:: Exercise 6: Interpreting Side-by-Side Boxplots
   :class: note

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch12-1/fig2_boxplots_overlap.png
      :alt: Side-by-side boxplots for three scenarios
      :align: center
      :width: 95%

      **Figure 1**: Side-by-side boxplots from three different studies comparing k = 4 groups.

   For each scenario (A, B, C) shown in Figure 1:

   a. Would you expect to reject :math:`H_0` in the ANOVA F-test? Explain your reasoning based on the overlap of boxplots.

   b. Are there any concerns about the equal variance assumption?

   c. Are there any potential outliers that might affect the analysis?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Scenario A:**

      a. **Likely to reject H‚ÇÄ**. The boxplots show minimal overlap‚ÄîGroup 4 is clearly separated from Groups 1-3, and Group 1 appears lower than Groups 2-3. The between-group variability appears large relative to within-group variability.

      b. **Equal variance appears reasonable**. All four boxplots have similar heights (IQR) and whisker lengths, suggesting comparable spread across groups.

      c. **One potential outlier** visible in Group 2 (marked with a point above the upper whisker). Should investigate this observation.

      **Scenario B:**

      a. **Unlikely to reject H‚ÇÄ**. The boxplots show substantial overlap‚Äîall four groups span similar ranges with medians close together. The between-group variability appears small relative to within-group variability.

      b. **Equal variance appears reasonable**. The spreads are similar across all groups.

      c. **No obvious outliers** visible.

      **Scenario C:**

      a. **May or may not reject H‚ÇÄ**. Some separation exists (Groups 1 and 4 appear different), but there's also substantial overlap among some groups. The result could go either way.

      b. **Potential concern about equal variance**. Group 3 appears to have much larger spread (taller box, longer whiskers) than the other groups. Should check the ratio of standard deviations.

      c. **Potential outlier** in Group 1 (below lower whisker).

      **Key insight**: Visual assessment from boxplots helps predict ANOVA results:
      
      - Large separation between boxes with small within-group spread ‚Üí likely significant
      - Substantial overlap with similar spreads ‚Üí likely not significant
      - Always check assumptions before drawing formal conclusions

----

.. admonition:: Exercise 7: Why "Analysis of Variance"?
   :class: note

   A common source of confusion is why a test for comparing *means* is called Analysis of *Variance*.

   a. Explain in your own words why comparing variabilities (between-group vs. within-group) helps us determine whether population means differ.

   b. Consider two scenarios with the same group sample means: :math:`\bar{x}_1 = 10`, :math:`\bar{x}_2 = 15`, :math:`\bar{x}_3 = 20`. In Scenario I, each group has :math:`s = 2`. In Scenario II, each group has :math:`s = 8`. Which scenario provides stronger evidence that the population means differ? Explain.

   c. If :math:`H_0: \mu_1 = \mu_2 = ... = \mu_k` is true, what would you expect the ratio MSA/MSE to be approximately equal to? Why?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Conceptual explanation**

      When comparing group means, the observed differences :math:`\bar{x}_i - \bar{x}_j` could arise from:
      
      1. **True differences** in population means (what we want to detect)
      2. **Random sampling variability** (noise)

      To determine if observed differences are "real," we must compare them to what we'd expect from random variation alone. This is exactly what ANOVA does:

      - **Between-group variability (MSA)** captures how much the group means vary from the overall mean
      - **Within-group variability (MSE)** captures the baseline "noise" level within each group

      If the between-group variability is much larger than expected from noise alone, we conclude the means truly differ.

      **Part (b): Comparing scenarios**

      **Scenario I (s = 2) provides much stronger evidence** that population means differ.

      - In Scenario I, the spread within each group is small (s = 2), so the observed differences of 5 units between consecutive means is large relative to the noise.
      - In Scenario II, the spread within each group is large (s = 8), so the same 5-unit differences could easily be due to random sampling variability.

      Think of it as a signal-to-noise ratio: same "signal" (mean differences) but different "noise" levels leads to different conclusions.

      **Part (c): Expected F-ratio under H‚ÇÄ**

      Under :math:`H_0`, we expect :math:`F = \frac{MSA}{MSE} \approx 1`.

      This is because:
      
      - When all population means are equal, MSA estimates œÉ¬≤ (with some sampling variability)
      - MSE always estimates œÉ¬≤ (regardless of whether H‚ÇÄ is true)
      - The ratio of two quantities both estimating œÉ¬≤ should be approximately 1

      Large values of F (substantially greater than 1) suggest MSA is estimating something larger than œÉ¬≤, which happens when population means differ.

----

.. admonition:: Exercise 8: The Multiple Testing Problem
   :class: note

   A researcher wants to compare mean response times across k = 5 different algorithm implementations.

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch12-1/fig1_fwer_inflation.png
      :alt: Family-wise error rate inflation
      :align: center
      :width: 80%

      **Figure**: Family-wise error rate (FWER) increases rapidly with the number of groups when using multiple t-tests at Œ± = 0.05.

   a. How many pairwise comparisons would be needed to compare all pairs of algorithms?

   b. If the researcher performs each pairwise comparison as a separate two-sample t-test at Œ± = 0.05, what is the probability of making at least one Type I error (assuming all null hypotheses are true and tests are independent)?

   c. Why does ANOVA provide a better approach than multiple t-tests?

   d. For k = 10 groups, how many pairwise comparisons are needed? What would the family-wise error rate be if using individual Œ± = 0.05 tests?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Number of comparisons for k = 5**

      .. math::
         c = \binom{k}{2} = \binom{5}{2} = \frac{5!}{2! \cdot 3!} = \frac{5 \times 4}{2} = 10 \text{ comparisons}

      **Part (b): Family-wise error rate**

      Assuming independence, the probability of at least one Type I error is:

      .. math::
         \alpha_{overall} = 1 - (1 - \alpha_{single})^c = 1 - (1 - 0.05)^{10} = 1 - 0.95^{10}

      .. math::
         = 1 - 0.5987 = 0.4013 \approx 40.1\%

      Even though each individual test has only a 5% false positive rate, the overall probability of making at least one false positive is about 40%!

      **Part (c): Advantages of ANOVA**

      1. **Controls Type I error**: ANOVA tests all means simultaneously with a single test at the specified Œ± level
      2. **Efficiency**: One test instead of many
      3. **Proper framework**: If ANOVA is significant, we can then use multiple comparison procedures (Tukey, Bonferroni) that properly control the family-wise error rate
      4. **Uses pooled variance**: More efficient estimation of œÉ¬≤ by combining information from all groups

      **Part (d): For k = 10 groups**

      Number of comparisons:

      .. math::
         c = \binom{10}{2} = \frac{10 \times 9}{2} = 45 \text{ comparisons}

      Family-wise error rate:

      .. math::
         \alpha_{overall} = 1 - (0.95)^{45} = 1 - 0.0994 = 0.9006 \approx 90\%

      With 45 separate tests, there's about a 90% chance of at least one false positive‚Äîmaking the approach essentially meaningless for controlling errors.

      **R verification:**

      .. code-block:: r

         # Part (a) and (b)
         k <- 5
         c <- choose(k, 2)  # 10
         alpha_overall <- 1 - (1 - 0.05)^c  # 0.4013

         # Part (d)
         k <- 10
         c <- choose(k, 2)  # 45
         alpha_overall <- 1 - (1 - 0.05)^c  # 0.9006

----

.. admonition:: Exercise 9: True/False Conceptual Questions
   :class: note

   Determine whether each statement is True or False. Provide a brief justification.

   1. In ANOVA, if we reject :math:`H_0`, we can conclude that all population means are different from each other.

   2. The ANOVA F-test requires that all group sample sizes be equal.

   3. If the boxplots for all groups show similar medians but very different spreads, the equal variance assumption may be violated.

   4. The alternative hypothesis in one-way ANOVA can be directional (e.g., :math:`\mu_1 < \mu_2 < \mu_3`).

   5. If sample sizes are large (n > 40 per group), ANOVA is robust to moderate departures from normality.

   6. ANOVA with k = 2 groups is equivalent to a two-sample t-test under certain conditions.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **1. False**

      Rejecting :math:`H_0` only tells us that **at least one** population mean differs from the others. It could be that only one mean is different, or some are different, or all are different. Multiple comparison procedures are needed to identify which specific means differ.

      **2. False**

      ANOVA does **not** require equal sample sizes (balanced design). The formulas accommodate unequal :math:`n_i` values. However, equal sample sizes provide some advantages: simpler calculations, more robust to assumption violations, and optimal power.

      **3. True**

      The equal variance assumption requires :math:`\sigma_1^2 = \sigma_2^2 = ... = \sigma_k^2`. Different spreads in boxplots suggest this assumption may be violated. We check formally using the ratio rule: :math:`\max(s_i)/\min(s_i) \leq 2`.

      **4. False**

      The ANOVA F-test is inherently **non-directional** (two-sided). The alternative hypothesis is always "at least one mean differs"‚Äîwe cannot specify the direction or pattern of differences in the standard ANOVA framework.

      **5. True**

      Like the t-test, ANOVA is robust to moderate violations of the normality assumption when sample sizes are large, due to the Central Limit Theorem. The F-test statistic's distribution is less affected by non-normality when n is large.

      **6. True**

      When k = 2, ANOVA is equivalent to a **two-sided pooled two-sample t-test** with :math:`\Delta_0 = 0`. Specifically, :math:`F_{TS} = t_{TS}^2` and the p-values are identical. This equivalence holds only for the equal variance (pooled) case and two-sided alternative.

----

.. admonition:: Exercise 10: Designing an ANOVA Study
   :class: note

   A biomedical engineering team wants to compare the effectiveness of 4 different stent designs in maintaining arterial blood flow. They plan to conduct an experiment using a laboratory flow simulation system.

   a. Identify the factor variable and its levels.

   b. Identify an appropriate quantitative response variable.

   c. Write the null and alternative hypotheses.

   d. What sample size considerations should the team address?

   e. How could the team ensure the independence assumption is satisfied?

   f. What potential issues might arise with the equal variance assumption, and how could they check it?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Factor variable and levels**

      - **Factor**: Stent design
      - **Levels**: Design A, Design B, Design C, Design D (k = 4 levels)
      - This is a categorical variable with 4 categories

      **Part (b): Response variable**

      Several quantitative response variables could be appropriate:
      
      - Mean blood flow rate (mL/min)
      - Flow resistance (pressure drop per unit flow)
      - Flow uniformity index
      - Maximum flow velocity achieved

      The choice depends on which aspect of "effectiveness" is most clinically relevant.

      **Part (c): Hypotheses**

      Let :math:`\mu_i` = true mean blood flow rate for Stent Design i, for i = A, B, C, D.

      .. math::
         &H_0: \mu_A = \mu_B = \mu_C = \mu_D\\
         &H_a: \text{At least one } \mu_i \text{ is different from the others}

      **Part (d): Sample size considerations**

      - **Power**: Larger samples increase power to detect true differences
      - **Effect size**: If differences between stents are expected to be small, larger samples are needed
      - **Variability**: Higher within-group variability requires larger samples
      - **Practical constraints**: Cost, time, and availability of simulation resources
      - **Balance**: Equal sample sizes per group are ideal but not required
      - **Rule of thumb**: At least 10-20 observations per group for adequate power

      **Part (e): Ensuring independence**

      - Use a **new simulation setup** for each trial (don't reuse configurations)
      - **Randomize** the order in which stent designs are tested to avoid systematic effects
      - Ensure **different arterial models** or simulation runs for each measurement
      - Avoid having the same researcher consistently test the same stent design (potential bias)
      - Check for **time-dependent effects** (e.g., equipment drift) and randomize to mitigate

      **Part (f): Equal variance concerns**

      *Potential issues*:
      
      - Different stent designs might produce inherently different variability in flow
      - Manufacturing precision might vary by design complexity
      - Some designs might perform consistently while others show variable results

      *How to check*:
      
      - Calculate sample standard deviation for each group
      - Apply the rule of thumb: :math:`\max(s_i)/\min(s_i) \leq 2`
      - Examine side-by-side boxplots for similar spreads
      - If violated, consider data transformation or Welch's ANOVA (beyond STAT 350)

----

Additional Practice Problems
----------------------------

**True/False Questions** (1 point each)

1. The ANOVA F-test can determine which specific group means are different from each other.

   ‚ìâ or ‚íª

2. If all sample means are identical (:math:`\bar{x}_1 = \bar{x}_2 = ... = \bar{x}_k`), the F-test statistic will equal exactly 0.

   ‚ìâ or ‚íª

3. The notation :math:`\bar{x}_{3.}` represents the mean of the third observation across all groups.

   ‚ìâ or ‚íª

4. ANOVA assumes that each group is sampled independently from its respective population.

   ‚ìâ or ‚íª

5. If an ANOVA study has k = 6 groups with 10 observations each, the total sample size is n = 60.

   ‚ìâ or ‚íª

6. The equal variance assumption can be checked by computing the ratio of the largest to smallest sample standard deviations.

   ‚ìâ or ‚íª

**Multiple Choice Questions** (2 points each)

7. In ANOVA notation, :math:`x_{2,7}` represents:

   ‚í∂ The 2nd observation in the 7th group
   
   ‚í∑ The 7th observation in the 2nd group
   
   ‚í∏ The product of 2 and 7
   
   ‚íπ The sum of observations in groups 2 and 7

8. For a study comparing k = 4 groups, the alternative hypothesis is:

   ‚í∂ :math:`H_a: \mu_1 \neq \mu_2 \neq \mu_3 \neq \mu_4`
   
   ‚í∑ :math:`H_a: \mu_1 = \mu_2 = \mu_3 = \mu_4`
   
   ‚í∏ :math:`H_a:` At least one :math:`\mu_i` is different from the others
   
   ‚íπ :math:`H_a: \mu_1 > \mu_2 > \mu_3 > \mu_4`

9. Which is NOT an assumption of one-way ANOVA?

   ‚í∂ Independent random samples from each population
   
   ‚í∑ Normal distributions (or large samples)
   
   ‚í∏ Equal population variances
   
   ‚íπ Equal sample sizes from each population

10. The rule of thumb for checking equal variances requires:

    ‚í∂ :math:`\max(s_i^2)/\min(s_i^2) \leq 2`
    
    ‚í∑ :math:`\max(s_i)/\min(s_i) \leq 2`
    
    ‚í∏ :math:`\max(\bar{x}_i)/\min(\bar{x}_i) \leq 2`
    
    ‚íπ All sample variances within 2 units of each other

11. How many pairwise comparisons are possible with k = 7 groups?

    ‚í∂ 7
    
    ‚í∑ 14
    
    ‚í∏ 21
    
    ‚íπ 49

12. The overall sample mean :math:`\bar{x}_{..}` is calculated as:

    ‚í∂ The simple average of group means
    
    ‚í∑ A weighted average of group means, weighted by sample sizes
    
    ‚í∏ The median of all observations
    
    ‚íπ The sum of all group means

.. dropdown:: Answers to Practice Problems
   :class-container: sd-border-success

   **True/False Answers:**

   1. **False** ‚Äî The F-test only determines if at least one mean differs; multiple comparison procedures identify which specific means differ.

   2. **True** ‚Äî If all :math:`\bar{x}_{i.} = \bar{x}_{..}`, then SSA = 0, so MSA = 0, and F = 0/MSE = 0.

   3. **False** ‚Äî :math:`\bar{x}_{3.}` represents the mean of Group 3 (the dot replaces the j subscript, indicating averaging over all observations in that group).

   4. **True** ‚Äî Independence within and between samples is a fundamental ANOVA assumption.

   5. **True** ‚Äî Total sample size n = 6 √ó 10 = 60.

   6. **True** ‚Äî We check max(s)/min(s) ‚â§ 2 using sample standard deviations. If the ratio is at most 2, the equal variance assumption is considered reasonable.

   **Multiple Choice Answers:**

   7. **‚í∑** ‚Äî First subscript is group, second is observation within group.

   8. **‚í∏** ‚Äî The alternative states at least one mean differs; we don't specify which or how.

   9. **‚íπ** ‚Äî Equal sample sizes are NOT required for ANOVA; unbalanced designs are allowed.

   10. **‚í∑** ‚Äî The rule uses standard deviations, not variances or means.

   11. **‚í∏** ‚Äî :math:`\binom{7}{2} = \frac{7 \times 6}{2} = 21`

   12. **‚í∑** ‚Äî :math:`\bar{x}_{..} = \frac{\sum n_i \bar{x}_{i.}}{n}`, a weighted average with weights proportional to sample sizes.