.. _9-5-ci-cb-sigma-unknown:

.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch7-1">
      <iframe
         id="video-ch7-1"
         title="STAT 350 â€“ Chapter 7.1 Statistics and Sampling Distributions Video"
         src="https://www.youtube.com/embed/3ZhAnYsmILo?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

.. admonition:: Slides ðŸ“Š
   :class: tip

   `Download Chapter 9 slides (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/
   Chapter%209%20Confidence%20Intervals/L19-21%20Confidence%20Intervals%20for%20Single%20Sample_AC.pptx>`_

Confidence Intervals and Bounds When Ïƒ is Unknown
==============================================================================================

So far, we developed confidence regions under the 
simplifying but unrealistic assumption that the population standard deviation :math:`\sigma` is known. 
**In practice, we rarely know** :math:`\sigma` **and must estimate it.**

This creates a fundamental challenge. Using a sample standard deviation :math:`S` in place of the unknown :math:`\sigma` 
introduces **additional uncertainty** that must be accounted for. 
The standard normal distribution is no longer appropriate because it does not capture this 
extra layer of uncertainty.

The solution to this problem comes from a distribution developed by William Sealy Gosset in the 
early 1900s: the **Student's t distribution**.

.. admonition:: Road Map ðŸ§­
   :class: important
   
   * Recognize that in most practical scenarios, :math:`\sigma` **is unknown**
     and must be estimated by :math:`S`.
   * Understand that when :math:`S` replaces :math:`\sigma`, the new pivotal quantity follows a *t*-**distribution**.
   * Derive confidence intervals and bounds based on the new *t*-distribution.
   * Understand the basic properties of *t*-distributions.
   * Learn what it means for a statistical procedure to be **robust**. Recognize the requirements for
     *t*-based procedures to be robust.


William Gosset and the Birth of Student's *t*-Distribution
-----------------------------------------------------------------

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/William-Gosset.jpg
   :alt: Portrait of William Sealy Gosset (Student)
   :figwidth: 35%
   :align: right

   William S. Gosset (1876-1937)

In 1908, William Sealy Gosset, a chemist and statistician employed by the Guinness brewery in Dublin, 
Ireland, published a paper titled "The Probable Error of a Mean" in the journal *Biometrika*. 
Due to Guinness company policy that prohibited employees from publishing their research, Gosset published 
under the pseudonym "Student"â€”leading to the now-famous *Student's* *t*-distribution.

Gosset's work at Guinness involved quality control for beer production. He needed statistical methods that 
worked reliably with small samples, as testing large quantities of beer would have been wasteful. 
Specifically, he faced the challenge of making inferences about a population mean when the population 
standard deviation was unknown and had to be estimated from the same limited sample.

His mathematical solutionâ€”the *t*-distributionâ€”accounts for the added uncertainty of estimating :math:`\sigma`
with :math:`S`. This breakthrough has become one of the most widely used 
statistical tools across virtually all fields of scientific inquiry.

The *t*-Statistic and Its Distribution
---------------------------------------

To construct confidence regions, we have so far relied on the fact that the 
pivotal quantity :math:`\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}` 
follows a standard normal distribution under certain assumptions. When 
the unknown :math:`\sigma` is replaced by
its estimator :math:`S`, however, the resulting statistic

.. math::
   T_{n-1} = \frac{\bar{X} - \mu}{S/\sqrt{n}}

**no longer follows a standard normal distribution**. Instead, it follows a
*t*-**distribution**. 

The *t*-distribution is a family of continuous distributions parameterized by
:math:`\nu` (Greek letter "nu"; also called the **degrees of freedom or df**). 
A *t*-statistic constructed using a sample of size :math:`n` has
:math:`\nu = n-1`. The subscript in :math:`T_{n-1}` reflects this fact, although it is often
ommitted when the context makes it clear or when the detail is unnecessary.

.. admonition:: Standardization, Studentization, and Pivotal Quantity
   :class: important

   So far, we have called the transformation of a general random variable :math:`X` into 
   :math:`\frac{X-\mu_X}{\sigma_X}` the **standardization** of :math:`X`. 
   When the sample standard deviation :math:`S_X` is used instead of :math:`\sigma_X`, giving

   .. math:: 
      \frac{X-\mu_X}{S_X},

   we call this the **studentization** of :math:`X`.

   Both transformations are variants of **pivotal quantities**, which are functions of :math:`X`
   constructed so that their distributions do not depend on the unkown parameters of :math:`X`. 

Properties of *t*-Distributions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/t-pdfs.png
   :alt: Student t density with various df overlaying the standard normal
   :figwidth: 60%
   :align: center

   *t*-densities with various degrees of freedom; the curve corresponding to
   :math:`+\infty` is the standard normal PDF.

1. A *t*-distribution is **symmetric around zero**, similar to the standard normal distribution.
2. It has **heavier tails** than the standard normal distribution, 
   reflecting the additional uncertainty from estimating :math:`\sigma`. 
   This means that a *t*-distribution is **always more spread out** than the standard normal distribution
   for any finite degrees of freedom.
3. The smaller the sample size, the heavier the tails. 
   The distribution **approaches the standard normal distribution** as the degrees of freedom increase.

.. admonition:: The PDF of a *t*-distribution
   :class: important 

   The probability density function of a *t*-distribution is given by:

   .. math::
      f_T(t) = \frac{1}{\sqrt{\nu\pi}} \frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})} \left(1 + \frac{t^2}{\nu}\right)^{-(\nu+1)/2}

   Where :math:`\Gamma`, the gamma function, is a generalization of the factorial function.
   Just like normal distributions, we rely on tables or software to compute probabilities
   and percentiles involving *t*-distributions.

Deriving *t*-Based Confidence Regions
--------------------------------------------------------

Preliminaries and Assumptions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The derivation of *t*-based confidence intervals requires a similar set of assumptions as
before. The only difference is that :math:`\sigma` is now unknown.

1. The data :math:`X_1, X_2, \cdots, X_n` must be an *iid* sample 
   from a population with mean :math:`\mu` and variance :math:`\sigma^2.`
2. Either the population is normally distributed, or we have sufficiently large :math:`n`
   for the CLT to hold.
3. Both :math:`\mu` and :math:`\sigma` are unknown.

We also need to define the *t*-critical values. A *t*-critical value, denoted :math:`t_{\alpha/2, \nu}`,
is the point on the *t*-distribution with :math:`\nu` degrees of freedom such that its
upper-tail area equals :math:`\alpha/2`. The notation includes an additional subscript 
for the degrees of freedom, since its location also depends on
the specific *t*-distribution on which it is defined.

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/CI-t-critical-value-labeled.png 
   :figwidth: 90%
   :align: center 
   :alt: Locations of t-critical values on a t density curve

Derivation of the Confidence Interval
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Similar to the case with known :math:`\sigma`, we derive a confidence interval for :math:`\mu` using 
the pivotal method. For the degrees of freedom :math:`n-1`, the following statement is true by
the definition of :math:`t_{\alpha/2, n-1}`:

.. math::
   P\left(-t_{\alpha/2, n-1} < T_{n-1} < t_{\alpha/2, n-1}\right) = C.

Replace :math:`T_{n-1}` with the new pivotal quantity:

.. math::
   P\left(-t_{\alpha/2, n-1} < \frac{\bar{X} - \mu}{S/\sqrt{n}} < t_{\alpha/2, n-1}\right) = C.

Through algebraic pivoting, we isolate :math:`\mu` to obtain:

.. math::
   P\left( \bar{X} - t_{\alpha/2, n-1} \frac{S}{\sqrt{n}}< \mu < \bar{X} + t_{\alpha/2, n-1} \frac{S}{\sqrt{n}}\right) = C.

Therefore, the :math:`C\cdot100\%` confidence interval is:

.. math::
   \bar{X} \pm t_{\alpha/2, n-1} \frac{S}{\sqrt{n}}.

Summary of *t*-Based Confidence Intervals and Bounds
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We leave it to the reader to work out the details of deriving the upper and lower
confidence bounds under a *t*-distribution. The results follow the same pattern as their 
:math:`z` equivalents; the margin of error will be computed with 
a smaller critical value :math:`t_{\alpha, n-1}` instead of :math:`t_{\alpha/2, n-1}`.

In summary, when we have :math:`\bar{x}` and :math:`s` from an observed sample,
we use the following formulas to compute confidence regions.


.. flat-table::
   :header-rows: 1
   :widths: 2 3
   :align: center
   :width: 70%

   * - :cspan:`1` Confidence Regions When :math:`\sigma` Is Unkonwn

   * - **Confidence Interval**
     - .. math::
         \bar{x} \pm t_{\alpha/2, n-1} \frac{s}{\sqrt{n}}

   * - **Lower Confidence Bound**
     - .. math::
         \bar{x} - t_{\alpha, n-1} \frac{s}{\sqrt{n}}

   * - **Upper Confidence Bound**
     - .. math::
         \bar{x} + t_{\alpha, n-1} \frac{s}{\sqrt{n}}








.. admonition:: Example ðŸ’¡: Cholesterol Reduction Study

   A pharmaceutical company is testing a new drug designed to lower LDL cholesterol levels. 
   In a clinical trial, 15 patients with high cholesterol received the drug for eight weeks, 
   and the reduction in their LDL cholesterol (in mg/dL) was measured.

   The sample mean reduction was :math:`\bar{x} = 23.4` mg/dL with a sample standard deviation 
   of :math:`s = 6.8` mg/dL. Construct a 95% confidence interval for the true mean reduction :math:`\mu`.

   **Step 1**: Identify the key information

      - Sample size: :math:`n = 15`
      - Sample mean: :math:`\bar{x} = 23.4` mg/dL
      - Sample standard deviation: :math:`s = 6.8` mg/dL
      - Confidence level: :math:`95\%` (:math:`\alpha = 0.05`)
      - Degrees of freedom: :math:`\nu = n - 1 = 14`

   **Step 2**: Find the critical value
      
   .. math::
      t_{0.025, 14} = 2.145
   
   .. code-block:: r

      qt(0.025, df = 14, lower.tail=FALSE)  # Returns 2.145


   **Step 3**: Calculate the margin of error

   .. math::
      \text{ME} = t_{0.025, 14} \cdot \frac{s}{\sqrt{n}} = 2.145 \cdot \frac{6.8}{\sqrt{15}} \approx 3.76 \text{ mg/dL}

   **Step 4**: Construct the confidence interval

   .. math::
      \bar{x} \pm \text{ME} = 23.4 \pm 3.76 = [19.64, 27.16] \text{ mg/dL}

   **Interpretation**: We are 95% confident that the true mean reduction in LDL cholesterol with 
   this drug is captured by the region between 19.64 and 27.16 mg/dL.

The Effect of Sample Size on *t*-Confidence Regions
----------------------------------------------------------

As with :math:`z`-confidence regions, a large :math:`n` makes :math:`t`-confidence regions more
precise in general. However, the ways in which :math:`n` influences this phenomenon are more multifaceted 
for *t*-based methods:

1. A larger :math:`n` reduces the true standard error, :math:`\sigma/n`.
2. Although the true standard error is unknown, its estimator :math:`S/n` targets it
   more accurately with larger :math:`n`.
3. The critical value itself decreases as :math:`n` increases, which further narrows the confidence region.

To see how the third point holds, see :numref:`dfs-comparison` below:

.. _dfs-comparison:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/dfs-comparison.png 
   :figwidth: 70%
   :align: center 
   :alt: t critical values with different degrees of freedom

   Two-sided *t*-critical values for :math:`\alpha = 0.05` with different degrees of freedom

In :numref:`dfs-comparison`, the upper tails of two *t*-distributions are compared: one with
:math:`df=n-1=99` and the other with :math:`df=n-1=9`. Recall that higher degrees of freedom
(and larger sample size) are associated with a lighter tail on a *t*-distribution.
As :math:`n` grows from 10 to 100, the difference in tail weight causes the critical value
to **move closer to the center (zero)** in order to maintain an area of :math:`\alpha/2` on its right.

In general, for the same confidence level and any two sample sizes :math:`n_1 < n_2`, 
it always holds that 

.. math::
   t_{\alpha/2, n_1-1} > t_{\alpha/2, n_2-1}.

A smaller critical value leads to a smaller margin of error if :math:`s` is held constant, 
which in turn results in a more precise (narrower) confidence region.
This relationship does not hold strictly in practice since :math:`S` fluctuates with data,
but the overall tendency remains.

Comparison with :math:`z`-Confidence Regions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The above result implies that the :math:`z`-confidence regionsâ€”
which can loosely be considered *t*-confidence regions with an
"infinite" dataset for sample variance computationâ€”are more precise on average than their *t*-based parallels.

When is a :math:`t`-Confidence Region Appropriate?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In practice, the true variance :math:`\sigma^2` is rarely known, leaving *t*-procedures 
as our only option. On the rare occasions when :math:`\sigma^2` is known, it is
always preferabale to use this true information.

Sample Size Planning When Ïƒ Is Unknown
----------------------------------------

Sample size planning is more challenging when :math:`\sigma` is unknown. 
Suppose we want :math:`n` such that

.. math::
   \text{ME} = t_{\alpha/2, n-1} \frac{s}{\sqrt{n}} \leq ME_{max}

for some given maximum margin of error, :math:`ME_{max}`. 
By taking similar steps as in Chapter 9.3.2, we have 

.. math::
   n \geq \left(\frac{t_{\alpha/2, n-1}s}{ME_{max}}\right)^2.

We now see that the problem is circular. To determine :math:`n`, we need the :math:`t`-critical value, 
which depends on :math:`n`. Additionally, we need a value for :math:`s`, which we don't 
have before collecting data. To address this issue, we use an iterative approach involving the following steps:

1. **Obtain a planning value** :math:`s_*`. This can be done by

   - Using :math:`s` from a pilot study or previous research,
   - Making an educated guess based on the expected range, or
   - Using a conservative upper bound when uncertainty is high.

2. **Update** :math:`n` **iteratively**.
   
   - Start with an initial guess using the :math:`z`-critical value: 
     :math:`n_0 = \left(\frac{z_{\alpha/2} s_*}{ME_{max}}\right)^2`.
   - Calculate the *t*-critical value using :math:`df = n_0 - 1`.
   - Recalculate :math:`n` using the *t*-critical value.
   - Repeat until convergence.

This process typically converges quickly, often in just a few iterations.

Robustness of the :math:`t`-Procedures
------------------------------------------

A statistical procedure is considered **robust** if it performs reasonably well even when its 
assumptions are somewhat violated. The :math:`t`-procedures show good robustness against moderate 
departures from normality, especially as sample size increases.

.. flat-table:: 
   :header-rows: 1
   :widths: 1 4

   * - :cspan:`1` Guidelines for Using *t*-Procedures When Normality May Not Hold

   * - :math:`n < 15`
     - The population distribution should be approximately normal. 
       Check the sample data with normal probability plots.

   * - :math:`15 â‰¤ n < 40`
     - A :math:`t`-procedure works well with some mild skewness. Avoid using with strongly skewed data 
       or data containing outliers.

   * - :math:`n â‰¥ 40`
     - A :math:`t`-procedure is generally reliable even with moderately skewed distributions, 
       thanks to the Central Limit Theorem.

Regardless of sample size, the procedure is sensitive to outliers, which can strongly 
influence both :math:`\bar{x}` and :math:`s`. **Always inspect your data for outliers** 
before applying a :math:`t`-procedure.

Bringing It All Together
-----------------------------

.. admonition:: Key Takeaways ðŸ“
   :class: important

   * The **Student's** *t*-**distribution** provides the appropriate framework for quantifying uncertainty 
     about a population mean when the population standard deviation is unknown.
   * The pivotal quantity :math:`T_{n-1}= \frac{\bar{X}-\mu}{S/\sqrt{n}}` now follows a *t*-distribution 
     with :math:`n-1` degrees of freedom.
   * The resulting confidence regions account for the additional uncertainty in estimating :math:`\sigma`,
     and are **wider than their** :math:`z` **parallels on average**.
   * The *t*-procedures are **robust to moderate violations of the normality assumption**. The robustness grows with 
     the sample size.

Exercises
~~~~~~~~~~~~~

1. A quality control engineer wants to estimate the mean tensile strength of steel cables. 
   A sample of 25 cables yields a mean strength of 3450 N with a standard deviation of 120 N. 
   Construct a 99% confidence interval for the mean strength.

2. A pilot study with 8 observations yielded a sample standard deviation of :math:`s = 15`. 
   If a researcher wants to estimate the population mean with a margin of error of no more 
   than 5 units at 95% confidence, how many observations should be planned for the full study?


.. _9-5-exercises:

=============================================================
Exercises: CI and Confidence Bounds (Ïƒ Unknown)
=============================================================

.. contents:: Table of Contents
   :local:
   :depth: 2

.. admonition:: Learning Objectives ðŸŽ¯
   :class: info

   These exercises will help you:

   â€¢ Recognize when to use the **t-distribution** instead of the z-distribution
   â€¢ Find **t-critical values** for various confidence levels and degrees of freedom
   â€¢ Construct **confidence intervals** for Î¼ when Ïƒ is unknown
   â€¢ Construct **confidence bounds** (UCB/LCB) when Ïƒ is unknown
   â€¢ Understand the relationship between **t and z** as df increases
   â€¢ Assess **robustness** of t-procedures to non-normality

.. admonition:: Key Formulas ðŸ“
   :class: tip

   **Confidence Interval for Î¼ (Ïƒ unknown)**:

   .. math::
      \bar{x} \pm t_{\alpha/2, n-1} \frac{s}{\sqrt{n}}

   **Confidence Bounds (Ïƒ unknown)**:

   .. math::
      UCB = \bar{x} + t_{\alpha, n-1} \frac{s}{\sqrt{n}} \qquad LCB = \bar{x} - t_{\alpha, n-1} \frac{s}{\sqrt{n}}

   **Degrees of freedom**: :math:`df = n - 1`

   **R Functions**:

   .. code-block:: r

      # t-critical values
      qt(alpha/2, df, lower.tail = FALSE)  # For CI
      qt(alpha, df, lower.tail = FALSE)    # For bounds
      
      # One-sample t-test with CI
      t.test(x, conf.level = 0.95)

Exercises
---------

.. admonition:: Exercise 1: t-Distribution Properties
   :class: note

   a. When do we use the t-distribution instead of the z-distribution for inference about Î¼?

   b. What are the degrees of freedom for a one-sample t-procedure with sample size n?

   c. How does the shape of the t-distribution compare to the standard normal? What causes this difference?

   d. As degrees of freedom increase, what happens to the t-distribution?

   e. Find :math:`t_{0.025, 15}` and :math:`z_{0.025}`. Which is larger? Why?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): When to use t-distribution**

      Use the t-distribution when:
      
      - Making inference about the population mean Î¼
      - The population standard deviation Ïƒ is **unknown** and must be estimated by s
      - The underlying population is approximately normal (or n is large enough for CLT)

      **Part (b): Degrees of freedom**

      For a one-sample t-procedure: :math:`df = n - 1`

      **Part (c): Shape comparison**

      The t-distribution is:
      
      - Symmetric and bell-shaped like the normal
      - **Heavier tails** than the standard normal (more probability in the extremes)
      - This occurs because using s instead of Ïƒ introduces additional uncertainty

      **Part (d): As df increases**

      As df â†’ âˆž, the t-distribution approaches the standard normal distribution. 

      Rule of thumb: By df â‰ˆ 30, t-critical values are close to z-critical values for most practical purposes. By df â‰ˆ 100, the difference is negligible.

      **Part (e): Comparing critical values**

      .. code-block:: r

         qt(0.025, 15, lower.tail = FALSE)  # 2.131
         qnorm(0.025, lower.tail = FALSE)   # 1.960

      :math:`t_{0.025, 15} = 2.131 > z_{0.025} = 1.960`

      The t-critical value is larger because the heavier tails of the t-distribution require going further from the center to capture 97.5% of the probability.

----

.. admonition:: Exercise 2: Finding t-Critical Values
   :class: note

   Find the t-critical value for each scenario using R or a t-table.

   a. 95% CI, n = 10

   b. 95% CI, n = 25

   c. 99% CI, n = 20

   d. 90% UCB, n = 15

   e. 95% LCB, n = 30

   f. 95% CI, n = 200 (compare to z-critical value)

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): 95% CI, n = 10** (df = 9)

      :math:`t_{0.025, 9} = 2.262`

      **Part (b): 95% CI, n = 25** (df = 24)

      :math:`t_{0.025, 24} = 2.064`

      **Part (c): 99% CI, n = 20** (df = 19)

      :math:`t_{0.005, 19} = 2.861`

      **Part (d): 90% UCB, n = 15** (df = 14)

      :math:`t_{0.10, 14} = 1.345`

      **Part (e): 95% LCB, n = 30** (df = 29)

      :math:`t_{0.05, 29} = 1.699`

      **Part (f): 95% CI, n = 200** (df = 199)

      :math:`t_{0.025, 199} = 1.972` vs :math:`z_{0.025} = 1.960`

      Difference is only 0.012â€”practically identical.

      **R verification:**

      .. code-block:: r

         qt(0.025, 9, lower.tail = FALSE)    # 2.262
         qt(0.025, 24, lower.tail = FALSE)   # 2.064
         qt(0.005, 19, lower.tail = FALSE)   # 2.861
         qt(0.10, 14, lower.tail = FALSE)    # 1.345
         qt(0.05, 29, lower.tail = FALSE)    # 1.699
         qt(0.025, 199, lower.tail = FALSE)  # 1.972

----

.. admonition:: Exercise 3: Basic CI Construction (Ïƒ Unknown)
   :class: note

   A chemical engineer measures the purity of a batch of pharmaceutical product. A random sample of n = 12 measurements yields:

   - Sample mean: :math:`\bar{x} = 98.45\%`
   - Sample standard deviation: :math:`s = 1.23\%`

   a. Find the appropriate t-critical value for a 95% CI.

   b. Calculate the estimated standard error.

   c. Calculate the margin of error.

   d. Construct the 95% confidence interval.

   e. Interpret the interval in context.

   .. dropdown:: Solution
      :class-container: sd-border-success

      Given: n = 12, :math:`\bar{x} = 98.45\%`, s = 1.23%

      **Part (a): t-critical value**

      df = 12 - 1 = 11

      :math:`t_{0.025, 11} = 2.201`

      **Part (b): Estimated standard error**

      .. math::
         \widehat{SE} = \frac{s}{\sqrt{n}} = \frac{1.23}{\sqrt{12}} = 0.355\%

      **Part (c): Margin of error**

      .. math::
         ME = t_{0.025, 11} \times \widehat{SE} = 2.201 \times 0.355 = 0.781\%

      **Part (d): 95% CI**

      .. math::
         CI: 98.45 \pm 0.78 = (97.67\%, 99.23\%)

      **Part (e): Interpretation**

      We are 95% confident that the true mean purity of this pharmaceutical batch is between 97.67% and 99.23%.

      **R verification:**

      .. code-block:: r

         xbar <- 98.45; s <- 1.23; n <- 12
         df <- n - 1
         t_crit <- qt(0.025, df, lower.tail = FALSE)
         SE <- s / sqrt(n)
         ME <- t_crit * SE
         c(xbar - ME, xbar + ME)  # [97.67, 99.23]

----

.. admonition:: Exercise 4: CI from Raw Data
   :class: note

   A biomedical engineer tests the glucose response time (seconds) of a new blood glucose monitor. The measured times from 8 test samples are:

   .. code-block:: text

      4.2, 3.8, 4.5, 4.1, 3.9, 4.4, 4.0, 4.3

   a. Calculate :math:`\bar{x}` and :math:`s`.

   b. Construct a 95% confidence interval for the mean response time.

   c. The manufacturer claims the mean response time is 4.0 seconds. Is this claim consistent with your interval?

   d. Use R's ``t.test()`` function to verify your results.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Summary statistics**

      .. code-block:: r

         times <- c(4.2, 3.8, 4.5, 4.1, 3.9, 4.4, 4.0, 4.3)
         mean(times)  # 4.15
         sd(times)    # 0.2449

      :math:`\bar{x} = 4.15` seconds, :math:`s = 0.245` seconds

      **Part (b): 95% CI**

      n = 8, df = 7

      :math:`t_{0.025, 7} = 2.365`

      .. math::
         \widehat{SE} = \frac{0.245}{\sqrt{8}} = 0.0866

      .. math::
         ME = 2.365 \times 0.0866 = 0.205

      .. math::
         CI: 4.15 \pm 0.205 = (3.95, 4.35) \text{ seconds}

      **Part (c): Manufacturer's claim**

      The claimed value of 4.0 seconds is within the 95% CI (3.95, 4.35). Yes, the claim is consistent with the data.

      **Part (d): R verification**

      .. code-block:: r

         times <- c(4.2, 3.8, 4.5, 4.1, 3.9, 4.4, 4.0, 4.3)
         t.test(times, conf.level = 0.95)
         
         # Output includes:
         # 95 percent confidence interval:
         #  3.945 to 4.355
         # sample mean: 4.15

----

.. admonition:: Exercise 5: Confidence Bounds (Ïƒ Unknown)
   :class: note

   A quality engineer tests the breaking strength (in Newtons) of climbing rope. From n = 15 samples:

   - :math:`\bar{x} = 2850` N
   - :math:`s = 125` N

   a. Construct a 95% lower confidence bound for mean breaking strength.

   b. Safety standards require mean strength of at least 2700 N. Does the rope meet this standard?

   c. Construct a 95% upper confidence bound.

   d. Compare the bounds to a 95% two-sided CI. Which provides tighter information about each limit?

   .. dropdown:: Solution
      :class-container: sd-border-success

      Given: n = 15, :math:`\bar{x} = 2850` N, s = 125 N, df = 14

      :math:`\widehat{SE} = \frac{125}{\sqrt{15}} = 32.27` N

      **Part (a): 95% LCB**

      :math:`t_{0.05, 14} = 1.761`

      .. math::
         LCB = 2850 - 1.761 \times 32.27 = 2850 - 56.8 = 2793.2 \text{ N}

      **Part (b): Safety standard**

      LCB (2793.2 N) > 2700 N requirement. Yes, the rope meets the safety standard with 95% confidence.

      **Part (c): 95% UCB**

      .. math::
         UCB = 2850 + 1.761 \times 32.27 = 2850 + 56.8 = 2906.8 \text{ N}

      **Part (d): Comparison to CI**

      95% CI using :math:`t_{0.025, 14} = 2.145`:

      .. math::
         ME = 2.145 \times 32.27 = 69.2 \text{ N}

      .. math::
         CI: (2780.8, 2919.2) \text{ N}

      Comparison:

      - CI lower bound: 2780.8 N; LCB: 2793.2 N (LCB is tighter/higher)
      - CI upper bound: 2919.2 N; UCB: 2906.8 N (UCB is tighter/lower)

      One-sided bounds provide tighter limits on the side of interest because they use :math:`t_{\alpha}` instead of :math:`t_{\alpha/2}`, and :math:`t_{0.05} < t_{0.025}`. The UCB is tighter than the CI's upper bound; the LCB is tighter than the CI's lower bound.

----

.. admonition:: Exercise 6: Comparing z and t Intervals
   :class: note

   A sensor is tested with n = 20 measurements: :math:`\bar{x} = 152.3` units, :math:`s = 8.4` units. Compare:

   a. Compute a 95% CI using the t-distribution (correct method).

   b. Compute what the CI would be if you incorrectly used the z-distribution with s.

   c. Which interval is wider? Why is using z inappropriate here?

   d. At what sample size would the difference become negligible?

   .. dropdown:: Solution
      :class-container: sd-border-success

      Given: n = 20, :math:`\bar{x} = 152.3`, s = 8.4, df = 19

      :math:`\widehat{SE} = \frac{8.4}{\sqrt{20}} = 1.878`

      **Part (a): Correct t-interval**

      :math:`t_{0.025, 19} = 2.093`

      .. math::
         CI: 152.3 \pm 2.093 \times 1.878 = 152.3 \pm 3.93 = (148.37, 156.23)

      **Part (b): Incorrect z-interval**

      :math:`z_{0.025} = 1.96`

      .. math::
         CI: 152.3 \pm 1.96 \times 1.878 = 152.3 \pm 3.68 = (148.62, 155.98)

      **Part (c): Comparison**

      The t-interval (width = 7.86) is **wider** than the z-interval (width = 7.36).

      Using z is inappropriate because:
      
      - Ïƒ is unknown and estimated by s
      - Using s introduces additional variability not accounted for by z
      - The t-distribution properly inflates the critical value to compensate

      **Part (d): When difference becomes negligible**

      For df â‰ˆ 30, :math:`t_{0.025, 30} = 2.042` vs :math:`z_{0.025} = 1.96` (difference â‰ˆ 4%)

      For df â‰ˆ 100, :math:`t_{0.025, 100} = 1.984` vs :math:`z_{0.025} = 1.96` (difference â‰ˆ 1%)

      For most practical purposes, the difference is negligible when n > 100 or so.

----

.. admonition:: Exercise 7: Multiple Confidence Levels
   :class: note

   Using the data from Exercise 3 (n = 12, :math:`\bar{x} = 98.45\%`, s = 1.23%):

   a. Construct 90%, 95%, and 99% confidence intervals.

   b. Create a table showing confidence level, t-critical value, ME, and interval bounds.

   c. What pattern do you observe?

   d. If the specification requires purity above 97.5%, at which confidence level(s) can you confidently claim compliance?

   .. dropdown:: Solution
      :class-container: sd-border-success

      Given: n = 12, df = 11, :math:`\bar{x} = 98.45\%`, s = 1.23%, :math:`\widehat{SE} = 0.355\%`

      **Parts (a) and (b): Table**

      .. list-table::
         :header-rows: 1

         * - Confidence
           - :math:`t_{crit}`
           - ME
           - Lower
           - Upper
         * - 90%
           - 1.796
           - 0.638
           - 97.81
           - 99.09
         * - 95%
           - 2.201
           - 0.781
           - 97.67
           - 99.23
         * - 99%
           - 3.106
           - 1.103
           - 97.35
           - 99.55

      **Part (c): Pattern**

      As confidence level increases:
      
      - t-critical value increases
      - Margin of error increases
      - Interval width increases
      
      Higher confidence requires wider intervals.

      **Part (d): Compliance claim**

      Specification: purity > 97.5%

      - At 90%: Lower bound (97.81) > 97.5 âœ“
      - At 95%: Lower bound (97.67) > 97.5 âœ“
      - At 99%: Lower bound (97.35) < 97.5 âœ—

      Can claim compliance at 90% and 95% confidence, but not at 99%.

      **R verification:**

      .. code-block:: r

         xbar <- 98.45; s <- 1.23; n <- 12
         SE <- s / sqrt(n)
         
         conf_levels <- c(0.90, 0.95, 0.99)
         alpha <- 1 - conf_levels
         t_crits <- qt(alpha/2, df = 11, lower.tail = FALSE)
         MEs <- t_crits * SE
         
         data.frame(
           Confidence = paste0(conf_levels * 100, "%"),
           t_crit = round(t_crits, 3),
           ME = round(MEs, 3),
           Lower = round(xbar - MEs, 2),
           Upper = round(xbar + MEs, 2)
         )

----

.. admonition:: Exercise 8: Robustness to Non-Normality
   :class: note

   The t-procedures assume the population is approximately normal. However, they are somewhat robust to departures from normality.

   a. For what sample sizes are t-procedures most sensitive to non-normality?

   b. What features of a distribution are most problematic for t-procedures?

   c. Given a sample with n = 8 that contains one apparent outlier, what should you do before constructing a CI?

   d. A researcher has n = 50 observations from a mildly skewed population. Is it appropriate to use t-procedures?

   e. If you discover a problematic outlier after constructing a CI, what remedies might you consider?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Most sensitive sample sizes**

      t-procedures are most sensitive to non-normality when **n is small** (generally n < 15). With small samples, there's little averaging to invoke the CLT, so the normality assumption is more critical.

      Guidelines:
      
      - **n < 15**: Population should be approximately normal with no outliers. t-procedures are sensitive to non-normality at small sample sizes.
      - **15 â‰¤ n < 30**: Mild departures from normality are acceptable; avoid strong skewness or outliers
      - **n â‰¥ 30**: t-procedures are reasonably robust; even moderately skewed populations are okay
      - **n â‰¥ 50**: Very robust to non-normality due to CLT

      **Part (b): Problematic distribution features**

      - **Outliers**: Most problematicâ€”inflate s and distort :math:`\bar{x}`
      - **Strong skewness**: Asymmetry can bias the sample mean
      - **Heavy tails**: Increase the chance of extreme observations
      - **Bimodality**: Violates the single-peak assumption

      **Part (c): Outlier in small sample (n = 8)**

      Before constructing a CI:
      
      1. Investigate the outlierâ€”is it a measurement error, data entry error, or legitimate observation?
      2. Create diagnostic plots (histogram, boxplot, QQ-plot)
      3. If error: correct or remove with justification
      4. If legitimate: consider the impact on results; report both with and without the outlier
      5. Consider robust alternatives if available

      **Part (d): n = 50, mildly skewed**

      **Yes, appropriate.** With n = 50, the CLT ensures the sampling distribution of :math:`\bar{x}` is approximately normal even if the population is mildly skewed. t-procedures are robust at this sample size.

      **Part (e): Remedies for problematic outliers**

      If an outlier is discovered after constructing a CI:
      
      1. **Investigate**: Determine if it's an error or valid data point
      2. **Consider removal**: If there's justification (measurement error, data recording mistake), remove and recompute
      3. **Acknowledge robust alternatives**: Median-based CI or bootstrap methods (not covered in this course) are less sensitive to outliers
      4. **Report with caution**: If the outlier appears valid, interpret results carefully and note the limitation

----

.. admonition:: Exercise 9: Sample Size Planning with Unknown Ïƒ
   :class: note

   When planning sample size with Ïƒ unknown, we face a challenge: we need s to find the t-critical value, but we don't have data yet.

   A researcher wants a 95% CI for mean reaction time with ME â‰¤ 5 ms. A pilot study suggests s â‰ˆ 20 ms.

   a. Using the z-approximation (pretending Ïƒ = 20), calculate the required sample size.

   b. Using the result from (a), find :math:`t_{0.025, n-1}` and recalculate the required n.

   c. Iterate: with the new n, find the new t-critical value and check if n is sufficient.

   d. What is the final recommended sample size?

   .. dropdown:: Solution
      :class-container: sd-border-success

      Given: 95% CI, ME â‰¤ 5 ms, estimated s = 20 ms

      **Step 1 â€” Initial z-approximation**

      .. math::
         n = \left\lceil \left(\frac{1.96 \times 20}{5}\right)^2 \right\rceil = \left\lceil 61.47 \right\rceil = 62

      **Step 2 â€” First iteration with t**

      With n = 62, df = 61: :math:`t_{0.025, 61} = 2.000`

      .. math::
         n = \left\lceil \left(\frac{2.000 \times 20}{5}\right)^2 \right\rceil = \left\lceil 64 \right\rceil = 64

      **Step 3 â€” Check for convergence**

      With n = 64, df = 63: :math:`t_{0.025, 63} = 1.998`

      .. math::
         n = \left\lceil \left(\frac{1.998 \times 20}{5}\right)^2 \right\rceil = \left\lceil 63.87 \right\rceil = 64

      Converged!

      **Part (d): Final recommendation**

      **n = 64** samples

      Note: One or two iterations is typically sufficient because t-critical values change slowly once df is moderate (beyond about 20).

      **R verification:**

      .. code-block:: r

         s <- 20; ME <- 5
         
         # Initial z-approximation
         n1 <- ceiling((qnorm(0.025, lower.tail=FALSE) * s / ME)^2)  # 62
         
         # First iteration
         n2 <- ceiling((qt(0.025, n1-1, lower.tail=FALSE) * s / ME)^2)  # 64
         
         # Second iteration
         n3 <- ceiling((qt(0.025, n2-1, lower.tail=FALSE) * s / ME)^2)  # 64
         
         # Verify
         qt(0.025, 63, lower.tail = FALSE)  # 1.998

----

Additional Practice Problems
----------------------------

**True/False Questions** (1 point each)

1. The t-distribution has heavier tails than the standard normal distribution.

   â“‰ or â’»

2. As degrees of freedom increase, t-critical values approach z-critical values.

   â“‰ or â’»

3. For a one-sample t-procedure with n = 20, the degrees of freedom is 20.

   â“‰ or â’»

4. The t-distribution is appropriate when Ïƒ is known.

   â“‰ or â’»

5. A 95% CI using t will always be wider than one using z (same data).

   â“‰ or â’»

6. t-procedures require the population to be exactly normal.

   â“‰ or â’»

**Multiple Choice Questions** (2 points each)

7. For n = 25 and 95% confidence, the appropriate critical value is:

   â’¶ :math:`z_{0.025} = 1.96`
   
   â’· :math:`t_{0.025, 25} = 2.060`
   
   â’¸ :math:`t_{0.025, 24} = 2.064`
   
   â’¹ :math:`t_{0.05, 24} = 1.711`

8. If :math:`\bar{x} = 45`, s = 6, n = 16, the 95% CI is approximately:

   â’¶ 45 Â± 2.131(1.5)
   
   â’· 45 Â± 1.96(1.5)
   
   â’¸ 45 Â± 2.131(6)
   
   â’¹ 45 Â± 1.753(1.5)

9. The degrees of freedom for a one-sample t-test equals n - 1 because:

   â’¶ One observation is lost to rounding
   
   â’· We estimate one parameter (Î¼) from the data
   
   â’¸ We estimate one parameter (Ïƒ) using s, losing one degree of freedom
   
   â’¹ The sample size must be reduced by 1

10. t-procedures are most robust to non-normality when:

    â’¶ Sample size is very small (n < 10)
    
    â’· Sample size is moderate to large (n â‰¥ 30)
    
    â’¸ The population is heavily skewed
    
    â’¹ Outliers are present

11. For a 90% LCB with n = 20, the critical value is:

    â’¶ :math:`t_{0.10, 19}`
    
    â’· :math:`t_{0.05, 19}`
    
    â’¸ :math:`t_{0.10, 20}`
    
    â’¹ :math:`z_{0.10}`

12. Which R command gives a 95% CI for mean of vector x?

    â’¶ ``t.test(x)``
    
    â’· ``z.test(x)``
    
    â’¸ ``confint(x)``
    
    â’¹ ``qt(0.025, length(x))``

.. dropdown:: Answers to Practice Problems
   :class-container: sd-border-success

   **True/False Answers:**

   1. **True** â€” The t-distribution has heavier tails to account for uncertainty in estimating Ïƒ.

   2. **True** â€” As df â†’ âˆž, t â†’ z. By df â‰ˆ 30, they're close; by df â‰ˆ 100, nearly identical.

   3. **False** â€” df = n - 1 = 19, not 20.

   4. **False** â€” When Ïƒ is known, use the z-distribution. t is for Ïƒ unknown.

   5. **True** â€” t-critical values exceed z-critical values for all finite df.

   6. **False** â€” t-procedures are robust to mild departures, especially with larger samples.

   **Multiple Choice Answers:**

   7. **â’¸** â€” df = n - 1 = 24, and for a CI use :math:`t_{0.025, 24}`.

   8. **â’¶** â€” SE = 6/âˆš16 = 1.5; df = 15; :math:`t_{0.025, 15} = 2.131`.

   9. **â’¸** â€” We use one degree of freedom to estimate Ïƒ with s.

   10. **â’·** â€” Larger samples invoke CLT, making the procedure robust to non-normality.

   11. **â’¶** â€” For a one-sided bound at 90% confidence, use :math:`t_{0.10, n-1} = t_{0.10, 19}`.

   12. **â’¶** â€” ``t.test(x)`` computes the one-sample t-test and 95% CI by default.