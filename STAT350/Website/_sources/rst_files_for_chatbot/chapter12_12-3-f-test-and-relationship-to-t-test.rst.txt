.. _12-3-f-test-and-relationship-to-t-test:


.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch12-3">
      <iframe
         id="video-ch12-3"
         title="STAT 350 ‚Äì Chapter 12.3 One-Way Hypothesis Test and F-Test Statistic Video"
         src="https://www.youtube.com/embed/wr-jFQm3DzM?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

.. admonition:: Slides üìä
   :class: tip

   `Download Chapter 12 slides (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/
   Chapter%2012%20ANOVA/OneWayANOVA_AC.pptx>`_
   
ANOVA F-Test and Its Relationship to Two-Sample *t*-Tests
===================================================================

We have developed the theoretical foundation for ANOVA by decomposing total variability into 
between-group and within-group components. Now we are ready to construct the hypothesis test 
that will tell us whether observed differences in sample means are statistically significant.

.. admonition:: Road Map üß≠
   :class: important

   * Understand why the :math:`F`-test statistic serves as an **indicator of differences** among 
     population means.
   * Describe the **properties of the** :math:`F` **distributions**.
   * Construct a **complete ANOVA table** and perform an ANOVA :math:`F`-test using the **four-step framework**.
   * Recognize the **connections between ANOVA and independent two-sample inference**.

Building the Test Statistic
---------------------------------

Recall the goal of the ANOVA hypothesis test: we would like to compare the variabilities within and
between groups, and reject the null hypothesis that all means are equal if the between-group variability
is significantly larger.

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter12/within-vs-between.png 
   :figwidth: 50%
   :align: center 
   :alt: Comparison of within-group and between-group variation

   Within-group vs between-group variability

To formalize this comparison, we use the **ratio between MSA and MSE**.

.. math::

   \frac{\text{Between-group variability}}{\text{Within-group variability}} = \frac{\text{MSA}}{\text{MSE}}

When :math:`H_0` is true, both MSA and MSE estimate :math:`\sigma^2`, so their observed ratio tends to be
close to 1. When :math:`H_0` is false, however, MSA estimates something larger, making it more likely for
the ratio to take a value significantly larger than 1.

Under the null hypothesis, the distribution of the ratio belongs to the family of :math:`F`-**distributions**.
For this reason, the ratio is called the :math:`F`-**test
statistic**, or :math:`F_{TS}`. To complete the hypothesis testing construction, we next review the main
properties of :math:`F`-distributed random variables.

The :math:`F`-Distribution
----------------------------

:math:`F`-distributions are parameterized by two degrees of freedom: :math:`df_1` and :math:`df_2`.
When a ramdom variable :math:`X` follows an :math:`F`-distribution, we write:

.. math::
   X \sim F(df_1, df_2).

:math:`F`-distributions are always supported on :math:`[0, \infty)` and are right-skewed regardless of the parameter values.
As the two degrees of freedom grow, 

* the skewness weakens (see the yellow curve in :numref:`f-dist`),
* the expected value quickly approaches 1, and
* the variance decreases.

.. _f-dist:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter12/f-dist.jpg
   :figwidth: 80%
   :align: center 
   :alt: F-distributions with different sets of parameter values

   :math:`F`-distribution with different sets of parameter values

Let us now discuss the specific :math:`F` distribution of the 
ANOVA test statistic. Under the null hypothesis, 

.. math::
   F_{TS} \sim F(df_A = k-1, df_E = n-k),

where :math:`k` represents the number of groups and :math:`n` the total sample size.

Drawing connections with the general properties of :math:`F`-distributions,

* :math:`F_{TS}` will always yield a non-negative outcome since it is a ratio of two non-negative random variables.
  This agrees with the support of its null distribution.
* As the total sample size :math:`n` grows,
  the expected value of :math:`F_{TS}` grows closer to 1 and its spread becomes narrower arround the mean.

The :math:`p`-Value for ANOVA
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Regardless of the analysis method, a :math:`p`-value always represents the
probability of obtaining a result **more inconsistent** with the null hypothesis than the one observed. 
In ANOVA, such inconsistency corresponds to a greater observed :math:`F`-test statistic. Therefore,

.. math:: 
   \text{p-value} = P(F_{k-1,n-k} \geq f_{ts}),

where :math:`F_{k-1,n-k}` is a random variable following an :math:`F` distribution with :math:`(df_1,df_2)=(k-1, n-k)`,
and :math:`f_{TS}` is the observed :math:`F`-test statistic. On R, the :math:`p`-value can be obtained using
the ``pf`` function:

.. code-block:: r

   pvalue <- pf(f_ts, df1=k-1, df2=n-k, lower.tail=FALSE)

The Complete ANOVA Table
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We are now fully equipped to construct the complete ANOVA table that we left partially filled in 
Chapter 12.2. The entries marked with ‚Öπ are typically left blank.


.. flat-table::
   :header-rows: 1
   :width: 95%
   :widths: 15 10 25 10 10 10

   * - Source
     - df
     - SS
     - MS
     - :math:`(f_{TS})`
     - :math:`p`-value

   * - Factor A
     - :math:`k-1`
     - :math:`\sum_{i=1}^k n_i(\bar{x}_{i \cdot} - \bar{x}_{\cdot \cdot})^2`
     - :math:`\frac{\text{SSA}}{k-1}`
     - :math:`\frac{MSA}{MSE}`
     - :math:`P(F_{k-1,n-k} \geq f_{ts})`

   * - Error
     - :math:`n-k`
     - :math:`\sum_{i=1}^k \sum_{j=1}^{n_i}(x_{ij} - \bar{x}_{i \cdot})^2`
     - :math:`\frac{\text{SSE}}{n-k}`
     - ‚Öπ
     - ‚Öπ

   * - Total
     - :math:`n-1`
     - :math:`\sum_{i=1}^k \sum_{j=1}^{n_i}(x_{ij} - \bar{x}_{\cdot \cdot})^2`
     - ‚Öπ
     - ‚Öπ
     - ‚Öπ


.. admonition:: Example üí°: The Complete ANOVA Table for the Coffeehouse Study 
   :class: note

   For the coffeehouse study, complete the remaining entries of the ANOVA table. 

   .. list-table:: Complete ANOVA Table
      :header-rows: 1
      :widths: 20 15 15 15 15 20
      :align: center

      * - Source
        - df
        - SS
        - MS
        - :math:`f_{TS}`
        - :math:`p`-value
      * - Factor A
        - 4
        - 8834
        - 2208.4
        - 22.14
        - :math:`4.4 \times 10^{-15}`
      * - Error
        - 195
        - 19451
        - 99.8
        - 
        - 
      * - Total
        - 199
        - 28285
        - 
        - 
        -

   We only need to fill the two entries corresponding to the observed :math:`f_{TS}` and the
   :math:`p`-value.

   **(1)** First,

   .. math::

      f_{TS} = \frac{MSA}{MSE} = \frac{2208.4}{99.8} = 22.14

   Recall that under the null hypothesis and a total sample size as large as 
   :math:`n=200`, the :math:`F`-test statistic is distributed sharply around 1. The observed value of 
   22.10 already gives a strong sign of inconsistency with the null hypothesis. 
   
   **(2)** Let us continue to computing the :math:`p`-value and check if our prediction is confirmed:

   .. math::
      \text{p-value} = P(F_{4,195} \geq 22.10) = 4.89 \times 10^{-15}

   As expected, the :math:`p`-value is very small.


We are now ready to organize the ANOVA hypothesis test into a full four-step framework.

The Four Steps of ANOVA Hypothesis Testing
-------------------------------------------------

Step 1: Define Parameters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Define the population mean :math:`\mu_i`, for each :math:`i \in \{1, \cdots, k\}`.
The definition should clearly describe the populations of interest and connect
each :math:`\mu_i` to a specific population.

Step 2: State the Hypotheses
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. math::
   &H_0: \mu_1 = \mu_2 = \cdots = \mu_k \\
   &H_a: \mu_i \neq \mu_j \text{ for some } i \neq j

The alternative hypothesis can be written in several equivalent ways:

- :math:`H_a:` At least one :math:`\mu_i` is different from the rest
- :math:`H_a:` Not all population means are equal  
- :math:`H_a:` At least one :math:`\mu_i` differs from the others

Step 3-1: Check Assumptions
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Before proceeding, we must verify that the ANOVA assumptions are reasonable.
See :numref:`visual_analysis` for a complete walkthrough of graphical verification.
In addition, we must confirm numerically that the equal variance assumption is reasonable
by showing:

.. math::

   \frac{\max(s_{1\cdot}, s_{2\cdot}, \ldots, s_{k\cdot})}{\min(s_{1\cdot}, s_{2\cdot}, \ldots, s_{k\cdot})} \leq 2.

Step 3-2: Calculate the Test Statistic, Degrees of Freedom, and :math:`p`-Value
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In this step, it is often helpful to first construct the full ANOVA table.

* Use the computed MSA and MSE for the observed test statistic, :math:`f_{TS}`:

  .. math::

     f_{TS} = \frac{\text{MSA}}{\text{MSE}}

* State the **degrees of freedom**:

   - :math:`df_A = k - 1`
   - :math:`df_E = n - k`

* Compute the :math:`p`-value, :math:`P(F_{df_A, df_E} \geq f_{TS})`:

.. code-block:: r

   pf(f_ts, df1 = k-1, df2 = n-k, lower.tail = FALSE)

Step 4: Make Decision and State Conclusion
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Decision rule** stays unchanged:

- If :math:`p`-value :math:`\leq \alpha`, reject :math:`H_0`.
- If :math:`p`-value :math:`> \alpha`, fail to reject :math:`H_0`.

**Conclusion template**: 

"The data [does/does not] give [weak/moderate/strong] support (p-value = [value]) to the claim that [statement of :math:`H_a` in context]."

.. admonition:: Performing ANOVA When Complete Data is Available
   :class: important

   Suppose the complete dataset can be organized into a ``data.frame`` with two columns:

   1. The column ``response_variable`` lists responses measurements for *all* groups.
   2. The column ``factor_variable`` lists the group labels for each entry of ``response_variable``
      in a matching order.

   Then, the R function ``aov()`` can be used to run all ANOVA computations from scratch:

   .. code-block:: r

      fit <- aov(response_variable ~ factor_variable, data = dataframe)

      # output 
      summary(fit)


What Happens If :math:`H_0` Is Rejected?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When ANOVA indicates that "at least one mean differs from the others," it naturally raises the next
question: "Which specific groups are different?" This brings us to **multiple comparison procedures**, explored in the next section. 
These methods allow specific pairwise comparisons while controlling the overall error rate.

For now, it's important to understand that ANOVA serves as a **gatekeeper test**, screening data sets that
require pairwise comparisons from those that do not.

.. admonition:: Exampleüí°: Complete ANOVA Testing for the Coffeehouse Data ‚òïÔ∏è
   :class: note

   Perform a hypothesis test at :math:`\alpha = 0.01` 
   to determine if the five coffeehouses around campus attract customers of different average ages.

   üìä `Download the coffeehouse dataset (CSV) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Data/AgeCoffee.csv>`_

   .. list-table:: Sample Statistics
      :header-rows: 1
      :widths: 30 20 25 25
      :align: center

      * - Sample (Levels of Factor Variable)
        - Sample Size
        - Mean
        - Variance
      * - Population 1
        - :math:`n_1 = 39`
        - :math:`\bar{x}_{1.} = 39.13`
        - :math:`s_1^2 = 62.43`
      * - Population 2
        - :math:`n_2 = 38`
        - :math:`\bar{x}_{2.} = 46.66`
        - :math:`s_2^2 = 168.34`
      * - Population 3
        - :math:`n_3 = 42`
        - :math:`\bar{x}_{3.} = 40.50`
        - :math:`s_3^2 = 119.62`
      * - Population 4
        - :math:`n_4 = 38`
        - :math:`\bar{x}_{4.} = 26.42`
        - :math:`s_4^2 = 48.90`
      * - Population 5
        - :math:`n_5 = 43`
        - :math:`\bar{x}_{5.} = 34.07`
        - :math:`s_5^2 = 98.50`
      * - **Combined**
        - :math:`n = 200`
        - :math:`\bar{x}_{..} = 37.35`
        - :math:`s^2 = 142.14`

   **Step 1: Define the Parameters**

   Let :math:`\mu_{1}, \mu_{2}, \mu_{3}, \mu_{4}, \mu_{5}` represent the true mean customer age at 
   coffeehouses 1, 2, 3, 4, and 5, respectively.

   **Step 2: State the Hypotheses**

   .. math::

      &H_0: \mu_{1} = \mu_{2} = \mu_{3} = \mu_{4} = \mu_{5}\\
      &H_a: \mu_{i} \neq \mu_{j} \text{ for some } i \neq j

   **Step 3-1: Check Assumptions**

   This step should include all the following elements:

   * Graphical check for any serious deviations from normality in individual samples
   * Graphical check for any signs of violation of the equal variance assumption
   * Using the **numerical method** to confirm that the sample variances (standard deviations) are within similar 
     ranges:
     
     .. math:: 
        \frac{\max{s_i}}{\min{s_i}} = \frac{\sqrt{168.34}}{\sqrt{48.90}} = 1.855 < 2 \checkmark

   Refer to the last example of Chapter 12.1.

   **Step 3-2: Calculate the Test Statistic, Degrees of Freedom, and p-Value**

   .. list-table:: Complete ANOVA Table
      :header-rows: 1
      :widths: 20 15 15 15 15 20
      :align: center

      * - Source
        - df
        - SS
        - MS
        - :math:`f_{TS}`
        - :math:`p`-value
      * - Factor A
        - 4
        - 8834
        - 2208.4
        - 22.14
        - :math:`4.4 \times 10^{-15}`
      * - Error
        - 195
        - 19451
        - 99.8
        - 
        - 
      * - Total
        - 199
        - 28285
        - 
        - 
        - 

   * Test statistic: :math:`f_{TS} = 22.14`
   * Degrees of freedom for the null distribution: :math:`df_A = 4`, :math:`df_E = 195` 
   * :math:`p`-value :math:`= 4.4 \times 10^{-15}`

   **Step 4: Decision and Conclusion**

   Since p-value = :math:`4.4 \times 10^{-15} < 0.01 = \alpha`, we reject :math:`H_0`.

   The data gives strong support (p-value = :math:`4.4 \times 10^{-15}`) to the claim that at least one of 
   the coffeehouses around campus differs in the mean age of customers from the rest.
   
The Connection Between F-Tests and t-Tests
----------------------------------------------

.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch12-3">
      <iframe
         id="video-ch12-3"
         title="STAT 350 ‚Äì Chapter 12.3.1 One-Way ANOVA and Two Independent Sample t-test Relationship"
         src="https://www.youtube.com/embed/8hNoZPqspq0?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

It is possible to view one-way ANOVA as a generalization of independent two-sample analysis
under certain conditions. Specifically, one-way ANOVA with :math:`k=2` is equivalent to 
a two-tailed independent two-sample hypothesis test with :math:`\Delta_0=0` and the equal variance assumption.

We show this special relationship by demonstrating that the :math:`F`-test statistic for ANOVA is **equal** 
to the square of the :math:`t`-test statistic for the two-sammple comparison. In turn, we also show that the :math:`p`-values
computed from these two statistics are identical.

Connection Between the Test Statistics
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When :math:`k=2`, the ANOVA :math:`F`-test statistic is:

.. math::

   F_{TS} = \frac{\text{MSA}}{\text{MSE}} = 
   \frac{n_1(\bar{X}_{1\cdot} - \bar{X}_{\cdot \cdot})^2 + n_2(\bar{X}_{2\cdot} - \bar{X}_{\cdot \cdot})^2}{\frac{(n_1-1)S_{1\cdot}^2 + (n_2-1)S_{2\cdot}^2}{n_1 + n_2 - 2}}.

Through algebraic manipulation (which involves expressing the overall mean :math:`\bar{X}_{\cdot \cdot}` as a 
weighted average of the group means), this simplifies to:

.. math::

   F_{TS} = \frac{(\bar{X}_{1\cdot} - \bar{X}_{2\cdot})^2}{S_p^2\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}.

Recall the :math:`t`-test statistic for independent two-sample comparison with the pooled variance estimator:

.. math::

   T_{TS} = \frac{(\bar{X}_1 - \bar{X}_2) - \Delta_0}{S_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}.

By setting :math:`\Delta_0 = 0` and squaring :math:`T_{TS}`, we recover :math:`F_{TS}`.


Equivalence of the :math:`p`-Values
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Using the connection between the two test statistics, the ANOVA :math:`p`-value satisfies:

.. math::

   P(F_{1, n-2} > f_{TS}) = P(T_{n-2}^2 > t^2_{TS}) = P(|T_{n-2}| > |t_{TS}|) = 2P(T_{n-2} > |t_{TS}|)

The final probability statement is, in fact, the :math:`p`-**value for the two-sided** :math:`t`-**test**. 
That is, the :math:`p`-value computed through one-way ANOVA is **identical** to the 
:math:`p`-value computed from a two-sided test for difference between two means.

It follows that the decision to reject or fail to reject the null hypothesis is also identical‚Äîessentially,
the two tests are the same procedure in difference forms.

Summary
~~~~~~~~~

In summary, ANOVA with :math:`k=2` is equivalent to an independent two-sample analysis 
with the equal variance assumption and a null value of zero.
Between the two options, then, what should we choose?
The decision depends on whether you
value the flexibility of the two-sample analysis or the generalizability of ANOVA.

.. flat-table:: 
   :header-rows: 2
   :widths: 20 35 35

   * - :cspan:`2` Comparison of Independent Two-Sample :math:`t`-Test and ANOVA

   * - Feature
     - Indepdent Two-Sample :math:`t`-Test
     - One-Way ANOVA

   * - **Variance Assumption**
     - Can assume equal or unequal variances among groups
     - Assumes equal variances

   * - **Hypothesis Type**
     - Any direction can be chosen
     - Two-sided only

   * - **Null Value** :math:`\Delta_0`
     - Can by any value 
     - Limited to :math:`\Delta_0 = 0`

   * - **Number of Groups**
     - Exactly 2 groups
     - 2 or more groups

Bringing It All Together
-------------------------------

.. admonition:: Key Takeaways üìù
   :class: important

   1. **The F-test statistic** :math:`\frac{\text{MSA}}{\text{MSE}}` compares between-group to within-group variability, 
      with large values providing evidence against :math:`H_0`.

   2. **The F-distribution** is right-skewed, non-negative, and with mean approximately 1.s
      Its shape is controlled by two degrees of freedom. Under the null hypothesis, the :math:`F`-test statistic
      follows an :math:`F` distribution with :math:`df_1=k-1` and :math:`df_2=n-k`.

   3. **The ANOVA table** organizes all components of ANOVA, including the :math:`F`-test statistic and the :math:`p`-value.

   4. The complete ANOVA hypothesis testing follows the **standard four-step framework**.

   5. ANOVA :math:`F`-tests with :math:`k=2` are equivalent to certain two-sample :math:`t`-tests.

   6. ANOVA serves as a **gatekeeper test** that determines whether any group differences exist before investigating 
      specific pairwise comparisons.


Exercises
---------

.. admonition:: Exercise 1: Properties of the F-Distribution
   :class: note

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch12-3/fig6_f_distributions.png
      :alt: F-distributions with different degrees of freedom
      :align: center
      :width: 90%

      **Figure 1**: F-distributions with various degrees of freedom parameters.

   Refer to Figure 1 showing F-distributions with different parameter values.

   a. What are the two parameters that define an F-distribution? What do they represent in ANOVA?

   b. What is the support (range of possible values) of an F-distribution? Why does this make sense for the F-statistic?

   c. As both degrees of freedom increase, what happens to the shape of the F-distribution?

   d. Under H‚ÇÄ, what value should the F-statistic be centered near? Explain.

   e. Why are F-tests always right-tailed (one-sided) rather than two-tailed?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): F-distribution parameters**

      The F-distribution is defined by two degrees of freedom:
      
      - **df‚ÇÅ (numerator df)** = k - 1 in ANOVA, where k is the number of groups
      - **df‚ÇÇ (denominator df)** = n - k in ANOVA, where n is total sample size

      In the context of the F-test statistic F = MSA/MSE:
      
      - df‚ÇÅ comes from MSA (based on k group means)
      - df‚ÇÇ comes from MSE (based on n observations minus k estimated means)

      **Part (b): Support of F-distribution**

      The F-distribution is supported on :math:`[0, \infty)`‚Äîit can only take non-negative values.

      This makes sense because:
      
      - F = MSA/MSE is a ratio of two non-negative quantities (mean squares are sums of squared deviations divided by positive df)
      - Both MSA ‚â• 0 and MSE > 0, so their ratio F ‚â• 0

      **Part (c): Shape as df increases**

      As both df‚ÇÅ and df‚ÇÇ increase:
      
      - The distribution becomes **less skewed** (more symmetric)
      - The distribution becomes **more concentrated** around its mean
      - The mean approaches 1 (specifically, E(F) = df‚ÇÇ/(df‚ÇÇ-2) for df‚ÇÇ > 2)
      - The variance decreases

      For large df, the F-distribution becomes more symmetric and tightly concentrated near 1, though it remains defined only for non-negative values.

      **Part (d): Center under H‚ÇÄ**

      Under H‚ÇÄ, the F-statistic should be centered near **1**.

      When H‚ÇÄ is true (all population means equal):
      
      - Both MSA and MSE are unbiased estimators of œÉ¬≤
      - E(MSA) = E(MSE) = œÉ¬≤
      - Therefore, E(F) = E(MSA)/E(MSE) ‚âà 1

      Values much larger than 1 suggest H‚ÇÄ is false.

      **Part (e): Why right-tailed only**

      F-tests are always right-tailed because:
      
      - Large F values indicate MSA >> MSE, suggesting group means differ (evidence against H‚ÇÄ)
      - Small F values (near 0) simply indicate no evidence of mean differences
      - We never "reject" because F is too small‚Äîthat would just mean groups are similar
      - The alternative hypothesis (at least one mean differs) corresponds only to large F values

      Unlike t-tests where we might test for differences in either direction, in ANOVA we only care about detecting when between-group variability exceeds within-group variability.

----

.. admonition:: Exercise 2: Computing the F-Test Statistic
   :class: note

   Using the blood glucose monitoring device data from Exercise 8 of Section 12.2, the partial ANOVA table is:

   .. list-table::
      :header-rows: 1
      :widths: 20 15 20 20

      * - Source
        - df
        - SS
        - MS
      * - Device
        - 2
        - 6.93
        - 3.47
      * - Error
        - 12
        - 2.62
        - 0.22
      * - Total
        - 14
        - 9.55
        - 

   a. Calculate the F-test statistic.

   b. Interpret the F-statistic value. What does it tell us about the ratio of between-group to within-group variability?

   c. Using R's ``pf()`` function, calculate the p-value. Show the R code.

   d. At Œ± = 0.05, what is your decision regarding H‚ÇÄ?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): F-test statistic**

      .. math::
         F_{TS} = \frac{\text{MSA}}{\text{MSE}} = \frac{3.47}{0.22} = 15.77

      **Part (b): Interpretation**

      The F-statistic of 15.77 indicates that the between-group variance (MSA) is about **15.77 times larger** than the within-group variance (MSE).

      Under H‚ÇÄ, we'd expect F ‚âà 1. A value of 15.77 is substantially larger than 1, suggesting strong evidence that at least one device has a different mean accuracy than the others.

      **Part (c): P-value calculation**

      .. code-block:: r

         F_ts <- 3.47 / 0.22  # 15.77
         df1 <- 2
         df2 <- 12
         
         p_value <- pf(F_ts, df1, df2, lower.tail = FALSE)
         # p_value = 0.000438

      The p-value is approximately **0.00044** (or 4.4 √ó 10‚Åª‚Å¥).

      **Part (d): Decision at Œ± = 0.05**

      Since p-value = 0.00044 < 0.05 = Œ±, we **reject H‚ÇÄ**.

      **Conclusion**: At the 0.05 significance level, there is sufficient evidence to conclude that at least one blood glucose monitoring device has a different mean measurement accuracy than the others.

----

.. admonition:: Exercise 3: Complete Four-Step ANOVA Hypothesis Test
   :class: note

   A software engineer compares the execution time (in milliseconds) of four different sorting algorithms on datasets of size n = 10,000. Each algorithm is run 15 times. Summary results:

   .. list-table::
      :header-rows: 1
      :widths: 25 15 20 15

      * - Algorithm
        - n
        - Mean (ms)
        - SD (ms)
      * - QuickSort
        - 15
        - 45.2
        - 5.8
      * - MergeSort
        - 15
        - 52.1
        - 6.2
      * - HeapSort
        - 15
        - 58.7
        - 5.5
      * - IntroSort
        - 15
        - 47.3
        - 6.0

   Conduct a complete ANOVA hypothesis test at Œ± = 0.01.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Step 1: Define the parameters**

      Let :math:`\mu_i` = true mean execution time (ms) for algorithm i, where:
      
      - :math:`\mu_1` = mean for QuickSort
      - :math:`\mu_2` = mean for MergeSort
      - :math:`\mu_3` = mean for HeapSort
      - :math:`\mu_4` = mean for IntroSort

      **Step 2: State the hypotheses**

      .. math::
         &H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4\\
         &H_a: \text{At least one } \mu_i \text{ is different from the others}

      *In words*: H‚ÇÄ states all algorithms have equal mean execution times. H‚Çê states at least one algorithm has a different mean execution time.

      **Step 3: Check assumptions and calculate test statistic**

      *Assumption checks:*

      - **Independence**: Assumed satisfied by the experimental design (separate algorithm runs).
      
      - **Equal variances** (can verify from summary statistics):

      .. math::
         \frac{\max(s_i)}{\min(s_i)} = \frac{6.2}{5.5} = 1.13 \leq 2 \quad \checkmark

      - **Normality**: With only summary statistics provided, we cannot create visual diagnostics. However, with n = 15 per group (total n = 60), ANOVA is reasonably robust to moderate departures from normality. *Assume normality is approximately satisfied based on the nature of execution time measurements.*

      *Calculate grand mean:*

      .. math::
         \bar{x}_{..} = \frac{15(45.2) + 15(52.1) + 15(58.7) + 15(47.3)}{60} = \frac{3049.5}{60} = 50.825

      *Calculate SSA:*

      .. math::
         \text{SSA} = 15[(45.2-50.825)^2 + (52.1-50.825)^2 + (58.7-50.825)^2 + (47.3-50.825)^2]

      .. math::
         = 15[31.64 + 1.63 + 62.00 + 12.43] = 15(107.70) = 1615.5

      *Calculate SSE:*

      .. math::
         \text{SSE} = 14(5.8^2) + 14(6.2^2) + 14(5.5^2) + 14(6.0^2)

      .. math::
         = 14(33.64 + 38.44 + 30.25 + 36.00) = 14(138.33) = 1936.62

      *Calculate degrees of freedom:*

      - :math:`df_A = k - 1 = 3`
      - :math:`df_E = n - k = 56`

      *Calculate mean squares:*

      .. math::
         \text{MSA} = \frac{1615.5}{3} = 538.5, \quad \text{MSE} = \frac{1936.62}{56} = 34.58

      *Calculate F-statistic:*

      .. math::
         F_{TS} = \frac{538.5}{34.58} = 15.57

      *Calculate p-value:*

      .. math::
         \text{p-value} = P(F_{3,56} \geq 15.57) = 1.75 \times 10^{-7}

      **Complete ANOVA Table:**

      .. list-table::
         :header-rows: 1
         :widths: 20 12 18 18 15 18

         * - Source
           - df
           - SS
           - MS
           - F
           - p-value
         * - Algorithm
           - 3
           - 1615.5
           - 538.5
           - 15.57
           - 1.75√ó10‚Åª‚Å∑
         * - Error
           - 56
           - 1936.6
           - 34.58
           - 
           - 
         * - Total
           - 59
           - 3552.1
           - 
           - 
           - 

      **Step 4: Decision and Conclusion**

      Since p-value = 1.75 √ó 10‚Åª‚Å∑ < 0.01 = Œ±, we **reject H‚ÇÄ**.

      **Conclusion**: At the 0.01 significance level, there is sufficient evidence to conclude that at least one sorting algorithm has a different mean execution time than the others (p < 0.001). Further analysis (multiple comparisons) is needed to determine which specific algorithms differ.

      **R verification:**

      .. code-block:: r

         n <- c(15, 15, 15, 15)
         xbar <- c(45.2, 52.1, 58.7, 47.3)
         s <- c(5.8, 6.2, 5.5, 6.0)
         
         grand_mean <- sum(n * xbar) / sum(n)  # 50.825
         SSA <- sum(n * (xbar - grand_mean)^2)  # 1615.5
         SSE <- sum((n - 1) * s^2)  # 1936.62
         
         df_A <- 3; df_E <- 56
         MSA <- SSA / df_A  # 538.5
         MSE <- SSE / df_E  # 34.58
         
         F_ts <- MSA / MSE  # 15.57
         p_value <- pf(F_ts, df_A, df_E, lower.tail = FALSE)  # 2.07e-7

----

.. admonition:: Exercise 4: ANOVA Table Completion
   :class: note

   Complete the missing entries in each ANOVA table.

   **(a)** Manufacturing study with 5 production methods:

   .. list-table::
      :header-rows: 1
      :widths: 18 12 18 18 15 18

      * - Source
        - df
        - SS
        - MS
        - F
        - p-value
      * - Method
        - ___
        - 840
        - ___
        - ___
        - ___
      * - Error
        - 45
        - ___
        - 30
        - 
        - 
      * - Total
        - ___
        - 2190
        - 
        - 
        - 

   **(b)** Clinical trial with 3 drug dosages (total n = 75):

   .. list-table::
      :header-rows: 1
      :widths: 18 12 18 18 15 18

      * - Source
        - df
        - SS
        - MS
        - F
        - p-value
      * - Dosage
        - ___
        - ___
        - 156.2
        - 4.87
        - ___
      * - Error
        - ___
        - ___
        - ___
        - 
        - 
      * - Total
        - ___
        - 2620.4
        - 
        - 
        - 

   .. dropdown:: Solution
      :class-container: sd-border-success

      **(a) Manufacturing study:**

      *Step 1: Degrees of freedom*
      
      - df_A = k - 1 = 5 - 1 = **4**
      - df_E = 45 (given)
      - df_T = df_A + df_E = 4 + 45 = **49**

      *Step 2: Sums of Squares*
      
      - SSE = MSE √ó df_E = 30 √ó 45 = **1350**
      - SSA = **840** (given)
      - Check: SSA + SSE = 840 + 1350 = 2190 = SST ‚úì

      *Step 3: MSA and F*
      
      - MSA = SSA/df_A = 840/4 = **210**
      - F = MSA/MSE = 210/30 = **7.0**

      *Step 4: p-value*
      
      - p-value = P(F_{4,45} ‚â• 7.0) = **0.00018**

      .. list-table::
         :header-rows: 1
         :widths: 18 12 18 18 15 18

         * - Source
           - df
           - SS
           - MS
           - F
           - p-value
         * - Method
           - 4
           - 840
           - 210
           - 7.0
           - 0.00018
         * - Error
           - 45
           - 1350
           - 30
           - 
           - 
         * - Total
           - 49
           - 2190
           - 
           - 
           - 

      **(b) Clinical trial:**

      *Step 1: Degrees of freedom*
      
      - k = 3 dosages ‚Üí df_A = **2**
      - n = 75 ‚Üí df_T = 75 - 1 = **74**
      - df_E = df_T - df_A = 74 - 2 = **72**

      *Step 2: Mean squares*
      
      - MSA = **156.2** (given)
      - F = MSA/MSE ‚Üí MSE = MSA/F = 156.2/4.87 = **32.07**

      *Step 3: Sums of Squares*
      
      - SSA = MSA √ó df_A = 156.2 √ó 2 = **312.4**
      - SSE = MSE √ó df_E = 32.07 √ó 72 = **2309.04**
      - Check: 312.4 + 2309.0 ‚âà 2621.4 ‚âà 2620.4 (rounding) ‚úì

      *Step 4: p-value*
      
      - p-value = P(F_{2,72} ‚â• 4.87) = **0.0103**

      .. list-table::
         :header-rows: 1
         :widths: 18 12 18 18 15 18

         * - Source
           - df
           - SS
           - MS
           - F
           - p-value
         * - Dosage
           - 2
           - 312.4
           - 156.2
           - 4.87
           - 0.0103
         * - Error
           - 72
           - 2308.0
           - 32.06
           - 
           - 
         * - Total
           - 74
           - 2620.4
           - 
           - 
           - 

      **R verification:**

      .. code-block:: r

         # Part (a)
         pf(7.0, 4, 45, lower.tail = FALSE)  # 0.00018
         
         # Part (b)
         MSA <- 156.2
         F_ts <- 4.87
         MSE <- MSA / F_ts  # 32.07
         pf(4.87, 2, 72, lower.tail = FALSE)  # 0.0104

----

.. admonition:: Exercise 5: The F = t¬≤ Relationship
   :class: note

   This exercise demonstrates that ANOVA with k = 2 is equivalent to a two-sided pooled two-sample t-test.

   A researcher compares the yield (kg/plot) of two fertilizer types:

   - Fertilizer A: n‚ÇÅ = 12, xÃÑ‚ÇÅ = 45.8, s‚ÇÅ = 6.2
   - Fertilizer B: n‚ÇÇ = 15, xÃÑ‚ÇÇ = 52.3, s‚ÇÇ = 5.8

   a. Conduct the comparison using a two-sample pooled t-test (H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ vs H‚Çê: Œº‚ÇÅ ‚â† Œº‚ÇÇ). Report the t-statistic and p-value.

   b. Conduct the comparison using one-way ANOVA. Report the F-statistic and p-value.

   c. Verify that F = t¬≤.

   d. Verify that the p-values are identical.

   e. Under what conditions does this equivalence hold?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Two-sample pooled t-test**

      *Pooled variance:*

      .. math::
         s_p^2 = \frac{(12-1)(6.2)^2 + (15-1)(5.8)^2}{12 + 15 - 2} = \frac{11(38.44) + 14(33.64)}{25} = \frac{422.84 + 470.96}{25} = 35.75

      *Standard error:*

      .. math::
         SE = \sqrt{s_p^2\left(\frac{1}{n_1} + \frac{1}{n_2}\right)} = \sqrt{35.75\left(\frac{1}{12} + \frac{1}{15}\right)} = \sqrt{35.75(0.150)} = \sqrt{5.363} = 2.316

      *t-statistic:*

      .. math::
         t_{TS} = \frac{\bar{x}_1 - \bar{x}_2}{SE} = \frac{45.8 - 52.3}{2.316} = \frac{-6.5}{2.316} = -2.807

      *Degrees of freedom:* df = 25

      *p-value (two-sided):*

      .. math::
         \text{p-value} = 2 \times P(T_{25} < -2.807) = 0.00957

      **Part (b): One-way ANOVA**

      *Grand mean:*

      .. math::
         \bar{x}_{..} = \frac{12(45.8) + 15(52.3)}{27} = \frac{549.6 + 784.5}{27} = 49.41

      *SSA:*

      .. math::
         \text{SSA} = 12(45.8 - 49.41)^2 + 15(52.3 - 49.41)^2 = 12(13.03) + 15(8.35) = 156.36 + 125.25 = 281.61

      *SSE (same as pooled SS):*

      .. math::
         \text{SSE} = (12-1)(6.2)^2 + (15-1)(5.8)^2 = 893.80

      *Mean squares:*

      .. math::
         \text{MSA} = \frac{281.61}{1} = 281.61, \quad \text{MSE} = \frac{893.80}{25} = 35.75

      *F-statistic:*

      .. math::
         F_{TS} = \frac{281.61}{35.75} = 7.88

      *p-value:*

      .. math::
         \text{p-value} = P(F_{1,25} \geq 7.88) = 0.00957

      **Part (c): Verify F = t¬≤**

      .. math::
         t^2 = (-2.807)^2 = 7.88 = F \quad \checkmark

      **Part (d): Verify p-values are identical**

      Both methods give p-value = **0.00957** ‚úì

      **Part (e): Conditions for equivalence**

      The F = t¬≤ equivalence holds when:
      
      1. **k = 2 groups** (two-sample comparison)
      2. **Equal variance assumption** (pooled t-test)
      3. **Null value Œî‚ÇÄ = 0** (testing for any difference)
      4. **Two-sided alternative** in the t-test

      If any of these conditions change (e.g., Welch t-test, one-sided alternative, or Œî‚ÇÄ ‚â† 0), the equivalence breaks down.

      **R verification:**

      .. code-block:: r

         n1 <- 12; n2 <- 15
         xbar1 <- 45.8; xbar2 <- 52.3
         s1 <- 6.2; s2 <- 5.8
         
         # Two-sample pooled t-test
         s2_p <- ((n1-1)*s1^2 + (n2-1)*s2^2) / (n1 + n2 - 2)
         SE <- sqrt(s2_p * (1/n1 + 1/n2))
         t_ts <- (xbar1 - xbar2) / SE  # -2.807
         p_t <- 2 * pt(t_ts, df = n1 + n2 - 2)  # 0.00957
         
         # ANOVA
         grand_mean <- (n1*xbar1 + n2*xbar2) / (n1 + n2)
         SSA <- n1*(xbar1 - grand_mean)^2 + n2*(xbar2 - grand_mean)^2
         MSA <- SSA / 1
         MSE <- s2_p  # Same as pooled variance!
         F_ts <- MSA / MSE  # 7.88
         p_F <- pf(F_ts, 1, n1 + n2 - 2, lower.tail = FALSE)  # 0.00957
         
         # Verify
         t_ts^2  # 7.88 = F_ts
         all.equal(p_t, p_F)  # TRUE

----

.. admonition:: Exercise 6: Interpreting F-Values
   :class: note

   For each scenario, interpret what the F-statistic value suggests and predict the likely outcome.

   a. F = 0.85 with df‚ÇÅ = 3 and df‚ÇÇ = 40

   b. F = 4.21 with df‚ÇÅ = 4 and df‚ÇÇ = 75

   c. F = 12.56 with df‚ÇÅ = 2 and df‚ÇÇ = 27

   d. F = 1.02 with df‚ÇÅ = 5 and df‚ÇÇ = 120

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): F = 0.85**

      F = 0.85 < 1 indicates that MSA < MSE‚Äîthe between-group variability is *less than* the within-group variability.

      **Interpretation**: The group means are very close together relative to the natural variation within groups. There is no evidence that population means differ.

      **p-value** = P(F_{3,40} ‚â• 0.85) = 0.475

      **Outcome**: Clearly fail to reject H‚ÇÄ.

      **Part (b): F = 4.21**

      F = 4.21 is moderately larger than 1, indicating some evidence that between-group variability exceeds within-group variability.

      **Interpretation**: The group means show more spread than expected under H‚ÇÄ, but we need to check if this is statistically significant.

      **p-value** = P(F_{4,75} ‚â• 4.21) = 0.0039

      **Outcome**: Reject H‚ÇÄ at Œ± = 0.05 (and even at Œ± = 0.01).

      **Part (c): F = 12.56**

      F = 12.56 is substantially larger than 1‚Äîbetween-group variability is about 12.5 times the within-group variability.

      **Interpretation**: Strong evidence that at least one population mean differs from the others.

      **p-value** = P(F_{2,27} ‚â• 12.56) = 0.00014

      **Outcome**: Strongly reject H‚ÇÄ; highly significant.

      **Part (d): F = 1.02**

      F = 1.02 ‚âà 1 indicates MSA ‚âà MSE‚Äîthe between-group and within-group variabilities are nearly equal.

      **Interpretation**: This is exactly what we'd expect under H‚ÇÄ. The observed differences in group means are consistent with random sampling variability.

      **p-value** = P(F_{5,120} ‚â• 1.02) = 0.409

      **Outcome**: Clearly fail to reject H‚ÇÄ.

      **R verification:**

      .. code-block:: r

         pf(0.85, 3, 40, lower.tail = FALSE)    # 0.475
         pf(4.21, 4, 75, lower.tail = FALSE)    # 0.0039
         pf(12.56, 2, 27, lower.tail = FALSE)   # 0.00014
         pf(1.02, 5, 120, lower.tail = FALSE)   # 0.409

----

.. admonition:: Exercise 7: Using R's aov() Function with Complete Assumption Checking
   :class: note

   A quality control engineer collects data on the fill volume (mL) of bottles from four production lines. The following R code creates and analyzes the data:

   .. code-block:: r

      # Create the dataset
      Line <- factor(rep(c("Line1", "Line2", "Line3", "Line4"), each = 10))
      Volume <- c(
        # Line 1
        502.3, 498.7, 501.2, 499.8, 500.5, 503.1, 497.9, 501.8, 500.2, 499.5,
        # Line 2
        505.2, 504.8, 506.1, 503.9, 505.5, 504.2, 507.3, 505.8, 504.4, 506.8,
        # Line 3
        500.1, 499.3, 501.5, 498.7, 500.8, 499.2, 502.1, 500.4, 498.9, 501.3,
        # Line 4
        503.8, 502.9, 504.5, 501.7, 503.2, 505.1, 502.4, 504.8, 503.1, 504.5
      )
      
      fill_data <- data.frame(Line, Volume)
      
      # Fit ANOVA model
      fit <- aov(Volume ~ Line, data = fill_data)
      summary(fit)

   The output is:

   .. code-block:: text

                   Df Sum Sq Mean Sq F value   Pr(>F)    
      Line         3  261.0   87.01   35.72 1.22e-10 ***
      Residuals   36   87.7    2.44                     
      ---
      Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

   a. **Before interpreting results**, verify the ANOVA assumptions using appropriate visualizations. Show the R code for boxplots, faceted histograms, and faceted QQ-plots.

   b. Interpret each column of the ANOVA output.

   c. What are the null and alternative hypotheses being tested?

   d. Based on the output, what is your conclusion at Œ± = 0.05?

   e. Estimate the common standard deviation œÉ.

   f. What would be the next step in the analysis?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Assumption checking**

      Before interpreting ANOVA results, we must verify the assumptions:

      **1. Equal Variance Check - Boxplots and SD Ratio:**

      .. code-block:: r

         library(ggplot2)
         
         # Side-by-side boxplots
         ggplot(fill_data, aes(x = Line, y = Volume, fill = Line)) +
           stat_boxplot(geom = "errorbar", width = 0.3) +
           geom_boxplot() +
           stat_summary(fun = mean, geom = "point", shape = 18, 
                        size = 3, color = "black") +
           ggtitle("Fill Volume by Production Line") +
           xlab("Production Line") +
           ylab("Fill Volume (mL)") +
           theme_minimal() +
           theme(legend.position = "none")
         
         # Numerical SD ratio check
         s <- tapply(fill_data$Volume, fill_data$Line, sd)
         cat("Group SDs:", round(s, 3), "\n")
         cat("SD ratio:", round(max(s)/min(s), 3), "\n")
         # SD ratio = 1.47 (< 2) ‚úì Equal variance assumption met

      **2. Normality Check - Faceted Histograms:**

      .. code-block:: r

         # Calculate group statistics
         xbar <- tapply(fill_data$Volume, fill_data$Line, mean)
         s <- tapply(fill_data$Volume, fill_data$Line, sd)
         
         # Add normal density column
         fill_data$normal.density <- mapply(function(vol, line) {
           dnorm(vol, mean = xbar[line], sd = s[line])
         }, fill_data$Volume, fill_data$Line)
         
         # Faceted histograms
         ggplot(fill_data, aes(x = Volume)) +
           geom_histogram(aes(y = after_stat(density)), 
                          bins = 6, fill = "grey", col = "black") +
           geom_density(col = "red", linewidth = 1) +
           geom_line(aes(y = normal.density), col = "blue", linewidth = 1) +
           facet_wrap(~ Line, ncol = 2) +
           ggtitle("Normality Check: Histograms by Line") +
           xlab("Fill Volume (mL)") +
           ylab("Density") +
           theme_minimal()

      **3. Normality Check - Faceted QQ-Plots:**

      .. code-block:: r

         ggplot(fill_data, aes(sample = Volume)) +
           stat_qq() +
           stat_qq_line(color = "red", linewidth = 1) +
           facet_wrap(~ Line, ncol = 2) +
           ggtitle("Normality Check: QQ-Plots by Line") +
           xlab("Theoretical Quantiles") +
           ylab("Sample Quantiles") +
           theme_minimal()

      .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch12-3/fig9a_fill_boxplots.png
         :alt: Fill volume boxplots by production line
         :align: center
         :width: 75%

         Side-by-side boxplots for equal variance assessment.

      .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch12-3/fig9b_fill_hist.png
         :alt: Fill volume histograms by production line
         :align: center
         :width: 90%

         Faceted histograms with kernel density (red) and normal overlay (blue).

      .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch12-3/fig9c_fill_qq.png
         :alt: Fill volume QQ-plots by production line
         :align: center
         :width: 90%

         Faceted QQ-plots for normality assessment.

      **Assumption Summary:**
      
      - **Equal variances**: SD ratio = 1.47 < 2 ‚úì (boxplots show similar spread)
      - **Normality**: Histograms and QQ-plots show approximately normal distributions within each group ‚úì
      - **Independence**: Assumed from study design (separate production lines)

      All assumptions are reasonably met; we can proceed with ANOVA interpretation.

      **Part (b): Column interpretation**

      - **Df**: Degrees of freedom
        - Line (Factor): df_A = k - 1 = 4 - 1 = 3
        - Residuals (Error): df_E = n - k = 40 - 4 = 36
      
      - **Sum Sq**: Sums of squares
        - SSA = 261.0 (between-group variability)
        - SSE = 87.7 (within-group variability)
      
      - **Mean Sq**: Mean squares
        - MSA = 261.0/3 = 87.01
        - MSE = 87.7/36 = 2.44
      
      - **F value**: F-statistic = MSA/MSE = 87.01/2.44 = 35.72
      
      - **Pr(>F)**: p-value = 1.22 √ó 10‚Åª¬π‚Å∞

      **Part (c): Hypotheses**

      - H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ = Œº‚ÇÉ = Œº‚ÇÑ (all production lines have equal mean fill volumes)
      - H‚Çê: At least one Œº·µ¢ is different (at least one line differs in mean fill volume)

      **Part (d): Conclusion at Œ± = 0.05**

      Since p-value = 1.22 √ó 10‚Åª¬π‚Å∞ << 0.05 = Œ±, we **reject H‚ÇÄ**.

      **Conclusion**: At the 0.05 significance level, there is overwhelming evidence that at least one production line has a different mean fill volume than the others (p < 0.001). The very small p-value indicates extremely strong evidence against H‚ÇÄ.

      **Part (e): Estimate œÉ**

      .. math::
         \hat{\sigma} = \sqrt{\text{MSE}} = \sqrt{2.44} = 1.56 \text{ mL}

      This represents the estimated within-line standard deviation of fill volumes.

      **Part (f): Next step**

      Since we rejected H‚ÇÄ, the next step is to perform **multiple comparisons** (post-hoc analysis) to identify which specific production lines differ from each other. We could use:
      
      - **Tukey's HSD** (recommended for all pairwise comparisons)
      - **Bonferroni correction**

      .. code-block:: r

         TukeyHSD(fit, conf.level = 0.95)

----

.. admonition:: Exercise 8: When ANOVA Fails to Reject H‚ÇÄ
   :class: note

   A researcher compares exam scores across three teaching methods and obtains:

   - F = 1.84
   - df‚ÇÅ = 2, df‚ÇÇ = 57
   - p-value = 0.168

   a. State the conclusion at Œ± = 0.05.

   b. Does failing to reject H‚ÇÄ prove that all population means are equal? Explain.

   c. List three reasons why the test might fail to reject H‚ÇÄ even if true differences exist.

   d. What could the researcher do to increase the chance of detecting differences if they exist?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Conclusion**

      Since p-value = 0.168 > 0.05 = Œ±, we **fail to reject H‚ÇÄ**.

      **Conclusion**: At the 0.05 significance level, there is not sufficient evidence to conclude that the mean exam scores differ among the three teaching methods.

      **Part (b): Does this prove equality?**

      **No.** Failing to reject H‚ÇÄ does NOT prove that all population means are equal.

      It only means we don't have enough evidence to conclude they're different. The true situation could be:
      
      - The means are truly equal (H‚ÇÄ is true)
      - The means differ, but we failed to detect it (Type II error)
      - The effect size is too small to detect with the current sample size

      "Absence of evidence is not evidence of absence."

      **Part (c): Why the test might miss true differences**

      1. **Insufficient sample size (low power)**: With small n per group, only large differences can be detected. The study may be underpowered.

      2. **High within-group variability**: Large MSE makes it harder to detect differences. Natural variation in exam scores might mask teaching method effects.

      3. **Small effect size**: The true differences between teaching methods may exist but be small‚Äîperhaps too small to be practically meaningful anyway.

      4. **Violation of assumptions**: Non-normality or unequal variances could affect the test's ability to detect differences.

      5. **Measurement error**: Imprecise measurement of the response variable adds noise.

      **Part (d): Ways to increase detection power**

      1. **Increase sample size**: More students per teaching method would increase power substantially.

      2. **Reduce within-group variability**: 
         - Use more standardized testing conditions
         - Control for covariates (e.g., prior GPA)
         - Use more reliable assessment instruments

      3. **Use blocking or repeated measures**: If the same students could be taught by multiple methods (crossover design), this would control for individual differences.

      4. **Pre-register a one-sided test**: If there's a specific hypothesis about which method is better, a directional test has more power (though this must be justified a priori).

      5. **Consider effect size**: Calculate Cohen's f or Œ∑¬≤ to understand the magnitude of effects, regardless of statistical significance.

----

.. admonition:: Exercise 9: Critical Value Approach
   :class: note

   Instead of computing p-values, hypothesis tests can also be conducted using critical values.

   For an ANOVA with k = 4 groups and n = 40 total observations at Œ± = 0.05:

   a. Determine the appropriate degrees of freedom.

   b. Find the critical value F* such that P(F_{df‚ÇÅ, df‚ÇÇ} ‚â• F*) = 0.05.

   c. If the computed F-statistic is F = 3.12, what is the decision?

   d. Compare this approach to using p-values. What are the advantages and disadvantages of each?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Degrees of freedom**

      - df‚ÇÅ = df_A = k - 1 = 4 - 1 = **3**
      - df‚ÇÇ = df_E = n - k = 40 - 4 = **36**

      **Part (b): Critical value**

      We need F* such that P(F_{3,36} ‚â• F*) = 0.05.

      Using R: ``qf(0.05, 3, 36, lower.tail = FALSE)``

      **F* = 2.866**

      **Part (c): Decision with F = 3.12**

      Since F = 3.12 > F* = 2.866, we **reject H‚ÇÄ**.

      The F-statistic falls in the rejection region (right tail beyond the critical value).

      **Part (d): Comparison of approaches**

      **Critical Value Approach:**
      
      *Advantages:*
      - Simple decision rule: reject if F > F*
      - Don't need to compute exact p-value
      - Useful for hand calculations
      
      *Disadvantages:*
      - Only gives binary decision (reject/don't reject)
      - Doesn't indicate strength of evidence
      - Need different critical values for different Œ± levels

      **P-value Approach:**
      
      *Advantages:*
      - Provides exact probability of observed result under H‚ÇÄ
      - Indicates strength of evidence (very small p ‚Üí strong evidence)
      - Same p-value works for any Œ± level
      - More informative for readers
      
      *Disadvantages:*
      - Requires computation (usually software)
      - Can be misinterpreted (p-value ‚â† probability H‚ÇÄ is true)

      **Recommendation**: Use p-values when possible (standard in modern practice), but understand critical values for theoretical understanding.

      **R verification:**

      .. code-block:: r

         qf(0.05, 3, 36, lower.tail = FALSE)  # Critical value = 2.866
         pf(3.12, 3, 36, lower.tail = FALSE)  # p-value = 0.038 < 0.05

----

Additional Practice Problems
----------------------------

**True/False Questions** (1 point each)

1. If F = MSA/MSE = 2.5, it means the between-group variance is 2.5 times the within-group variance.

   ‚ìâ or ‚íª

2. The p-value for an ANOVA F-test is calculated as P(F ‚â§ f_TS).

   ‚ìâ or ‚íª

3. An F-statistic less than 1 always indicates that the null hypothesis is true.

   ‚ìâ or ‚íª

4. For k = 2 groups, the ANOVA F-statistic equals the square of the pooled two-sample t-statistic.

   ‚ìâ or ‚íª

5. The F-distribution is symmetric around its mean.

   ‚ìâ or ‚íª

6. A very large F-statistic (e.g., F = 50) suggests strong evidence that at least one population mean differs from the others.

   ‚ìâ or ‚íª

**Multiple Choice Questions** (2 points each)

7. Which R code correctly computes the p-value for an ANOVA F-test with F = 4.5, df‚ÇÅ = 3, df‚ÇÇ = 45?

   ‚í∂ ``pf(4.5, 3, 45)``
   
   ‚í∑ ``pf(4.5, 3, 45, lower.tail = FALSE)``
   
   ‚í∏ ``1 - pf(4.5, 45, 3)``
   
   ‚íπ ``qf(4.5, 3, 45)``

8. Under the null hypothesis, the expected value of the F-statistic is approximately:

   ‚í∂ 0
   
   ‚í∑ 1
   
   ‚í∏ k (number of groups)
   
   ‚íπ n (total sample size)

9. Which of the following would NOT result in the F = t¬≤ relationship holding?

   ‚í∂ Using Welch's t-test instead of pooled t-test
   
   ‚í∑ Having k = 2 groups
   
   ‚í∏ Testing H‚ÇÄ: Œº‚ÇÅ - Œº‚ÇÇ = 0
   
   ‚íπ Using a two-sided alternative hypothesis

10. If MSA = 150 and MSE = 25, the F-statistic equals:

    ‚í∂ 125
    
    ‚í∑ 175
    
    ‚í∏ 6
    
    ‚íπ 0.167

11. An ANOVA F-test yields p-value = 0.03. At Œ± = 0.01, we:

    ‚í∂ Reject H‚ÇÄ because 0.03 < 1
    
    ‚í∑ Reject H‚ÇÄ because 0.03 < 0.05
    
    ‚í∏ Fail to reject H‚ÇÄ because 0.03 > 0.01
    
    ‚íπ Cannot determine without more information

12. The F-distribution with df‚ÇÅ = 1 and df‚ÇÇ = n-2 is related to which other distribution?

    ‚í∂ Normal distribution
    
    ‚í∑ Chi-square distribution
    
    ‚í∏ t-distribution squared
    
    ‚íπ Exponential distribution

.. dropdown:: Answers to Practice Problems
   :class-container: sd-border-success

   **True/False Answers:**

   1. **True** ‚Äî F = MSA/MSE directly represents this ratio of variances.

   2. **False** ‚Äî The p-value is P(F ‚â• f_TS), using the upper tail (lower.tail = FALSE).

   3. **False** ‚Äî F < 1 simply means no evidence against H‚ÇÄ; it doesn't prove H‚ÇÄ is true. Random sampling can produce F < 1 even when means differ slightly.

   4. **True** ‚Äî This is the F = t¬≤ relationship when using pooled variance, testing Œî‚ÇÄ = 0, with two-sided alternative.

   5. **False** ‚Äî The F-distribution is right-skewed, not symmetric.

   6. **True** ‚Äî Large F indicates MSA >> MSE, strong evidence that between-group variability exceeds within-group variability.

   **Multiple Choice Answers:**

   7. **‚í∑** ‚Äî ``pf(4.5, 3, 45, lower.tail = FALSE)`` correctly gives P(F ‚â• 4.5).

   8. **‚í∑** ‚Äî Under H‚ÇÄ, E(F) ‚âà 1 since both MSA and MSE estimate œÉ¬≤.

   9. **‚í∂** ‚Äî Welch's t-test uses unpooled variance, breaking the equivalence.

   10. **‚í∏** ‚Äî F = MSA/MSE = 150/25 = 6.

   11. **‚í∏** ‚Äî At Œ± = 0.01, we need p-value ‚â§ 0.01 to reject. Since 0.03 > 0.01, we fail to reject.

   12. **‚í∏** ‚Äî F_{1,n-2} = t¬≤_{n-2}; the F(1, df‚ÇÇ) distribution equals the square of t_{df‚ÇÇ}.