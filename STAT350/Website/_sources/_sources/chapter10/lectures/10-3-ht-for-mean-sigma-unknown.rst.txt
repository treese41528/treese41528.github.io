.. _10-3-ht-for-mean-sigma-unknown:


.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch10-3">
      <iframe
         id="video-ch10-3"
         title="STAT 350 ‚Äì Chapter 10.3 Hypothesis Test and Confidence Interval-Bound Video"
         src="https://www.youtube.com/embed/oVXZ-UAhrwQ?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

.. admonition:: Slides üìä
   :class: tip
   
   - `Hypothesis Testing for Single Sample (Part 3) (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%2010%20Hypothesis%20Testing/Hypothesis%20Testing%20for%20Single%20Sample%20Part3_AC.pptx>`_


Connecting CI and HT; *t*-Test for Œº When œÉ Is Unknown
======================================================================================

**Hypothesis testing and confidence regions are complementary tools** that address essentially
the same question from two different perspectives. When certain conditions are carefully matched,
a confidence region and a hypothesis test yield outcomes that carry direct implications for
one another.

We also dicsuss how to extend our understanding of hypothesis testing to cases where **the population 
standard deviation is unknown**. 
As with confidence regions, we employ the :math:`t`-distribution to construct a testing procedure that accounts
for the added uncertainty.

.. admonition:: Road Map üß≠
   :class: important

   * Understand the underlying **connection between confidence regions and hypothesis testing**. For a
     given confidene region, identify its complementary hypothesis testing scenario, and vice versa.
   * Use the :math:`t`-**distribution** to construct hypothesis tests when the population standard 
     deviation :math:`\sigma` is unknown.

The Duality of Hypothesis Tests and Confidence Regions
---------------------------------------------------------

Two Perspectives on the Same Question
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We begin our discussion by comparing the key components of hypothesis testing and confidence regions:

.. flat-table::
   :header-rows: 1

   * - Inference Component
     - Confidence region for :math:`\mu`
     - Hypothesis testing on :math:`\mu`


   * - **Parameter of interest**
     - They both aim to understand a population mean, :math:`\mu`

   * - **Question**
     - "What parameter values are consistent with the sample?"
     - "Is this specific parameter value consistent with the sample?"

   * - **How inference strength is conveyed**
     - A large :math:`C`
     - A small :math:`\alpha` 

   * - **Sample information used**
     - :cspan:`1` Both use :math:`\bar{X}` and its approximate normality due to the CLT

   * - **Outcome**
     - A range of plausible values
     - Answer to whether a candidate value (:math:`\mu_0`) is plausible

It is evident from the summary above that confidence intervals and hypothesis tests 
address the **same fundamental question from different angles**. 

The mathematical connection becomes even deeper when the two inference methods are matched 
by their **inferential strengths and sidedness**. Under this pairing, 
the two methods are in fact **equivalent**: the result of one has direct implications for the result of the other.

Confidence Intervals and Two-sided Hypothesis Tests  
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Consider the :math:`C \cdot 100 \%` confidence interval for a population mean.
With :math:`\alpha=1-C`, we use the formula:

.. math:: 
   \left(\bar{x} - z_{\alpha/2} \frac{\sigma}{\sqrt{n}}, \bar{x} + z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\right).

Let us now perform a two-sided hypothesis test on a candidate
value :math:`\mu_0` using the significance level :math:`\alpha = 1-C`. The hypotheses are:

.. math::
   &H_0: \mu = \mu_0\\
   &H_a: \mu \neq \mu_0

Based on the cutoff method, we reject the null hypothesis if:

.. math:: 
   \bar{x} \geq z_{\alpha/2}\frac{\sigma}{\sqrt{n}} + \mu_0 \quad \text{ or }
   \quad \bar{x} \leq -z_{\alpha/2}\frac{\sigma}{\sqrt{n}} + \mu_0.

Isolate :math:`\mu_0` in both inequalities. Then the null hypothesis is rejected
when:

.. math:: 
   \bar{x} - z_{\alpha/2}\frac{\sigma}{\sqrt{n}} \geq \mu_0 \quad \text{ or }
   \quad \bar{x} + z_{\alpha/2}\frac{\sigma}{\sqrt{n}} \leq \mu_0.

Note that the **left-hand side of the inequalities are exactly the two ends of
the confidence interval**.

**The Connection**

The null hypothesis for a two-tailed test is **rejected** excatly when the null value
:math:`\mu_0` **is outside** a matching confidence interval. Conversely, if the chosen :math:`\mu_0` is **inside**
the confidence interval, we would **not reject** the null hypothesis for that test.

Lower Confidence Bounds and Upper-Tailed Tests  
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :math:`C\cdot 100 \%` lower confidence bound for the population mean :math:`\mu` is:

.. math::
   \left(\bar{x} - z_{\alpha} \frac{\sigma}{\sqrt{n}}, \quad \infty\right).

When performing an upper-tailed test:

.. math::
   &H_0: \mu \leq \mu_0\\
   &H_a: \mu > \mu_0,

we reject the null hypothesis if :math:`\bar{x} \geq z_\alpha\frac{\sigma}{\sqrt{n}} + \mu_0`.
By isolating :math:`\mu_0`, the inequality becomes:

.. math::
   \bar{x} - z_\alpha\frac{\sigma}{\sqrt{n}} \geq \mu_0.

**The Connection**

Given :math:`\alpha = 1-C`, 
the null hypothesis of an upper-tailed test is **rejected** if and only if 
the null value :math:`\mu_0` **fails to be inside the confidence region** defined by the lower bound.

Upper Confidence Bounds and Lower-Tailed Tests  
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :math:`C\cdot 100 \%` upper confidence bound for the population mean :math:`\mu` is:

.. math::
   \left(-\infty, \quad \bar{x} + z_{\alpha} \frac{\sigma}{\sqrt{n}} \right).

For a lower-tailed hypothesis test with

.. math::
   &H_0: \mu \geq \mu_0\\
   &H_a: \mu < \mu_0,

The null hypothesis is rejected if :math:`\bar{x} \leq -z_\alpha\frac{\sigma}{\sqrt{n}} + \mu_0`.
By isolating :math:`\mu_0`, the inequality becomes:

.. math::
   \bar{x} + z_\alpha\frac{\sigma}{\sqrt{n}} \leq \mu_0.

**The Connection**

As expected, the values of :math:`\mu_0` that lead to rejection of the null hypothesis in
a lower-tailed test coincide with those that fall **outside** the upper confidence bound
of a matching confidence level, :math:`C= 1-\alpha`.

Summary
~~~~~~~~~

For the duality to work, we need three crucial conditions:

1. The two inference methods are being applied to the same experimental result. 
2. :math:`C + \alpha = 1`.
3. The methods are paired corrrectly based on sidedness (two-sided test and CI, upper-tailed test and 
   LCB, lower-tailed test and UCB).

When these conditions hold,

- :math:`\mu_0` lies **inside** the confidence region :math:`\iff` **fail to reject** :math:`H_0`
- :math:`\mu_0` lies **outside** the confidence region :math:`\iff` **reject** :math:`H_0`

.. admonition:: Example üí°: Quality Control for Cherry Tomatoes
   :class: note

   Tom Green oversees quality control for a large produce company. 
   The weights of cherry tomato packages are known to be
   normally distributed with  :math:`\mu=227g` (1/2 lbs) and :math:`\sigma=5g`.
   He obtains a simple random sample of four packages of cherry tomatoes and discovers that
   their average weight is 222g. 
   

   1. Construct a 95% confidence interval for the mean weight.
   2. Tom would like to test whether the true mean weight of the packages is different from 227g
      with :math:`\alpha = 0.05`. Based on the result of #1, (do not compute the test statistic or the 
      :math:`p`-value), predict wether the null hypothesis will be rejected.
   3. Perform the hypothesis test and confirm your answer from part 2.

   **Q1: Construct the 95% Confidence Interval**

   Since :math:`\sigma` is known and the data is normally distributed, we use the :math:`z`-procedure. 
   In general,

   .. math::

      \left(\bar{x} - z_{\alpha/2} \frac{\sigma}{\sqrt{n}}, 
      \bar{x} + z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\right).

   For 95% confidence, :math:`\alpha = 0.05`. The critical value :math:`z_{0.025}` can be found using:

   .. code-block:: r

      z_critical <- qnorm(0.025, lower.tail = FALSE)
      z_critical
      # [1] 1.959964

   Calculate the interval:

   .. math::

      \left(222 - (1.96)\frac{5}{\sqrt{4}}, 222 + (1.96) \frac{5}{\sqrt{4}}\right) = (217.1, 226.9)

   We are 95% confident that the true mean weight of cherry tomato packages
   is captured between 217.1 and 226.9 grams.

   **Q2: Use Duality to Predict the Conlusion for the Hypothesis Test**

   We want to test:

   .. math::
      &H_0: \mu = 227\\
      &H_a: \mu \neq 227

   Since we have :math:`C + \alpha = 0.95 + 0.05 = 1`, and both the confidence region and the hypothesis test
   are two-sided, the duality relationship applies.
   The null value :math:`\mu_0 = 227` lies **outside** the 95% confidence interval :math:`(217.1, 226.9)`.
   Therefore, we would **reject** the null hypothesis if we performed the hypothesis test. 
   :math:`\mu_0 = 227` is NOT a plausaible value for the true mean weight according to the CI, so
   we should be able to draw the same conclusion from the dual hypothesis test.

   **Q3: Verify with Formal Hypothesis Test**

   Let's confirm this conclusion by performing a z-test for the hypothesis pair.

   .. math::

      z_{TS} = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}} = \frac{222 - 227}{5/\sqrt{4}} = \frac{-5}{2.5} = -2.0

   The p-value is:

   .. code-block:: r

      z_test_stat <- -2.0
      p_value <- 2 * pnorm(abs(z_test_stat), lower.tail = FALSE)
      p_value
      # [1] 0.04550026

   Since p-value = :math:`0.0455 < \alpha = 0.05`, we **reject** the null hypothesis.
   Both approaches give the same conclusion. This confirms the duality relationship.

:math:`t`-Tests: When œÉ is Unknown
---------------------------------------------------------

.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch10-3-1">
      <iframe
         id="video-ch10-3-1"
         title="STAT 350 ‚Äì Chapter 10.3.1 Test Statistic when œÉ is Unknown Video"
         src="https://www.youtube.com/embed/Qf1OChGzcQE?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

So far, we have been building our test procedures based on the convenient assumption
that the population standard deviation is known. If we do not know the population 
mean :math:`\mu`, however, we almost certainly do not know :math:`\sigma`, either.

In such cases, we will take the natural step of replacing the unknown 
:math:`\sigma` with the estimator, :math:`S`. The sample standard deviation :math:`S` 
is itself a random variable that varies from sample to sample, and this extra variability must be accounted for.

The Assumptions
~~~~~~~~~~~~~~~~~

For the new test procedure, we use a slightly modified set of assumtions:

1. :math:`X_1, X_2, \cdots, X_n` form an *iid* sample from
   the population :math:`X` with mean :math:`\mu` and variance :math:`\sigma^2`.
2. Either the population :math:`X` is normally distributed, or the sample size :math:`n` is
   sufficiently large for the CLT to hold.
3. The population variance :math:`\sigma^2` is **unknown**.

The only difference is that the population variance (and sd) is unknown. 

The :math:`t`-Test Statistic 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Recall that when :math:`\sigma` was known, the :math:`z`-test statistic

.. math:: Z_{TS} = \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}

played a key role. We used it to

* measure the standardized discrepancy of the data from the null assumption,
* compare it with a :math:`z`-critical value and draw a conclusion using the cutoff method, and
* compute the tail probabiltiy of the observed :math:`z_{TS}` and draw a conclusion in the
  :math:`p`-value method.

We obtain a new test statistic by
replacing the ununknown :math:`\sigma` with the sample standard deviation, :math:`S:`

.. math::

   T_{TS} = \frac{\bar{X} - \mu_0}{S/\sqrt{n}}

This new test stastistic is called the :math:`t`-**test statistic**. When the null hypothesis holds,
the :math:`t`-test statistic has a :math:`t`-distribution with the degrees of freedom :math:`\nu= n-1`.

The :math:`t`-test statistic plays the same roles as the :math:`z`-test statistic, but
we must account for **the change in distribution** by referencing the appropriate *t*-distribution
rather than standard normal when computing critical values and :math:`p`-values.

Cutoff Method for :math:`t`-Tests
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Recall that the cutoff method rejects the null hypothesis if
the observed test statistic falls in a region that is too unusual for the null hypothesis.

For an upper-tailed :math:`t`-test, the null hypothesis would be rejected if the observed sample mean
is much higher than the null value :math:`\mu_0` and satisfies:

   .. math::
      t_{TS} = \frac{\bar{x}-\mu_0}{s/\sqrt{n}} > t_{\alpha, n-1},

where :math:`t_{\alpha, n-1}` is the appropriate :math:`t`-critical value.

Likewise, the rejection rule for a lower-tailed test is:

   .. math::
      t_{TS} = \frac{\bar{x}-\mu_0}{s/\sqrt{n}} < -t_{\alpha, n-1}.

Finally, for a two-tailed test,

   .. math::
      |t_{TS}| = \left|\frac{\bar{x}-\mu_0}{s/\sqrt{n}}\right| > t_{\alpha/2, n-1}.

:math:`p`-Values for :math:`t`-Tests
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. flat-table::
   :header-rows: 1
   :widths: 15 10 50

   * - :cspan:`2` :math:`p`-Values for :math:`t`-Tests

   * - **Upper-tailed p-value**
     - .. math:: 
         P(T_{n-1} \geq t_{TS})
      
       .. code-block:: r
         
         tts <- (xbar-mu0)/(s/sqrt(n))
         pt(tts, df=n-1, lower.tail=FALSE)

   * - **Lower-tailed p-value**
     - .. math:: 
          P(T_{n-1} \leq t_{TS})
      
       .. code-block:: r

         pt(tts, df=n-1) 

   * - **Two-tailed p-value**
     - .. math::
          2P(T_{n-1} \leq -|t_{TS}|) \quad \text{ or } \quad 2P(T_{n-1} \geq |t_{TS}|)
      
       .. code-block:: r
          
          2 * pt(-abs(tts), df=n-1)
          2 * pt(abs(tts), df=n-1, lower.tail=FALSE)

The Rejection Rule Remains Unchanged
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Once a :math:`p`-value is computed, it is compared against a pre-specified significance level
:math:`\alpha`. If the :math:`p`-value is less than :math:`\alpha`, the null hypothesis is rejected.

.. admonition:: Example üí°: Radon Detector Accuracy
   :class: note
   
   University researchers want to find out whether their radon detectors are working correctly.
   Thy collected a random sample of 12 detectors and placed them in a chamber exposed to exactly 105
   picocuries per liter of radon. If the detectors work properly, their measurements should be close
   to 105, on average.

   .. flat-table::
      :header-rows: 1

      * - :cspan:`5` The Measurements (in picocuries per liter)

      * - 91.9
        - 97.8
        - 111.4
        - 122.3
        - 105.4
        - 95.0
      
      * - 103.8
        - 99.6
        - 119.3
        - 104.8
        - 101.7
        - 96.6

   In addition, suppose that the population distribution is known to be normal. Perform a
   hypothesis test with the significance level :math:`\alpha=0.1`.

   **Step 0: Which Procedure?**

   The experiment uses a random sample from a normally distributed population. Therefore,
   we are justified to use an inference method which assumes approximate normality of the
   sample mean. We use the :math:`t`-test procedure since the population
   standard deviation is unknown.

   **Step 1: Define the Parameter**

   Let :math:`\mu` denote the true mean of the measurements produced by the detectors
   in a chamber with exactly 105 picocuries per liter of radon.

   **Step 2: State the Hypotheses**

   .. math::
      &H_0: \mu = 105\\
      &H_a: \mu \neq 105

   **Step 3: Calculate the Observed Test Statistic and the p-value**

   Comonents:

   * :math:`n=12`
   * :math:`\bar{x}=104.1333`
   * :math:`s = 9.397421`
   * :math:`df = n-1 = 11`

   The sample mean and the sample standard deviation can be computed from the data set.

   .. math::

      t_{TS} = \frac{\bar{x} - \mu_0}{s/\sqrt{n}} = \frac{104.1333 - 105}{9.397421/\sqrt{12}} = \frac{-0.8667}{2.7136} = -0.319

   The :math:`p`-value is computed using R:

   .. code-block:: r

      p_value <- 2 * pt(abs(t_test_stat), df = 11, lower.tail = FALSE)
      p_value
      # [1] 0.755

   **Step 4: Make the Decision and Write the Conclusion**

   Since :math:`p`-value :math:`= 0.755 > \alpha = 0.10`, we **fail to reject** the null hypothesis.
   With the significance level :math:`\alpha=0.1`, we do not have enough evidence to
   reject the null hypothesis that the true mean measurent is 105 picocuries per liter.

   ü§î **Why Such a Large P-Value?**

   Although the individual measurements in the data set seem quite inaccurate, 
   we failed to reject the null hypothesis with a large :math:`p`-value of :math:`0.755`.
   Several factors contribute:

   1. The sample mean (:math:`\bar{x} = 104.1`) is very close to null value (:math:`\mu_0 = 105.0`).
   2. The sample size of 12 is small and limits precision.  
   3. The sample standard deviation (:math:`s=9.4`) is relatively large.
   4. We are performing a two-sided test, which makes the rejection region farther toward the tails
      than a one-sided test.

   This example illustrates why, in hypothesis testing, we say we "fail to reject"
   rather than "accept" the null hypothesis. The absence of evidence against the null does not
   necessarily constitute evidence in its favor.
   
   When there is a large degree of uncertainty, hypothesis tests tend to grow more
   **conservative**, which means that it will require the evidence to be stronger
   for a rejection of the null.

Duality Revisited for :math:`t`-Procedures
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The duality relationship established for :math:`z`-procedures carries over directly to 
:math:`t`-procedures. A confidence region and a hypothesis test based on :math:`t`-distributions
are equivalent if:

1. The two inference methods are being applied to the same experimental result. 
2. :math:`C + \alpha = 1`.
3. The methods are paired corrrectly based on sidedness (two-sided test and CI, upper-tailed test and 
   LCB, lower-tailed test and UCB).

.. admonition:: Example üí°: Complementary CI for Radon Detector Accuracy

   Compute the 90% confidence interval for the Radon Detector experiment and
   comment on its consistency with the hypothesis test.

   A :math:`t`-confidence interval is, in general,

   .. math::

      \left(\bar{x} - t_{\alpha/2, n-1}\frac{s}{\sqrt{n}},
      \quad \bar{x} + t_{\alpha/2, n-1}\frac{s}{\sqrt{n}}\right).

   From the previous example, we have:

   * :math:`\bar{x} =104.1333`
   * :math:`s = 9.397421`
   * :math:`n = 12`

   The t-critical value :math:`t_{\alpha/2, n-1}` is computed using R:

   .. code-block:: r

      alpha <- 0.10
      t_critical <- qt(alpha/2, df = 11, lower.tail = FALSE)
      t_critical
      # [1] 1.795885

   Substituting the values to the general formula,
   the 90% confidence interval is:
   
   .. math:: (99.3, 109.0). 

   Since :math:`\mu_0 = 105` lies **within** this interval, 
   the duality principle tells us we should fail to reject :math:`H_0`,
   which matches our hypothesis test conclusion.


   **Single-call Verification Using t.test**

   When the raw data set is available, the R command ``t.test`` produces
   both inference results simultaneously.

   .. code-block:: r

      radon <- c(91.9, 97.8, 111.4, 122.3, 105.4,
           95.0, 103.8, 99.6, 119.3, 104.8, 101.7, 96.6)

      t.test(radon,
             mu = 105,
             alternative = "two.sided",
             conf.level=0.9)
      
      #output
      '''
      One Sample t-test

      data:  radon
      
      t = -0.31947, df = 11, p-value = 0.7554
      alternative hypothesis: true mean is not equal to 105
      
      90 percent confidence interval:
      99.26145 109.00521
      
      sample estimates:
      mean of x 
      104.1333 
      '''


   The :math:`t`-statistic, :math:`p`-value, and confidence interval match the hand
   calculations‚Äîalways a good final check.

   
:math:`t`-Procedures vs. :math:`z`-Procedures
----------------------------------------------------------

We learned in Chapter 9.5.4 that for any given significance level, 
the :math:`t`-**critical value decreases as** :math:`n` **(and therefore the df) increases**.
This also meant that 

.. math:: 
   t_{\alpha, n-1} > z_\alpha

for any finite :math:`n`, since the standard normal distribution
can be viewed as a :math:`t`-distribution with "infinite" degrees of freedom.
As a result, :math:`t`-**based confidence regions were wider on average than** :math:`z`-**based regions**. 

In hypothesis tests, if the observed test statistic is held constant, its **p-value** is larger in a
:math:`t`-test than in a :math:`z`-test because the tails of a :math:`t`-distribution are **heavier** than 
those of the standard normal. This makes it more difficult for a :math:`t`-test to reject the null hypothesis.

The trend is consistent: in the presence of added uncertainty,
both inference methods become more **conservative**‚Äîmore cautious in labeling an experimental result as
unusual. The confidence region widens, and the test becomes more reluctant to
reject the status quo.

..
   When Assumptions Are Violated
   -----------------------------------

   *t*-procedures assume that the sample mean has a normal distribution. While T-tests are reasonably robust to 
   moderate departures from normality, serious violations can be problematic, especially with small samples.
   Always use graphical and/or numerical measures to check assumptions. If any serious violations are
   observed, consider the following alternative approaches:

   1. Data transformation(e.g., log transformation for right-skewed data)
   2. Non-parametric methods (e.g., Wilcoxon signed-rank test)
   3. Bootstrap methods for empirical sampling distributions
   4. Exact distributional methods when the true distribution is known


Bringing It All Together
-----------------------------

.. admonition:: Key Takeaways üìù
   :class: important

   1. **Hypothesis tests and confidence regions are dual procedures** that address the same questions 
      from different perspectives, connected by the relationship :math:`C + \alpha = 1`. Further,
      
      * Two-sided hypothesis tests pair with confidence intervals.
      * Upper-tailed tests pair with lower confidence bounds.
      * Lower-tailed tests pair with upper confidence bounds.
   
   2. When the population standard deviation :math:`\sigma` is unknown, :math:`t`-**tests** are used instead 
      of :math:`z`-tests.

   3. :math:`t`-procedures generally produce more **conservative** inference results than the corresponding
      :math:`z`-procedure; the confidence regions are wider, and it is more difficult to reject the null hypothesis.
   

Exercises
~~~~~~~~~~~~

2. **One-Sided Test**: A manufacturer wants to show that their batteries last **more than** 20 hours on average.
   With a random sample of 12 batteries, they obtain :math:`\bar{x} = 22.1` hours and :math:`s = 3.5` hours.

   a) Perform the appropriate hypothesis test at :math:`\alpha = 0.01`.
   b) What type of confidence region is appropriate for this context? 
      Compute the appropriate 99% confidence region and confirm that it aligns with the
      conclusion of the hypothesis test.

3. **Sample Size Impact**: Explain why a :math:`t`-test with :math:`n = 5` requires a larger test statistic to 
   reject :math:`H_0` than a :math:`z`-test with the same data and significance level. What does this say about our 
   confidence in conclusions from small samples?

4. **Cherry Tomato Follow-up**: In the cherry tomato example, suppose :math:`\sigma` is in fact unknown and 
   estimated as :math:`s = 5` grams from the sample of 4 packages. Rework the entire analysis using :math:`t`-procedures 
   and compare your conclusions to the original :math:`z`-procedure results.

5. **Critical Thinking**: A study reports "no significant difference" with :math:`p = 0.12` and :math:`n = 8.` 
   The researcher concludes the null hypothesis is *true*. Identify at least three problems with this reasoning and 
   suggest better ways to interpret the results.