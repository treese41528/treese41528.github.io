.. _9-5-ci-cb-sigma-unknown:

.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch9-5">
      <iframe
         id="video-ch9-5"
         title="STAT 350 â€“ Chapter 9.5 Confidence Intervals when o is Unknown_Students' t-distribution"
         src="https://www.youtube.com/embed/3ZhAnYsmILo?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

Confidence Intervals and Bounds When Ïƒ is Unknown
==============================================================================================

In previous chapters, we developed confidence intervals for a population mean under the 
simplifyingâ€”but usually unrealisticâ€”assumption that the population standard deviation Ïƒ is known. 
In practice, we rarely know Ïƒ and must estimate it from the same sample that provides our estimate of Î¼.

This creates a fundamental challenge: using a sample standard deviation *s* in place of the known Ïƒ 
introduces additional uncertainty that must be accounted for in our confidence intervals. 
The standard normal distribution (Z) is no longer appropriate because it doesn't capture this 
extra layer of uncertainty.

The solution to this problem comes from a distribution developed by William Sealy Gosset in the 
early 1900s: the **Student's t distribution**.

.. admonition:: Road Map ðŸ§­
   :class: important
   
   Fill Content

William Sealy Gosset and the Birth of the *t* Distribution
-----------------------------------------------------------

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/William-Gosset.jpg
   :alt: Portrait of William Sealy Gosset (Student)
   :width: 35%
   :align: right

   *William S. Gosset (1876-1937)*

In 1908, William Sealy Gosset, a chemist and statistician employed by the Guinness brewery in Dublin, 
Ireland, published a paper titled "The Probable Error of a Mean" in the journal *Biometrika*. 
Due to Guinness company policy that prohibited employees from publishing their research, Gosset published 
under the pseudonym "Student"â€”leading to the now-famous "Student's *t*" distribution.

Gosset's work at Guinness involved quality control for beer production. He needed statistical methods that 
worked reliably with small samples, as testing large quantities of beer would have been wasteful. 
The specific problem he faced was how to make inferences about a population mean when the population 
standard deviation is unknown and must be estimated from the same small sample.

His mathematical solutionâ€”the *t* distributionâ€”accounts for the added uncertainty of estimating Ïƒ with *s*, 
especially crucial when working with small samples. This breakthrough has become one of the most widely used 
statistical tools across virtually all fields of scientific inquiry.

The *t* Statistic and Its Distribution
---------------------------------------

When the population standard deviation Ïƒ is unknown, we replace it with the sample standard deviation *s*. Our pivotal quantity changes from a Z-statistic to a *t*-statistic:

.. math::
   T = \frac{\bar{X} - \mu}{S/\sqrt{n}}

Under the assumption that the data comes from a normal population with unknown mean Î¼ and unknown variance ÏƒÂ², this statistic follows a Student's *t* distribution with **degrees of freedom** (df) equal to:

.. math::
   \nu = n - 1

The probability density function of the *t* distribution is given by:

.. math::
   f_T(t) = \frac{1}{\sqrt{\nu\pi}} \frac{\Gamma(\frac{\nu+1}{2})}{\Gamma(\frac{\nu}{2})} \left(1 + \frac{t^2}{\nu}\right)^{-(\nu+1)/2}

Where Î“ represents the gamma function, a generalization of the factorial function.

Properties of the *t* Distribution
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The Student's *t* distribution has several important properties:

1. **Symmetric around zero**, similar to the standard normal distribution
2. **Heavier tails** than the normal distribution, reflecting the additional uncertainty from estimating Ïƒ
3. **Approaches the standard normal distribution** as the degrees of freedom increase (Î½ â†’ âˆž)
4. **Always more spread out** than the normal distribution for finite degrees of freedom

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/t-pdfs.png
   :alt: Student t density with various df overlaying the standard normal
   :width: 75%

   *Figure 9.8: The heavier tails of the Student's t distribution compared to the standard normal distribution for different degrees of freedom (df). As df increases, the t distribution approaches the standard normal.*

The heavier tails of the *t* distribution are crucial because they provide the correct probability coverage when Ïƒ is estimated rather than known. The smaller the sample size, the heavier the tails need to be to maintain the desired confidence level.

Deriving the *t*-Based Confidence Interval
-------------------------------------------

Similar to the Ïƒ-known case, we can derive a confidence interval for Î¼ using the pivotal method. Starting with the pivotal probability statement:

.. math::
   P\left(-t_{\alpha/2, \nu} < T < t_{\alpha/2, \nu}\right) = 1 - \alpha

Where:
- :math:`t_{\alpha/2, \nu}` is the critical value from the *t* distribution with Î½ degrees of freedom that corresponds to a right-tail probability of Î±/2
- T is our *t*-statistic: :math:`T = \frac{\bar{X} - \mu}{S/\sqrt{n}}`

Through algebraic manipulation ("pivoting"), we isolate Î¼ to obtain the (1-Î±)100% confidence interval:

.. math::
   \bar{x} \pm t_{\alpha/2, n-1} \frac{s}{\sqrt{n}}

This formula closely resembles the z-interval, with two critical differences:
1. We use the sample standard deviation *s* instead of the population standard deviation Ïƒ
2. We use the *t* critical value with n-1 degrees of freedom instead of the z critical value

Finding *t* Critical Values
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The *t* critical value :math:`t_{\alpha/2, \nu}` can be found using statistical software or *t* distribution tables. In R, we can use the `qt()` function:

.. code-block:: r

   # For a 95% confidence interval with df = 14
   t_critical <- qt(0.975, df = 14)  # Note: 0.975 = 1 - 0.025
   t_critical  # Returns 2.145

*t* critical values are always larger than the corresponding z critical values for the same confidence level, reflecting the additional uncertainty from estimating Ïƒ. As the degrees of freedom increase, the *t* critical values converge to the z critical values.

Assumptions for the *t*-Based Confidence Interval
-------------------------------------------------

The validity of the *t*-based confidence interval rests on three key assumptions:

1. **Random Sample**: The data represents a simple random sample from the population of interest.
   
2. **Normal Population**: The sampled population follows a normal distribution. However, the procedure is robust to moderate departures from normality, especially for larger sample sizes.
   
3. **Unknown Ïƒ**: The population standard deviation is unknown and must be estimated from the sample data.

The *t* procedure's reliance on the normality assumption varies by sample size:

- For **n < 15**, the population should be close to normal
- For **15 â‰¤ n < 40**, moderate departures from normality are acceptable
- For **n â‰¥ 40**, the procedure is generally robust to all but severe non-normality

Regardless of sample size, the presence of outliers can seriously distort both :math:`\bar{x}` and *s*, potentially invalidating the inference.

.. admonition:: Example ðŸ’¡ - Cholesterol Reduction Study

   A pharmaceutical company is testing a new drug designed to lower LDL cholesterol levels. 
   In a clinical trial, 15 patients with high cholesterol received the drug for eight weeks, 
   and the reduction in their LDL cholesterol (in mg/dL) was measured.

   The sample mean reduction was :math:`\bar{x} = 23.4` mg/dL with a sample standard deviation 
   of *s* = 6.8 mg/dL. Construct a 95% confidence interval for the mean reduction Î¼.

   **Step 1**: Identify the key information
      - Sample size: n = 15
      - Sample mean: :math:`\bar{x} = 23.4` mg/dL
      - Sample standard deviation: s = 6.8 mg/dL
      - Confidence level: 95% (Î± = 0.05)
      - Degrees of freedom: Î½ = n - 1 = 14

   **Step 2**: Find the critical value
      
   .. math::
      t_{0.025, 14} = 2.145

   **Step 3**: Calculate the margin of error

   .. math::
      \text{ME} = t_{0.025, 14} \cdot \frac{s}{\sqrt{n}} = 2.145 \cdot \frac{6.8}{\sqrt{15}} \approx 3.76 \text{ mg/dL}

   **Step 4**: Construct the confidence interval

   .. math::
      \bar{x} \pm \text{ME} = 23.4 \pm 3.76 = [19.64, 27.16] \text{ mg/dL}

   **Interpretation**: We are 95% confident that the true mean reduction in LDL cholesterol with this drug is between 19.64 and 27.16 mg/dL.

   Here's the R code for this analysis:

   .. code-block:: r

      # Sample data
      xbar <- 23.4    # Sample mean (mg/dL)
      s <- 6.8        # Sample standard deviation (mg/dL)
      n <- 15         # Sample size
      df <- n - 1     # Degrees of freedom
      
      # Calculate 95% confidence interval
      alpha <- 0.05
      t_crit <- qt(1 - alpha/2, df)
      margin_of_error <- t_crit * s / sqrt(n)
      
      # Construct the confidence interval
      ci_lower <- xbar - margin_of_error
      ci_upper <- xbar + margin_of_error
      
      # Display results
      c(ci_lower, ci_upper)  # [19.64, 27.16]

   Alternatively, R's `t.test()` function provides a more streamlined approach:

   .. code-block:: r

      # Using t.test() function
      t.test(x, conf.level = 0.95)
      
      # Output would include:
      # 95 percent confidence interval:
      # 19.64 27.16

Sample Size Planning When Ïƒ Is Unknown
----------------------------------------

Planning a study's sample size is more challenging when Ïƒ is unknown. We start with the formula for the margin of error:

.. math::
   E = t_{\alpha/2, n-1} \cdot \frac{s}{\sqrt{n}}

Notice the circular problem: to determine n, we need the *t* critical value, which depends on n (through the degrees of freedom). Additionally, we need a value for s, which we don't have before collecting data.

A practical approach involves these steps:

1. **Obtain a planning value for s**:
   - Use s from a pilot study or previous research
   - Make an educated guess based on the expected range (range/4 is a rough approximation)
   - Use a conservative upper bound when uncertainty is high

2. **Use an iterative process**:
   - Start with an initial guess using the z critical value: :math:`n_0 = \left(\frac{z_{\alpha/2} \cdot s_*}{E}\right)^2`
   - Calculate the *t* critical value using df = nâ‚€ - 1
   - Recalculate n using the *t* critical value
   - Repeat until convergence

This process typically converges quickly, often in just a few iterations.

Comparison: *t* Interval vs. *z* Interval
-------------------------------------------

The *t*-based confidence interval is always wider than the corresponding z-based interval would be (if Ïƒ were known and equal to s). This difference reflects the additional uncertainty from estimating Ïƒ.

Key differences include:

1. **Critical values**: *t* critical values are always larger than z critical values for the same confidence level (except as df â†’ âˆž)

2. **Effect of sample size**: The difference between *t* and z intervals decreases as sample size increases

3. **Width reduction**: Increasing sample size reduces interval width more dramatically for *t* intervals than for z intervals

4. **Appropriate use**: Use *t* intervals when Ïƒ is unknown (the most common situation); use z intervals only when Ïƒ is truly known

One-Sided Confidence Bounds with the *t* Distribution
-------------------------------------------------------

Just as with the Ïƒ-known case, we can construct one-sided confidence bounds when our interest lies primarily in one direction. The formulas are analogous, with *t* replacing z:

**Lower Confidence Bound** (with confidence level 1-Î±):

.. math::
   \mu > \bar{x} - t_{\alpha, n-1} \cdot \frac{s}{\sqrt{n}}

**Upper Confidence Bound** (with confidence level 1-Î±):

.. math::
   \mu < \bar{x} + t_{\alpha, n-1} \cdot \frac{s}{\sqrt{n}}

Where :math:`t_{\alpha, n-1}` is the *t* critical value with n-1 degrees of freedom that corresponds to a right-tail probability of Î±.

Note that for one-sided bounds, all Î± is allocated to one tail, resulting in a different critical value than for two-sided intervals.

Robustness of the *t* Procedure
---------------------------------

A statistical procedure is considered **robust** if it performs reasonably well even when its assumptions are somewhat violated. The *t* procedure shows good robustness against moderate departures from normality, especially as sample size increases.

Guidelines for using the *t* procedure when the normality assumption may not hold:

* For **n < 15**: The population distribution should be approximately normal. Check the sample data with normal probability plots or Shapiro-Wilk tests.

* For **15 â‰¤ n < 40**: The procedure works well even with some mild skewness. Avoid using with strongly skewed data or data containing outliers.

* For **n â‰¥ 40**: Generally reliable even with moderately skewed distributions, thanks to the Central Limit Theorem.

Regardless of sample size, the procedure is sensitive to outliers, which can strongly influence both :math:`\bar{x}` and s. Always inspect your data for outliers before applying the *t* procedure.

Practical Implementation in R
-------------------------------

R provides several ways to construct *t*-based confidence intervals. The most direct method is the `t.test()` function:

.. code-block:: r

   # For data stored in a vector 'x'
   t.test(x, conf.level = 0.95)
   
   # The output includes:
   # Sample mean
   # Degrees of freedom
   # Confidence interval
   # And other test statistics

For one-sided bounds, specify the `alternative` parameter:

.. code-block:: r

   # Lower bound (testing if mean is greater than some value)
   t.test(x, conf.level = 0.95, alternative = "greater")
   
   # Upper bound (testing if mean is less than some value)
   t.test(x, conf.level = 0.95, alternative = "less")


Bringing It All Together
-----------------------------

The Student's *t* distribution provides the appropriate framework for quantifying uncertainty about a population mean when 
the population standard deviation is unknown:

* Replace Ïƒ with the sample standard deviation s
* Replace z critical values with *t* critical values based on n-1 degrees of freedom
* The resulting interval accounts for the additional uncertainty in estimating Ïƒ
* The procedure is robust to moderate violations of the normality assumption, especially for larger samples


Bridge to Hypothesis Testing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The *t* statistic we've used for confidence intervals also forms the basis for the **one-sample *t* test**, which we'll explore in Chapter 10. This test is used to assess evidence for or against specific claims about the population mean.

The duality between confidence intervals and hypothesis tests means that a 95% confidence interval contains all the null hypothesis values that would not be rejected at the Î± = 0.05 significance levelâ€”a relationship that highlights the close connection between these two approaches to statistical inference.

Exercises
~~~~~~~~~~~~~

1. A botanist measures the nitrogen content in the leaves of n = 12 plants of a certain species. The sample mean is :math:`\bar{x} = 4.9\%` with a sample standard deviation of s = 1.1%. Construct a 90% confidence interval for the true mean nitrogen content Î¼.

2. A quality control engineer wants to estimate the mean tensile strength of steel cables. A sample of 25 cables yields a mean strength of 3450 N with a standard deviation of 120 N. Construct a 99% confidence interval for the mean strength. If the company advertises a mean strength of at least 3400 N, does the confidence interval support this claim?

3. A pilot study with 8 observations yielded a sample standard deviation of s = 15. If a researcher wants to estimate the population mean with a margin of error of no more than 5 units at 95% confidence, how many observations should be planned for the full study?

4. Using the cholesterol reduction example, find the sample size needed to reduce the margin of error to 2 mg/dL while maintaining 95% confidence. Start with s = 6.8 mg/dL from the initial study and use iterative refinement.

5. Generate random samples of size n = 10 from an exponential distribution with rate parameter Î» = 1. For each sample, construct a 95% *t*-based confidence interval for the mean. Record whether each interval captures the true mean (Î¼ = 1/Î» = 1). Repeat 1000 times and calculate the proportion of intervals that contain the true mean. How does this empirical coverage compare to the nominal 95% level? What does this tell you about the robustness of the *t* procedure to violations of normality?
