.. _11-5-mean-of-paired-differences-two-dependent-populations:

.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch11-5">
      <iframe
         id="video-ch11-5"
         title="STAT 350 – Chapter 11.5 Comparing Two Population Means Using Paired Samples Video"
         src="https://www.youtube.com/embed/9qEfrrRcbRw?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

.. admonition:: Slides
   :class: tip

   `Download Chapter 11 slides (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%2011%20Two%20Sample%20Procedures/CI%20and%20HT%20for%20Two%20Samples%20or%20Treatments_AC.pptx>`_


Analyzing the Mean of Paired Differences Between two Dependent Populations
============================================================================

In the independent sample procedures we have developed so far, we have operated under the fundamental assumption 
that observations from one population are completely independent of observations from the other population. 
However, many important research questions involve comparisons where this independence assumption is violated 
by design. When observations are naturally linked or paired, we must modify our statistical approach to account 
for these dependencies while gaining the substantial benefits that pairing can provide.

.. admonition:: Road Map 🧭
   :class: important

   • **Problem we will solve** – How to compare two population means when observations are paired or matched, 
   violating the independence assumption required for independent sample procedures
   • **Tools we'll learn** – Paired sample t-procedures that transform two-sample problems into familiar 
   one-sample analyses of differences
   • **How it fits** – This provides a powerful alternative to independent samples that controls for individual 
   variability and often yields more precise inference about treatment effects

When Independence Fails: The Paired Design Framework
------------------------------------------------------

The independence assumption that underlies our previous two-sample procedures requires that the process of selecting individuals from one population has no effect on or relation to the selection from the other population. While this assumption is reasonable in many contexts, there are important scenarios where it is systematically violated by the nature of the research design or the inherent structure of the data.

**Characteristics of Paired Observations**

Paired sample procedures are appropriate when observations are linked by some underlying characteristic or relationship that creates dependencies between measurements. These dependencies can arise through several mechanisms:

**Same Subject Measured Twice**

The most common pairing scenario involves measuring the same individuals under two different conditions or at two different times. Examples include:

- **Before and after studies**: Measuring patient blood pressure before and after treatment
- **Pre-test and post-test designs**: Assessing student performance before and after an educational intervention  
- **Crossover trials**: Administering two different treatments to the same subjects with appropriate washout periods

In these designs, each subject serves as their own control, eliminating between-subject variability from the comparison.

**Matched Subjects with Similar Characteristics**

Pairing can also involve different subjects who are matched on characteristics that might otherwise introduce substantial variability into the comparison:

- **Twin studies**: Comparing outcomes between twins who receive different treatments
- **Sibling pairs**: Studying interventions within families to control for genetic and environmental factors
- **Matched pairs**: Deliberately pairing subjects on age, gender, disease severity, or other relevant characteristics

**Naturally Paired Materials or Units**

Some research contexts involve natural pairing relationships:

- **Split-plot designs**: Cutting material from the same source and applying different treatments to each piece
- **Bilateral measurements**: Comparing left versus right measurements on the same subjects
- **Temporal dependencies**: Measurements taken on consecutive days or under related conditions

**The Statistical Rationale for Pairing**

Pairing is particularly valuable when the characteristic that links the observations creates large variability that might otherwise obscure the treatment effect of interest. By controlling for these lurking variables through the pairing mechanism, we can isolate the effect of the treatment or intervention being studied.

Consider a study evaluating the effectiveness of a new pain medication. If we used an independent sample design, individual differences in pain tolerance, medical history, and baseline pain levels would contribute substantial noise to our comparison. However, by measuring the same patients before and after treatment (a paired design), these individual characteristics affect both measurements equally and are eliminated when we analyze the differences.

The Mathematical Foundation: Working with Differences
--------------------------------------------------------

The key insight in paired sample procedures is to transform the two-sample comparison problem into a one-sample analysis problem by focusing on the differences between paired observations.

**Parameter Definitions and Notation**

For paired samples, we have observations :math:`X_{A1}, X_{A2}, \ldots, X_{An}` from population A and :math:`X_{B1}, X_{B2}, \ldots, X_{Bn}` from population B, where :math:`X_{Ai}` is paired with :math:`X_{Bi}` for each :math:`i`. The crucial aspect is that these observations are not independent across populations.

Rather than working with the original populations separately, we define the differences:

.. math::

   D_i = X_{Ai} - X_{Bi} \text{ for } i = 1, 2, \ldots, n

These differences :math:`D_1, D_2, \ldots, D_n` form a new dataset that captures the essence of the comparison while eliminating the correlation structure between the original observations.

**Population Parameters for Differences**

The population parameter of primary interest becomes the mean difference:

.. math:

   \mu_D = E[D_i] = E[X_{Ai} - X_{Bi}] = E[X_{Ai}] - E[X_{Bi}] = \mu_A - \mu_B

This parameter represents the average difference between the two conditions or treatments in the population.

The variance of the differences involves a more complex relationship:

.. math:

   \sigma^2_D = \text{Var}[D_i] = \text{Var}[X_{Ai} - X_{Bi}]

Using the properties of variance for correlated random variables:

.. math:

   \sigma^2_D = \text{Var}[X_{Ai}] + \text{Var}[X_{Bi}] - 2\text{Cov}[X_{Ai}, X_{Bi}]

.. math:

   = \sigma^2_A + \sigma^2_B - 2\sigma_A\sigma_B\rho_{AB}

where :math:`\rho_{AB}` is the correlation between paired observations.

**The Power of Avoiding Correlation Estimation**

While we could theoretically estimate the individual population parameters and their correlation to construct our inference procedures, this approach would be unnecessarily complex and potentially imprecise. Instead, paired procedures take the elegant approach of working directly with the differences, treating them as a simple random sample from the population of differences with mean :math:`\mu_D` and variance :math:`\sigma^2_D`.

This transformation eliminates the need to estimate or model the correlation structure, allowing us to apply the familiar one-sample t-procedures to the differences.

Sample Statistics for Paired Data
-----------------------------------

**Sample Mean Difference**

The sample mean difference provides our point estimator for :math:`\mu_D`:

.. math:

   \bar{D} = \frac{1}{n}\sum_{i=1}^n D_i = \frac{1}{n}\sum_{i=1}^n (X_{Ai} - X_{Bi}) = \bar{X}_A - \bar{X}_B

This estimator is unbiased: :math:`E[\bar{D}] = \mu_D`.

**Sample Variance of Differences**

The sample variance of differences is calculated using the standard formula applied to the difference values:

.. math:

   S^2_D = \frac{1}{n-1}\sum_{i=1}^n (D_i - \bar{D})^2

This provides an unbiased estimator for :math:`\sigma^2_D`: :math:`E[S^2_D] = \sigma^2_D`.

**Sampling Distribution of the Sample Mean Difference**

Under the assumption that the differences are normally distributed (or that the Central Limit Theorem applies), the sample mean difference follows:

.. math:

   \bar{D} \sim N\left(\mu_D, \frac{\sigma_D}{\sqrt{n}}\right)

When :math:`\sigma_D` is unknown and estimated by :math:`S_D`, we obtain the t-distribution result that forms the foundation for our inference procedures.

Assumptions for Paired Sample Procedures
-------------------------------------------

Paired sample procedures require three fundamental assumptions that mirror those for one-sample procedures:

**1. Independent Pairs**

Each pair :math:`(X_{Ai}, X_{Bi})` must be independent of all other pairs :math:`(X_{Aj}, X_{Bj})` for :math:`i \neq j`. This means that while observations within a pair are dependent (which is the point of pairing), different pairs must be independently sampled.

**2. Simple Random Sampling from the Population of Pairs**

The pairs themselves must constitute a simple random sample from the broader population of potential pairs. This ensures that our sample is representative of the population we wish to make inferences about.

**3. Normality of Differences**

The differences :math:`D_i` must be normally distributed, or the sample size must be large enough for the Central Limit Theorem to ensure that :math:`\bar{D}` is approximately normally distributed. Note that this assumption concerns the distribution of differences, not the original observations.

This normality assumption is often more readily satisfied than normality of the original observations because the differencing process can reduce skewness when both original distributions are skewed in similar ways.

Hypothesis Testing for Paired Samples: The Four-Step Process
--------------------------------------------------------------

Paired sample hypothesis testing follows the same four-step framework as one-sample procedures, but with careful attention to defining the differences appropriately.

**Step 1: Parameter Identification and Difference Definition**

The parameter of interest is :math:`\mu_D`, the mean difference between paired observations. Critically, we must explicitly define how the difference is calculated, as this determines the direction of our alternative hypothesis.

For example, if studying a training program's effectiveness:
- :math:`D = X_{\text{pre}} - X_{\text{post}}` (pre-training score minus post-training score)

The choice of difference direction should align with the research question and the anticipated direction of the effect.

**Step 2: Hypothesis Formulation**

Our hypotheses are formulated in terms of :math:`\mu_D`:

- **Null hypothesis**: :math:`H_0: \mu_D = \Delta_0` (typically :math:`\Delta_0 = 0`)
- **Alternative hypotheses**:
  - Two-sided: :math:`H_a: \mu_D \neq \Delta_0`
  - Right-tailed: :math:`H_a: \mu_D > \Delta_0`
  - Left-tailed: :math:`H_a: \mu_D < \Delta_0`

The choice of alternative depends on the research question and how we defined the differences in Step 1.

**Step 3: Test Statistic and P-Value Calculation**

The test statistic follows the familiar one-sample t-test format:

.. math:

   t_{TS} = \frac{\bar{d} - \Delta_0}{s_d/\sqrt{n}}

where :math:`\bar{d}` is the observed sample mean difference, :math:`s_d` is the sample standard deviation of differences, and :math:`n` is the number of pairs.

Under the null hypothesis and our stated assumptions, this test statistic follows a t-distribution with :math:`df = n - 1` degrees of freedom.

P-value calculation follows the same patterns as one-sample procedures:
- **Two-sided**: p-value = :math:`2P(T > |t_{TS}|)` where :math:`T \sim t_{n-1}`
- **Right-tailed**: p-value = :math:`P(T > t_{TS})`
- **Left-tailed**: p-value = :math:`P(T < t_{TS})`

**Step 4: Decision and Conclusion**

Compare the p-value to the predetermined significance level :math:`\alpha` and draw conclusions in the context of the original research question, being careful to interpret results in terms of the mean difference as defined in Step 1.

Confidence Intervals for Paired Differences
---------------------------------------------

Confidence intervals for the mean difference follow the standard one-sample format:

.. math:

   \bar{d} \pm t_{\alpha/2, n-1} \cdot \frac{s_d}{\sqrt{n}}

**Confidence Bounds for One-Sided Alternatives**

For one-sided alternatives, we construct confidence bounds rather than intervals:

**Upper confidence bound** (for :math:`H_a: \mu_D < \Delta_0`):

.. math:

   \mu_D < \bar{d} + t_{\alpha, n-1} \cdot \frac{s_d}{\sqrt{n}}

**Lower confidence bound** (for :math:`H_a: \mu_D > \Delta_0`):

.. math:

   \mu_D > \bar{d} - t_{\alpha, n-1} \cdot \frac{s_d}{\sqrt{n}}

These bounds provide ranges of plausible values for the true mean difference and can be used to assess both statistical and practical significance.

A Complete Example: Nursing Sensitivity Training Study
---------------------------------------------------------

To illustrate the complete paired sample procedure, we analyze a study evaluating the effectiveness of sensitivity training for hospital nurses.

**Study Design and Context**

A regional hospital conducted a study to determine whether sensitivity training would improve the quality of care provided by their nursing staff. Eight nurses were selected, and their nursing skills were evaluated on a scale from 1 to 10, where higher scores indicate greater sensitivity to patients. After this initial assessment, the nurses participated in a training program, and their skills were evaluated again using the same scale.

Since each nurse serves as their own control (measured before and after training), this is clearly a paired design. The pairing controls for individual differences in baseline nursing ability, personality, experience, and other factors that might otherwise obscure the training effect.

**Data Analysis**

The data shows pre-training scores, post-training scores, and the calculated differences for each nurse:

.. list-table::
   :header-rows: 1
   :widths: 20 20 20 20

   * - Nurse
     - Pre-Training
     - Post-Training
     - Difference (Pre - Post)
   * - 1
     - 2.56
     - 4.54
     - -1.98
   * - 2
     - 3.22
     - 5.33
     - -2.11
   * - 3
     - 3.45
     - 4.32
     - -0.87
   * - 4
     - 5.55
     - 7.45
     - -1.90
   * - 5
     - 5.63
     - 7.00
     - -1.37
   * - 6
     - 7.89
     - 9.80
     - -1.91
   * - 7
     - 7.66
     - 7.33
     - 0.33
   * - 8
     - 6.20
     - 6.80
     - -0.60

Summary statistics for the differences: :math:`\bar{d} = -1.30`, :math:`s_d = 0.8608`, :math:`n = 8`.

**Step 1: Parameter Identification**

The parameter of interest is :math:`\mu_D`, the true mean difference between pre-training and post-training nursing sensitivity scores, where :math:`D = X_{\text{pre}} - X_{\text{post}}`.

Since higher scores indicate better performance, we expect training to increase scores, making the differences (pre minus post) negative on average.

**Step 2: Hypothesis Formulation**

We want to test whether the training improves nursing skills on average:

- :math:`H_0: \mu_D \geq 0` (no improvement; pre-training scores are greater than or equal to post-training scores)
- :math:`H_a: \mu_D < 0` (improvement; pre-training scores are less than post-training scores)

This is a left-tailed test with :math:`\Delta_0 = 0`.

**Step 3: Test Statistic and P-Value**

The test statistic is:

.. math:

   t_{TS} = \frac{\bar{d} - \Delta_0}{s_d/\sqrt{n}} = \frac{-1.30 - 0}{0.8608/\sqrt{8}} = \frac{-1.30}{0.3044} = -4.2755

With :math:`df = n - 1 = 7` degrees of freedom.

For a left-tailed test, the p-value is:

p-value = :math:`P(T_7 < -4.2755) = 0.001838`

**Step 4: Decision and Conclusion**

Since p-value = 0.001838 < :math:`\alpha = 0.01`, we reject the null hypothesis.

**Conclusion**: The data gives strong support (p-value = 0.001838) to the claim that the population average nursing sensitivity scores improved after training for the population of nurses at the regional hospital.

**99% Upper Confidence Bound**

Since we conducted a left-tailed test, the corresponding confidence bound is an upper bound:

Critical value: :math:`t_{0.01,7} = 2.998`

Upper bound: :math:`\mu_D < -1.30 + 2.998 \times \frac{0.8608}{\sqrt{8}} = -1.30 + 0.913 = -0.387`

We are 99% confident that the true mean difference between pre- and post-training scores is less than -0.387. Since this upper bound is negative, it confirms that the training program produces improvement (negative differences indicate post-training scores exceed pre-training scores).

Implementation in R
---------------------

**Method 1: Using t.test() with Paired Data**

.. code-block:: r

   # Define the data
   pre_training <- c(2.56, 3.22, 3.45, 5.55, 5.63, 7.89, 7.66, 6.20)
   post_training <- c(4.54, 5.33, 4.32, 7.45, 7.00, 9.80, 7.33, 6.80)
   
   # Perform paired t-test
   t.test(pre_training, post_training,
          mu = 0,
          conf.level = 0.99,
          paired = TRUE,
          alternative = "less")

**Method 2: Manual Difference Calculation**

.. code-block:: r

   # Calculate differences manually
   differences <- pre_training - post_training
   
   # Perform one-sample t-test on differences
   t.test(differences,
          mu = 0,
          conf.level = 0.99,
          alternative = "less")

Both methods produce identical results, demonstrating that paired procedures are simply one-sample procedures applied to the differences.

**Key R Arguments for Paired Procedures**

- **paired = TRUE**: Specifies that observations should be treated as paired
- **alternative**: Specifies the direction of the alternative hypothesis ("less", "greater", or "two.sided")
- **mu**: The null hypothesis value :math:`\Delta_0` (typically 0)
- **conf.level**: The confidence level for the corresponding confidence interval or bound

When to Use Paired vs. Independent Procedures: A Decision Framework
----------------------------------------------------------------------

The choice between paired and independent sample procedures is fundamental and depends on the study design and data structure. Making the wrong choice can lead to invalid inference or substantial loss of statistical power.

**Use Paired Procedures When:**

1. **Natural Pairing Exists**: Observations are naturally linked through same subjects, matched characteristics, or other dependencies

2. **Large Lurking Variable Variance**: There are important variables that create substantial variability but are controlled through pairing

3. **Pairing is Feasible**: The study design allows for meaningful pairing without compromising other aspects of the research

4. **Power Considerations**: When individual differences are large relative to treatment effects, pairing can substantially increase statistical power

**Use Independent Procedures When:**

1. **No Natural Pairing**: Observations come from distinct, unrelated populations with no meaningful way to create pairs

2. **Independence is Maintained**: The sampling process for one group has no relationship to the sampling for the other group

3. **Large Sample Sizes**: When sample sizes are large enough that the loss of efficiency from not pairing is acceptable

4. **Pairing is Inappropriate**: When forcing artificial pairing would introduce bias or compromise the research design

**Advantages of Paired Designs**

**Statistical Advantages:**

- **Increased Power**: By controlling for individual variability, paired designs often have greater power to detect true differences
- **Improved Precision**: Standard errors are typically smaller when pairing is effective
- **Reduced Sample Size Requirements**: The same statistical power can often be achieved with fewer subjects

**Practical Advantages:**

- **Cost Efficiency**: Measuring the same subjects twice can be more economical than recruiting separate groups
- **Ethical Considerations**: In medical research, paired designs may be preferred when withholding treatment from a control group raises ethical concerns

**Disadvantages of Paired Designs**

**Statistical Limitations:**

- **Dependency Requirements**: Observations must be meaningfully paired, which is not always possible or appropriate
- **Carryover Effects**: In crossover designs, treatment effects from the first period may influence the second period
- **Missing Data Complications**: If one member of a pair is lost, the entire pair must typically be excluded from analysis

**Practical Limitations:**

- **Logistical Complexity**: Coordinating paired measurements can be more complex than independent sampling
- **Time Constraints**: Longitudinal paired designs require extended follow-up periods
- **Subject Dropout**: Higher risk of losing data when the same subjects must be measured multiple times

The Relationship to One-Sample Procedures
-------------------------------------------

Paired sample procedures demonstrate a fundamental principle in statistics: complex problems can often be reduced to simpler, well-understood methods through appropriate data transformation. By working with differences rather than original observations, we transform the two-sample paired problem into a one-sample problem about the mean difference.

This reduction allows us to leverage all the theory and methods we developed for one-sample procedures:

- **Test statistics** follow the same t-distribution under the null hypothesis
- **Confidence intervals** use the same pivotal quantity approach
- **Assumption checking** focuses on the normality of differences rather than original observations
- **Effect size calculations** can be applied directly to the differences

**Connection to Independent Sample Procedures**

Interestingly, when the correlation between paired observations is zero (:math:`\rho_{AB} = 0`), the variance of differences becomes :math:`\sigma^2_D = \sigma^2_A + \sigma^2_B`, which is exactly what we would use in independent sample procedures. In this case, pairing provides no advantage and may actually reduce power slightly due to the smaller degrees of freedom (:math:`n-1` instead of :math:`n_A + n_B - 2`).

However, when correlation is positive (which is typical in well-designed paired studies), the variance of differences is reduced: :math:`\sigma^2_D = \sigma^2_A + \sigma^2_B - 2\sigma_A\sigma_B\rho_{AB} < \sigma^2_A + \sigma^2_B`, leading to more precise inference.

Looking Forward: Extensions and Applications
----------------------------------------------

The principles developed in paired sample procedures extend to more complex experimental designs and provide the foundation for understanding repeated measures analysis and longitudinal data methods. The key insight—that we can often simplify complex dependency structures by focusing on appropriate transformations of the data—appears throughout advanced statistical methodology.

In the context of our course progression, paired procedures complete our toolkit for comparing two population means. We now have methods that work whether populations are independent or dependent, whether variances are equal or unequal, and whether we want to make strong assumptions for efficiency or robust assumptions for broad applicability.

.. admonition:: Key Takeaways 📝
   :class: important

   1. **Paired procedures apply when observations are linked** through natural pairing relationships that violate the independence assumption of two-sample procedures.
   
   2. **The key transformation is working with differences** :math:`D_i = X_{Ai} - X_{Bi}`, which reduces the two-sample problem to a familiar one-sample analysis.
   
   3. **All inference focuses on the mean difference** :math:`\mu_D = \mu_A - \mu_B`, using test statistics of the form :math:`t_{TS} = \frac{\bar{d} - \Delta_0}{s_d/\sqrt{n}}` with :math:`n-1` degrees of freedom.
   
   4. **Proper difference definition is crucial** – the direction of subtraction must align with the research question and alternative hypothesis formulation.
   
   5. **Pairing controls for individual variability** that might otherwise obscure treatment effects, often leading to more powerful statistical tests.
   
   6. **Three key assumptions** must be satisfied: independent pairs, simple random sampling from the population of pairs, and normality of differences.
   
   7. **R implementation** uses `t.test()` with `paired = TRUE` or equivalent one-sample analysis of manually calculated differences.
   
   8. **The choice between paired and independent procedures** depends on study design, the presence of natural pairing relationships, and the magnitude of individual variability relative to treatment effects.

Exercises
~~~~~~~~~~~~~~~

1. **Design Recognition**: For each scenario below, determine whether a paired or independent sample design is most appropriate and explain your reasoning:

   a) Comparing blood pressure medications by randomly assigning patients to receive either drug A or drug B
   b) Evaluating a weight-loss program by measuring participants before and after the intervention
   c) Studying gender differences in mathematical ability using standardized test scores
   d) Comparing two teaching methods using identical twins, where one twin receives method A and the other receives method B
   e) Assessing the effectiveness of a new sleep aid by measuring sleep quality before and after treatment

2. **Difference Definition Impact**: A researcher studies whether a new exercise program improves cardiovascular fitness, measured by time to complete a standard fitness test (in minutes, where lower times indicate better fitness).

   a) If the difference is defined as :math:`D = \text{Time}_{\text{before}} - \text{Time}_{\text{after}}`, write appropriate hypotheses to test whether the program improves fitness
   b) If the difference is defined as :math:`D = \text{Time}_{\text{after}} - \text{Time}_{\text{before}}`, write appropriate hypotheses for the same research question
   c) Explain how the choice of difference definition affects the interpretation of results

3. **Complete Analysis**: Eight patients with chronic pain participated in a study of acupuncture therapy. Their pain levels were measured on a 10-point scale before and after a series of acupuncture treatments:

   .. list-table::
      :header-rows: 1

      * - Patient
        - Before
        - After
        - Difference
      * - 1
        - 8.2
        - 6.1
        - 
      * - 2
        - 7.5
        - 5.8
        - 
      * - 3
        - 9.1
        - 7.2
        - 
      * - 4
        - 6.8
        - 6.0
        - 
      * - 5
        - 8.9
        - 5.5
        - 
      * - 6
        - 7.2
        - 6.8
        - 
      * - 7
        - 8.5
        - 6.9
        - 
      * - 8
        - 7.8
        - 6.2
        - 

   a) Calculate the differences and summary statistics
   b) Test whether acupuncture reduces pain levels on average (use :math:`\alpha = 0.05`)
   c) Construct a 95% confidence interval for the mean reduction in pain
   d) Interpret your results in the context of the study

4. **Assumption Checking**: Explain what assumptions must be verified for paired sample procedures and describe how you would check each assumption with a small sample like the acupuncture study above.

5. **Power Comparison**: Explain why paired designs often have higher statistical power than independent sample designs for detecting treatment effects. Under what circumstances might an independent design be preferred despite this power advantage?

6. **R Implementation**: Write R code to analyze the acupuncture data from Exercise 3 using both the paired t.test() approach and the manual difference calculation approach. Verify that both methods produce identical results.