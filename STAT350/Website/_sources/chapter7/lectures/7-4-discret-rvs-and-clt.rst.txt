.. _7-4-discrete-rvs-and-clt:


.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch7-4">
      <iframe
         id="video-ch7-4"
         title="STAT 350 ‚Äì Chapter 7.4 Discrete Random Variables and the CLT Video"
         src="https://www.youtube.com/embed/U98siSK61oY?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

.. admonition:: Slides üìä
   :class: tip

   `Download Chapter 7 slides (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/
   Chapter%207%20Sampling%20Distributions/Sampling%20Distributions%20%28Chapter7%29_AC.pptx>`_
   
Understanding Binomial and Poisson Distributions through CLT
================================================================

Sections 5.6 and 5.7 showed that for certain parameter values, the binomial and Poisson distributions have a 
pmf with a bell-shaped trend. In this section, we use the CLT to explain why this similarity occurs and explicitly characterize 
the set of parameters for which this happens. We also identify the issue that can arise from approximating a **discrete** distribution 
with a **continuous** normal distribution.

.. admonition:: Road Map üß≠
   :class: important

   * Use CLT to explain why certain binomial and Poisson distributions can be approximated using normal distributions.
   * Understand the issue that can arise from the support difference between the true (discrete) and approximated 
     (continuous) distributions.
     Know that a technique called **continuity correction** can be used as a remedy.

The Preliminary: An Alternative Statement for the CLT
-------------------------------------------------------------

For an iid sample :math:`X_1, X_2, \cdots, X_n` from a population with finite mean :math:`\mu` and finite
standard deviation :math:`\sigma`, let :math:`S_n = X_1 + X_2 + \ldots + X_n`. Then,

.. math::

   \frac{S_n - n\mu}{\sigma\sqrt{n}} \xrightarrow{d} N(0,1) \text{ as } n \rightarrow \infty

.. admonition:: How is this connected to the original statement of the CLT? üîé
   :class: important
   
   The fraction at the beginning of the mathematical statement is in fact identical to
   the one used in Section 7.3:

   .. math::
      \frac{S_n - n\mu}{\sigma\sqrt{n}} = \frac{(S_n - n\mu)/n}{(\sigma\sqrt{n})/n} 
      = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}}.
   
By using this alternative expression, we can also view the **sample sum** as approximately normally distributed:

.. math::

   S_n \stackrel{\text{approx}}{\sim} N(n\mu, \sigma\sqrt{n})


Binomial Distribution and the CLT
-------------------------------------

A binomial random variable :math:`X \sim B(n,p)` counts the number of successes in :math:`n` independent trials, 
each with probability of success :math:`p`. Recall that it can also be expressed 
as:

.. math::

   X = \sum_{i=1}^n X_i,

where each :math:`X_i` is an **independent** Bernoulli random variable that 
equals 1 with probability :math:`p` and 0 with probability :math:`(1-p)`. Since a 
binomial random variable is a sum of independent and identically distributed random variables,
the CLT applies as :math:`n` increases. For a sufficiently large :math:`n`, 
the distribution of :math:`X` can be approximated by:

.. math::

   X \stackrel{\text{approx}}{\sim} N \left(\mu_X = np, \sigma_X = \sqrt{np(1-p)}\right)

The two normal parameters are obtained simply by taking :math:`E[X]` and :math:`\sigma_X`
from the true distribution of :math:`X`.

When does it apply?
~~~~~~~~~~~~~~~~~~~~~~~

Recall that a "large enough" :math:`n` for the CLT depends on the skewness of
the population distribution. For binomial distributions, the skewness is determined by :math:`p` 
(symmetric for :math:`p=0.5`, stronger skewness as :math:`p` nears :math:`0` or :math:`1`).
Therefore, we usually consider the two parameters :math:`n` and :math:`p` jointly to identify cases where
the binomial distribution is well-approximated by a normal distribution. The rule of thumb is:

1. Both :math:`np ‚â• 10` and :math:`n(1-p) ‚â• 10`.
2. Alternatively, :math:`np(1-p) ‚â• 10`.

The figure below shows some concrete examples:

.. _binomial-normal:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/binomial-normal.png 
   :figwidth: 100%
   :align: center 
   :alt: Cases which work well with normal approximation vs cases which don't

   Cases with different compatibilities with normal approximation

In Figure :numref:`binomial-normal`, 

**(a)** is symmetric, but :math:`n` is too small. It fails the rule-of-thumb tests. Normal approximation will not work well. ‚ùå

**(b)** is symmetric with sufficiently large :math:`n`. It passes the rule-of-thumb tests. Normal approximation will work well. ‚úî

**(c)** has the same :math:`n` as (b), but the distribution is very skewed because :math:`p=0.1`. 
Normal approximation will not work well. ‚ùå

**(d)** has even larger :math:`n` which compensates for the :math:`p` far from 0.5. Normal approximation will work well.‚úî


Poisson Distribution and the CLT
-----------------------------------

A Poisson random variable counts the number of independent events 
occurring in a fixed interval, where  events happen at a constant average rate :math:`\lambda`.

An interesting property of the Poisson distribution is that the **sum of independent Poisson 
random variables is also Poisson** distributed. If :math:`Y_1 \sim \text{Poisson}(\lambda_1)` and 
:math:`Y_2 \sim \text{Poisson}(\lambda_2)` are independent, 
then :math:`Y_1 + Y_2 \sim \text{Poisson}(\lambda_1 + \lambda_2)`.

By extension, if :math:`Y_1, Y_2, \cdots, Y_n` are **independent** Poisson random variables with an 
**identical** rate parameter :math:`\lambda`, then:

.. math::

   \sum_{i=1}^n Y_i \sim \text{Poisson}(n\lambda).

Let :math:`X = \sum_{i=1}^n Y_i` and :math:`\tilde{\lambda} = n\lambda`. Since :math:`Y_i`'s are iid,
the CLT applies for a sufficiently large :math:`n`: 

.. math::
   X \stackrel{\text{approx}}{\sim} N\left(\mu_X = \tilde{\lambda}, \sigma_X = \sqrt{\tilde{\lambda}}\right)

Again, the normal parameters come from :math:`E[X]` and :math:`\sigma_X` of the true distribution.

When does it apply?
~~~~~~~~~~~~~~~~~~~~~


In practice, we do not have an explicit :math:`n` for a Poisson random variable. If :math:`X \sim Pois(\lambda)`,
it can be expressed as a sum of two Poisson random variables, each with parameter :math:`\lambda/2`, or of a thousand,
each with parameter :math:`\lambda/1000`. 

Thus we focus solely on the size of :math:`\lambda`. 
Typically, :math:`\lambda \geq 10` is large enough for approximation by a normal distribution.
See :numref:`poisson-normal` to verify that the Poisson PMF grows more bell-shaped as :math:`\lambda`
becomes larger.

.. _poisson-normal:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter7/Poisson-normal.png
   :width: 80%
   :align: center 
   :alt: Poission PMF approaches bell-shape as lambda grows

   :math:`\lambda =1,5,10,50` from top to bottom, respectively.

The Practicality of Normal Approximation to Binomial & Poisson Distributions
------------------------------------------------------------------------------

Suppose a random variable :math:`X` has a distribution :math:`B(n=100, p=0.5)` and we are to
compute :math:`P(X < 50)`. Without access to a computational software, we can either

1. compute :math:`P(X < 50)` directly, which requires computation of 50 separate 
   pmf terms: :math:`P(X=0) + P(X=1) + \cdots + P(X=49)`, or
2. use the approximate normal distribution to compute a *slightly* less accurate value
   in one access to the standard normal table.

As :math:`n` gets larger, both the convenience and accuracy of Option 2 increase.
This example only touches on the binomial case, but a similar logic can be applied 
to a Poisson case with a large :math:`\lambda`.

This techinque was especially relevant when computational software was less accessible. 
Today, it still plays an important role in illustrating the
broad implications of the CLT and in showing how different distributions are connected.

Continuity Correction
------------------------------

When using a normal distribution to approximate discrete distributions like 
the binomial or Poisson, we need to account for the difference between their supports.
Consider :math:`X \sim B(n=100, p=0.5)` again. Using the exact distribution,

.. math::
   P(X=48) = {100 \choose 48} \left(\frac{1}{2}\right)^{48}\left(\frac{1}{2}\right)^{100-48} = 0.0735.

But using its approximated distribution :math:`N(\mu=50, \sigma = \sqrt{25})`,

.. math:: P(X = 48) \approx 0. 

A discrete distribution always has a positive probability for a value in its support, while 
a normal distribution assigns a zero probability to any single value. This difference needs to be
addressed by a technique called **continuity correction**, which is not covered in detail in this course.
You are encouraged to read about it independently.

Bringing It All Together
-----------------------------------------------------------------

.. admonition:: Key Takeaways üìù
   :class: important

   1. **The CLT can be used to describe certain binomial and Poisson distributions**.
   
   2. **For binomial distributions**, the normal approximation works well when :math:`np \geq 10` 
      and :math:`n(1-p) \geq 10` (or alternatively when :math:`np(1-p) \geq 10`).
   
   3. **For Poisson distributions**, the normal approximation works well when :math:`\lambda \geq 10`.
   
   4. **Continuity corrections may be needed** when using a continuous distribution to approximate a discrete one.


Exercises
---------

These exercises develop your skills in applying the Central Limit Theorem to approximate binomial and Poisson distributions with normal distributions.

.. admonition:: Key Formulas
   :class: tip

   **Normal Approximation to Binomial**: If :math:`X \sim \text{Binomial}(n, p)`, then for large :math:`n`:

   .. math::
      X \stackrel{\text{approx}}{\sim} N\left(\mu = np, \sigma^2 = np(1-p)\right)

   **Rule of thumb**: Approximation is adequate when :math:`np \geq 10` **and** :math:`n(1-p) \geq 10`.

   **Normal Approximation to Poisson**: If :math:`X \sim \text{Poisson}(\lambda)`, then for large :math:`\lambda`:

   .. math::
      X \stackrel{\text{approx}}{\sim} N\left(\mu = \lambda, \sigma^2 = \lambda\right)

   **Rule of thumb**: Approximation is adequate when :math:`\lambda \geq 10`.

   Throughout these exercises, :math:`N(\mu, \sigma^2)` denotes a normal distribution with mean :math:`\mu` and **variance** :math:`\sigma^2`.

.. admonition:: Note on Continuity Correction
   :class: info

   When approximating a discrete distribution (binomial, Poisson) with a continuous normal distribution, **continuity correction** can improve accuracy by adjusting boundaries by ¬±0.5. For example, :math:`P(X \leq 45)` for a discrete :math:`X` would use :math:`P(Y \leq 45.5)` in the normal approximation.

   **In this course**, continuity correction is not required unless explicitly requested. Solutions below note where continuity correction would apply but compute answers without it for simplicity.

.. admonition:: R Functions for Exact and Approximate Calculations
   :class: tip

   **Exact binomial probabilities:**

   .. code-block:: r

      pbinom(x, size = n, prob = p)                # P(X ‚â§ x)
      pbinom(x, size = n, prob = p, lower.tail = FALSE)  # P(X > x)
      dbinom(x, size = n, prob = p)                # P(X = x)

   **Exact Poisson probabilities:**

   .. code-block:: r

      ppois(x, lambda)                             # P(X ‚â§ x)
      ppois(x, lambda, lower.tail = FALSE)         # P(X > x)
      dpois(x, lambda)                             # P(X = x)

   **Normal approximations:**

   .. code-block:: r

      # Binomial(n, p): use N(np, sqrt(np(1-p)))
      mu <- n * p
      sigma <- sqrt(n * p * (1 - p))
      pnorm(x, mean = mu, sd = sigma)

      # Poisson(Œª): use N(Œª, sqrt(Œª))
      pnorm(x, mean = lambda, sd = sqrt(lambda))

.. admonition:: Exercise 1: Checking Approximation Conditions (Binomial)
   :class: note

   For each binomial distribution, determine whether the normal approximation is appropriate. If so, state the approximate normal distribution.

   a. :math:`X \sim \text{Binomial}(n = 200, p = 0.45)`

   b. :math:`X \sim \text{Binomial}(n = 50, p = 0.08)`

   c. :math:`X \sim \text{Binomial}(n = 80, p = 0.90)`

   d. :math:`X \sim \text{Binomial}(n = 500, p = 0.02)`

   e. :math:`X \sim \text{Binomial}(n = 30, p = 0.50)`

   .. dropdown:: Solution
      :class-container: sd-border-success

      For normal approximation to binomial, check: :math:`np \geq 10` **and** :math:`n(1-p) \geq 10`.

      **Part (a): n = 200, p = 0.45**

      - :math:`np = 200(0.45) = 90 \geq 10` ‚úì
      - :math:`n(1-p) = 200(0.55) = 110 \geq 10` ‚úì

      **Approximation is appropriate.**

      .. math::
         \mu = np = 90, \quad \sigma^2 = np(1-p) = 200(0.45)(0.55) = 49.5

      .. math::
         X \stackrel{\text{approx}}{\sim} N(90, 49.5), \quad \text{with } \sigma = \sqrt{49.5} = 7.04

      **Part (b): n = 50, p = 0.08**

      - :math:`np = 50(0.08) = 4 < 10` ‚úó

      **Approximation is NOT appropriate.** The expected number of successes is too small.

      **Part (c): n = 80, p = 0.90**

      - :math:`np = 80(0.90) = 72 \geq 10` ‚úì
      - :math:`n(1-p) = 80(0.10) = 8 < 10` ‚úó

      **Approximation is NOT appropriate.** The expected number of failures is too small.

      **Part (d): n = 500, p = 0.02**

      - :math:`np = 500(0.02) = 10 \geq 10` ‚úì (borderline)
      - :math:`n(1-p) = 500(0.98) = 490 \geq 10` ‚úì

      **Approximation is marginally appropriate** (borderline at :math:`np = 10`).

      .. math::
         \mu = 10, \quad \sigma^2 = 500(0.02)(0.98) = 9.8

      .. math::
         X \stackrel{\text{approx}}{\sim} N(10, 9.8), \quad \text{with } \sigma = 3.13

      Note: With :math:`np` exactly at the threshold, the approximation may be less accurate than for cases well above 10.

      **Part (e): n = 30, p = 0.50**

      - :math:`np = 30(0.50) = 15 \geq 10` ‚úì
      - :math:`n(1-p) = 30(0.50) = 15 \geq 10` ‚úì

      **Approximation is appropriate.**

      .. math::
         \mu = 15, \quad \sigma^2 = 30(0.50)(0.50) = 7.5

      .. math::
         X \stackrel{\text{approx}}{\sim} N(15, 7.5), \quad \text{with } \sigma = 2.74

----

.. admonition:: Exercise 2: Normal Approximation to Binomial ‚Äî Quality Control
   :class: note

   A semiconductor manufacturing process has a 3% defect rate. In a batch of 400 chips:

   a. Verify that the normal approximation to the binomial is appropriate.

   b. Find the approximate probability that fewer than 10 chips are defective.

   c. Find the approximate probability that between 10 and 20 chips (inclusive) are defective.

   d. Find the approximate probability that more than 18 chips are defective.

   .. dropdown:: Solution
      :class-container: sd-border-success

      Let :math:`X` = number of defective chips, where :math:`X \sim \text{Binomial}(n = 400, p = 0.03)`.

      **Part (a): Check conditions**

      - :math:`np = 400(0.03) = 12 \geq 10` ‚úì
      - :math:`n(1-p) = 400(0.97) = 388 \geq 10` ‚úì

      **Normal approximation is appropriate.**

      Parameters:

      .. math::
         \mu = np = 12, \quad \sigma = \sqrt{np(1-p)} = \sqrt{400(0.03)(0.97)} = \sqrt{11.64} = 3.41

      .. math::
         X \stackrel{\text{approx}}{\sim} N(12, 11.64)

      **Part (b): P(X < 10)**

      "Fewer than 10" means :math:`X \leq 9`. Ignoring continuity correction:

      .. math::
         P(X < 10) \approx P\left(Z < \frac{10 - 12}{3.41}\right) = P(Z < -0.59)

      .. math::
         = \Phi(-0.59) = 0.2776

      *Note*: With continuity correction, we would use :math:`P(X \leq 9) \approx P(Z < 9.5)`, giving :math:`z = (9.5 - 12)/3.41 = -0.73` and probability 0.2327, which is more accurate.

      **Part (c): P(10 ‚â§ X ‚â§ 20)**

      Ignoring continuity correction:

      .. math::
         P(10 \leq X \leq 20) \approx P\left(\frac{10 - 12}{3.41} \leq Z \leq \frac{20 - 12}{3.41}\right)

      .. math::
         = P(-0.59 \leq Z \leq 2.35) = \Phi(2.35) - \Phi(-0.59)

      .. math::
         = 0.9906 - 0.2776 = 0.7130

      *Note*: With continuity correction, we would use boundaries 9.5 and 20.5.

      **Part (d): P(X > 18)**

      "More than 18" means :math:`X \geq 19`. Ignoring continuity correction:

      .. math::
         P(X > 18) \approx P\left(Z > \frac{18 - 12}{3.41}\right) = P(Z > 1.76)

      .. math::
         = 1 - \Phi(1.76) = 1 - 0.9608 = 0.0392

      *Note*: With continuity correction, we would use 18.5, giving :math:`z = 1.91` and probability 0.0281.

      **R verification (exact vs. approximate):**

      .. code-block:: r

         n <- 400; p <- 0.03
         mu <- n * p  # 12
         sigma <- sqrt(n * p * (1 - p))  # 3.41

         # Part (b): P(X < 10) = P(X ‚â§ 9)
         pbinom(9, size = n, prob = p)              # Exact: 0.2384
         pnorm(10, mean = mu, sd = sigma)           # Normal approx (no CC): 0.2789
         pnorm(9.5, mean = mu, sd = sigma)          # Normal approx (with CC): 0.2327

         # Part (c): P(10 ‚â§ X ‚â§ 20)
         pbinom(20, n, p) - pbinom(9, n, p)         # Exact: 0.7240
         pnorm(20, mu, sigma) - pnorm(10, mu, sigma) # Normal approx (no CC): 0.7029

         # Part (d): P(X > 18) = P(X ‚â• 19)
         pbinom(18, n, p, lower.tail = FALSE)       # Exact: 0.0351
         pnorm(18, mu, sigma, lower.tail = FALSE)   # Normal approx (no CC): 0.0393

----

.. admonition:: Exercise 3: Checking Approximation Conditions (Poisson)
   :class: note

   For each Poisson distribution, determine whether the normal approximation is appropriate. If so, state the approximate normal distribution.

   a. :math:`X \sim \text{Poisson}(\lambda = 25)`

   b. :math:`X \sim \text{Poisson}(\lambda = 6)`

   c. :math:`X \sim \text{Poisson}(\lambda = 50)`

   d. A server receives requests at a rate of 3 per minute. Let :math:`X` be the number of requests in a 5-minute window.

   e. A call center receives calls at a rate of 0.5 per minute. Let :math:`X` be the number of calls in an 8-hour shift.

   .. dropdown:: Solution
      :class-container: sd-border-success

      For normal approximation to Poisson, check: :math:`\lambda \geq 10`.

      **Part (a): Œª = 25**

      :math:`\lambda = 25 \geq 10` ‚úì

      **Approximation is appropriate.**

      .. math::
         X \stackrel{\text{approx}}{\sim} N(25, 25), \quad \text{with } \sigma = 5

      **Part (b): Œª = 6**

      :math:`\lambda = 6 < 10` ‚úó

      **Approximation is NOT appropriate.** Use exact Poisson calculations.

      **Part (c): Œª = 50**

      :math:`\lambda = 50 \geq 10` ‚úì

      **Approximation is appropriate.**

      .. math::
         X \stackrel{\text{approx}}{\sim} N(50, 50), \quad \text{with } \sigma = \sqrt{50} = 7.07

      **Part (d): 3 requests/minute, 5-minute window**

      :math:`\lambda = 3 \times 5 = 15 \geq 10` ‚úì

      **Approximation is appropriate.**

      .. math::
         X \sim \text{Poisson}(15) \stackrel{\text{approx}}{\sim} N(15, 15), \quad \text{with } \sigma = 3.87

      **Part (e): 0.5 calls/minute, 8-hour shift**

      8 hours = 480 minutes, so :math:`\lambda = 0.5 \times 480 = 240 \geq 10` ‚úì

      **Approximation is appropriate** (and highly accurate given the large :math:`\lambda`).

      .. math::
         X \sim \text{Poisson}(240) \stackrel{\text{approx}}{\sim} N(240, 240), \quad \text{with } \sigma = 15.49

----

.. admonition:: Exercise 4: Normal Approximation to Poisson ‚Äî Network Traffic
   :class: note

   A network router receives packets at an average rate of 50 packets per second. Let :math:`X` be the number of packets received in a 1-second interval.

   a. What distribution does :math:`X` follow? Verify that the normal approximation is appropriate.

   b. Find the approximate probability that the router receives more than 60 packets in a second.

   c. Find the approximate probability that the router receives between 40 and 55 packets (inclusive).

   d. Find the value :math:`k` such that :math:`P(X > k) \approx 0.05`.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Distribution and conditions**

      :math:`X \sim \text{Poisson}(\lambda = 50)`.

      Check: :math:`\lambda = 50 \geq 10` ‚úì

      **Normal approximation is appropriate.**

      .. math::
         \mu = \lambda = 50, \quad \sigma = \sqrt{\lambda} = \sqrt{50} = 7.07

      .. math::
         X \stackrel{\text{approx}}{\sim} N(50, 50)

      **Part (b): P(X > 60)**

      "More than 60" means :math:`X \geq 61`. Ignoring continuity correction:

      .. math::
         P(X > 60) \approx P\left(Z > \frac{60 - 50}{7.07}\right) = P(Z > 1.41)

      .. math::
         = 1 - \Phi(1.41) = 1 - 0.9207 = 0.0793

      *Note*: With continuity correction (using 60.5), we get :math:`z = 1.48` and probability 0.0694.

      **Part (c): P(40 ‚â§ X ‚â§ 55)**

      Ignoring continuity correction:

      .. math::
         P(40 \leq X \leq 55) \approx P\left(\frac{40 - 50}{7.07} \leq Z \leq \frac{55 - 50}{7.07}\right)

      .. math::
         = P(-1.41 \leq Z \leq 0.71) = \Phi(0.71) - \Phi(-1.41)

      .. math::
         = 0.7611 - 0.0793 = 0.6818

      *Note*: With continuity correction (using 39.5 and 55.5), the probability would be slightly different.

      **Part (d): Find k such that P(X > k) ‚âà 0.05**

      We need :math:`P(Z > z) = 0.05`, which gives :math:`z = z_{0.95} = 1.645`.

      Ignoring continuity correction:

      .. math::
         k = \mu + z \cdot \sigma = 50 + 1.645(7.07) = 50 + 11.63 = 61.63

      Since :math:`X` takes integer values, :math:`P(X > 61) \approx 0.05` or equivalently :math:`P(X \geq 62) \approx 0.05`.

      *Note*: With continuity correction, we would solve for the boundary more precisely, but the integer threshold would be similar.

      **R verification (exact vs. approximate):**

      .. code-block:: r

         lambda <- 50
         sigma <- sqrt(lambda)  # 7.07

         # Part (b): P(X > 60)
         ppois(60, lambda, lower.tail = FALSE)      # Exact: 0.0722
         pnorm(60, mean = lambda, sd = sigma, lower.tail = FALSE)  # Normal approx: 0.0787

         # Part (c): P(40 ‚â§ X ‚â§ 55)
         ppois(55, lambda) - ppois(39, lambda)      # Exact: 0.7029
         pnorm(55, lambda, sigma) - pnorm(40, lambda, sigma)  # Normal approx: 0.6818

         # Part (d): Find k for P(X > k) ‚âà 0.05
         qnorm(0.95, mean = lambda, sd = sigma)     # Normal approx: 61.63
         qpois(0.95, lambda)                        # Exact quantile: 62

----

.. admonition:: Exercise 5: Comparing Approximation to Exact (Binomial)
   :class: note

   Let :math:`X \sim \text{Binomial}(n = 100, p = 0.5)`.

   a. Verify that the normal approximation is appropriate.

   b. Using the normal approximation, find :math:`P(X \leq 45)`.

   c. The exact probability is :math:`P(X \leq 45) = 0.1841` (from software). How close is your approximation?

   d. What feature of the binomial distribution (being discrete) causes the approximation error? How might "continuity correction" address this?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Check conditions**

      - :math:`np = 100(0.5) = 50 \geq 10` ‚úì
      - :math:`n(1-p) = 100(0.5) = 50 \geq 10` ‚úì

      **Normal approximation is appropriate.**

      Parameters:

      .. math::
         \mu = 50, \quad \sigma = \sqrt{100(0.5)(0.5)} = \sqrt{25} = 5

      .. math::
         X \stackrel{\text{approx}}{\sim} N(50, 25)

      **Part (b): P(X ‚â§ 45) using normal approximation**

      .. math::
         P(X \leq 45) \approx P\left(Z \leq \frac{45 - 50}{5}\right) = P(Z \leq -1.00)

      .. math::
         = \Phi(-1.00) = 0.1587

      **Part (c): Comparison to exact**

      - Exact: 0.1841
      - Approximation: 0.1587
      - Error: :math:`|0.1841 - 0.1587| = 0.0254`

      The approximation underestimates the true probability by about 0.025 (or about 14% relative error).

      **Part (d): Continuity correction**

      The binomial distribution is **discrete**‚Äîit assigns positive probability to each integer value. When we approximate with a continuous normal distribution, we're replacing probability "bars" (each with width 1) with a smooth curve.

      The issue: When computing :math:`P(X \leq 45)` for the discrete binomial, we include the entire probability mass at :math:`X = 45`. But the normal approximation :math:`P(Z \leq -1.00)` effectively "splits" this bar, capturing only the left half.

      **Continuity correction** addresses this by adjusting boundaries by 0.5:
      
      - For :math:`P(X \leq 45)`, use :math:`P(X \leq 45.5)` in the normal approximation
      - This gives :math:`z = (45.5 - 50)/5 = -0.90`, so :math:`P(Z \leq -0.90) = 0.1841`

      With continuity correction, the approximation matches the exact answer much more closely.

      **R verification:**

      .. code-block:: r

         n <- 100; p <- 0.5
         mu <- n * p  # 50
         sigma <- sqrt(n * p * (1 - p))  # 5

         # Exact probability
         pbinom(45, size = n, prob = p)
         # [1] 0.1841

         # Normal approximation (no continuity correction)
         pnorm(45, mean = mu, sd = sigma)
         # [1] 0.1587

         # Normal approximation (with continuity correction)
         pnorm(45.5, mean = mu, sd = sigma)
         # [1] 0.1841

      .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch7-4/fig5_continuity_correction.png
         :alt: Continuity correction illustration
         :align: center
         :width: 80%

         Each binomial bar spans [x ‚àí 0.5, x + 0.5]. Continuity correction aligns the normal cutoff with bar edges.

----

.. admonition:: Exercise 6: Why the CLT Applies
   :class: note

   This exercise explores *why* the CLT leads to normal approximations for binomial and Poisson distributions.

   a. A binomial random variable :math:`X \sim \text{Binomial}(n, p)` can be written as :math:`X = \sum_{i=1}^{n} X_i` where each :math:`X_i \sim \text{Bernoulli}(p)`. Explain why this representation allows us to apply the CLT.

   b. For Bernoulli random variables with parameter :math:`p`:
      
      - What is :math:`E[X_i]`?
      - What is :math:`\text{Var}(X_i)`?
      
      Use these to derive :math:`E[X]` and :math:`\text{Var}(X)` for :math:`X \sim \text{Binomial}(n, p)`.

   c. Why does the condition ":math:`np \geq 10` and :math:`n(1-p) \geq 10`" make sense in terms of CLT convergence? (Hint: Think about the skewness of Bernoulli distributions for different :math:`p` values.)

   d. Explain why the normal approximation to the Poisson distribution improves as :math:`\lambda` increases. (Hint: When :math:`\lambda` is an integer, how can we express :math:`X \sim \text{Poisson}(\lambda)` as a sum?)

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): CLT for binomial**

      The representation :math:`X = \sum_{i=1}^{n} X_i` expresses the binomial as a sum of :math:`n` **independent and identically distributed** random variables (each :math:`X_i` is Bernoulli(p)). The CLT applies to sums (or averages) of iid random variables with finite mean and variance. Since Bernoulli random variables have:

      - Finite mean: :math:`E[X_i] = p`
      - Finite variance: :math:`\text{Var}(X_i) = p(1-p)`

      all CLT conditions are met. As :math:`n` increases, the distribution of the sum approaches normal.

      **Part (b): Deriving binomial parameters from Bernoulli**

      For :math:`X_i \sim \text{Bernoulli}(p)`:

      - :math:`E[X_i] = p`
      - :math:`\text{Var}(X_i) = p(1-p)`

      For :math:`X = \sum_{i=1}^{n} X_i`:

      .. math::
         E[X] = \sum_{i=1}^{n} E[X_i] = np

      .. math::
         \text{Var}(X) = \sum_{i=1}^{n} \text{Var}(X_i) = np(1-p)

      (The variance sum uses independence of the :math:`X_i`'s.)

      **Part (c): Why np ‚â• 10 and n(1-p) ‚â• 10**

      The Bernoulli distribution is:
      
      - Symmetric when :math:`p = 0.5`
      - Right-skewed when :math:`p < 0.5` (more 0s than 1s)
      - Left-skewed when :math:`p > 0.5` (more 1s than 0s)

      The farther :math:`p` is from 0.5, the more skewed each Bernoulli is, and the larger :math:`n` must be for the CLT to produce a good normal approximation.

      - :math:`np \geq 10` ensures enough expected **successes** so the right tail develops properly
      - :math:`n(1-p) \geq 10` ensures enough expected **failures** so the left tail develops properly

      Together, these conditions ensure the distribution has enough "room" on both sides to approximate a symmetric normal curve.

      **Part (d): CLT intuition for Poisson**

      When :math:`\lambda` is a positive integer, we can write :math:`X \sim \text{Poisson}(\lambda)` as a sum of :math:`\lambda` independent :math:`\text{Poisson}(1)` random variables:

      .. math::
         X = Y_1 + Y_2 + \cdots + Y_\lambda, \quad \text{where each } Y_i \sim \text{Poisson}(1)

      Each :math:`Y_i` has:
      
      - Mean: :math:`E[Y_i] = 1`
      - Variance: :math:`\text{Var}(Y_i) = 1`

      As :math:`\lambda` increases, we sum more iid terms, and CLT intuition suggests the distribution approaches normal. The variance of :math:`X` equals :math:`\lambda` (the number of terms), which grows with :math:`\lambda`.

      The condition :math:`\lambda \geq 10` ensures the Poisson has enough "spread" for an adequate normal approximation. Small :math:`\lambda` produces highly right-skewed Poisson distributions concentrated near 0, similar to how small :math:`n` produces poor CLT approximations for binomial.

      *Note*: For non-integer :math:`\lambda`, this "sum of Poisson(1)" interpretation doesn't apply exactly, but the intuition still holds‚Äîlarger :math:`\lambda` means more variability and a more symmetric, bell-shaped distribution.

----

.. admonition:: Exercise 7: Application ‚Äî Election Polling
   :class: note

   A polling organization surveys 600 randomly selected voters. Suppose the true proportion supporting a candidate is :math:`p = 0.52`.

   a. Let :math:`X` be the number of supporters in the sample. What is the distribution of :math:`X`?

   b. Verify that the normal approximation is appropriate.

   c. Find the approximate probability that fewer than 300 voters (less than 50%) support the candidate.

   d. Find the approximate probability that the poll correctly identifies the candidate as having majority support (i.e., :math:`X > 300`).

   e. How would the probability in (d) change if the sample size were increased to 1500?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Distribution**

      :math:`X \sim \text{Binomial}(n = 600, p = 0.52)`

      **Part (b): Check conditions**

      - :math:`np = 600(0.52) = 312 \geq 10` ‚úì
      - :math:`n(1-p) = 600(0.48) = 288 \geq 10` ‚úì

      **Normal approximation is appropriate.**

      Parameters:

      .. math::
         \mu = np = 312, \quad \sigma = \sqrt{np(1-p)} = \sqrt{600(0.52)(0.48)} = \sqrt{149.76} = 12.24

      .. math::
         X \stackrel{\text{approx}}{\sim} N(312, 149.76)

      **Part (c): P(X < 300)**

      "Fewer than 300" means :math:`X \leq 299`. Ignoring continuity correction:

      .. math::
         P(X < 300) \approx P\left(Z < \frac{300 - 312}{12.24}\right) = P(Z < -0.98)

      .. math::
         = \Phi(-0.98) = 0.1635

      There is about a **16.4%** chance that the poll shows fewer than 50% support, even though the true support is 52%.

      *Note*: With continuity correction (using 299.5), the probability would be slightly different.

      **Part (d): P(X > 300)**

      "More than 300" means :math:`X \geq 301`. Ignoring continuity correction:

      .. math::
         P(X > 300) \approx 1 - P(X \leq 300) \approx 1 - \Phi\left(\frac{300 - 312}{12.24}\right)

      .. math::
         = 1 - \Phi(-0.98) = 1 - 0.1635 = 0.8365

      There is about an **83.7%** chance that the poll correctly identifies majority support.

      **Part (e): Effect of increasing n to 1500**

      With :math:`n = 1500`:

      .. math::
         \mu = 1500(0.52) = 780, \quad \sigma = \sqrt{1500(0.52)(0.48)} = \sqrt{374.4} = 19.35

      :math:`P(X > 750)` (ignoring continuity correction):

      .. math::
         P(X > 750) = P\left(Z > \frac{750 - 780}{19.35}\right) = P(Z > -1.55) = 1 - \Phi(-1.55)

      .. math::
         = 1 - 0.0606 = 0.9394

      With :math:`n = 1500`, there is about a **93.9%** chance of correctly identifying majority support‚Äîa significant improvement from 83.7%.

      **Key insight**: Larger samples produce more precise estimates, reducing the probability of incorrect conclusions.

      **R verification:**

      .. code-block:: r

         # n = 600
         n <- 600; p <- 0.52
         mu <- n * p  # 312
         sigma <- sqrt(n * p * (1 - p))  # 12.24

         # Part (c): P(X < 300)
         pbinom(299, n, p)                           # Exact: 0.1612
         pnorm(300, mean = mu, sd = sigma)           # Normal approx: 0.1635

         # Part (d): P(X > 300)
         pbinom(300, n, p, lower.tail = FALSE)       # Exact: 0.8264
         pnorm(300, mu, sigma, lower.tail = FALSE)   # Normal approx: 0.8365

         # Part (e): n = 1500
         n2 <- 1500
         mu2 <- n2 * p  # 780
         sigma2 <- sqrt(n2 * p * (1 - p))  # 19.35
         pnorm(750, mu2, sigma2, lower.tail = FALSE) # 0.9393

----

.. admonition:: Exercise 8: Application ‚Äî Server Reliability
   :class: note

   A data center monitors server errors. On average, critical errors occur at a rate of 2 per hour.

   a. What is the distribution of :math:`X`, the number of critical errors in a 12-hour period?

   b. Is the normal approximation appropriate? If so, state the approximate distribution.

   c. Find the approximate probability of more than 30 errors in a 12-hour period.

   d. The data center triggers an alert if the error count exceeds a threshold :math:`k`. Find :math:`k` such that alerts occur approximately 1% of the time under normal operating conditions.

   e. If the error rate doubles (to 4 per hour) due to a problem, what is the probability of triggering an alert at the threshold from (d)?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Distribution**

      Errors occur at rate 2 per hour. In 12 hours:

      :math:`\lambda = 2 \times 12 = 24`

      :math:`X \sim \text{Poisson}(24)`

      **Part (b): Normal approximation check**

      :math:`\lambda = 24 \geq 10` ‚úì

      **Normal approximation is appropriate.**

      .. math::
         \mu = 24, \quad \sigma = \sqrt{24} = 4.90

      .. math::
         X \stackrel{\text{approx}}{\sim} N(24, 24)

      **Part (c): P(X > 30)**

      "More than 30" means :math:`X \geq 31`. Ignoring continuity correction:

      .. math::
         P(X > 30) \approx P\left(Z > \frac{30 - 24}{4.90}\right) = P(Z > 1.22)

      .. math::
         = 1 - \Phi(1.22) = 1 - 0.8888 = 0.1112

      About **11%** probability of more than 30 errors.

      *Note*: With continuity correction (using 30.5), :math:`z = 1.33` and probability ‚âà 0.092.

      **Part (d): Find k for 1% alert rate**

      We need :math:`P(X > k) = 0.01`, so :math:`P(X \leq k) = 0.99`.

      From Z-table: :math:`z_{0.99} = 2.33`.

      Ignoring continuity correction:

      .. math::
         k = \mu + z \cdot \sigma = 24 + 2.33(4.90) = 24 + 11.42 = 35.42

      Since :math:`X` is discrete, set threshold at :math:`k = 35`. Alert triggers when :math:`X > 35` (i.e., :math:`X \geq 36`), which occurs approximately 1% of the time.

      **Part (e): Detection probability when rate doubles**

      If rate = 4 per hour, then :math:`\lambda = 4 \times 12 = 48` for 12 hours.

      .. math::
         \mu = 48, \quad \sigma = \sqrt{48} = 6.93

      Probability of alert (:math:`X > 35`), ignoring continuity correction:

      .. math::
         P(X > 35) = P\left(Z > \frac{35 - 48}{6.93}\right) = P(Z > -1.88)

      .. math::
         = 1 - \Phi(-1.88) = 1 - 0.0301 = 0.9699

      There is about a **97%** probability of detecting the doubled error rate‚Äîthe alerting system is effective at identifying the problem.

      **R verification:**

      .. code-block:: r

         # Normal operating conditions: Œª = 24
         lambda1 <- 24
         sigma1 <- sqrt(lambda1)  # 4.90

         # Part (c): P(X > 30)
         ppois(30, lambda1, lower.tail = FALSE)      # Exact: 0.0958
         pnorm(30, lambda1, sigma1, lower.tail = FALSE)  # Normal approx: 0.1103

         # Part (d): Find k for 1% alert rate
         qpois(0.99, lambda1)                        # Exact: 36
         qnorm(0.99, lambda1, sigma1)                # Normal approx: 35.39

         # Part (e): Problem conditions: Œª = 48
         lambda2 <- 48
         sigma2 <- sqrt(lambda2)  # 6.93

         # Detection probability with k = 35
         ppois(35, lambda2, lower.tail = FALSE)      # Exact: 0.9691
         pnorm(35, lambda2, sigma2, lower.tail = FALSE)  # Normal approx: 0.9696

----

Additional Practice Problems
----------------------------

**True/False Questions** (1 point each)

1. The normal approximation to a binomial distribution requires only that :math:`n` be large.

   ‚ìâ or ‚íª

2. If :math:`X \sim \text{Poisson}(\lambda = 5)`, the normal approximation is appropriate.

   ‚ìâ or ‚íª

3. For :math:`X \sim \text{Binomial}(n = 100, p = 0.95)`, the normal approximation is appropriate.

   ‚ìâ or ‚íª

4. The variance of the normal approximation to :math:`\text{Poisson}(\lambda)` equals :math:`\lambda`.

   ‚ìâ or ‚íª

5. Continuity correction is needed because the binomial and Poisson are discrete, while the normal is continuous.

   ‚ìâ or ‚íª

6. The sum of independent Poisson random variables is also Poisson distributed.

   ‚ìâ or ‚íª

**Multiple Choice Questions** (2 points each)

7. For :math:`X \sim \text{Binomial}(n = 200, p = 0.3)`, the normal approximation is :math:`N(\mu, \sigma^2)` with:

   ‚í∂ :math:`\mu = 60, \sigma^2 = 42`
   
   ‚í∑ :math:`\mu = 60, \sigma^2 = 18`
   
   ‚í∏ :math:`\mu = 0.3, \sigma^2 = 42`
   
   ‚íπ :math:`\mu = 200, \sigma^2 = 60`

8. Which binomial distribution can be approximated well by a normal distribution?

   ‚í∂ :math:`\text{Binomial}(n = 20, p = 0.5)`
   
   ‚í∑ :math:`\text{Binomial}(n = 100, p = 0.02)`
   
   ‚í∏ :math:`\text{Binomial}(n = 50, p = 0.3)`
   
   ‚íπ :math:`\text{Binomial}(n = 200, p = 0.98)`

9. For :math:`X \sim \text{Poisson}(\lambda = 36)`, find :math:`P(X > 42)` using the normal approximation (ignoring continuity correction):

   ‚í∂ :math:`P(Z > 0.5)`
   
   ‚í∑ :math:`P(Z > 1.0)`
   
   ‚í∏ :math:`P(Z > 6.0)`
   
   ‚íπ :math:`P(Z > 1.17)`

10. The normal approximation to binomial works better when:

    ‚í∂ :math:`p` is close to 0 or 1
    
    ‚í∑ :math:`n` is small
    
    ‚í∏ :math:`p` is close to 0.5
    
    ‚íπ :math:`np < 10`

11. If :math:`Y_1 \sim \text{Poisson}(8)` and :math:`Y_2 \sim \text{Poisson}(12)` are independent, then :math:`Y_1 + Y_2 \sim`:

    ‚í∂ :math:`\text{Poisson}(96)`
    
    ‚í∑ :math:`\text{Poisson}(20)`
    
    ‚í∏ :math:`\text{Binomial}(20, 0.5)`
    
    ‚íπ :math:`N(20, 20)`

12. For the normal approximation to :math:`\text{Binomial}(n, p)`, both :math:`np \geq 10` and :math:`n(1-p) \geq 10` are required because:

    ‚í∂ The CLT requires at least 20 observations
    
    ‚í∑ These ensure sufficient expected successes and failures for symmetry
    
    ‚í∏ The binomial variance must exceed 10
    
    ‚íπ The normal distribution requires integer parameters

.. dropdown:: Answers to Practice Problems
   :class-container: sd-border-success

   **True/False Answers:**

   1. **False** ‚Äî Both :math:`n` **and** :math:`p` matter. We need :math:`np \geq 10` and :math:`n(1-p) \geq 10`.

   2. **False** ‚Äî :math:`\lambda = 5 < 10`, so the normal approximation is not appropriate.

   3. **False** ‚Äî :math:`n(1-p) = 100(0.05) = 5 < 10`, so the condition fails.

   4. **True** ‚Äî For Poisson(:math:`\lambda`), both the mean and variance equal :math:`\lambda`, so the normal approximation has variance :math:`\lambda`.

   5. **True** ‚Äî The discrete-to-continuous mismatch causes approximation error, which continuity correction helps address.

   6. **True** ‚Äî If :math:`Y_1 \sim \text{Poisson}(\lambda_1)` and :math:`Y_2 \sim \text{Poisson}(\lambda_2)` are independent, then :math:`Y_1 + Y_2 \sim \text{Poisson}(\lambda_1 + \lambda_2)`.

   **Multiple Choice Answers:**

   7. **‚í∂** ‚Äî :math:`\mu = np = 200(0.3) = 60`; :math:`\sigma^2 = np(1-p) = 200(0.3)(0.7) = 42`.

   8. **‚í∏** ‚Äî Check each: (A) :math:`np = 10`, :math:`n(1-p) = 10` ‚Äî borderline; (B) :math:`np = 2 < 10` ‚Äî fails; (C) :math:`np = 15 \geq 10`, :math:`n(1-p) = 35 \geq 10` ‚Äî passes well; (D) :math:`n(1-p) = 4 < 10` ‚Äî fails.

   9. **‚í∑** ‚Äî :math:`\sigma = \sqrt{36} = 6`; ignoring continuity correction, :math:`z = (42 - 36)/6 = 1.0`.

   10. **‚í∏** ‚Äî When :math:`p \approx 0.5`, the Bernoulli distribution is symmetric, so the CLT converges faster.

   11. **‚í∑** ‚Äî Sum of independent Poissons is Poisson with :math:`\lambda = 8 + 12 = 20`. (Note: The normal approximation N(20, 20) could be used since :math:`\lambda = 20 \geq 10`, but the exact distribution is Poisson(20).)

   12. **‚í∑** ‚Äî These conditions ensure enough expected successes (np) and failures (n(1-p)) so the distribution has adequate spread on both sides to resemble a symmetric bell curve.