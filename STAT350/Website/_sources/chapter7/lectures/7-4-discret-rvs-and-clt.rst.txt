.. _7-4-discrete-rvs-and-clt:


.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch7-4">
      <iframe
         id="video-ch7-4"
         title="STAT 350 ‚Äì Chapter 7.4 Discrete Random Variables and the CLT Video"
         src="https://www.youtube.com/embed/U98siSK61oY?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

.. admonition:: Slides
   :class: tip

   `Download Chapter 7 slides (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%207%20Sampling%20Distributions/Sampling%20Distributions%20%28Chapter7%29_AC.pptx>`_


Understanding Binomial and Poisson Distributions through CLT
================================================================

Sections 5.6 and 5.7 showed that for certain parameter values, the binomial and Poisson distributions have a 
pmf with a bell-shaped trend. In this section, we use the CLT to explain why this similarity occurs and characterize the set of 
parameters for which it happens. We also identify the issue that can arise from approximating a **discrete** distribution 
with a **continuous** normal distribution.

.. admonition:: Road Map üß≠
   :class: important

   * Use CLT to explain why certain binomial and Poisson distributions can be approximated using normal distributions.
   * Understand the issue that can arise from the support difference between the true (discrete) and approximated 
     (continuous) distributions.
     Know that a technique called **continuity correction** can be used as a remedy.

The Preliminary: An Alternative Statement for CLT
-------------------------------------------------------------

For an iid sample :math:`X_1, X_2, \cdots, X_n` from a population with finite mean :math:`\mu` and finite
standard deviation :math:`\sigma`, let :math:`S_n = X_1 + X_2 + \ldots + X_n`. Then,

.. math::

   \frac{S_n - n\mu}{\sigma\sqrt{n}} \xrightarrow{d} N(0,1) \text{ as } n \rightarrow \infty

.. admonition:: How is this connected to the original statement of the CLT? üîé
   :class: important
   
   The fraction at the beginning of the mathematical statement is in fact identical to
   the one used in Section 7.3:

   .. math::
      \frac{S_n - n\mu}{\sigma\sqrt{n}} = \frac{(S_n - n\mu)/n}{(\sigma\sqrt{n})/n} 
      = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}}.
   
By using this alternative expression, we can also view the **sample sum** as approximately normally distributed:

.. math::

   S_n \stackrel{\text{approx}}{\sim} N(n\mu, \sigma\sqrt{n})


Binomial Distribution and the CLT
-------------------------------------

A binomial random variable :math:`X \sim B(n,p)` counts the number of successes in :math:`n` independent trials, 
each with probability of success :math:`p`. Recall that it can also be expressed 
as:

.. math::

   X = \sum_{i=1}^n X_i,

where each :math:`X_i` is an **independent** Bernoulli random variable that 
equals 1 with probability :math:`p` and 0 with probability :math:`(1-p)`. Since a 
binomial random variable is a sum of independent and identically distributed random variables,
the CLT applies as :math:`n` increases. For a sufficiently large :math:`n`, 
the distribution of :math:`X` can be approximated by:

.. math::

   X \stackrel{\text{approx}}{\sim} N \left(np, \sqrt{np(1-p)}\right)

The two normal parameters are obtained simply by taking :math:`E[X]` and :math:`\sigma_X`
from the true distribution of :math:`X`.

When does it apply?
~~~~~~~~~~~~~~~~~~~~~~~

Recall that the "large enough" :math:`n` for the CLT depends on the skewness of
the population distribution. For binomial distributions, the skewness is determined by :math:`p` 
(symmetric for :math:`p=0.5`, stronger skewness as :math:`p` nears :math:`0` or :math:`1`).
Therefore, we usually consider the two parameters :math:`n` and :math:`p` jointly to identify cases where
the binomial distribution is well-approximated by a normal distribution. The rule of thumb is:

1. Both :math:`np ‚â• 10` and :math:`n(1-p) ‚â• 10`.
2. Alternatively, :math:`np(1-p) ‚â• 10`.

The figure below shows some concrete examples:

.. _binomial-normal:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/images/chapter7/binomial-normal.png 
   :figwidth: 100%
   :align: center 
   :alt: Cases which work well with normal approximation vs cases which don't

   Cases with different compatibilities with normal approximation

In Figure :numref:`binomial-normal`, 

**(a)** is symmetric, but :math:`n` is too small. It fails the rule-of-thumb tests. Normal approximation will not work well. ‚ùå

**(b)** is symmetric with sufficiently large :math:`n`. It passes the rule-of-thumb tests. Normal approximation will work well. ‚úî

**(c)** has the same :math:`n` as (b), but the distribution is very skewed because :math:`p=0.1`. 
Normal approximation will not work well. ‚ùå

**(d)** has even larger :math:`n` which compensates for the :math:`p` far from 0.5. Normal approximation will work well.‚úî


Poisson Distribution and the CLT
-----------------------------------

A Poisson random variable counts the number of independent events 
occurring in a fixed interval, where  events happen at a constant average rate :math:`\lambda`.

An interesting property of the Poisson distribution is that the **sum of independent Poisson 
random variables is also Poisson** distributed. If :math:`Y_1 \sim Pois(\lambda_1)` and 
:math:`Y_2 \sim Pois(\lambda_2)` are independent, 
then :math:`Y_1 + Y_2 \sim Pois(\lambda_1 + \lambda_2)`.

By extension, if :math:`Y_1, Y_2, \cdots, Y_n` are **independent** Poisson random variables with the 
**identical** parameter :math:`\lambda`, then:

.. math::

   \sum_{i=1}^n Y_i \sim \text{Poisson}(n\lambda)

Let :math:`X = \sum_{i=1}^n Y_i` and :math:`\tilde{\lambda} = n\lambda`. Since :math:`Y_i`'s are iid,
the CLT applies for a sufficiently large :math:`n`: 

.. math::
   X \stackrel{\text{approx}}{\sim} N\left(\tilde{\lambda}, \sqrt{\tilde{\lambda}}\right)

Again, the normal parameters come from :math:`E[X]` and :math:`\sigma_X` of the true distribution.

When does it apply?
~~~~~~~~~~~~~~~~~~~~~


In practice, we do not have an explicit :math:`n` for a Poisson random variable. If :math:`X \sim Pois(\lambda)`,
it can be expressed as a sum of two Poisson random variables, each with parameter :math:`\lambda/2`, or of a thousand,
each with parameter :math:`\lambda/1000`. 

Thus we focus solely on the size of :math:`\lambda`. 
Typically, :math:`\lambda \geq 10` is large enough for approximation by a normal distribution.
See :numref:`poisson-normal` to verify that the Poisson PMF grows more bell-shaped as :math:`\lambda`
becomes larger.

.. _poisson-normal:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/images/chapter7/poisson-normal.png 
   :width: 80%
   :align: center 
   :alt: Poission PMF approaches bell-shape as lambda grows

   :math:`\lambda =1,5,10,50` from top to bottom, respectively.

The Practicality of Normal Approximation to Binomial & Poisson Distributions
------------------------------------------------------------------------------

Suppose a random variable :math:`X` has a distribution :math:`B(n=100, p=0.5)`, and we are to
compute :math:`P(X < 50)`. Without access to a computational software, we can either

1. compute :math:`P(X < 50)` directly, which requires computation of 50 separate 
   pmf terms: :math:`P(X=0) + P(X=1) + \cdots + P(X=49)`, or
2. use the approximate normal distribution to compute a *slightly* less accurate value
   in one access to the standard normal table.

As :math:`n` gets larger, both the convenience and accuracy of Option 2 increase.
This example only touches on the binomial case, but a similar logic can be applied 
to a Poisson case with a large :math:`\lambda`.

This techinque was especially relevant when computational software was less accessible. 
Today, it still plays an important role in illustrating the
broad implications of the CLT and in showing how different distributions are connected.

Continuity Correction
------------------------------

When using the normal distribution to approximate discrete distributions like 
the binomial or Poisson, we need to account for the difference between their supports.
Consider :math:`X \sim B(n=100, p=0.5)` again. Using the exact distribution,

.. math::
   P(X=48) = {100 \choose 48} \left(\frac{1}{2}\right)^{48}\left(\frac{1}{2}\right)^{100-48} = 0.0735.

But using its approximated distribution :math:`N(\mu=50, \sigma = \sqrt{25})`,

.. math:: P(X = 48) \approx 0. 

A discrete distribution always has a positive probability for a value in its support, while 
a normal distribution assigns a zero probability to any single value. This difference needs to be
addressed by a technique called **continuity correction**, which is not covered in detail in this course.
You are encouraged to read about it independently.

Bringing It All Together
-----------------------------------------------------------------

.. admonition:: Key Takeaways üìù
   :class: important

   1. **The CLT can be used to describe certain binomial and Poisson distributions discrete distributions**.
   
   2. **For binomial distributions**, the normal approximation works well when :math:`np \geq 10` 
      and :math:`n(1-p) \geq 10` (or alternatively when :math:`np(1-p) \geq 10`).
   
   3. **For Poisson distributions**, the normal approximation works well when :math:`\lambda \geq 10`.
   
   4. **Continuity corrections may be needed** when using a continuous distribution to approximate a discrete one.
