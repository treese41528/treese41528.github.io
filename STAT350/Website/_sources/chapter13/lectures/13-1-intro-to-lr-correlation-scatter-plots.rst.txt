.. _13-1-intro-to-lr-correlation-scatter-plots:

.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch13-1">
      <iframe
         id="video-ch13-1"
         title="STAT 350 ‚Äì Chapter 13.1 Correlation and Regression: Simple Linear Regression Video"
         src="https://www.youtube.com/embed/NfbWwbuUVEg?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

.. admonition:: Slides üìä
   :class: tip

   `Download Chapter 13 slides (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/
   slides/Chapter%2013%20Linear%20Regression/SimpleLinearRegression_AC.pptx>`_
   
Introduction to Linear Regression
=========================================================================

So far, we have studied inference methods that describe a single population or the relationship 
between a quantitative variable and a categorical variable.
Regression analysis, in contrast, examines relationships between **two quantitative variables**. 
While many core statistical ideas parallel the methods from previous chapters, one major shift occurs‚Äîwe can now describe the
relationship using a **functional form**, represented by a the trendline.

After a brief introduction to general regression analysis, we narrow our focus to variables
that exhibit a **linear associations**.

.. admonition:: Road Map
   :class: important

   * Express the core ideas of previous inference methods in model form.
   * Build the general regression model for two quantitative variables. 
     Understand its components and see how it extends the modeling ideas from earlier methods.
   * Graphically assess the association of two quantitative variables using scatter plots.


The Evolution of Our Statistical Journey
---------------------------------------------

Before diving into linear regression, let us reflect on our journey through statistical
inference. Each major phase has built systematically toward the culminating topic of linear regression.

Model for Single Population Inference 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We began with the fundamental problem of inferring an unknown population mean :math:`\mu` from 
sample data. The corresponding model can be written as:

.. math::

   X_i = \mu + \varepsilon_i,

where :math:`\varepsilon_i` represent *iid* errors with :math:`E(\varepsilon_i)=0` and 
:math:`\text{Var}(\varepsilon_i) = \sigma^2` for :math:`i = 1, 2, \ldots, n`. 
This model captures the essential idea that each observation consists of an underlying mean plus random 
variation around that mean.

Two-Population Models
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**A. Independent Two-Sample Inference**


We then extended our methods to comparison of two population means, handling both independent and 
dependent sampling scenarios.

For independent two-sample inference, the assumptions can be expressed using
the model:

.. math::
   &X_{Ai} = \mu_A + \varepsilon_{Ai} \\ 
   &X_{Bi} = \mu_B + \varepsilon_{Bi},

where

* :math:`\mu_A` and :math:`\mu_B` are the unknown population means,
* :math:`\varepsilon_{Ai}` are *iid* with :math:`E(\varepsilon_{Ai})=0` and :math:`\text{Var}(\varepsilon_{Ai}) = \sigma^2_A` 
  for all :math:`i=1,\cdots,n_A`,
* :math:`\varepsilon_{Bi}` are *iid* with :math:`E(\varepsilon_{Bi})=0` and :math:`\text{Var}(\varepsilon_{Bi}) = \sigma^2_B` 
  for all :math:`i=1,\cdots,n_B`, and
* error terms of Population A are independent from error terms of Population B.

**B. Paired Two-Sample Inference**

For paired samples, the difference is modeled directly:

.. math::

   D_i = X_{Ai} - X_{Bi} = (\mu_A - \mu_B) + \varepsilon_i

where :math:`\varepsilon_i` are *iid* with :math:`E(\varepsilon_i)=0` and :math:`\text{Var}(\varepsilon_i)=\sigma^2_D`.

The ANOVA Model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ANOVA extended the modeling ideas for the independent two-sample analysis to  :math:`k`-samples. Each 
observation :math:`X_{ij}` is assumed to satisfy:

.. math::

   X_{ij} = \mu_i + \varepsilon_{ij},

where 

* :math:`\mu_i` is the true mean for group :math:`i`, and
* :math:`\varepsilon_{ij}` are *iid* errors with :math:`E(\varepsilon_{ij})=0` and :math:`\text{Var}(\varepsilon_{ij}) = \sigma^2`
  for all possible pairs :math:`(i,j)`.

----------------------------------------

The Regression Framework
--------------------------------------

Throughout our progression, we consistently worked with a **single quantitative variable**‚Äîeither on its own
or in connection with a **categorical factor variable** that divides data into groups.

In regression analyses, we study the relationship of **two quantitative variables**. Because both variables carry
numerical order and magnitude, our interest expands: 
we now examine not only whether an association exists but also the **functional form** that characterizes how the two variables relate.

The General Regression Model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Our new modeling framework can be expressed as:

.. math::

   Y = g(X) + \varepsilon.

This simple equation contains profound ideas:

* The **response variable** :math:`Y` (also called the **dependent variable**) represents the outcome to be understood and predicted.

* The **explanatory variable** :math:`X` (also called the **independent variable**) represents the variable that may explain,
  influence, or predict changes in the response variable.

* The **regression function** :math:`g(X)` defines the systematic relationship between the explanatory and response variables. 
  This function captures the *average* behavior of how :math:`Y` changes with :math:`X`.

* The error rerm :math:`\varepsilon` represents **unexplained variation**‚Äîeverything about :math:`Y` that cannot be explained 
  by the functional relationship with :math:`X`.

.. admonition:: Functional Association Does Not Guarantee Causality
   :class: danger

   Two variables are said to be **associated** if changes in one variable are accompanied by systematic changes in the other variable. 
   
   **Causation** makes a stronger claim that one variable brings about changes in the other. 
   Establishing causation requires careful experimental design and advanced analytical techniques that allow the
   causal argument to be statistically rigorous.

   ‚ÄºÔ∏è Regression analyses covered in this course **can establish association, but not causation.**

---------------------------------------------



.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch13-2">
      <iframe
         id="video-ch13-2"
         title="STAT 350 ‚Äì Chapter 13.2 Scatter Plots Video"
         src="https://www.youtube.com/embed/5wECoca89ls?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

Preliminary Assessment of Linear Relationship Through Scatter Plots
----------------------------------------------------------------------

Before mathematically constructing regression analysis, let us examine the association between 
two quantitative variables graphically. Scatter plots are the primary tool for this stage.

The Anatomy of a Scatter Plot
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. _scatter-intro:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/scatter-intro.png
   :width: 60%
   :align: center 
   :alt: Scatter plot

   An example of a scatter plot


A scatter plot consists of: 

- **Horizontal X-axis** whose range includes all :math:`x_i` values in the data set
- **Vertical Y-axis** whose range includes all observed :math:`y_i` values
- **Points** at coordinates :math:`(x_i, y_i)`, each representing an observed pair

The assessment of a scatter plot consists of three main steps: 

* **Step 1:** Check whether there is any relationship between the two variables, and if yes, identify the form of 
  the relationship (linear, curved, etc.). 
 
Once the relationship is confirmed to be linear, proceed to:

* **Step 2:** Assess the direction and strength of the linear relationship.
* **Step 3:** Check if any horizontal or vertical ouliers exist.

Step 1: The Functional Form
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

During this stage, we visualize a curve which best summarizes the trend created by the data points.
Depending on its functional form, we classify the association as linear, exponential, polynonomial, 
clustered, etc. :numref:`scatter-intro` shows a scatter plot with a linear trend.

See :numref:`scatter-plot-forms` for scatter plots exhibiting trends of different functional forms.

.. _scatter-plot-forms:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/scatter-form.png
   :width: 95%
   :align: center
   :alt: Scatter plots showing different functional forms

   Scatter plots showing trends with exponential, polynomial, and sinusoidal forms

Other possible forms are: 

- **Threshold or breakpoint patterns**: The relationship changes character at certain values, requiring 
  different functional forms in different regions.
- **Clustered form**: Points group into distinct clusters rather than following a smooth pattern. This suggests 
  the presence of subgroups or categories within the data.
- **No pattern**: Points appear randomly scattered with no discernible relationship. This suggests that the 
  explanatory variable provides little or no information about the response variable.


Step 2: Direction and Strength of a Linear Relationship
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Once a linear form is identified, we characterize the association further with its **direction** 
and **strength**. 

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/scatter-direction.png
   :width: 95%
   :align: center
   :alt: Scatter plots with varying directions of linear association

   Scatter plots with different directions of linear association

**Positive linear association** is indicated by an **upward trend** in the scatter plot.
As the explanatory variable :math:`X` increases, the response variable :math:`Y` tends to increase as well.

**Negative linear association** is indicated by a **downward trend**, with the variables moving in "opposite" directions.

.. _scatter-plot-strength:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/scatter-strength.png
   :width: 95%
   :align: center
   :alt: Scatter plots with varying strengths of linear association

   Strength of linear association increases from left to right


**Strength** of a linear relationship is indicated on a scatter plot by how closely the points gather around the 
best-fit line. We say that :math:`X` and :math:`Y` have a deterministic (perfect) linear association when 
the data points lie on a straight line (first on the right of :numref:`scatter-plot-strength`).

.. admonition:: Exception: A Perfect Horizontal Line
   :class: important

   When the summary line is horizontal, we consider the two random variables to be **unassociated**, even if 
   the dots draw a perfect line. This may seem contradictory to our prior discussion at first, but recall that two variables 
   are associated if information of one variable gives us **extra** information about the other. 
   In an association described by a flat line, the knowledge of an :math:`X` value gives no
   additional information on the potential location of :math:`Y`.

Step 3: Outliers and Influential Points
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

There are two types of outliers in regression analysis:

* :math:`X`-outliers deviate horizontally **from other** :math:`X` **values** (:numref:`x-outliers`).
* :math:`Y`-outliers show a greater vertical **distance from the trendline** than other data points (:numref:`y-outlier`). 

Note the key distinction: :math:`Y`-outliers are determined by their distance from the
associational trend with :math:`X`, not from other :math:`Y` values.

.. _y-outlier:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/y-outlier.png
   :width: 50%
   :align: center
   :alt: Y-outlier

   Y-outlier is circled in red

We further define an **influential point** as an observation that has a large impact on the fitted 
regression line. Removing this point would substantially change the slope, the intercept, or both.
We also say that such points have **high leverage**.

.. _x-outliers:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/x-outliers.png
   :width: 80%
   :align: center
   :alt: X-outliers

   X-outliers

In :numref:`y-outlier` and :numref:`x-outliers`, the red trend lines summarize all 
data points, while the blue trend lines summarize the data with outliers removed. These graphs
provide important takeaways:

* It is problematic if few outliers have high leverage, as they distort the *general* trend.
* Between the two types, :math:`X`-outliers are generally more influential than :math:`Y`-outliers,
  often "pulling" the best fit line toward them. 
* Not all outliers are influential, and not all influential points are outliers. 

.. admonition:: Exampleüí°: Car Engine Performance üöò
   :class: note

   Automotive engineers collected data on eight four-cylinder vehicles that are considered to be among the most fuel-efficient in 2006. 
   For each vehicle, they measured:

   - The total displacement of the engine, in cylinder volume (liters)
   - The power output of the engine, in orsepower (hp)

   See the complete dataset below: 

   .. flat-table::
      :header-rows: 2
      :widths: 10 30 20 20

      * - :cspan:`3` 2006 Fuel-efficient vehicle data
      * - Obs #
        - Vehicle
        - Cylinder Volume (L)
        - Horsepower (hp)
      * - 1
        - Honda Civic
        - 1.8
        - 100
      * - 2
        - Toyota Prius
        - 1.5
        - 96
      * - 3
        - VW Golf
        - 2.0
        - 115
      * - 4
        - VW Beetle
        - 2.4
        - 150
      * - 5
        - Toyota Corolla
        - 1.8
        - 126
      * - 6
        - VW Jetta
        - 2.5
        - 150
      * - 7
        - Mini Cooper
        - 1.6
        - 118
      * - 8
        - Toyota Yaris
        - 1.5
        - 106


   **Q1: Which variable should be explanatory and which should be response?**

   From an engineering perspective, the physical size of the engine largely determines its potential power output. 
   Larger engines generally have the capacity to produce more power, though other factors like engine design and tuning also matter. Therefore,
   we use cylindar volume as the explanatory variable :math:`X` and the power output as the respones :math:`Y`.

   **Q2: Create a Scatter Plot**

   1. Save the data set in the ``data.frame`` format:

   .. code-block:: r

      car_efficiency <- data.frame(
      hp = c(100, 96, 115, 150, 126, 150, 118, 106),
      cylinder_volume = c(1.8, 1.5, 2.0, 2.4, 1.8, 2.5, 1.6, 1.5)
      )
   
   2. Use ``ggplot`` to make a scatter plot with a fitted line:

   .. code-block:: r

      ggplot(car_efficiency, aes(x = cylinder_volume, y = hp)) +
      geom_point() +
      geom_smooth(method = "lm", se = FALSE, color = "black", size = 1) +
      labs(
         title = "2006 Fuel Efficiency",
         x = "Cylinder Volume (L)",
         y = "Horsepower (hp)"
      ) +
      theme_minimal()

   The resulting plot is:

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter13/scatter-car.png
      :width: 80%
      :align: center 
      :alt: Scatter plot of car engine performance data set

      Scatter plot of car engine performance data set

   **Q3: Identify the form of the relationship between the total displacement and the power output.**

   The points roughly follow a linear pattern. We don't see curvature, clustering, or other non-linear patterns.

   **Q4: If the form is linear, state the direction and strength of the linear relationship. Are there any outliers? If there are, are the outliers influential?**

   * The linear association is positive‚Äîas the cylinder volume increases, the power output tends to increase. 
   * The strength is moderate‚Äîmost points cluster reasonably close to the apparent trend line, though there is some scatter. 
   * There are no obvious outliers or influential points. All data points fall within reasonable ranges in both directions 
     and follow the general pattern.

Bringing It All Together
-------------------------------------

.. admonition:: Key Takeaways üìù
   :class: important

   1. **The regression model** :math:`Y = g(X) + \varepsilon` decomposes observations into systematic relationships plus unexplained 
      variation.

   2. Most regression analyses can **only establish association**; causation requires well-designed experiments and advanced 
      analysis methods.

   3. **Scatter plots are the primary tool** for assessing form, direction, and strength of bivariate 
      relationships.

   4. There are **two types of outliers** in regression analysis. :math:`X`-outliers lie far from most
      :math:`X` values. 
      :math:`Y`-outliers lie far from the trend line of their association with :math:`X`. 
      
   5. **Outliers and influential points require special attention** because they can dramatically affect fitted 
      models and conclusions. :math:`X`-outliers are more prone to being influential than :math:`Y`-outliers.
