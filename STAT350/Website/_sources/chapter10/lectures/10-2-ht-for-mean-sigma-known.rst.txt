.. _10-2-ht-for-mean-sigma-known:


.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch10-2">
      <iframe
         id="video-ch10-2"
         title="STAT 350 – Chapter 10.2 Hypothesis Testing and Power for the Mean of a Population Video"
         src="https://www.youtube.com/embed/vjzyQHJrHE0?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

.. admonition:: Slides 📊
   :class: tip
   
   - `Hypothesis Testing for Single Sample (Part 2) (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%2010%20Hypothesis%20Testing/Hypothesis%20Testing%20for%20Single%20Sample%20Part2_AC.pptx>`_

Hypothesis Test for the Population Mean When σ is Known
========================================================================

In the previous lesson, we learned the conceptual framework of hypothesis testing and constructed a simple rule for
rejecting the null hypothesis in an upper-tailed test. Let us now extend this concept to all three types of
hypotheses (upper-tailed, lower-tailed, and two-tailed), and discuss an alternative decision-making method using
**p-values**.

.. admonition:: Road Map 🧭
   :class: important

   * Organize the **formal hypothesis pairs and decision rules** for the three types of tests on a population mean
     (upper-tailed, lower-tailed, and two-tailed), when :math:`\sigma` is known.
   * Learn the **p-value method** for making decisions and compare it with
     the **cutoff method**.

Z-Test for Population Means
--------------------------------------------------------

Summary of the Three Dual Hypotheses
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In Section 10.1.1, we learned how to translate a research question about a population mean into a pair of formal hypotheses. 
Such pairs take three general forms, whose properties are summarized in the table below:

.. flat-table::
   :header-rows: 1
   :widths: 1 1 3

   * - Name of test
     - Hypotheses
     - Question 

   * - Upper-tailed (right-tailed)
     - .. math:: 
          &H_0: \mu \leq \mu_0\\
          &H_a: \mu > \mu_0
     - The population mean :math:`\mu` is suspected to be **greater** than
       a baseline belief, :math:`\mu_0`
   
   * - Lower-tailed (left-tailed)
     - .. math:: 
          &H_0: \mu \geq \mu_0\\
          &H_a: \mu < \mu_0
     - The population mean :math:`\mu` is suspected to be **less** than
       a baseline belief, :math:`\mu_0`

   * - Two-tailed
     - .. math:: 
          &H_0: \mu = \mu_0\\
          &H_a: \mu \neq \mu_0
     - The population mean :math:`\mu` is suspected to be **different** than
       a baseline belief, :math:`\mu_0`

The Assumptions
~~~~~~~~~~~~~~~~~

Recall the assumptions needed for the decision-rule construction in Section 10.1.1:

1. :math:`X_1, X_2, \cdots, X_n` form an *iid* sample from
   the population :math:`X` with mean :math:`\mu` and variance :math:`\sigma^2`.
2. Either the population :math:`X` is normally distributed, or the sample size :math:`n` is
   sufficiently large for the CLT to hold.
3. The population variance :math:`\sigma^2` is known.

These assumptions allowed us to use the CLT to establish:

.. math::

   \bar{X} \sim N\left(\mu_0, \frac{\sigma}{\sqrt{n}}\right)

under the null hypothesis. The distributional property of :math:`\bar{X}`
continues to play a crucial role for the remaining two decision rules.

The Decision Rules
~~~~~~~~~~~~~~~~~~~~~~

A. Upper-Tailed Hypothesis Test — A Review
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In an upper-tailed hypothesis test, with

.. math::
   &H_0: \mu \leq \mu_0\\
   &H_a: \mu > \mu_0,

we agreed to reject the null hypothesis
when the observed sample mean was **too large** to be a typical value under the null haypothesis.

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter10/upper-HT-decision-general.png 
   :figwidth: 90%
   :align: center 
   :alt: Decision rule for upper-tailed hypothesis test

   Decision rule for upper-tailed hypothesis test

Specifically, we reject :math:`H_0` when :math:`\bar{x}` is on the upper
:math:`\alpha\cdot100`-th percentile of the null distribution:

.. math::
   \bar{x} > \text{cutoff}_{upper} = z_\alpha\frac{\sigma}{\sqrt{n}} +\mu_0.

By standardizing both sides of the inequality, the null hypothesis is rejected when:

.. math::
   \frac{\bar{x}-\mu_0}{\sigma/\sqrt{n}} > z_\alpha.



B. Lower-Tailed Hypthesis Test — A Mirror Argument
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Recall the pair of hypotheses for a lower-tailed test:

.. math::
   &H_0: \mu \geq \mu_0\\
   &H_a: \mu < \mu_0.

The rule for rejecting the null hypothesis follows
the same chain of logic as the upper-tailed case, only with the sides flipped. Since we
are now challenging the status quo belief that :math:`H_0:\mu \geq \mu_0`,
we must reject the null hypothesis if the evidence from the sample mean is **too low**.

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter10/lower-HT-decision.png 
   :figwidth: 90%
   :align: center 
   :alt: Decision rule for lower-tailed hypothesis test

   Decision rule for lower-tailed hypothesis test

Formally, the null hypothesis is rejected if the observed sample mean
falls below the lower :math:`\alpha \cdot 100`-th percentile of the null distribution, or
if :math:`\bar{x} < -z_\alpha\frac{\sigma}{\sqrt{n}} + \mu_0`. Standardizing both sides,
rejection occurs when:


.. math::
   \frac{\bar{x}-\mu_0}{\sigma/\sqrt{n}} < -z_\alpha.



C. Two-Tailed Hypothesis Test — Splitting the Error Probability in Half
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In a two-tailed hypothesis test with

.. math::
   &H_0: \mu = \mu_0\\
   &H_a: \mu \neq \mu_0,

we are starting off with the belief that the true mean is equal to :math:`\mu_0`.
Thus, an extreme deviation on either side should lead to its rejection.
We set two cutoffs—upper and lower—around :math:`\mu_0` and reject the null 
if the sample mean falls outside this range by being **either too small or too large**. 


.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter10/two-HT-decision.png 
   :figwidth: 90%
   :align: center 
   :alt: Decision rule for two-tailed hypothesis test

   Decision rule for two-tailed hypothesis test

To identify rejection regions on both ends of the null distribution while keeping the 
Type I error probability to at most :math:`\alpha`, we must split :math:`\alpha`
into half for each tail. :math:`H_0` is rejected either if

.. math::
   \bar{x} > z_{\alpha/2}\frac{\sigma}{\sqrt{n}} + \mu_0 \quad \text{ or if } \quad 
   \bar{x} < -z_{\alpha/2}\frac{\sigma}{\sqrt{n}} + \mu_0. 
   
By standardizing both sides and
combining the two cases using an absolute value sign, this rule is equivalent to rejecting the null when:

.. math::

   \left|\frac{\bar{x}-\mu_0}{\sigma/\sqrt{n}}\right| > z_{\alpha/2}.

..
   The Z-Test Statistic and the Z-Test
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

   **This info is already in section 10.1**
   In all three cases, we used the observed value of the :math:`z`-**test statistic**:

   .. math::

      Z_{TS} = \frac{\bar{X} - \mu_0}{\sigma/\sqrt{n}}.

   We now have the background to understand where its name comes from.
   This statistic is centeral to all three basic types of hypothesis tests on
   a population mean, and it follows a standard
   normal distribution under the null hypothesis and the standard assumptions.

   The entire testing procedure about a population mean :math:`\mu` with 
   known population standard deviation :math:`\sigma`
   is also called a **Z-test** for the same reason.

The :math:`p`-Value Method
-------------------------------

While we could use cutoffs and rejection regions to draw conclusions to a hypothesis test, 
the convention is to use an alternative :math:`p`-**value method**. 
We will learn that this method provides more nuanced information 
about the strength of evidence against the null hypothesis.

What Is the :math:`p`-Value Method?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :math:`p`-value method focuses on the **tail area created by the observed sample mean**
instead of its :math:`x`-axis location on the null distribution. Let us use an upper-tailed
case for our initial illustration:

.. math::
   & H_0: \mu \leq \mu_0\\
   & H_0: \mu > \mu_0

First, suppose we observe :math:`\bar{x}` that is *too large* for the null and falls in the rejection region.
The tail area created by :math:`\bar{x}`, marked in blue in :numref:`pvalue-reject`, is
bound to be smaller than :math:`\alpha`.

.. _pvalue-reject:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter10/pvalue-reject.png 
   :figwidth: 90%
   :align: center 
   :alt: p-value when the null hypothesis is rejected in an upper-tailed test

   P-value when the null hypothesis is rejected (upper-tailed test)

Let us also observe a case where :math:`\bar{x}` is not large enough to be rejected.
We find that the tail area created by :math:`\bar{x}` must be at least of size :math:`\alpha`.

.. _pvalue-fail-to-reject:
.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter10/pvalue-fail-to-reject.png 
   :figwidth: 90%
   :align: center 
   :alt: p-value when the null hypothesis is not rejected in an upper-tailed test

   P-value when the null hypothesis is not rejected (upper-tailed test)

The takeaway here is that comparing p-values againt :math:`\alpha` can be used
as an alternative to comparing :math:`z_{TS}` against a :math:`z`-critical value for a conclusion.
We will define :math:`p`-values for the remaining two test types so that in every case,
a :math:`p`-value smaller than :math:`\alpha` leads to the rejection of :math:`H_0`.

How To Compute :math:`p`-Values
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A :math:`p`-value is universally interpreted as "**the probability of observing an outcome
at least as unusual as the current one, under the null hypothesis**". Let us first confirm that the
upper-tailed :math:`p`-value explored in the previous section agrees with this general description.
We will then define :math:`p`-values for the remaining test types accordingly.

A. :math:`p`-Value for an Upper-Tailed Hypothesis Test
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We translate the general description of :math:`p`-values 
to a mathematical expression for an upper-tailed hypothesis test:

.. math::
   p\text{-value} = P(\bar{X} \geq \bar{x} |H_0 \text{ is true}).

This setup aligns with the graphical illustrations in :numref:`pvalue-reject` and :numref:`pvalue-fail-to-reject`,
as well as the description in words. If it is believed that :math:`\mu` is less than
or equal to a value, the "unsual" case would always correspond to the larger side. Let us continue
to simplify the :math:`p`-value:

.. math::
   p\text{-value} &= P(\bar{X} \geq \bar{x} |H_0 \text{ is true})\\
   &=P\left(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \geq \frac{\bar{x}-\mu_0}{\sigma/\sqrt{n}} \Bigg|H_0 \text{ is true}\right)\\
   &=P(Z \geq z_{TS})

This can be computed in R using:

.. code-block:: r 

   zts <- (xbar - mu0)/(sigma/sqrt(n))
   pvalue <- pnorm(zts, lower.tail=FALSE)

B. :math:`p`-Value for a Lower-Tailed Hypothesis Test
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter10/pvalues-lower-tailed.png 
   :figwidth: 90%
   :align: center 
   :alt: p-values for lower-tailed hypothesis test

   **Upper**: :math:`p`-value when :math:`\bar{x}` is in the rejection region;
   **Lower**: :math:`p`-value when :math:`\bar{x}` is not small enough

In a lower-tailed hypothesis test where the baseline belief is that :math:`\mu` is greater than
or equal to a :math:`\mu_0`, the "unusual" is always toward the lower end. 


.. math::
   \text{p-value} &= P(\bar{X} \leq \bar{x}|H_0 \text{ is true})\\
   &=P\left(\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \leq \frac{\bar{x}-\mu_0}{\sigma/\sqrt{n}} \Bigg|H_0 \text{ is true}\right)\\
   &=P(Z \leq z_{TS})

.. code-block:: r 

   zts <- (xbar - mu0)/(sigma/sqrt(n))
   pvalue <- pnorm(zts)
   
C. :math:`p`-Value for a Two-Tailed Hypothesis Test
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter10/pvalues-two-tailed.png 
   :figwidth: 90%
   :align: center 
   :alt: p-values for lower-tailed hypothesis test

   **Upper**: :math:`p`-value when :math:`\bar{x}` is in the rejection region;
   **Lower**: :math:`p`-value when :math:`\bar{x}` is not far enough from :math:`\mu_0`
   
In a two-tailed hypothesis test, we must consider the "unusual" deviations on both sides. 
Therefore, we compute the area corresponding to **larger absolute deviations from** :math:`\mu_0`
**than the currently observed** :math:`|\bar{x}-\mu_0|`:

.. math::
   \text{p-value} = P(|\bar{X}-\mu_0|\geq |\bar{x}-\mu_0| \big| H_0 \text{ is true})

Dividing both sides of the inequality by the standard error :math:`\sigma/\sqrt{n}`,

.. math::
   \text{p-value} &= \left(\frac{|\bar{X}-\mu_0|}{\sigma/\sqrt{n}}\geq \frac{|\bar{x}-\mu_0|}{\sigma/\sqrt{n}} \Bigg| H_0 \text{ is true}
   \right)\\
   &= P(|Z| \geq |z_{TS}|)\\
   &= P(Z \leq -|z_{TS}| \text{ or } Z \geq |z_{TS}|) \\
   &=2P(Z \leq -|z_{TS}|) = 2P(Z \geq |z_{TS}|)\\

The final two steps are true due to the symmetry of the standard normal distribution around :math:`0`.
Either can be used for computation.

.. code-block:: r 

   abs_zts <- abs((xbar - mu0)/(sigma/sqrt(n)))
   pvalue <- 2 * pnorm(-abs_zts)

   #alternatively,
   pvalue <- 2 * pnorm(abs_zts, lower.tail=FALSE)

Making the Decision
~~~~~~~~~~~~~~~~~~~~

Once the :math:`p`-value is obtained, we compare it to the pre-specified significance level :math:`\alpha`.

- If :math:`p`-value :math:`< \alpha`, **reject** :math:`H_0`.
- If :math:`p`-value :math:`\geq \alpha`, **fail to reject** :math:`H_0`.

Why is the :math:`p`-Value Method Preferred?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :math:`p`-value method is generally preferred over the cutoff method for two main reasons. 

1. Its decision rule **does not depend on the test type**.
   A small :math:`p`-value always indicates evidence against the null hypothesis,
   whether the test is lower-tailed, upper-tailed, or two-tailed. 

2. More importantly, it **conveys the strength of the data evidence** 
   without referencing a fixed standard, :math:`\alpha`. 
   Whether :math:`\alpha=0.05` or :math:`\alpha=0.01`, 
   a :math:`p`-value of :math:`0.00001` universally implies a very strong evidence against the null, 
   while a :math:`p`-value of :math:`0.9` indicates little or no of evidence.

   Because a :math:`p`-value lies in :math:`[0,1]`, we also have a **more natural intuition 
   for its size**, compared with the test statistic :math:`z_{TS}`, which can in principle take any real value.

.. admonition:: Example 💡: Spiral Galaxy Diameters
   :class: note

   A theory predicts that spiral galaxies have an average diameter of 50,000
   light years. A research group wants to test whether local galaxies in a neighborhood of Milky Way are 
   larger than this overall average using :math:`\alpha = 0.01`.

   - The study has an SRS of 50 spiral galaxies from a catalog.
   - Their sample mean is :math:`\bar{x} = 51,600` light years.
   - The population standard deviation is known to be :math:`\sigma = 4,000` light years.
   - The data appears fairly symmetric and is free of outliers.

   **Step 0: Check Assumptions**

   The data does not have a strong deviation from normality and the sample is
   an SRS from the population, so the sample size of 50 is large enough for CLT to hold.
   Since the population standard deviation is known, our use of the :math:`z`-test procedure is justified.

   **Step 1: Define the Parameter**

   Let :math:`\mu` represent the true mean diameter of spiral galaxies in the chosen neighborhood
   of Milky Way.

   **Step 2: State the Hypothesis**

   - :math:`H_0: \mu \leq 50,000`
   - :math:`H_a: \mu > 50,000`

   **Step 3: Calculate the Observed Test Statistic and the P-Value**

   .. math::

      z_{TS} = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}} = \frac{51,600 - 50,000}{4,000/\sqrt{50}} = \frac{1,600}{565.685} = 2.828

   Since this is a right-tailed test,

   .. code-block:: r

      zts <- 2.828
      p_value <- pnorm(zts, lower.tail = FALSE)
      p_value
      # [1] 0.002339

   **Step 4: Make the Decision and State the Conclusion**

   Since :math:`p`-value :math:`=0.002339 < 0.01` we **reject** the null hypothesis.
   With the significance level :math:`\alpha=0.01`, 
   we have sufficient evidence that the true mean diameter of 
   spiral galaxies in this neighborhood is greater than 50,000 light years.

   🔎 See the Appendix at the end of this lession for additional practice on power
   and sample size computation in the same context.


.. admonition:: Example 💡: A Manufacturing Quality Control
   :class: note

   Bulls Eye Production manufactures precision components whose diameters 
   follow a normal distribution with mean 5mm and standard deviation 0.5mm.
   The company collects a random sample as part of their regular maintenance.
   If the sample provides evidence that the true mean diameter **differs** significantly from 5mm, 
   they must recaibrate the production equipment. From the previous round of the regular maintenance,
   the company obtained the following result:

   - **Sample size**: :math:`n = 64`
   - **Sample mean**: :math:`\bar{x} = 4.85` mm
   - **Population standard deviation**: :math:`\sigma = 0.5` mm
   - **Significance level**: :math:`\alpha = 0.01`

   **Step 0: Can We Use a** :math:`z`-**Test?**

   The population distribution is known to be normal, which guarantees that its sample mean will be
   normally distributed for any sample size. :math:`n=64` is large enough even if the population has
   moderate deviations from normal. Since the population standard deviation is also known,
   we have enough justification to use a :math:`z`-test procedure.

   **Step 1: Define the Parameter**

   Let us use :math:`\mu` to denote the true mean diamter of the components produced by the current
   production equipment. 

   **Step 2: State the Hypotheses**

   .. math::
      &H_0: \mu = 5\\
      &H_a: \mu \neq 5

   **Step 2: Calculate the Observed Test Statistic and the P-Value**

   .. math::

      Z_{TS} = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}} = \frac{4.85 - 5.0}{0.5/\sqrt{64}} = \frac{-0.15}{0.0625} = -2.4

   For a two-tailed test, we need the probability of observing a test statistic at least as extreme 
   as :math:`\pm 2.4`:

   .. code-block:: r

      z_test_stat <- -2.4
      p_value <- 2 * pnorm(abs(z_test_stat), lower.tail = FALSE)
      p_value
      # [1] 0.01639472

   **Step 4: Make the Decision and Write the Conclusion**

   - p-value :math:`= 0.0164`
   - :math:`\alpha = 0.01`  
   
   Since :math:`0.0164 > 0.01`, we **fail to reject** the null hypothesis. 
   At the 1% significance level, we do not have sufficient evidence to conclude that the population mean
   of component diameters is different than 5mm.

Bringing It All together
-------------------------------

.. admonition:: Key Takeaways 📝
   :class: important

   1. :math:`z`-**tests for population means** are used when the population standard deviation is known and
      the sampling distribution of the sample mean can be approximated with normal using the CLT.
   
   2. **The test statistic** :math:`Z_{TS} = \frac{\bar{X} - \mu_0}{\sigma/\sqrt{n}}` provides 
      standardized evidence against the null hypothesis.
   
   3. A :math:`p`-**value quantifies the strength of data evidence** by providing the probability 
      of observing more unusual results than the current one under the null hypothesis.
   
Exercises
~~~~~~~~~~~~~~~~~

1. **Pharmaceutical Testing**: A pharmaceutical company claims their new pain medication reduces recovery time from an 
   average of 7.2 days to less than that. In a clinical trial of 100 patients, the sample mean recovery time was 6.8 days. 
   Assuming :math:`\sigma = 1.5` days, test the company's claim at :math:`\alpha = 0.05`.

2. **Manufacturing**: A bottling company targets 12 oz per bottle. Quality control samples 36 bottles and finds 
   :math:`\bar{x} = 11.85` oz. With :math:`\sigma = 0.6` oz, test whether the process mean differs from target 
   at :math:`\alpha = 0.02`.

3. :math:`p`-**Value Interpretation**: A study reports a :math:`p`-value of 0.08 for testing 
   :math:`H_0: \mu = 100` versus :math:`H_a: \mu \neq 100`. 
   Write three different statements about what this :math:`p`-value means, avoiding common misinterpretations.



Appendix: Power Analysis for the Galaxy Study
-----------------------------------------------

.. admonition:: Example 💡: Compute Power for the Galaxy Study
   :class: note

   Suppose the researchers want to know their power to detect galaxies that are 2,000 light years larger on 
   average than the theory predicts (i.e., :math:`\mu_a = 52,000` light years).

   **Step 1: Find the Critical Cutoff Value**

   Under the null hypothesis, we reject :math:`H_0` when our test statistic exceeds :math:`z_{0.01} = 2.326`:

   .. code-block:: r

      z_alpha <- qnorm(0.01, lower.tail = FALSE)
      z_alpha
      # [1] 2.326348

   The corresponding cutoff value for :math:`\bar{x}` is:

   .. math::

      \bar{x}_{cutoff} = \mu_0 + z_{\alpha} \cdot \frac{\sigma}{\sqrt{n}} = 50,000 + 2.326 \times \frac{4,000}{\sqrt{50}} = 51,316

   **Step 2: Calculate Type II Error Probability**

   If the true mean is :math:`\mu_a = 52,000`, the Type II error is the probability that :math:`\bar{X} < 51,316`:

   .. code-block:: r

      # Type II error calculation
      beta <- pnorm(51316, mean = 52000, sd = 4000/sqrt(50), lower.tail = TRUE)
      beta
      # [1] 0.1132957

   **Step 3: Calculate Power**

   .. math::

      \text{Power} = 1 - \beta = 1 - 0.113 = 0.887

   **Interpretation**

   This study has about 88.7% power to detect a 2,000 light-year increase in galaxy diameter. This is quite good power—if galaxies in this region truly average 52,000 light years in diameter, there's about an 89% chance this study would detect that difference.

.. admonition:: Example 💡: Compute the Required Sample Size for the Galaxy Study
   :class: note

   **Planning for Higher Power**

   Suppose the researchers wanted 95% power to detect the same 2,000 light-year difference. What sample size would they need?

   **The Sample Size Formula**

   For a one-tailed z-test, the required sample size is:

   .. math::

      n = \left[\frac{(z_{\alpha} + z_{\beta}) \sigma}{\mu_0 - \mu_a}\right]^2

   Where:
   - :math:`z_{\alpha}` is the critical value for the significance level
   - :math:`z_{\beta}` is the critical value corresponding to the desired power
   - :math:`\sigma` is the population standard deviation
   - :math:`|\mu_0 - \mu_a|` is the effect size we want to detect

   **Step-by-Step Calculation**

   For 95% power, :math:`\beta = 0.05`:

   .. code-block:: r

      z_alpha <- qnorm(0.01, lower.tail = FALSE)  # 2.326
      z_beta <- qnorm(0.05, lower.tail = FALSE)   # 1.645
      sigma <- 4000
      effect_size <- abs(50000 - 52000)  # 2000
      
      n_required <- ((z_alpha + z_beta) * sigma / effect_size)^2
      n_required
      # [1] 63.08177

   Rounding up to the nearest integer: **n = 64**

   **Verification**

   We can verify this calculation by checking that n = 64 indeed gives us 95% power:

   .. code-block:: r

      # With n = 64, what's the power?
      std_error_new <- 4000 / sqrt(64)  # 500
      cutoff_new <- 50000 + 2.326 * 500  # 51163
      
      power_check <- 1 - pnorm(51163, mean = 52000, sd = 500)
      power_check
      # [1] 0.9505285

   Indeed, with n = 64, the power is approximately 95%.