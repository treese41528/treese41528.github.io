.. _10-3-ht-for-mean-sigma-unknown:


.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch10-3">
      <iframe
         id="video-ch10-3"
         title="STAT 350 ‚Äì Chapter 10.3 Hypothesis Test and Confidence Interval-Bound Video"
         src="https://www.youtube.com/embed/oVXZ-UAhrwQ?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

.. admonition:: Slides üìä
   :class: tip
   
   - `Hypothesis Testing for Single Sample (Part 3) (PPTX) <https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%2010%20Hypothesis%20Testing/Hypothesis%20Testing%20for%20Single%20Sample%20Part3_AC.pptx>`_


Connecting CI and HT; *t*-Test for Œº When œÉ Is Unknown
======================================================================================

**Hypothesis testing and confidence regions are complementary tools** that address essentially
the same question from two different perspectives. When certain conditions are carefully matched,
a confidence region and a hypothesis test yield outcomes that carry direct implications for
one another.

We also dicsuss how to extend our understanding of hypothesis testing to cases where **the population 
standard deviation is unknown**. 
As with confidence regions, we employ the :math:`t`-distribution to construct a testing procedure that accounts
for the added uncertainty.

.. admonition:: Road Map üß≠
   :class: important

   * Understand the underlying **connection between confidence regions and hypothesis testing**. For a
     given confidene region, identify its complementary hypothesis testing scenario, and vice versa.
   * Use the :math:`t`-**distribution** to construct hypothesis tests when the population standard 
     deviation :math:`\sigma` is unknown.

The Duality of Hypothesis Tests and Confidence Regions
---------------------------------------------------------

Two Perspectives on the Same Question
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We begin our discussion by comparing the key components of hypothesis testing and confidence regions:

.. flat-table::
   :header-rows: 1

   * - Inference Component
     - Confidence region for :math:`\mu`
     - Hypothesis testing on :math:`\mu`


   * - **Parameter of interest**
     - They both aim to understand a population mean, :math:`\mu`

   * - **Question**
     - "What parameter values are consistent with the sample?"
     - "Is this specific parameter value consistent with the sample?"

   * - **How inference strength is conveyed**
     - A large :math:`C`
     - A small :math:`\alpha` 

   * - **Sample information used**
     - :cspan:`1` Both use :math:`\bar{X}` and its approximate normality due to the CLT

   * - **Outcome**
     - A range of plausible values
     - Answer to whether a candidate value (:math:`\mu_0`) is plausible

It is evident from the summary above that confidence intervals and hypothesis tests 
address the **same fundamental question from different angles**. 

The mathematical connection becomes even deeper when the two inference methods are matched 
by their **inferential strengths and sidedness**. Under this pairing, 
the two methods are in fact **equivalent**: the result of one has direct implications for the result of the other.

Confidence Intervals and Two-sided Hypothesis Tests  
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Consider the :math:`C \cdot 100 \%` confidence interval for a population mean.
With :math:`\alpha=1-C`, we use the formula:

.. math:: 
   \left(\bar{x} - z_{\alpha/2} \frac{\sigma}{\sqrt{n}}, \bar{x} + z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\right).

Let us now perform a two-sided hypothesis test on a candidate
value :math:`\mu_0` using the significance level :math:`\alpha = 1-C`. The hypotheses are:

.. math::
   &H_0: \mu = \mu_0\\
   &H_a: \mu \neq \mu_0

Based on the cutoff method, we reject the null hypothesis if:

.. math:: 
   \bar{x} \geq z_{\alpha/2}\frac{\sigma}{\sqrt{n}} + \mu_0 \quad \text{ or }
   \quad \bar{x} \leq -z_{\alpha/2}\frac{\sigma}{\sqrt{n}} + \mu_0.

Isolate :math:`\mu_0` in both inequalities. Then the null hypothesis is rejected
when:

.. math:: 
   \bar{x} - z_{\alpha/2}\frac{\sigma}{\sqrt{n}} \geq \mu_0 \quad \text{ or }
   \quad \bar{x} + z_{\alpha/2}\frac{\sigma}{\sqrt{n}} \leq \mu_0.

Note that the **left-hand side of the inequalities are exactly the two ends of
the confidence interval**.

**The Connection**

The null hypothesis for a two-tailed test is **rejected** excatly when the null value
:math:`\mu_0` **is outside** a matching confidence interval. Conversely, if the chosen :math:`\mu_0` is **inside**
the confidence interval, we would **not reject** the null hypothesis for that test.

Lower Confidence Bounds and Upper-Tailed Tests  
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :math:`C\cdot 100 \%` lower confidence bound for the population mean :math:`\mu` is:

.. math::
   \left(\bar{x} - z_{\alpha} \frac{\sigma}{\sqrt{n}}, \quad \infty\right).

When performing an upper-tailed test:

.. math::
   &H_0: \mu \leq \mu_0\\
   &H_a: \mu > \mu_0,

we reject the null hypothesis if :math:`\bar{x} \geq z_\alpha\frac{\sigma}{\sqrt{n}} + \mu_0`.
By isolating :math:`\mu_0`, the inequality becomes:

.. math::
   \bar{x} - z_\alpha\frac{\sigma}{\sqrt{n}} \geq \mu_0.

**The Connection**

Given :math:`\alpha = 1-C`, 
the null hypothesis of an upper-tailed test is **rejected** if and only if 
the null value :math:`\mu_0` **fails to be inside the confidence region** defined by the lower bound.

Upper Confidence Bounds and Lower-Tailed Tests  
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :math:`C\cdot 100 \%` upper confidence bound for the population mean :math:`\mu` is:

.. math::
   \left(-\infty, \quad \bar{x} + z_{\alpha} \frac{\sigma}{\sqrt{n}} \right).

For a lower-tailed hypothesis test with

.. math::
   &H_0: \mu \geq \mu_0\\
   &H_a: \mu < \mu_0,

The null hypothesis is rejected if :math:`\bar{x} \leq -z_\alpha\frac{\sigma}{\sqrt{n}} + \mu_0`.
By isolating :math:`\mu_0`, the inequality becomes:

.. math::
   \bar{x} + z_\alpha\frac{\sigma}{\sqrt{n}} \leq \mu_0.

**The Connection**

As expected, the values of :math:`\mu_0` that lead to rejection of the null hypothesis in
a lower-tailed test coincide with those that fall **outside** the upper confidence bound
of a matching confidence level, :math:`C= 1-\alpha`.

Summary
~~~~~~~~~

For the duality to work, we need three crucial conditions:

1. The two inference methods are being applied to the same experimental result. 
2. :math:`C + \alpha = 1`.
3. The methods are paired corrrectly based on sidedness (two-sided test and CI, upper-tailed test and 
   LCB, lower-tailed test and UCB).

When these conditions hold,

- :math:`\mu_0` lies **inside** the confidence region :math:`\iff` **fail to reject** :math:`H_0`
- :math:`\mu_0` lies **outside** the confidence region :math:`\iff` **reject** :math:`H_0`

.. admonition:: Example üí°: Quality Control for Cherry Tomatoes
   :class: note

   Tom Green oversees quality control for a large produce company. 
   The weights of cherry tomato packages are known to be
   normally distributed with  :math:`\mu=227g` (1/2 lbs) and :math:`\sigma=5g`.
   He obtains a simple random sample of four packages of cherry tomatoes and discovers that
   their average weight is 222g. 
   

   1. Construct a 95% confidence interval for the mean weight.
   2. Tom would like to test whether the true mean weight of the packages is different from 227g
      with :math:`\alpha = 0.05`. Based on the result of #1, (do not compute the test statistic or the 
      :math:`p`-value), predict wether the null hypothesis will be rejected.
   3. Perform the hypothesis test and confirm your answer from part 2.

   **Q1: Construct the 95% Confidence Interval**

   Since :math:`\sigma` is known and the data is normally distributed, we use the :math:`z`-procedure. 
   In general,

   .. math::

      \left(\bar{x} - z_{\alpha/2} \frac{\sigma}{\sqrt{n}}, 
      \bar{x} + z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\right).

   For 95% confidence, :math:`\alpha = 0.05`. The critical value :math:`z_{0.025}` can be found using:

   .. code-block:: r

      z_critical <- qnorm(0.025, lower.tail = FALSE)
      z_critical
      # [1] 1.959964

   Calculate the interval:

   .. math::

      \left(222 - (1.96)\frac{5}{\sqrt{4}}, 222 + (1.96) \frac{5}{\sqrt{4}}\right) = (217.1, 226.9)

   We are 95% confident that the true mean weight of cherry tomato packages
   is captured between 217.1 and 226.9 grams.

   **Q2: Use Duality to Predict the Conlusion for the Hypothesis Test**

   We want to test:

   .. math::
      &H_0: \mu = 227\\
      &H_a: \mu \neq 227

   Since we have :math:`C + \alpha = 0.95 + 0.05 = 1`, and both the confidence region and the hypothesis test
   are two-sided, the duality relationship applies.
   The null value :math:`\mu_0 = 227` lies **outside** the 95% confidence interval :math:`(217.1, 226.9)`.
   Therefore, we would **reject** the null hypothesis if we performed the hypothesis test. 
   :math:`\mu_0 = 227` is NOT a plausaible value for the true mean weight according to the CI, so
   we should be able to draw the same conclusion from the dual hypothesis test.

   **Q3: Verify with Formal Hypothesis Test**

   Let's confirm this conclusion by performing a z-test for the hypothesis pair.

   .. math::

      z_{TS} = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}} = \frac{222 - 227}{5/\sqrt{4}} = \frac{-5}{2.5} = -2.0

   The p-value is:

   .. code-block:: r

      z_test_stat <- -2.0
      p_value <- 2 * pnorm(abs(z_test_stat), lower.tail = FALSE)
      p_value
      # [1] 0.04550026

   Since p-value = :math:`0.0455 < \alpha = 0.05`, we **reject** the null hypothesis.
   Both approaches give the same conclusion. This confirms the duality relationship.

:math:`t`-Tests: When œÉ is Unknown
---------------------------------------------------------

.. raw:: html

   <div class="video-placeholder" role="group" aria-labelledby="video-ch10-3-1">
      <iframe
         id="video-ch10-3-1"
         title="STAT 350 ‚Äì Chapter 10.3.1 Test Statistic when œÉ is Unknown Video"
         src="https://www.youtube.com/embed/Qf1OChGzcQE?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
         allowfullscreen>
      </iframe>
   </div>

So far, we have been building our test procedures based on the convenient assumption
that the population standard deviation is known. If we do not know the population 
mean :math:`\mu`, however, we almost certainly do not know :math:`\sigma`, either.

In such cases, we will take the natural step of replacing the unknown 
:math:`\sigma` with the estimator, :math:`S`. The sample standard deviation :math:`S` 
is itself a random variable that varies from sample to sample, and this extra variability must be accounted for.

The Assumptions
~~~~~~~~~~~~~~~~~

For the new test procedure, we use a slightly modified set of assumtions:

1. :math:`X_1, X_2, \cdots, X_n` form an *iid* sample from
   the population :math:`X` with mean :math:`\mu` and variance :math:`\sigma^2`.
2. Either the population :math:`X` is normally distributed, or the sample size :math:`n` is
   sufficiently large for the CLT to hold.
3. The population variance :math:`\sigma^2` is **unknown**.

The only difference is that the population variance (and sd) is unknown. 

The :math:`t`-Test Statistic 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Recall that when :math:`\sigma` was known, the :math:`z`-test statistic

.. math:: Z_{TS} = \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}

played a key role. We used it to

* measure the standardized discrepancy of the data from the null assumption,
* compare it with a :math:`z`-critical value and draw a conclusion using the cutoff method, and
* compute the tail probabiltiy of the observed :math:`z_{TS}` and draw a conclusion in the
  :math:`p`-value method.

We obtain a new test statistic by
replacing the ununknown :math:`\sigma` with the sample standard deviation, :math:`S:`

.. math::

   T_{TS} = \frac{\bar{X} - \mu_0}{S/\sqrt{n}}

This new test stastistic is called the :math:`t`-**test statistic**. When the null hypothesis holds,
the :math:`t`-test statistic has a :math:`t`-distribution with the degrees of freedom :math:`\nu= n-1`.

The :math:`t`-test statistic plays the same roles as the :math:`z`-test statistic, but
we must account for **the change in distribution** by referencing the appropriate *t*-distribution
rather than standard normal when computing critical values and :math:`p`-values.

Cutoff Method for :math:`t`-Tests
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Recall that the cutoff method rejects the null hypothesis if
the observed test statistic falls in a region that is too unusual for the null hypothesis.

For an upper-tailed :math:`t`-test, the null hypothesis would be rejected if the observed sample mean
is much higher than the null value :math:`\mu_0` and satisfies:

   .. math::
      t_{TS} = \frac{\bar{x}-\mu_0}{s/\sqrt{n}} > t_{\alpha, n-1},

where :math:`t_{\alpha, n-1}` is the appropriate :math:`t`-critical value.

Likewise, the rejection rule for a lower-tailed test is:

   .. math::
      t_{TS} = \frac{\bar{x}-\mu_0}{s/\sqrt{n}} < -t_{\alpha, n-1}.

Finally, for a two-tailed test,

   .. math::
      |t_{TS}| = \left|\frac{\bar{x}-\mu_0}{s/\sqrt{n}}\right| > t_{\alpha/2, n-1}.

:math:`p`-Values for :math:`t`-Tests
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. flat-table::
   :header-rows: 1
   :widths: 15 10 50

   * - :cspan:`2` :math:`p`-Values for :math:`t`-Tests

   * - **Upper-tailed p-value**
     - .. math:: 
         P(T_{n-1} \geq t_{TS})
      
       .. code-block:: r
         
         tts <- (xbar-mu0)/(s/sqrt(n))
         pt(tts, df=n-1, lower.tail=FALSE)

   * - **Lower-tailed p-value**
     - .. math:: 
          P(T_{n-1} \leq t_{TS})
      
       .. code-block:: r

         pt(tts, df=n-1) 

   * - **Two-tailed p-value**
     - .. math::
          2P(T_{n-1} \leq -|t_{TS}|) \quad \text{ or } \quad 2P(T_{n-1} \geq |t_{TS}|)
      
       .. code-block:: r
          
          2 * pt(-abs(tts), df=n-1)
          2 * pt(abs(tts), df=n-1, lower.tail=FALSE)

The Rejection Rule Remains Unchanged
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Once a :math:`p`-value is computed, it is compared against a pre-specified significance level
:math:`\alpha`. If the :math:`p`-value is less than :math:`\alpha`, the null hypothesis is rejected.

.. admonition:: Example üí°: Radon Detector Accuracy
   :class: note
   
   University researchers want to find out whether their radon detectors are working correctly.
   Thy collected a random sample of 12 detectors and placed them in a chamber exposed to exactly 105
   picocuries per liter of radon. If the detectors work properly, their measurements should be close
   to 105, on average.

   .. flat-table::
      :header-rows: 1

      * - :cspan:`5` The Measurements (in picocuries per liter)

      * - 91.9
        - 97.8
        - 111.4
        - 122.3
        - 105.4
        - 95.0
      
      * - 103.8
        - 99.6
        - 119.3
        - 104.8
        - 101.7
        - 96.6

   In addition, suppose that the population distribution is known to be normal. Perform a
   hypothesis test with the significance level :math:`\alpha=0.1`.

   **Step 0: Which Procedure?**

   The experiment uses a random sample from a normally distributed population. Therefore,
   we are justified to use an inference method which assumes approximate normality of the
   sample mean. We use the :math:`t`-test procedure since the population
   standard deviation is unknown.

   **Step 1: Define the Parameter**

   Let :math:`\mu` denote the true mean of the measurements produced by the detectors
   in a chamber with exactly 105 picocuries per liter of radon.

   **Step 2: State the Hypotheses**

   .. math::
      &H_0: \mu = 105\\
      &H_a: \mu \neq 105

   **Step 3: Calculate the Observed Test Statistic and the p-value**

   Comonents:

   * :math:`n=12`
   * :math:`\bar{x}=104.1333`
   * :math:`s = 9.397421`
   * :math:`df = n-1 = 11`

   The sample mean and the sample standard deviation can be computed from the data set.

   .. math::

      t_{TS} = \frac{\bar{x} - \mu_0}{s/\sqrt{n}} = \frac{104.1333 - 105}{9.397421/\sqrt{12}} = \frac{-0.8667}{2.7136} = -0.319

   The :math:`p`-value is computed using R:

   .. code-block:: r

      p_value <- 2 * pt(abs(t_test_stat), df = 11, lower.tail = FALSE)
      p_value
      # [1] 0.755

   **Step 4: Make the Decision and Write the Conclusion**

   Since :math:`p`-value :math:`= 0.755 > \alpha = 0.10`, we **fail to reject** the null hypothesis.
   With the significance level :math:`\alpha=0.1`, we do not have enough evidence to
   reject the null hypothesis that the true mean measurent is 105 picocuries per liter.

   ü§î **Why Such a Large P-Value?**

   Although the individual measurements in the data set seem quite inaccurate, 
   we failed to reject the null hypothesis with a large :math:`p`-value of :math:`0.755`.
   Several factors contribute:

   1. The sample mean (:math:`\bar{x} = 104.1`) is very close to null value (:math:`\mu_0 = 105.0`).
   2. The sample size of 12 is small and limits precision.  
   3. The sample standard deviation (:math:`s=9.4`) is relatively large.
   4. We are performing a two-sided test, which makes the rejection region farther toward the tails
      than a one-sided test.

   This example illustrates why, in hypothesis testing, we say we "fail to reject"
   rather than "accept" the null hypothesis. The absence of evidence against the null does not
   necessarily constitute evidence in its favor.
   
   When there is a large degree of uncertainty, hypothesis tests tend to grow more
   **conservative**, which means that it will require the evidence to be stronger
   for a rejection of the null.

Duality Revisited for :math:`t`-Procedures
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The duality relationship established for :math:`z`-procedures carries over directly to 
:math:`t`-procedures. A confidence region and a hypothesis test based on :math:`t`-distributions
are equivalent if:

1. The two inference methods are being applied to the same experimental result. 
2. :math:`C + \alpha = 1`.
3. The methods are paired corrrectly based on sidedness (two-sided test and CI, upper-tailed test and 
   LCB, lower-tailed test and UCB).

.. admonition:: Example üí°: Complementary CI for Radon Detector Accuracy

   Compute the 90% confidence interval for the Radon Detector experiment and
   comment on its consistency with the hypothesis test.

   A :math:`t`-confidence interval is, in general,

   .. math::

      \left(\bar{x} - t_{\alpha/2, n-1}\frac{s}{\sqrt{n}},
      \quad \bar{x} + t_{\alpha/2, n-1}\frac{s}{\sqrt{n}}\right).

   From the previous example, we have:

   * :math:`\bar{x} =104.1333`
   * :math:`s = 9.397421`
   * :math:`n = 12`

   The t-critical value :math:`t_{\alpha/2, n-1}` is computed using R:

   .. code-block:: r

      alpha <- 0.10
      t_critical <- qt(alpha/2, df = 11, lower.tail = FALSE)
      t_critical
      # [1] 1.795885

   Substituting the values to the general formula,
   the 90% confidence interval is:
   
   .. math:: (99.3, 109.0). 

   Since :math:`\mu_0 = 105` lies **within** this interval, 
   the duality principle tells us we should fail to reject :math:`H_0`,
   which matches our hypothesis test conclusion.


   **Single-call Verification Using t.test**

   When the raw data set is available, the R command ``t.test`` produces
   both inference results simultaneously.

   .. code-block:: r

      radon <- c(91.9, 97.8, 111.4, 122.3, 105.4,
           95.0, 103.8, 99.6, 119.3, 104.8, 101.7, 96.6)

      t.test(radon,
             mu = 105,
             alternative = "two.sided",
             conf.level=0.9)
      
      #output
      '''
      One Sample t-test

      data:  radon
      
      t = -0.31947, df = 11, p-value = 0.7554
      alternative hypothesis: true mean is not equal to 105
      
      90 percent confidence interval:
      99.26145 109.00521
      
      sample estimates:
      mean of x 
      104.1333 
      '''


   The :math:`t`-statistic, :math:`p`-value, and confidence interval match the hand
   calculations‚Äîalways a good final check.

   
:math:`t`-Procedures vs. :math:`z`-Procedures
----------------------------------------------------------

We learned in Chapter 9.5.4 that for any given significance level, 
the :math:`t`-**critical value decreases as** :math:`n` **(and therefore the df) increases**.
This also meant that 

.. math:: 
   t_{\alpha, n-1} > z_\alpha

for any finite :math:`n`, since the standard normal distribution
can be viewed as a :math:`t`-distribution with "infinite" degrees of freedom.
As a result, :math:`t`-**based confidence regions were wider on average than** :math:`z`-**based regions**. 

In hypothesis tests, if the observed test statistic is held constant, its **p-value** is larger in a
:math:`t`-test than in a :math:`z`-test because the tails of a :math:`t`-distribution are **heavier** than 
those of the standard normal. This makes it more difficult for a :math:`t`-test to reject the null hypothesis.

The trend is consistent: in the presence of added uncertainty,
both inference methods become more **conservative**‚Äîmore cautious in labeling an experimental result as
unusual. The confidence region widens, and the test becomes more reluctant to
reject the status quo.

..
   When Assumptions Are Violated
   -----------------------------------

   *t*-procedures assume that the sample mean has a normal distribution. While T-tests are reasonably robust to 
   moderate departures from normality, serious violations can be problematic, especially with small samples.
   Always use graphical and/or numerical measures to check assumptions. If any serious violations are
   observed, consider the following alternative approaches:

   1. Data transformation(e.g., log transformation for right-skewed data)
   2. Non-parametric methods (e.g., Wilcoxon signed-rank test)
   3. Bootstrap methods for empirical sampling distributions
   4. Exact distributional methods when the true distribution is known


Bringing It All Together
-----------------------------

.. admonition:: Key Takeaways üìù
   :class: important

   1. **Hypothesis tests and confidence regions are dual procedures** that address the same questions 
      from different perspectives, connected by the relationship :math:`C + \alpha = 1`. Further,
      
      * Two-sided hypothesis tests pair with confidence intervals.
      * Upper-tailed tests pair with lower confidence bounds.
      * Lower-tailed tests pair with upper confidence bounds.
   
   2. When the population standard deviation :math:`\sigma` is unknown, :math:`t`-**tests** are used instead 
      of :math:`z`-tests.

   3. :math:`t`-procedures generally produce more **conservative** inference results than the corresponding
      :math:`z`-procedure; the confidence regions are wider, and it is more difficult to reject the null hypothesis.
   
Exercises
---------

.. admonition:: Exercise 1: T vs Z Critical Values
   :class: note

   Compare t-critical values to z-critical values for a two-tailed test at Œ± = 0.05.

   a. Find :math:`z_{0.025}` (standard normal).

   b. Find :math:`t_{0.025, df}` for df = 5, 10, 20, 30, 100.

   c. Create a table comparing these values.

   d. What pattern do you observe as df increases?

   e. Explain why t-critical values are larger than z-critical values.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Z-critical value**

      :math:`z_{0.025} = 1.960`

      **Parts (b) and (c): T-critical values and comparison**

      .. list-table::
         :header-rows: 1

         * - df
           - :math:`t_{0.025, df}`
           - Difference from z
         * - 5
           - 2.571
           - +0.611
         * - 10
           - 2.228
           - +0.268
         * - 20
           - 2.086
           - +0.126
         * - 30
           - 2.042
           - +0.082
         * - 100
           - 1.984
           - +0.024
         * - ‚àû (z)
           - 1.960
           - 0

      **Part (d): Pattern**

      As df increases, t-critical values **decrease** and approach the z-critical value. By df = 30, the difference is small (~0.08). By df = 100, they're nearly identical.

      **Part (e): Why t > z**

      .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch10-3/fig7_t_vs_z.png
         :align: center
         :width: 85%
         :alt: T-distribution vs standard normal

         The t-distribution has heavier tails than the standard normal, especially with low df.

      T-critical values are larger because the t-distribution has **heavier tails** than the standard normal. This reflects the additional uncertainty from estimating œÉ with s‚Äîwe "pay a penalty" for not knowing the true œÉ. More probability mass in the tails means we must go further from the center to capture the same probability.

      .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch10-3/fig8_t_crit_vs_df.png
         :align: center
         :width: 80%
         :alt: T-critical values approach z as df increases

         As df ‚Üí ‚àû, t-critical values converge to z-critical values.

      **R verification:**

      .. code-block:: r

         qnorm(0.025, lower.tail = FALSE)  # 1.960
         qt(0.025, df = 5, lower.tail = FALSE)   # 2.571
         qt(0.025, df = 10, lower.tail = FALSE)  # 2.228
         qt(0.025, df = 20, lower.tail = FALSE)  # 2.086
         qt(0.025, df = 30, lower.tail = FALSE)  # 2.042
         qt(0.025, df = 100, lower.tail = FALSE) # 1.984

----

.. admonition:: Exercise 2: Computing T-Test Statistics
   :class: note

   Calculate the t-test statistic and state the degrees of freedom for each scenario.

   a. :math:`\bar{x} = 24.5`, :math:`\mu_0 = 22`, :math:`s = 5.2`, :math:`n = 16`

   b. :math:`\bar{x} = 98.3`, :math:`\mu_0 = 100`, :math:`s = 4.1`, :math:`n = 12`

   c. :math:`\bar{x} = 515`, :math:`\mu_0 = 500`, :math:`s = 45`, :math:`n = 25`

   .. dropdown:: Solution
      :class-container: sd-border-success

      Formula: :math:`t_{TS} = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}`, df = n - 1

      **Part (a):**

      .. math::
         t_{TS} = \frac{24.5 - 22}{5.2 / \sqrt{16}} = \frac{2.5}{1.3} = 1.923

      df = 16 - 1 = **15**

      **Part (b):**

      .. math::
         t_{TS} = \frac{98.3 - 100}{4.1 / \sqrt{12}} = \frac{-1.7}{1.184} = -1.436

      df = 12 - 1 = **11**

      **Part (c):**

      .. math::
         t_{TS} = \frac{515 - 500}{45 / \sqrt{25}} = \frac{15}{9} = 1.667

      df = 25 - 1 = **24**

----

.. admonition:: Exercise 3: P-values with T-Distribution
   :class: note

   Calculate p-values for each scenario from Exercise 2.

   a. Part (a) data: Upper-tailed test (H‚Çê: Œº > 22)

   b. Part (b) data: Two-tailed test (H‚Çê: Œº ‚â† 100)

   c. Part (c) data: Upper-tailed test (H‚Çê: Œº > 500)

   d. Compare these p-values to what you would get using z-distribution. Which are larger?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): t = 1.923, df = 15, upper-tailed**

      .. math::
         p\text{-value} = P(T_{15} > 1.923) = 0.0369

      **Part (b): t = -1.436, df = 11, two-tailed**

      .. math::
         p\text{-value} = 2 \times P(T_{11} > 1.436) = 2 \times 0.0894 = 0.1788

      **Part (c): t = 1.667, df = 24, upper-tailed**

      .. math::
         p\text{-value} = P(T_{24} > 1.667) = 0.0543

      **Part (d): Comparison with z-distribution**

      Using z instead of t:

      - (a) P(Z > 1.923) = 0.0272 (t gives 0.0369)
      - (b) 2 √ó P(Z > 1.436) = 0.151 (t gives 0.179)
      - (c) P(Z > 1.667) = 0.0478 (t gives 0.0543)

      **T-distribution p-values are always larger** because the t-distribution has heavier tails. This makes it harder to reject H‚ÇÄ with a t-test, appropriately accounting for the uncertainty in estimating œÉ.

      **R verification:**

      .. code-block:: r

         # T-distribution p-values
         pt(1.923, df = 15, lower.tail = FALSE)     # 0.0369
         2 * pt(abs(-1.436), df = 11, lower.tail = FALSE)  # 0.1788
         pt(1.667, df = 24, lower.tail = FALSE)     # 0.0543
         
         # Z-distribution p-values (for comparison)
         pnorm(1.923, lower.tail = FALSE)  # 0.0272

----



.. admonition:: Exercise 4: Checking Assumptions Before a T-Test
   :class: note

   Before conducting a one-sample t-test, we must verify that key assumptions are satisfied. The validity of our inference depends on these assumptions being reasonably met.

   A biomedical engineer measures the response time (ms) of a neural signal processing chip for n = 15 test signals:

   .. code-block:: text

      12.4, 14.2, 11.8, 15.1, 13.5, 12.9, 14.7, 11.2, 13.8, 12.1,
      14.5, 13.2, 15.8, 12.6, 13.9

   The manufacturer claims the chip has a mean response time of 12.0 ms. Before testing this claim, assess whether the assumptions are satisfied.

   **Diagnostic Plots:**

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch10-3/fig10_assumption_hist.png
      :alt: Histogram of chip response times
      :align: center
      :width: 80%

      Histogram with kernel density (red) and normal overlay (blue)

   .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch10-3/fig11_assumption_qq.png
      :alt: QQ-plot of chip response times
      :align: center
      :width: 70%

      Normal Q-Q plot

   a. What are the assumptions required for a valid one-sample t-test?

   b. Based on the histogram, does the data appear approximately normal? Comment on symmetry and shape.

   c. Based on the QQ-plot, does the normality assumption appear satisfied? Explain what to look for.

   d. If normality were severely violated and n remained at 15, what would you recommend?

   e. If the sample size were n = 50, would the normality check be as critical? Explain using the Central Limit Theorem.

   f. Assuming the assumptions are satisfied, conduct the hypothesis test at Œ± = 0.05 using the complete four-step framework.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Assumptions for one-sample t-test**

      1. **Random sampling / Independence**: The observations must be independent and randomly selected from the population.

      2. **Normality**: The population from which the sample is drawn should be approximately normally distributed, OR the sample size should be large enough (n ‚â• 30) for the Central Limit Theorem to apply.

      **Part (b): Histogram assessment**

      The histogram shows:
      
      - **Shape**: Approximately symmetric and unimodal
      - **Center**: The distribution is centered around 13-14 ms
      - **Spread**: Reasonable spread without extreme outliers
      - **Comparison to normal**: The kernel density (red) and normal overlay (blue) track each other reasonably well
      
      **Assessment**: The histogram supports approximate normality ‚úì

      **Part (c): QQ-plot assessment**

      In a QQ-plot, we look for:
      
      - Points falling approximately along the reference line
      - No systematic curvature (S-shape suggests skewness, U-shape suggests heavy tails)
      - No extreme departures in the tails
      
      The QQ-plot shows points closely following the reference line with minor random deviations expected for n = 15. There is no systematic pattern suggesting departure from normality.
      
      **Assessment**: The QQ-plot supports approximate normality ‚úì

      **Part (d): If normality were severely violated**

      With n = 15 (small sample) and severe non-normality, options include:
      
      1. **Transform the data** (e.g., log transformation if right-skewed)
      2. **Use a nonparametric test** such as the Wilcoxon signed-rank test (beyond STAT 350 scope)
      3. **Increase sample size** to invoke the CLT
      4. **Report cautiously** that results may not be reliable
      
      Do NOT proceed with the t-test if assumptions are severely violated.

      **Part (e): Effect of larger sample size (CLT)**

      With n = 50, the normality check becomes **less critical** because:
      
      - The **Central Limit Theorem** states that for sufficiently large n, the sampling distribution of xÃÑ is approximately normal regardless of the population distribution
      - The general guideline is n ‚â• 30, though this depends on the severity of non-normality
      - With n = 50, we can be confident the sampling distribution of xÃÑ is approximately normal even if the underlying data shows moderate skewness or non-normality
      
      **Key insight**: The normality assumption is about the sampling distribution of xÃÑ, not the raw data. Large samples ensure xÃÑ is approximately normal via CLT.

      **Part (f): Complete hypothesis test**

      First, calculate summary statistics:

      .. code-block:: r

         times <- c(12.4, 14.2, 11.8, 15.1, 13.5, 12.9, 14.7, 11.2, 13.8, 12.1,
                    14.5, 13.2, 15.8, 12.6, 13.9)
         n <- length(times)   # 15
         xbar <- mean(times)  # 13.447
         s <- sd(times)       # 1.278

      **Step 1: Define the parameter**

      Let Œº = true mean response time (ms) of the neural signal processing chip.

      **Step 2: State the hypotheses**

      .. math::
         H_0: \mu = 12.0 \quad \text{vs} \quad H_a: \mu \neq 12.0

      *In words*: H<sub>0</sub> states the mean response time equals the claimed 12.0 ms. H‚Çê states the mean response time differs from 12.0 ms.

      **Step 3: Check assumptions and calculate test statistic**

      *Assumption checks:*
      
      - **Independence**: Assumed satisfied by the experimental design (separate test signals)
      - **Normality**: With n = 15 (< 30), normality must be verified. The histogram and QQ-plot both support approximate normality ‚úì

      *Test statistic:*

      .. math::
         t_{TS} = \frac{\bar{x} - \mu_0}{s / \sqrt{n}} = \frac{13.447 - 12.0}{1.278 / \sqrt{15}} = \frac{1.447}{0.330} = 4.385

      Degrees of freedom: df = n - 1 = 14

      *P-value (two-tailed):*

      .. math::
         p\text{-value} = 2 \times P(T_{14} > 4.385) = 0.00063

      **Step 4: Decision and Conclusion**

      Since p-value = 0.00063 < Œ± = 0.05, **reject H<sub>0</sub>**.

      **Conclusion**: At the 0.05 significance level, there is sufficient evidence to conclude that the true mean response time of the chip differs from the manufacturer's claim of 12.0 ms (p < 0.001). The sample mean of 13.45 ms suggests the chip is actually slower than claimed.

      **R verification:**

      .. code-block:: r

         times <- c(12.4, 14.2, 11.8, 15.1, 13.5, 12.9, 14.7, 11.2, 13.8, 12.1,
                    14.5, 13.2, 15.8, 12.6, 13.9)
         
         # Verify summary statistics
         mean(times)  # 13.447
         sd(times)    # 1.278
         
         # Conduct t-test
         t.test(times, mu = 12, alternative = "two.sided")
         
         # Output confirms:
         # t = 4.385, df = 14, p-value = 0.000628
         # 95% CI: (12.74, 14.16)

----



.. admonition:: Exercise 5: Complete T-Test (Upper-tailed)
   :class: note

   A battery manufacturer claims their new batteries last more than 20 hours on average. A consumer group tests n = 16 batteries and finds :math:`\bar{x} = 22.1` hours with s = 4.2 hours. Test the manufacturer's claim at Œ± = 0.05.

   Perform a complete hypothesis test using the four-step framework.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Step 1: Define the Parameter**

      Let Œº = true mean battery life (hours).

      **Step 2: State the Hypotheses**

      .. math::
         H_0: \mu \leq 20 \quad \text{vs} \quad H_a: \mu > 20

      **Step 3: Calculate Test Statistic and P-value**

      Since œÉ is unknown, use t-test.

      .. math::
         t_{TS} = \frac{22.1 - 20}{4.2 / \sqrt{16}} = \frac{2.1}{1.05} = 2.00

      df = 16 - 1 = 15

      P-value (upper-tailed):

      .. math::
         p\text{-value} = P(T_{15} > 2.00) = 0.0320

      **Step 4: Decision and Conclusion**

      Since p-value = 0.0320 < Œ± = 0.05, **reject H‚ÇÄ**.

      **Conclusion**: The data does give support (p-value = 0.032) to the claim that the mean battery life exceeds 20 hours.

      **R verification:**

      .. code-block:: r

         xbar <- 22.1; mu_0 <- 20; s <- 4.2; n <- 16
         t_ts <- (xbar - mu_0) / (s / sqrt(n))  # 2.00
         df <- n - 1  # 15
         p_value <- pt(t_ts, df, lower.tail = FALSE)  # 0.0320

----

.. admonition:: Exercise 6: Complete T-Test (Two-tailed)
   :class: note

   A calibration standard has a target value of 100 units. A technician measures n = 12 samples and obtains :math:`\bar{x} = 98.3` units with s = 4.1 units. Test whether the instrument is properly calibrated at Œ± = 0.10.

   Perform a complete hypothesis test using the four-step framework.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Step 1: Define the Parameter**

      Let Œº = true mean measurement from the calibration standard (units).

      **Step 2: State the Hypotheses**

      Testing if mean differs from target:

      .. math::
         H_0: \mu = 100 \quad \text{vs} \quad H_a: \mu \neq 100

      **Step 3: Calculate Test Statistic and P-value**

      .. math::
         t_{TS} = \frac{98.3 - 100}{4.1 / \sqrt{12}} = \frac{-1.7}{1.184} = -1.436

      df = 12 - 1 = 11

      P-value (two-tailed):

      .. math::
         p\text{-value} = 2 \times P(T_{11} > 1.436) = 0.1788

      **Step 4: Decision and Conclusion**

      Since p-value = 0.1788 > Œ± = 0.10, **fail to reject H‚ÇÄ**.

      **Conclusion**: The data does not give support (p-value = 0.179) to the claim that the mean measurement differs from the target value of 100 units. The instrument appears to be properly calibrated.

      **R verification:**

      .. code-block:: r

         xbar <- 98.3; mu_0 <- 100; s <- 4.1; n <- 12
         t_ts <- (xbar - mu_0) / (s / sqrt(n))  # -1.436
         df <- n - 1  # 11
         p_value <- 2 * pt(abs(t_ts), df, lower.tail = FALSE)  # 0.1788

----

.. admonition:: Exercise 7: Duality - From CI to Hypothesis Test
   :class: note

   A researcher calculates a 95% confidence interval for Œº and obtains (23.5, 28.7).

   a. Without performing any calculations, predict the result of testing H‚ÇÄ: Œº = 25 vs H‚Çê: Œº ‚â† 25 at Œ± = 0.05.

   b. Predict the result of testing H‚ÇÄ: Œº = 30 vs H‚Çê: Œº ‚â† 30 at Œ± = 0.05.

   c. Predict the result of testing H‚ÇÄ: Œº = 23 vs H‚Çê: Œº ‚â† 23 at Œ± = 0.05.

   d. Explain the duality principle you used to make these predictions.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Testing H‚ÇÄ: Œº = 25**

      Œº‚ÇÄ = 25 is **inside** the 95% CI (23.5, 28.7).

      By duality: **Fail to reject H‚ÇÄ** at Œ± = 0.05.

      **Part (b): Testing H‚ÇÄ: Œº = 30**

      Œº‚ÇÄ = 30 is **outside** the 95% CI (23.5, 28.7).

      By duality: **Reject H‚ÇÄ** at Œ± = 0.05.

      **Part (c): Testing H‚ÇÄ: Œº = 23**

      Œº‚ÇÄ = 23 is **outside** the 95% CI (23.5, 28.7).

      By duality: **Reject H‚ÇÄ** at Œ± = 0.05.

      **Part (d): Duality Principle**

      .. figure:: https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch10-3/fig9_ci_ht_duality.png
         :align: center
         :width: 85%
         :alt: CI-HT duality visualization

         Values inside the CI lead to non-rejection; values outside lead to rejection.

      For a two-sided hypothesis test and confidence interval with matching confidence/significance levels (C + Œ± = 1):

      - If Œº‚ÇÄ is **inside** the CI ‚Üí **Fail to reject** H‚ÇÄ
      - If Œº‚ÇÄ is **outside** the CI ‚Üí **Reject** H‚ÇÄ

      This works because both procedures use the same information and criteria. The CI contains all values of Œº that would not be rejected by the corresponding test.

----

.. admonition:: Exercise 8: Duality - From Hypothesis Test to CI
   :class: note

   A researcher conducts a two-sided t-test at Œ± = 0.05 with:
   
   - n = 25
   - :math:`\bar{x} = 48.2`
   - s = 6.5
   - Œº‚ÇÄ = 45
   
   The test yields t_TS = 2.462 and p-value = 0.0213, leading to rejection of H‚ÇÄ.

   a. Construct the corresponding 95% confidence interval.

   b. Verify that Œº‚ÇÄ = 45 is outside this CI.

   c. What would be the result of testing H‚ÇÄ: Œº = 47 at Œ± = 0.05?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): 95% Confidence Interval**

      df = 25 - 1 = 24

      :math:`t_{0.025, 24} = 2.064`

      .. math::
         SE = \frac{s}{\sqrt{n}} = \frac{6.5}{\sqrt{25}} = 1.3

      .. math::
         CI: \bar{x} \pm t_{0.025, 24} \times SE = 48.2 \pm 2.064 \times 1.3

      .. math::
         = 48.2 \pm 2.68 = (45.52, 50.88)

      **Part (b): Verification**

      Œº‚ÇÄ = 45 is **outside** the CI (45.52, 50.88). ‚úì

      This is consistent with rejecting H‚ÇÄ: Œº = 45 at Œ± = 0.05.

      **Part (c): Testing H‚ÇÄ: Œº = 47**

      Œº‚ÇÄ = 47 is **inside** the CI (45.52, 50.88).

      By duality: **Fail to reject H‚ÇÄ** at Œ± = 0.05.

      **R verification:**

      .. code-block:: r

         xbar <- 48.2; s <- 6.5; n <- 25
         SE <- s / sqrt(n)  # 1.3
         t_crit <- qt(0.025, df = 24, lower.tail = FALSE)  # 2.064
         c(xbar - t_crit * SE, xbar + t_crit * SE)  # (45.52, 50.88)

----

.. admonition:: Exercise 9: Using t.test() in R
   :class: note

   A quality control engineer measures the tensile strength (in MPa) of 10 steel specimens:

   .. code-block:: text

      425, 438, 412, 445, 428, 433, 419, 441, 436, 423

   a. Calculate :math:`\bar{x}` and s from this data.

   b. Use R's ``t.test()`` function to test H‚ÇÄ: Œº = 420 vs H‚Çê: Œº ‚â† 420 at Œ± = 0.05.

   c. Interpret the output, including the t-statistic, df, p-value, and CI.

   d. What is your conclusion about the mean tensile strength?

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Summary Statistics**

      .. code-block:: r

         strength <- c(425, 438, 412, 445, 428, 433, 419, 441, 436, 423)
         mean(strength)  # 430
         sd(strength)    # 10.42

      :math:`\bar{x} = 430` MPa, s = 10.42 MPa

      **Part (b): t.test() Output**

      .. code-block:: r

         t.test(strength, mu = 420, alternative = "two.sided", conf.level = 0.95)
         
         # Output:
         # One Sample t-test
         # 
         # data:  strength
         # t = 3.0336, df = 9, p-value = 0.01422
         # alternative hypothesis: true mean is not equal to 420
         # 95 percent confidence interval:
         #  422.5441 437.4559
         # sample estimates:
         # mean of x 
         #       430

      **Part (c): Interpretation**

      - **t-statistic**: t = 3.034
      - **Degrees of freedom**: df = 9
      - **P-value**: 0.0142
      - **95% CI**: (422.54, 437.46) MPa

      The t-statistic of 3.034 indicates the sample mean is about 3 standard errors above Œº‚ÇÄ = 420.

      The p-value of 0.0142 is less than Œ± = 0.05.

      The CI does not contain Œº‚ÇÄ = 420, consistent with rejection.

      **Part (d): Conclusion**

      The data does give support (p-value = 0.014) to the claim that the mean tensile strength differs from 420 MPa. The 95% CI suggests the true mean is between 422.5 and 437.5 MPa, indicating the steel may be slightly stronger than the 420 MPa specification.

----

.. admonition:: Exercise 10: Application with Raw Data
   :class: note

   A cognitive psychologist measures reaction times (in milliseconds) for 20 participants in a visual recognition task:

   .. code-block:: text

      245, 238, 252, 241, 259, 247, 236, 255, 243, 249,
      251, 240, 258, 244, 237, 253, 246, 250, 242, 248

   The standard reaction time for this task is believed to be 250 ms. Test whether this sample suggests a different mean reaction time at Œ± = 0.05.

   a. State the hypotheses.

   b. Calculate summary statistics.

   c. Perform the t-test manually (calculate t_TS and p-value).

   d. Verify using R's ``t.test()`` function.

   e. Construct the 95% CI and verify duality.

   f. State your conclusion in context.

   .. dropdown:: Solution
      :class-container: sd-border-success

      **Part (a): Hypotheses**

      Let Œº = true mean reaction time (ms).

      .. math::
         H_0: \mu = 250 \quad \text{vs} \quad H_a: \mu \neq 250

      **Part (b): Summary Statistics**

      .. code-block:: r

         times <- c(245, 238, 252, 241, 259, 247, 236, 255, 243, 249,
                    251, 240, 258, 244, 237, 253, 246, 250, 242, 248)
         n <- length(times)    # 20
         xbar <- mean(times)   # 246.7
         s <- sd(times)        # 6.729

      n = 20, :math:`\bar{x}` = 246.7 ms, s = 6.73 ms

      **Part (c): Manual T-test**

      .. math::
         t_{TS} = \frac{246.7 - 250}{6.729 / \sqrt{20}} = \frac{-3.3}{1.505} = -2.193

      df = 19

      P-value (two-tailed):

      .. math::
         p\text{-value} = 2 \times P(T_{19} > 2.193) = 0.0409

      **Part (d): R Verification**

      .. code-block:: r

         t.test(times, mu = 250)
         
         # t = -2.1933, df = 19, p-value = 0.04094
         # 95% CI: (243.5502, 249.8498)

      **Part (e): 95% CI and Duality**

      95% CI: (243.55, 249.85) ms

      Œº‚ÇÄ = 250 is **outside** this CI (just barely).

      By duality, this is consistent with rejecting H‚ÇÄ at Œ± = 0.05. ‚úì

      **Part (f): Conclusion**

      The data does give support (p-value = 0.041) to the claim that the mean reaction time for this task differs from the standard of 250 ms. The sample suggests participants responded slightly faster, with a mean around 246.7 ms. However, note that the p-value is close to 0.05, so this is a relatively weak rejection.

----

Additional Practice Problems
----------------------------

**True/False Questions** (1 point each)

1. The t-distribution is used when œÉ is unknown and must be estimated.

   ‚ìâ or ‚íª

2. As df increases, the t-distribution approaches the standard normal distribution.

   ‚ìâ or ‚íª

3. For a given test statistic value, the p-value from a t-test is smaller than from a z-test.

   ‚ìâ or ‚íª

4. Degrees of freedom for a one-sample t-test equals n.

   ‚ìâ or ‚íª

5. If Œº‚ÇÄ is inside a 95% CI, we would reject H‚ÇÄ at Œ± = 0.05.

   ‚ìâ or ‚íª

6. The t.test() function in R can perform both one-sided and two-sided tests.

   ‚ìâ or ‚íª

**Multiple Choice Questions** (2 points each)

7. For n = 20 and Œ± = 0.05 (two-tailed), the t-critical value is:

   ‚í∂ t‚ÇÄ.‚ÇÄ‚ÇÖ,‚ÇÇ‚ÇÄ
   
   ‚í∑ t‚ÇÄ.‚ÇÄ‚ÇÇ‚ÇÖ,‚ÇÇ‚ÇÄ
   
   ‚í∏ t‚ÇÄ.‚ÇÄ‚ÇÇ‚ÇÖ,‚ÇÅ‚Çâ
   
   ‚íπ t‚ÇÄ.‚ÇÄ‚ÇÖ,‚ÇÅ‚Çâ

8. If :math:`\bar{x} = 52`, Œº‚ÇÄ = 50, s = 8, n = 16, then t_TS equals:

   ‚í∂ 0.25
   
   ‚í∑ 1.00
   
   ‚í∏ 2.00
   
   ‚íπ 4.00

9. A 90% CI is (45, 55). Testing H‚ÇÄ: Œº = 58 at Œ± = 0.10 leads to:

   ‚í∂ Reject H‚ÇÄ
   
   ‚í∑ Fail to reject H‚ÇÄ
   
   ‚í∏ Cannot determine without more information
   
   ‚íπ Accept H‚ÇÄ

10. The t-test is more conservative than the z-test because:

    ‚í∂ t-critical values are smaller
    
    ‚í∑ t-critical values are larger (for finite df)
    
    ‚í∏ t-tests use larger samples
    
    ‚íπ t-tests have smaller p-values

11. For t_TS = 2.5 with df = 10 (upper-tailed), the p-value is calculated as:

    ‚í∂ pt(2.5, 10)
    
    ‚í∑ pt(2.5, 10, lower.tail = FALSE)
    
    ‚í∏ 2 * pt(2.5, 10, lower.tail = FALSE)
    
    ‚íπ 1 - pt(2.5, 10)

12. Which correctly pairs a CI type with a hypothesis test type for duality?

    ‚í∂ 95% CI with Œ± = 0.10 two-tailed test
    
    ‚í∑ 95% CI with Œ± = 0.05 two-tailed test
    
    ‚í∏ 95% LCB with Œ± = 0.05 two-tailed test
    
    ‚íπ 90% CI with Œ± = 0.05 two-tailed test

.. dropdown:: Answers to Practice Problems
   :class-container: sd-border-success

   **True/False Answers:**

   1. **True** ‚Äî When œÉ is unknown, we use s and the t-distribution.

   2. **True** ‚Äî As df ‚Üí ‚àû, t ‚Üí z (standard normal).

   3. **False** ‚Äî T-distribution has heavier tails, so p-values are *larger*.

   4. **False** ‚Äî df = n - 1 for one-sample t-test.

   5. **False** ‚Äî If Œº‚ÇÄ is inside the CI, we *fail to reject* H‚ÇÄ.

   6. **True** ‚Äî Use ``alternative = "less"`` or ``"greater"`` for one-sided.

   **Multiple Choice Answers:**

   7. **‚í∏** ‚Äî For n = 20: df = 19, and two-tailed uses Œ±/2 = 0.025.

   8. **‚í∑** ‚Äî t_TS = (52 - 50)/(8/‚àö16) = 2/2 = 1.00.

   9. **‚í∂** ‚Äî 58 is outside (45, 55), so reject H‚ÇÄ by duality.

   10. **‚í∑** ‚Äî Larger critical values make rejection harder (more conservative).

   11. **‚í∑** ‚Äî Upper-tailed: p-value = P(T > t_TS) = pt(t_ts, df, lower.tail = FALSE).

   12. **‚í∑** ‚Äî Duality requires C + Œ± = 1, so 95% CI pairs with Œ± = 0.05.