

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>9.1. Introduction to Statistical Inference &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=581abb6a" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter9/lectures/9-1-intro-statistical-inference.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=de5959cf"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="9.2. Confidence Intervals for the Population Mean, When œÉ is Known" href="9-2-ci-sigma-known.html" />
    <link rel="prev" title="9. Confidence Intervals and Bounds" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#simulation-exercise">Simulation Exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes‚Äô Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes‚Äô Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#quick-reference-table">Quick Reference Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#recommended-workflow">Recommended workflow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#getting-started-with-swirl">Getting Started with swirl</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#setup-and-use-swirl">Setup and Use swirl</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#alternative-r-learning-resources">Alternative R Learning Resources</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#base-r">Base R</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#tidyverse">tidyverse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#r-markdown">R Markdown</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#statistical-computing">Statistical Computing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#video-resources">Video Resources</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#function-reference-alphabetized-within-category">Function Reference (Alphabetized within Category)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#simulation-functions">Simulation Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#inference-functions">Inference Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#graphics-ggplot2">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#tables-reporting">Tables &amp; Reporting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#best-practices-common-pitfalls">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#appendix-quick-links">Appendix: Quick Links</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#assignments">Assignments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#getting-help">Getting Help</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes‚Äô Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">9. Confidence Intervals and Bounds</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When œÉ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When œÉ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When œÉ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">9. </span>Confidence Intervals and Bounds</a></li>
      <li class="breadcrumb-item active"><span class="section-number">9.1. </span>Introduction to Statistical Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter9/lectures/9-1-intro-statistical-inference.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch9-1">
   <iframe
      id="video-ch9-1"
      title="STAT 350 ‚Äì Chapter 9.1 Single Sample Confidence Intervals"
      src="https://www.youtube.com/embed/P3Nyg84h0A8?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="introduction-to-statistical-inference">
<h1><span class="section-number">9.1. </span>Introduction to Statistical Inference<a class="headerlink" href="#introduction-to-statistical-inference" title="Link to this heading">ÔÉÅ</a></h1>
<p>After developing the foundational tools of probability theory, exploring random variables, and
understanding sampling distributions, we have finally arrived at the core of statistical practice:
<strong>statistical inference</strong>. This exciting chapter marks our transition from describing uncertainty to
making decisions under uncertainty‚Äîthe essence of statistics as a discipline.</p>
<p>Throughout the earlier chapters, we‚Äôve methodically built a toolkit for this moment:</p>
<ul class="simple">
<li><p>We developed the language of probability to quantify uncertainty</p></li>
<li><p>We explored both discrete and continuous probability distributions as mathematical models for random phenomena</p></li>
<li><p>We focused particularly on the normal distribution due to its central importance in statistical theory</p></li>
<li><p>We established the Central Limit Theorem as a bridge connecting theoretical probability to practical data analysis</p></li>
<li><p>We studied principles of experimental design and sampling to ensure our data collection produces valid information</p></li>
</ul>
<p>Now, these elements converge as we learn to estimate unknown population parameters and‚Äîcrucially‚Äîto
quantify the uncertainty in our estimates.</p>
<div class="important admonition">
<p class="admonition-title">Road Map üß≠</p>
<p>Fill Content</p>
</div>
<section id="from-population-parameters-to-estimators">
<h2><span class="section-number">9.1.1. </span>From Population Parameters to Estimators<a class="headerlink" href="#from-population-parameters-to-estimators" title="Link to this heading">ÔÉÅ</a></h2>
<section id="the-challenge-of-unknown-parameters">
<h3>The Challenge of Unknown Parameters<a class="headerlink" href="#the-challenge-of-unknown-parameters" title="Link to this heading">ÔÉÅ</a></h3>
<p>In statistical research, we aim to understand characteristics of a population that are fixed but unknown to us. These characteristics, called <strong>parameters</strong>, might include:</p>
<ul class="simple">
<li><p>The population mean (<span class="math notranslate nohighlight">\(\mu\)</span>)</p></li>
<li><p>The population variance (<span class="math notranslate nohighlight">\(\sigma^2\)</span>)</p></li>
<li><p>The population proportion (<span class="math notranslate nohighlight">\(p\)</span>)</p></li>
<li><p>Other quantities describing the population‚Äôs distribution</p></li>
</ul>
<p>The fundamental challenge we face is that examining every member of a population is typically impractical or impossible. Instead, we must rely on a representative sample to make inferences about these parameters.</p>
<figure class="align-default" id="id1">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/parameter-estimator.png"><img alt="Diagram showing relationship between population parameters and sample estimates" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/parameter-estimator.png" style="width: 75%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 9.1 </span><span class="caption-text"><em>Figure 9.1: The relationship between population parameters and sample estimates. The population parameter (Œ∏) is fixed but unknown, while the sample estimate (Œ∏ÃÇ) varies from sample to sample.</em></span><a class="headerlink" href="#id1" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
</section>
<section id="estimation-procedures">
<h3>Estimation Procedures<a class="headerlink" href="#estimation-procedures" title="Link to this heading">ÔÉÅ</a></h3>
<p>An <strong>estimator</strong> is a procedure (or formula) that tells us how to use sample data to calculate an estimate of a population parameter. The numerical result we obtain from applying this procedure to a particular sample is called a <strong>point estimate</strong>.</p>
<p>For instance, when trying to estimate the population mean (<span class="math notranslate nohighlight">\(\mu\)</span>), our estimator is the sample mean (<span class="math notranslate nohighlight">\(\bar{x}\)</span>). This calculation procedure‚Äîadding all observed values and dividing by the sample size‚Äîis our estimator, while the specific numerical result (e.g., 42.7) is our point estimate.</p>
<p>It‚Äôs important to realize that because our sample is just one possible sample from the population, our point estimate will likely differ from the true parameter value. This inherent variability is why understanding the <strong>sampling distribution</strong> of our estimator becomes crucial.</p>
</section>
</section>
<section id="evaluating-estimators-bias-and-variance">
<h2><span class="section-number">9.1.2. </span>Evaluating Estimators: Bias and Variance<a class="headerlink" href="#evaluating-estimators-bias-and-variance" title="Link to this heading">ÔÉÅ</a></h2>
<p>When selecting an estimator, we prioritize procedures that produce values close to the true parameter on average. Two key properties help us evaluate estimators:</p>
<section id="bias-does-the-estimator-target-the-right-value">
<h3>Bias: Does the Estimator Target the Right Value?<a class="headerlink" href="#bias-does-the-estimator-target-the-right-value" title="Link to this heading">ÔÉÅ</a></h3>
<p>The <strong>bias</strong> of an estimator measures whether it systematically overestimates or underestimates the parameter of interest. Mathematically, we define bias as:</p>
<div class="math notranslate nohighlight">
\[\text{Bias}(\hat{\theta}) = \mathbb{E}[\hat{\theta}] - \theta\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is our estimator
- <span class="math notranslate nohighlight">\(\mathbb{E}[\hat{\theta}]\)</span> is the expected value (average) of the estimator across all possible samples
- <span class="math notranslate nohighlight">\(\theta\)</span> is the true population parameter</p>
<p>An estimator is <strong>unbiased</strong> if its expected value equals the parameter it aims to estimate:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\hat{\theta}] = \theta\]</div>
<p>The sample mean (<span class="math notranslate nohighlight">\(\bar{x}\)</span>) provides an excellent example of an unbiased estimator for the population mean (<span class="math notranslate nohighlight">\(\mu\)</span>):</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\bar{x}] = \mu\]</div>
<p>This unbiasedness holds regardless of the population distribution, provided it has a finite mean‚Äîa remarkable property that makes the sample mean so useful in statistics.</p>
</section>
<section id="variance-how-precise-is-the-estimator">
<h3>Variance: How Precise is the Estimator?<a class="headerlink" href="#variance-how-precise-is-the-estimator" title="Link to this heading">ÔÉÅ</a></h3>
<p>The <strong>variance</strong> of an estimator quantifies the spread of its sampling distribution‚Äîessentially how much the estimator fluctuates from sample to sample. Lower variance indicates greater precision and reliability.</p>
<p>When comparing unbiased estimators, we typically prefer the one with lower variance, as this reduces the expected ‚Äúdistance‚Äù between our estimate and the true parameter. The ideal is a <strong>minimum-variance unbiased estimator (MVUE)</strong>, which has the smallest possible variance among all unbiased estimators for that parameter.</p>
<figure class="align-default" id="id2">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/bias-variance-tradeoff.png"><img alt="Visual comparison of biased versus unbiased estimators" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/bias-variance-tradeoff.png" style="width: 70%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 9.2 </span><span class="caption-text"><em>Figure 9.2: Visual representation of bias and variance. The left panel shows an unbiased estimator with high variance, the middle panel shows a biased estimator with low variance, and the right panel shows an unbiased estimator with low variance (ideal).</em></span><a class="headerlink" href="#id2" title="Link to this image">ÔÉÅ</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="examples-of-estimators">
<h2><span class="section-number">9.1.3. </span>Examples of Estimators<a class="headerlink" href="#examples-of-estimators" title="Link to this heading">ÔÉÅ</a></h2>
<p>To solidify these concepts, let‚Äôs examine several common estimators and their properties:</p>
<section id="sample-mean-for-population-mean">
<h3>Sample Mean for Population Mean<a class="headerlink" href="#sample-mean-for-population-mean" title="Link to this heading">ÔÉÅ</a></h3>
<p>The sample mean serves as our estimator for the population mean:</p>
<div class="math notranslate nohighlight">
\[\bar{X} = \frac{1}{n}\sum_{i=1}^{n}X_i\]</div>
<p>This estimator is unbiased: <span class="math notranslate nohighlight">\(\mathbb{E}[\bar{X}] = \mu\)</span>.</p>
<p>When sampling from a normal distribution, the sample mean is also a minimum-variance unbiased estimator (MVUE), making it optimal for estimating the population mean. Even for non-normal distributions, the sample mean remains an excellent estimator, especially as sample size increases, thanks to the Central Limit Theorem.</p>
</section>
<section id="sample-proportion-for-population-proportion">
<h3>Sample Proportion for Population Proportion<a class="headerlink" href="#sample-proportion-for-population-proportion" title="Link to this heading">ÔÉÅ</a></h3>
<p>For categorical variables where we‚Äôre interested in the proportion possessing a certain attribute, we use:</p>
<div class="math notranslate nohighlight">
\[\hat{p} = \frac{X}{n}\]</div>
<p>Where <span class="math notranslate nohighlight">\(X\)</span> represents the count of ‚Äúsuccesses‚Äù or observations with the attribute of interest.</p>
<p>This estimator is unbiased: <span class="math notranslate nohighlight">\(\mathbb{E}[\hat{p}] = p\)</span>.</p>
</section>
<section id="estimating-discrete-probabilities">
<h3>Estimating Discrete Probabilities<a class="headerlink" href="#estimating-discrete-probabilities" title="Link to this heading">ÔÉÅ</a></h3>
<p>When estimating the probability mass function for discrete random variables, we use relative frequencies. For a specific value <span class="math notranslate nohighlight">\(x\)</span>, we construct an estimator using indicator functions:</p>
<div class="math notranslate nohighlight">
\[\hat{p}_X(x) = \frac{1}{n}\sum_{i=1}^{n}I(X_i = x)\]</div>
<p>Where <span class="math notranslate nohighlight">\(I(X_i = x)\)</span> equals 1 if the observation equals <span class="math notranslate nohighlight">\(x\)</span>, and 0 otherwise.</p>
<p>This essentially counts how many times the value <span class="math notranslate nohighlight">\(x\)</span> appears in our sample, divided by the sample size. We can prove this estimator is unbiased:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbb{E}[\hat{p}_X(x)] &amp;= \mathbb{E}\left[\frac{1}{n}\sum_{i=1}^{n}I(X_i = x)\right] \\
&amp;= \frac{1}{n}\sum_{i=1}^{n}\mathbb{E}[I(X_i = x)] \\
&amp;= \frac{1}{n}\sum_{i=1}^{n}p_X(x) \\
&amp;= p_X(x)\end{split}\]</div>
</section>
<section id="estimating-continuous-distribution-functions">
<h3>Estimating Continuous Distribution Functions<a class="headerlink" href="#estimating-continuous-distribution-functions" title="Link to this heading">ÔÉÅ</a></h3>
<p>Similarly, for continuous random variables, we can estimate the cumulative distribution function (CDF) at any point using:</p>
<div class="math notranslate nohighlight">
\[\hat{F}_X(x) = \frac{1}{n}\sum_{i=1}^{n}I(X_i \leq x)\]</div>
<p>This counts the proportion of observations less than or equal to <span class="math notranslate nohighlight">\(x\)</span>. This estimator is also unbiased:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\hat{F}_X(x)] = F_X(x)\]</div>
</section>
</section>
<section id="the-special-case-of-variance-estimation">
<h2><span class="section-number">9.1.4. </span>The Special Case of Variance Estimation<a class="headerlink" href="#the-special-case-of-variance-estimation" title="Link to this heading">ÔÉÅ</a></h2>
<p>The estimation of population variance presents an interesting case where intuition alone might lead us astray.</p>
<section id="population-variance-with-known-mean">
<h3>Population Variance with Known Mean<a class="headerlink" href="#population-variance-with-known-mean" title="Link to this heading">ÔÉÅ</a></h3>
<p>If we knew the population mean <span class="math notranslate nohighlight">\(\mu\)</span> (which we typically don‚Äôt), we could estimate the population variance as:</p>
<div class="math notranslate nohighlight">
\[\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n}(X_i - \mu)^2\]</div>
<p>This would be an unbiased estimator: <span class="math notranslate nohighlight">\(\mathbb{E}[\hat{\sigma}^2] = \sigma^2\)</span>.</p>
</section>
<section id="sample-variance-with-estimated-mean">
<h3>Sample Variance with Estimated Mean<a class="headerlink" href="#sample-variance-with-estimated-mean" title="Link to this heading">ÔÉÅ</a></h3>
<p>In practice, we must estimate the mean using <span class="math notranslate nohighlight">\(\bar{X}\)</span>. This changes our variance estimator to:</p>
<div class="math notranslate nohighlight">
\[S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2\]</div>
<p>Notice the crucial difference: we divide by <span class="math notranslate nohighlight">\(n-1\)</span> rather than <span class="math notranslate nohighlight">\(n\)</span>. This adjustment corrects for the bias introduced by using <span class="math notranslate nohighlight">\(\bar{X}\)</span> instead of <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p>To understand why this correction is necessary, we can analyze the expected value:</p>
<ol class="arabic simple">
<li><p>Add and subtract <span class="math notranslate nohighlight">\(\mu\)</span> inside the squared term:
<span class="math notranslate nohighlight">\((X_i - \bar{X})^2 = ((X_i - \mu) - (\bar{X} - \mu))^2\)</span></p></li>
<li><p>Expand the expression and take the expected value</p></li>
<li><p>This reveals that dividing by <span class="math notranslate nohighlight">\(n\)</span> would give us <span class="math notranslate nohighlight">\(\frac{n-1}{n}\sigma^2\)</span>, which is biased</p></li>
<li><p>Dividing by <span class="math notranslate nohighlight">\(n-1\)</span> instead gives us an unbiased estimator: <span class="math notranslate nohighlight">\(\mathbb{E}[S^2] = \sigma^2\)</span></p></li>
</ol>
<p>This division by <span class="math notranslate nohighlight">\(n-1\)</span> rather than <span class="math notranslate nohighlight">\(n\)</span> accounts for the loss of one degree of freedom when estimating the mean.</p>
</section>
<section id="the-biased-case-of-sample-standard-deviation">
<h3>The Biased Case of Sample Standard Deviation<a class="headerlink" href="#the-biased-case-of-sample-standard-deviation" title="Link to this heading">ÔÉÅ</a></h3>
<p>While the sample variance <span class="math notranslate nohighlight">\(S^2\)</span> provides an unbiased estimate of <span class="math notranslate nohighlight">\(\sigma^2\)</span>, the sample standard deviation <span class="math notranslate nohighlight">\(S = \sqrt{S^2}\)</span> is actually a biased estimator of the population standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p>This bias stems from Jensen‚Äôs inequality and the fact that the square root is a concave function. We can prove this bias exists:</p>
<ol class="arabic simple">
<li><p>The variance of any non-constant random variable is positive: <span class="math notranslate nohighlight">\(\text{Var}(S) &gt; 0\)</span></p></li>
<li><p>From the definition of variance: <span class="math notranslate nohighlight">\(\text{Var}(S) = \mathbb{E}[S^2] - (\mathbb{E}[S])^2 &gt; 0\)</span></p></li>
<li><p>Rearranging: <span class="math notranslate nohighlight">\(\mathbb{E}[S^2] &gt; (\mathbb{E}[S])^2\)</span></p></li>
<li><p>Since <span class="math notranslate nohighlight">\(\mathbb{E}[S^2] = \mathbb{E}[\sigma^2] = \sigma^2\)</span></p></li>
<li><p>Thus: <span class="math notranslate nohighlight">\(\sigma^2 &gt; (\mathbb{E}[S])^2\)</span></p></li>
<li><p>Taking the square root: <span class="math notranslate nohighlight">\(\sigma &gt; \mathbb{E}[S]\)</span></p></li>
</ol>
<p>This inequality shows that the expected value of <span class="math notranslate nohighlight">\(S\)</span> is less than <span class="math notranslate nohighlight">\(\sigma\)</span>, meaning <span class="math notranslate nohighlight">\(S\)</span> systematically underestimates the population standard deviation.</p>
<p>Despite this bias, we still use <span class="math notranslate nohighlight">\(S\)</span> as our estimator for <span class="math notranslate nohighlight">\(\sigma\)</span> because:
- The bias is typically small, especially for larger sample sizes
- No unbiased estimator exists for <span class="math notranslate nohighlight">\(\sigma\)</span> that works for all distributions
- The formula is straightforward and intuitive</p>
</section>
</section>
<section id="minimum-variance-unbiased-estimators-mvue">
<h2><span class="section-number">9.1.5. </span>Minimum Variance Unbiased Estimators (MVUE)<a class="headerlink" href="#minimum-variance-unbiased-estimators-mvue" title="Link to this heading">ÔÉÅ</a></h2>
<p>In the world of unbiased estimators, we often seek the most efficient option‚Äîthe one with the smallest variance.</p>
<section id="the-concept-of-mvue">
<h3>The Concept of MVUE<a class="headerlink" href="#the-concept-of-mvue" title="Link to this heading">ÔÉÅ</a></h3>
<p>A <strong>minimum variance unbiased estimator (MVUE)</strong> achieves the lowest possible variance among all unbiased estimators for a given parameter. This represents the theoretical ideal for parameter estimation.</p>
<p>Finding MVUEs requires advanced statistical theory and depends on the specifics of the population distribution. However, some important results:</p>
<ul class="simple">
<li><p>For normal populations, the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> is the MVUE for the population mean <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
<li><p>For normal populations, the sample variance <span class="math notranslate nohighlight">\(S^2\)</span> is the MVUE for the population variance <span class="math notranslate nohighlight">\(\sigma^2\)</span></p></li>
<li><p>For Bernoulli populations, the sample proportion <span class="math notranslate nohighlight">\(\hat{p}\)</span> is the MVUE for the population proportion <span class="math notranslate nohighlight">\(p\)</span></p></li>
</ul>
</section>
<section id="why-mvues-matter">
<h3>Why MVUEs Matter<a class="headerlink" href="#why-mvues-matter" title="Link to this heading">ÔÉÅ</a></h3>
<p>MVUEs matter because they extract maximum information from our data. When we use an MVUE, we‚Äôre getting the most precise unbiased estimate possible given our sample size.</p>
<p>Even when we can‚Äôt achieve the theoretical MVUE (such as when the population distribution is unknown), understanding this concept helps us evaluate and compare different estimation procedures.</p>
</section>
</section>
<section id="from-point-estimates-to-interval-estimates">
<h2><span class="section-number">9.1.6. </span>From Point Estimates to Interval Estimates<a class="headerlink" href="#from-point-estimates-to-interval-estimates" title="Link to this heading">ÔÉÅ</a></h2>
<p>While estimators with desirable properties provide our best ‚Äúpoint guesses‚Äù at parameters, they still suffer from a critical limitation: they don‚Äôt communicate uncertainty. A single number fails to convey how confident we should be in our estimate.</p>
<p>This limitation motivates our next major topic: <strong>confidence intervals</strong>. Rather than providing just a point estimate, a confidence interval gives a range of plausible values for the parameter, along with a measure of our confidence in that range.</p>
<p>A confidence interval for the population mean, assuming known population standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>, takes the form:</p>
<div class="math notranslate nohighlight">
\[\bar{x} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\]</div>
<p>Where <span class="math notranslate nohighlight">\(z_{\alpha/2}\)</span> is a critical value from the standard normal distribution that corresponds to our desired confidence level.</p>
<p>This concept of confidence intervals forms the bridge to our next section, where we‚Äôll explore how to quantify the precision of our estimates and communicate statistical uncertainty honestly and accurately.</p>
</section>
<section id="brining-it-all-together">
<h2><span class="section-number">9.1.7. </span>Brining It All Together<a class="headerlink" href="#brining-it-all-together" title="Link to this heading">ÔÉÅ</a></h2>
<p>In this chapter, we‚Äôve transitioned from probability theory to statistical inference by exploring the
properties of estimators.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaway üìù</p>
<ol class="arabic simple">
<li><p><strong>Parameters vs. Estimates</strong>: Population parameters are fixed but unknown, while sample estimates vary from sample to sample.</p></li>
<li><p><strong>Bias and Variance</strong>: Unbiased estimators target the correct parameter on average, while low-variance estimators provide more consistent results across samples.</p></li>
<li><p><strong>Common Estimators</strong>: The sample mean, proportion, variance, and their properties.</p></li>
<li><p><strong>Special Case of Variance</strong>: The necessity of dividing by n-1 in the sample variance formula, and the inherent bias in the sample standard deviation.</p></li>
<li><p><strong>Minimum Variance Unbiased Estimators (MVUEs)</strong>: The theoretical ideal that minimizes estimation error while maintaining unbiasedness.</p></li>
</ol>
</div>
<p>In subsequent chapters, we‚Äôll build on these foundations to develop confidence intervals and hypothesis tests‚Äîpowerful tools
that form the backbone of modern statistical inference.</p>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">ÔÉÅ</a></h3>
<ol class="arabic simple">
<li><p><strong>Proof Exercise</strong>: Show that the sample variance <span class="math notranslate nohighlight">\(S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})^2\)</span> is an unbiased estimator of the population variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. (Hint: Add and subtract <span class="math notranslate nohighlight">\(\mu\)</span> inside the parentheses and expand the squared term.)</p></li>
<li><p><strong>Conceptual Question</strong>: Explain why we divide by n-1 rather than n when calculating the sample variance. How does this relate to degrees of freedom?</p></li>
<li><p><strong>Applied Problem</strong>: A researcher collects a sample of 25 measurements and calculates a sample mean of 42.7 and a sample standard deviation of 5.3. What can the researcher conclude about the precision of the estimated mean? How would this precision change if the sample size were increased to 100?</p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="9. Confidence Intervals and Bounds" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="9-2-ci-sigma-known.html" class="btn btn-neutral float-right" title="9.2. Confidence Intervals for the Population Mean, When œÉ is Known" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>