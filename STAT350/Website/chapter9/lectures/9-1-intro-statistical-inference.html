

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>9.1. Introduction to Statistical Inference &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=d9cab97b" />
      <link rel="stylesheet" type="text/css" href="../../_static/credits.css?v=f7efa099" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/Website/chapter9/lectures/9-1-intro-statistical-inference.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=3cc62c56"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="9.2. Confidence Intervals for the Population Mean, When σ is Known" href="9-2-ci-sigma-known.html" />
    <link rel="prev" title="9. Confidence Intervals and Bounds" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#troubleshooting-guide">Troubleshooting Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-and-binomial-distributions">Part 1: The Bernoulli and Binomial Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#the-binomial-distribution">The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-poisson-distribution">Part 2: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-other-named-discrete-distributions">Part 3: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-standard-normal-table">Part 2: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-z-score-transformation">Part 3: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html">Worksheet 11: The Central Limit Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#tutorial-generating-the-sampling-distribution-of-bar-x">Tutorial: Generating the Sampling Distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-1-exploring-clt-with-skewed-distributions">Part 1: Exploring CLT with Skewed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-2-application-of-the-clt">Part 2: Application of the CLT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-3-beyond-mean-and-sum">Part 3: Beyond Mean and Sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-4-exploring-clt-generalizability-with-ai-assistance-exploration">Part 4: Exploring CLT Generalizability with AI Assistance (Exploration)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html">Part 2: Sample Size Determination</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-3-one-sided-confidence-bounds">Part 3: One-Sided Confidence Bounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-4-confidence-intervals-when-is-unknown">Part 4: Confidence Intervals When σ is Unknown</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html">Getting Started with R and RStudio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#getting-started-with-swirl">Getting Started with swirl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#alternative-r-learning-resources">Alternative R Learning Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_quick_reference.html">Quick Reference Table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html">Computer Assignments and Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-structure-by-session">Assignment Structure by Session</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html">Function Reference Part 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#simulation-functions">Simulation Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html">Function Reference Part 2: Inference Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html#diagnostic-plots-for-assumptions">Diagnostic Plots for Assumptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#tables-reporting">Tables &amp; Reporting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#data-import-validation">Data Import &amp; Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#statistical-assumptions">Statistical Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#common-errors-to-avoid">Common Errors to Avoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#workflow-template">Workflow Template</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html">Course Datasets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#primary-course-dataset-apprating">Primary Course Dataset - AppRating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#tutorial-support-datasets">Tutorial Support Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#loading-datasets-in-r">Loading Datasets in R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#built-in-r-datasets-used-in-course">Built-in R Datasets Used in Course</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#data-download-and-organization">Data Download and Organization</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Sequential Bayesian Updating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. The Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">9. Confidence Intervals and Bounds</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. The Foundation of Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Connecting CI and HT; <em>t</em>-Test for μ When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. The Four Steps to Hypothesis Testing and Understanding the Result</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Statistical Inference for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Independent Two-Sample Analysis When Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Independent Two-Sample Analysis - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Independent Two-Sample Analysis - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Paired Two-Sample Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">9. </span>Confidence Intervals and Bounds</a></li>
      <li class="breadcrumb-item active"><span class="section-number">9.1. </span>Introduction to Statistical Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter9/lectures/9-1-intro-statistical-inference.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch7-1">
   <iframe
      id="video-ch7-1"
      title="STAT 350 – Chapter 7.1 Statistics and Sampling Distributions Video"
      src="https://www.youtube.com/embed/P3Nyg84h0A8?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><div class="tip admonition">
<p class="admonition-title">Slides 📊</p>
<p><a class="reference external" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%209%20Confidence%20Intervals/L19-21%20Confidence%20Intervals%20for%20Single%20Sample_AC.pptx">Download Chapter 9 slides (PPTX)</a></p>
</div>
<section id="introduction-to-statistical-inference">
<h1><span class="section-number">9.1. </span>Introduction to Statistical Inference<a class="headerlink" href="#introduction-to-statistical-inference" title="Link to this heading"></a></h1>
<p>After developing the foundational tools of probability theory, exploring random variables, and
understanding sampling distributions, we have finally arrived at the core of statistical practice:
<strong>statistical inference</strong>. This exciting chapter marks our transition from describing uncertainty to
making decisions under uncertainty—the essence of statistics as a discipline.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p>Recall the relationship between a <strong>population parameter</strong> and its <strong>estimator</strong>. Estimator yields
<strong>estimates</strong> that vary from sample to sample, and their behavior is described by the <strong>sampling distribution</strong>.</p></li>
<li><p>Select an optimal estimator out of many candidates by evaluating their distributional properties.
Know the definitions of <strong>bias and variance</strong>, and use them appropriately as selection criteria.
Be able to compute bias for some simple estimators.</p></li>
<li><p>Know the definition of <strong>Minimum Variance Unbiased Estimator (MVUE)</strong>.</p></li>
</ul>
</div>
<section id="from-population-parameters-to-estimators">
<h2><span class="section-number">9.1.1. </span>From Population Parameters to Estimators<a class="headerlink" href="#from-population-parameters-to-estimators" title="Link to this heading"></a></h2>
<p>In statistical research, we aim to understand certain characteristics of a population that are fixed but
unknown to us. These characteristics, called <strong>parameters</strong>, include:</p>
<ul class="simple">
<li><p>The population mean (<span class="math notranslate nohighlight">\(\mu\)</span>),</p></li>
<li><p>The population variance (<span class="math notranslate nohighlight">\(\sigma^2\)</span>), and</p></li>
<li><p>Other quantities describing the population’s distribution.</p></li>
</ul>
<p>The fundamental challenge we face is that examining every member of a population is typically
impractical or impossible, even though doing so would be required to determine these characteristics with certainty.
Instead, we rely on a representative sample to make inferences about the popoulation and
specify <em>how uncertain</em> we are about the result.</p>
<figure class="align-center" id="id1" style="width: 75%">
<img alt="Diagram showing relationship between population parameters and sample estimates" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/parameter-estimator.png" />
<figcaption>
<p><span class="caption-number">Fig. 9.1 </span><span class="caption-text">Relationship of Parameters, estimators, and estimates</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
<section id="point-estimators-and-estimates">
<h3>Point Estimators and Estimates<a class="headerlink" href="#point-estimators-and-estimates" title="Link to this heading"></a></h3>
<p>An <strong>estimator</strong> is a <strong>random variable</strong> which contains instructions on how to use sample data to calculate
an estimate of a population parameter. When an estimator is designed to yield a
single numerical value as an outcome, it is called a <strong>point estimator</strong>.
The single-valued outcome is called a <strong>point estimate</strong>.</p>
<div class="note admonition">
<p class="admonition-title">Example💡: <span class="math notranslate nohighlight">\(\bar{X}\)</span> is a Point Estimator of <span class="math notranslate nohighlight">\(\mu\)</span></p>
<p>One possible <strong>point estimator</strong> of the population mean <span class="math notranslate nohighlight">\(\mu\)</span> is the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span>.
Its definition contains instructions on the calculation procedure—adding all
observed values and dividing by the sample size.
A <strong>point estimate</strong> <span class="math notranslate nohighlight">\(\bar{x}\)</span> is obtained as a single concrete numerical value
(e.g., <span class="math notranslate nohighlight">\(\bar{x} = 42.7\)</span>) by applying these instructions to an observed sample.</p>
</div>
</section>
<section id="a-parameter-has-many-point-estimators">
<h3>A Parameter Has Many Point Estimators<a class="headerlink" href="#a-parameter-has-many-point-estimators" title="Link to this heading"></a></h3>
<p>There are many different ways to guess a parameter value using data. For example,
we can choose to estimate the population mean <span class="math notranslate nohighlight">\(\mu\)</span> with</p>
<ul class="simple">
<li><p>The sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> (the typical choice),</p></li>
<li><p>The sample median <span class="math notranslate nohighlight">\(\tilde{X}\)</span> (for symmetric distributions whose true mean and true median are
equal, this is reasonable),</p></li>
<li><p>The mean of all data points except <span class="math notranslate nohighlight">\(m\)</span> most extreme values, etc.</p></li>
</ul>
<p>It is easy to generate many <em>reasonable</em> candidates. The key question is, then:
<strong>What objective criteria can we use to determine which estimator is better than others?</strong></p>
<p>Recall from Chapter 7 that each estimator has its own distribution, called
the <strong>sampling distribution</strong>. To answer the question, we focus on two key properties
of the sampling distribution: <strong>bias and variance</strong>.
For the remainder of this section, we use <span class="math notranslate nohighlight">\(\theta\)</span> (Greek letter “theta”) to denote a population parameter,
and <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> (“theta hat”) for an estimator of <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</section>
</section>
<section id="evaluating-estimators">
<h2><span class="section-number">9.1.2. </span>Evaluating Estimators<a class="headerlink" href="#evaluating-estimators" title="Link to this heading"></a></h2>
<section id="bias-does-the-estimator-target-the-right-value">
<h3>Bias: Does the Estimator Target the Right Value?<a class="headerlink" href="#bias-does-the-estimator-target-the-right-value" title="Link to this heading"></a></h3>
<p>The <strong>bias</strong> of an estimator measures whether it systematically overestimates or underestimates
the parameter of interest. It is mathematically defined as</p>
<div class="math notranslate nohighlight">
\[\text{Bias}(\hat{\theta}) = E[\hat{\theta}] - \theta.\]</div>
<p>An estimator <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is <strong>unbiased</strong> if <span class="math notranslate nohighlight">\(\text{Bias}(\hat{\theta})=0\)</span>, or equivalently,
if its expected value equals the parameter it aims to estimate:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\hat{\theta}] = \theta.\]</div>
<div class="note admonition">
<p class="admonition-title">Example 💡: Is the Sample Mean Unbiased?</p>
<p>We know that <span class="math notranslate nohighlight">\(\mathbb{E}[\bar{X}] = \mu\)</span>. So the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> is an <strong>unbiased
estimator</strong> of <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
</div>
</section>
<section id="variance-how-precise-is-the-estimator">
<h3>Variance: How Precise is the Estimator?<a class="headerlink" href="#variance-how-precise-is-the-estimator" title="Link to this heading"></a></h3>
<p>The <strong>variance</strong> of an estimator quantifies the spread of its sampling distribution—essentially how much the estimator fluctuates
from sample to sample. Lower variance indicates greater precision and reliability.</p>
<p><strong>Minimum-Variance Unbiased Estimator (MVUE)</strong></p>
<p>When choosing froom a set of unbiased estimators, we typically prefer the one with the smaller variance,
as this reduces the expected “distance” between the estimate and the true parameter.
An ideal estimator is called <strong>minimum-variance unbiased estimator (MVUE)</strong>—that is,
an estimator with the <strong>smallest possible variance among all unbiased estimators</strong> for a given parameter.</p>
<p>Whether an estimator is MVUE depends on the population distribution, and proving this property generally requires
advanced theoretical tools. Nonetheless, we will encounter several examples as we explore the properties
of key estimators.</p>
</section>
<section id="bias-variance-tradeoff">
<h3>Bias-Variance Tradeoff<a class="headerlink" href="#bias-variance-tradeoff" title="Link to this heading"></a></h3>
<p>An unbiased estimator is not always a better choice than a biased estimator. If an estimator
is slightly biased but has a significantly lower variance than its unbiased competitor,
then there may be situations where
the former is more practical. In fact, bias and variance often exhibit a trade-off relationship;
reducing bias in an estimator may increase its variance, and vice versa.
We should always take the <strong>degree</strong> of both bias and variance into consideration when
choosing an estimator. See Figure <a class="reference internal" href="#bias-variance"><span class="std std-numref">Fig. 9.2</span></a> for a visual illustratiion:</p>
<figure class="align-center" id="id2" style="width: 90%">
<span id="bias-variance"></span><img alt="Comparison of biased versus unbiased estimators" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/bias-variance-tradeoff.png" />
<figcaption>
<p><span class="caption-number">Fig. 9.2 </span><span class="caption-text">Comparison of biased and unbiabsed estimators</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
</section>
<section id="important-estimators-and-their-properties">
<h2><span class="section-number">9.1.3. </span>Important Estimators and Their Properties<a class="headerlink" href="#important-estimators-and-their-properties" title="Link to this heading"></a></h2>
<p>To solidify the concepts of bias and variance in estimators, let’s examine several common estimators
and their properties. In all cases below, suppose <span class="math notranslate nohighlight">\(X_1, X_2, \cdots, X_n\)</span> form an <em>iid</em> sample from
the same population.</p>
<section id="a-sample-mean-for-population-mean">
<h3>A. Sample Mean for Population Mean<a class="headerlink" href="#a-sample-mean-for-population-mean" title="Link to this heading"></a></h3>
<p>The sample mean <span class="math notranslate nohighlight">\(\bar{X} = \frac{1}{n}\sum_{i=1}^{n}X_i\)</span>
serves as an estimator for the population mean <span class="math notranslate nohighlight">\(\mu\)</span>. We know that <span class="math notranslate nohighlight">\(\mathbb{E}[\bar{X}] = \mu\)</span>,
which makes it an unbiased estimator of <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p>When sampling from a normal distribution, the sample mean is also a minimum-variance unbiased estimator (MVUE).</p>
</section>
<section id="b-sample-proportion-for-true-probability">
<h3>B. Sample Proportion for True Probability<a class="headerlink" href="#b-sample-proportion-for-true-probability" title="Link to this heading"></a></h3>
<p>Suppose identical trials are performed <span class="math notranslate nohighlight">\(n\)</span> times, and whether an event <span class="math notranslate nohighlight">\(A\)</span> occurs or not in each trial
is recorded using Bernoulli random variables of the following form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}I_i(A) =
\begin{cases}
1, &amp; \text{with probability } P(A) \\
0, &amp; \text{with probability } 1 - P(A)
\end{cases}\end{split}\]</div>
<p>for <span class="math notranslate nohighlight">\(i=1,2, \cdots, n\)</span>.</p>
<p>Define <span class="math notranslate nohighlight">\(\hat{p} = \frac{1}{n}\sum_{i=1}^n I_i(A)\)</span>. Then <span class="math notranslate nohighlight">\(\hat{p}\)</span> is an unbiased
estimator for <span class="math notranslate nohighlight">\(P(A)\)</span> because</p>
<div class="math notranslate nohighlight">
\[\begin{split}E[\hat{p}] &amp;= E\left[\frac{1}{n}\sum_{i=1}^n I_i(A)\right] = \frac{1}{n}\sum_{i=1}^n E[I_i(A)]\\
&amp;=\frac{1}{n}\sum_{i=1}^n (1 \cdot P(A) + 0 \cdot (1-P(A))) \\
&amp;= \frac{n}{n}P(A) = P(A).\end{split}\]</div>
<p>This result can be used to define an unbiased estimator for an entire probability distribution.</p>
<section id="a-estimating-a-pmf">
<h4>(a) Estimating a PMF<a class="headerlink" href="#a-estimating-a-pmf" title="Link to this heading"></a></h4>
<blockquote>
<div><p>Suppose <span class="math notranslate nohighlight">\(X_1, X_2, \cdots, X_n\)</span> form an <em>iid</em> sample of a discrete population <span class="math notranslate nohighlight">\(X\)</span>.
For each value <span class="math notranslate nohighlight">\(x \in \text{supp}(X)\)</span>, define:</p>
<div class="math notranslate nohighlight">
\[\hat{p}_X(x) = \frac{1}{n}\sum_{i=1}^{n}I(X_i = x),\]</div>
<p>where <span class="math notranslate nohighlight">\(I(X_i = x)=1\)</span> if the <span class="math notranslate nohighlight">\(i\)</span>-th sample point equals <span class="math notranslate nohighlight">\(x\)</span>, and <span class="math notranslate nohighlight">\(0\)</span> otherwise.
Then, by the same logic as the general case, <span class="math notranslate nohighlight">\(\hat{p}_X(x)\)</span> is an unbiased estimator
of <span class="math notranslate nohighlight">\(p_X(x)\)</span> for each <span class="math notranslate nohighlight">\(x \in \text{supp}(X)\)</span>:</p>
<div class="math notranslate nohighlight">
\[E[\hat{p}_X(x)] = p_X(x) = P(X = x).\]</div>
</div></blockquote>
</section>
<section id="b-estimating-a-cdf">
<h4>(b) Estimating a CDF<a class="headerlink" href="#b-estimating-a-cdf" title="Link to this heading"></a></h4>
<blockquote>
<div><p>For continuous random variables, we can estimate the cumulative distribution function (CDF) at
any <span class="math notranslate nohighlight">\(x \in \text{supp}(X)\)</span> using:</p>
<div class="math notranslate nohighlight">
\[\hat{F}_X(x) = \frac{1}{n}\sum_{i=1}^{n}I(X_i \leq x).\]</div>
<p><span class="math notranslate nohighlight">\(\hat{F}_X(x)\)</span> represents the proportion of observations less than or equal to <span class="math notranslate nohighlight">\(x\)</span>.
As another special application of the general case, this is an unbiased
estimator of the true CDF <span class="math notranslate nohighlight">\(F_X(x)\)</span>. That is,</p>
<div class="math notranslate nohighlight">
\[E[\hat{F}_X(x)] = P(X \leq x) = F_X(x).\]</div>
</div></blockquote>
</section>
</section>
<section id="c-sample-variance">
<h3>C. Sample Variance<a class="headerlink" href="#c-sample-variance" title="Link to this heading"></a></h3>
<p>The sample variance:</p>
<div class="math notranslate nohighlight">
\[S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2\]</div>
<p>is an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span>. To see how, let us compute the expected value.</p>
<ol class="arabic">
<li><p>Add and subtract <span class="math notranslate nohighlight">\(\mu\)</span> inside each squared term:
<span class="math notranslate nohighlight">\((X_i - \bar{X})^2 = ((X_i - \mu) - (\bar{X} - \mu))^2\)</span>.</p></li>
<li><p>Using Step 1,</p>
<div class="math notranslate nohighlight">
\[\begin{split}E[S^2]=&amp;E\left[\frac{1}{n-1}\sum_{i=1}^n ((X_i - \mu) - (\bar{X} - \mu))^2\right]\\
=&amp;\frac{1}{n-1}\sum_{i=1}^nE[((X_i - \mu) - (\bar{X} - \mu))^2]\\
=&amp;\frac{1}{n-1}\sum_{i=1}^n E[(X_i - \mu)^2 -2(X_i - \mu)(\bar{X} - \mu) + (\bar{X} - \mu)^2]\\
=&amp;\frac{1}{n-1}\sum_{i=1}^n E[(X_i - \mu)^2] -2E[(X_i - \mu)(\bar{X} - \mu)] + E[(\bar{X} - \mu)^2]\\\end{split}\]</div>
</li>
<li><p>The first and third expecations are respectively the variances of <span class="math notranslate nohighlight">\(X_i\)</span> and <span class="math notranslate nohighlight">\(\bar{X}\)</span>
by definition.</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;E[(X_i - \mu)^2] = Var(X_i) = \sigma^2\\
&amp;E[(\bar{X} - \mu)^2] = Var(\bar{X}) = \frac{\sigma^2}{n}\end{split}\]</div>
</li>
<li><p>The expectation <span class="math notranslate nohighlight">\(E[(X_i - \mu)(\bar{X} - \mu)]\)</span> can be simplified to</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;E[(X_i - \mu)\cdot \frac{1}{n}\sum_{j}(X_j - \mu)]= \frac{1}{n} \sum_{j=1}^n E[(X_i - \mu)(X_j - \mu)]\\
&amp;= \frac{1}{n}E[(X_i - \mu)(X_i - \mu)] = \frac{1}{n}E[(X_i -\mu)^2] = \frac{\sigma^2}{n}\end{split}\]</div>
<p>All terms involving indices <span class="math notranslate nohighlight">\(j\neq i\)</span> disappear in the final steps since
<span class="math notranslate nohighlight">\(Cov(X_i, X_j) = E[(X_i-\mu)(X_j - \mu)] =0\)</span> due to their independnce.</p>
</li>
<li><p>Substituting the results back to the final line of Step 2,
we can verify that the sum simplifies to <span class="math notranslate nohighlight">\((n-1)\sigma^2\)</span>. Therefore,</p>
<div class="math notranslate nohighlight">
\[E[S^2] = \frac{1}{n-1} (n-1)\sigma^2 = \sigma^2.\]</div>
</li>
</ol>
<p>This shows why we devide by <span class="math notranslate nohighlight">\(n-1\)</span> instead of <span class="math notranslate nohighlight">\(n\)</span> when computing a sample variance;
this is key to making the estimator unbiased.</p>
<p>When sampling from normal populations, the sample variance <span class="math notranslate nohighlight">\(S^2\)</span> is also the MVUE for the
population variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<div class="note admonition">
<p class="admonition-title">Additional Exercise 💡: Sample Variance When <span class="math notranslate nohighlight">\(\mu\)</span> is Known</p>
<p>In an unrealistic situation where <span class="math notranslate nohighlight">\(\sigma^2\)</span> is not known but <span class="math notranslate nohighlight">\(\mu\)</span> is,
we must incorporate the known information into our variance estimation. Show that</p>
<div class="math notranslate nohighlight">
\[\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n}(X_i - \mu)^2\]</div>
<p>is an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
</div>
<div class="important admonition">
<p class="admonition-title">The Biased Case of Sample Standard Deviation</p>
<p>While the sample variance <span class="math notranslate nohighlight">\(S^2\)</span> is an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span>,
the sample standard deviation <span class="math notranslate nohighlight">\(S = \sqrt{S^2}\)</span> is a <strong>biased estimator</strong> of the
population standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p>Its biasedness can be shown using a concept called <em>Jensen’s inequality</em> and the fact that the square root
is a concave function. The details are beyond the scope of this course, but you are encouraged to
read about the topic independently.</p>
<p>We still use <span class="math notranslate nohighlight">\(S\)</span> as our estimator for <span class="math notranslate nohighlight">\(\sigma\)</span> because the formula is
straightforward and intuitive, while the bias is typically small, especially for larger sample sizes.</p>
</div>
</section>
</section>
<section id="brining-it-all-together">
<h2><span class="section-number">9.1.4. </span>Brining It All Together<a class="headerlink" href="#brining-it-all-together" title="Link to this heading"></a></h2>
<p>In this chapter, we’ve transitioned from probability theory to statistical inference by exploring the
properties of point estimators.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaway 📝</p>
<ol class="arabic simple">
<li><p><strong>Estimators</strong> yield <strong>estimates</strong> intended to approximate a fixed but unknown <strong>population parameter</strong>.
Estimates vary from sample to sample according to their <strong>sampling distribution</strong>.</p></li>
<li><p>The two most important distributional characteristics of an estimator are <strong>bias and variance</strong>.
Unbiased estimators target the correct parameter on average, while low-variance
estimators provide more consistent results across samples.</p></li>
<li><p><strong>Minimum Variance Unbiased Estimators (MVUEs)</strong> have the smallest variance among all unbiased estimators of
a target parameter.</p></li>
<li><p>We can show that <span class="math notranslate nohighlight">\(\bar{X}\)</span> are <span class="math notranslate nohighlight">\(S^2\)</span> are unbiased estimators of their respective targets,
<span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span>. When the population is normal, they are also the MVUEs.</p></li>
</ol>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="9. Confidence Intervals and Bounds" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="9-2-ci-sigma-known.html" class="btn btn-neutral float-right" title="9.2. Confidence Intervals for the Population Mean, When σ is Known" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
  <p class="footer-credits-inline">
    <strong>Website Credits:</strong>
    Website development by Dr. Timothy Reese and Halin Shin.
    Generative AI tools were used to draft and refine some prose, code, and documentation; all content was reviewed by the instructors.
    Models: OpenAI o3 (2025-04-16 release) and Anthropic Claude Opus 4.1 (2025-08-05).
  </p>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>