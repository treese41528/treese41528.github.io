

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>9.1. Introduction to Statistical Inference &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=2f168d12" />
      <link rel="stylesheet" type="text/css" href="../../_static/credits.css?v=f7efa099" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/Website/chapter9/lectures/9-1-intro-statistical-inference.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=7e0058eb"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="9.2. Confidence Intervals for the Population Mean, When σ is Known" href="9-2-ci-sigma-known.html" />
    <link rel="prev" title="9. Confidence Intervals and Bounds" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#exam-2-preparation-materials-not-comprensive-for-final">Exam 2 Preparation Materials (Not comprensive for final)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#troubleshooting-guide">Troubleshooting Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-and-binomial-distributions">Part 1: The Bernoulli and Binomial Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#the-binomial-distribution">The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-poisson-distribution">Part 2: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-other-named-discrete-distributions">Part 3: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-standard-normal-table">Part 2: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-z-score-transformation">Part 3: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html">Worksheet 11: The Central Limit Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#tutorial-generating-the-sampling-distribution-of-bar-x">Tutorial: Generating the Sampling Distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-1-exploring-clt-with-skewed-distributions">Part 1: Exploring CLT with Skewed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-2-application-of-the-clt">Part 2: Application of the CLT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-3-beyond-mean-and-sum">Part 3: Beyond Mean and Sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-4-exploring-clt-generalizability-with-ai-assistance-exploration">Part 4: Exploring CLT Generalizability with AI Assistance (Exploration)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html">Worksheet 12: Point Estimators and Unbiased Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-1-estimating-parameters-of-the-exponential-distribution">Part 1: Estimating Parameters of the Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-2-estimating-the-maximum-of-a-uniform-distribution">Part 2: Estimating the Maximum of a Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-3-minimum-variance-unbiased-estimators-mvue">Part 3: Minimum Variance Unbiased Estimators (MVUE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html">Worksheet 13: Introduction to Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-1-pivotal-quantities-and-deriving-confidence-intervals">Part 1: Pivotal Quantities and Deriving Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-2-sample-size-determination">Part 2: Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-3-one-sided-confidence-bounds">Part 3: One-Sided Confidence Bounds</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-4-confidence-intervals-when-is-unknown">Part 4: Confidence Intervals When σ is Unknown</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html">Worksheet 14: Student’s t-Distribution and Statistical Power</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#assumptions-for-t-distribution-inference">Assumptions for t-Distribution Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-1-analyzing-chick-growth-with-confidence-intervals">Part 1: Analyzing Chick Growth with Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-2-introduction-to-hypothesis-testing">Part 2: Introduction to Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-3-sample-size-determination-and-power-analysis">Part 3: Sample Size Determination and Power Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html">The Hypothesis Testing Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-test-statistic-known">The Test Statistic (Known σ)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#distribution-of-the-test-statistic">Distribution of the Test Statistic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-p-value">The p-value</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#part-1-simulating-test-statistics-and-p-values">Part 1: Simulating Test Statistics and P-values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1a-simulation-when-null-hypothesis-is-true">Question 1a: Simulation When Null Hypothesis is True</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1b-simulation-when-null-hypothesis-is-false">Question 1b: Simulation When Null Hypothesis is False</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1c-comparing-the-two-scenarios">Question 1c: Comparing the Two Scenarios</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-t-test-when-is-unknown">The t-Test When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-t-test-statistic">The t-Test Statistic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#properties-of-the-t-distribution">Properties of the t-Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#relationship-between-confidence-intervals-and-hypothesis-tests">Relationship Between Confidence Intervals and Hypothesis Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#part-2-epa-ozone-concentration-analysis">Part 2: EPA Ozone Concentration Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2a-assumptions-and-exploratory-analysis">Question 2a: Assumptions and Exploratory Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2b-full-hypothesis-testing-procedure">Question 2b: Full Hypothesis Testing Procedure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2c-manual-verification">Question 2c: Manual Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2d-confidence-bound">Question 2d: Confidence Bound</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2e-power-calculation">Question 2e: Power Calculation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html">Worksheet 16: Two-Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-1-independent-vs-paired-designs">Part 1: Independent vs. Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-2-independent-samples-with-known-variances">Part 2: Independent Samples with Known Variances</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-3-pooled-two-sample-t-test-equal-variances">Part 3: Pooled Two-Sample t-Test (Equal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-4-welch-s-two-sample-t-test-unequal-variances">Part 4: Welch’s Two-Sample t-Test (Unequal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html">Worksheet 17: Paired Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-1-theory-and-procedure-for-paired-samples">Part 1: Theory and Procedure for Paired Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-2-sleep-study-analysis">Part 2: Sleep Study Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-3-sample-size-calculation-for-paired-designs">Part 3: Sample Size Calculation for Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html">Worksheet 18: One-Way ANOVA (Analysis of Variance)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#why-use-one-way-anova">Why Use One-Way ANOVA?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#one-way-anova-assumptions">One-Way ANOVA Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#one-way-anova-f-test-statistic-and-sources-of-variation">One-Way ANOVA F-test Statistic and Sources of Variation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#notation-and-setup">Notation and Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-1-computing-the-overall-sample-mean">Part 1: Computing the Overall Sample Mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-2-checking-the-equal-variance-assumption">Part 2: Checking the Equal Variance Assumption</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-3-pooled-variance-estimator">Part 3: Pooled Variance Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-4-within-group-variability-sum-of-squares-within-sse">Part 4: Within-Group Variability (Sum of Squares Within, SSE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-5-between-group-variability-sum-of-squares-among-ssa">Part 5: Between-Group Variability (Sum of Squares Among, SSA)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-6-total-variability-and-partitioning">Part 6: Total Variability and Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-7-degrees-of-freedom">Part 7: Degrees of Freedom</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-8-mean-squares">Part 8: Mean Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-9-the-f-test-statistic">Part 9: The F-Test Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-10-computing-the-p-value-and-making-a-decision">Part 10: Computing the P-Value and Making a Decision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-11-completing-the-anova-table">Part 11: Completing the ANOVA Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-12-limitations-and-follow-up-questions">Part 12: Limitations and Follow-Up Questions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html">Worksheet 19: Multiple Comparisons and Post-Hoc Testing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#the-multiple-comparisons-problem">The Multiple Comparisons Problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#methods-to-control-the-family-wise-error-rate">Methods to Control the Family-Wise Error Rate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-1-simulation-study-type-i-error-with-multiple-comparison-methods">Part 1: Simulation Study - Type I Error with Multiple Comparison Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-2-applying-tukey-s-hsd-to-worksheet-18-data">Part 2: Applying Tukey’s HSD to Worksheet 18 Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-3-comprehensive-anova-analysis-toothgrowth-dataset">Part 3: Comprehensive ANOVA Analysis - ToothGrowth Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html">Worksheet 20: Introduction to Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#from-anova-to-regression-same-core-ideas-new-application">From ANOVA to Regression: Same Core Ideas, New Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#the-simple-linear-regression-model">The Simple Linear Regression Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#least-squares">Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-1-deriving-least-squares-estimators">Part 1: Deriving Least Squares Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-2-the-general-simple-linear-regression-estimators">Part 2: The General Simple Linear Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-3-sampling-distributions-of-regression-estimators">Part 3: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-4-practice-problems">Part 4: Practice Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html">Worksheet 21: Inference for Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-1-sampling-distributions-of-regression-estimators">Part 1: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-2-checking-regression-assumptions">Part 2: Checking Regression Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-3-bird-data-analysis">Part 3: Bird Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-4-regression-anova">Part 4: Regression ANOVA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html">Worksheet 22: Model Assessment and Prediction in Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-1-the-coefficient-of-determination">Part 1: The Coefficient of Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-2-confidence-intervals-vs-prediction-intervals">Part 2: Confidence Intervals vs. Prediction Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-3-simulation-study-ci-vs-pi-coverage">Part 3: Simulation Study — CI vs. PI Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-4-prediction-with-the-bird-data">Part 4: Prediction with the Bird Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-5-diamonds-data-analysis">Part 5: Diamonds Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html">Getting Started with R and RStudio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#getting-started-with-swirl">Getting Started with swirl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#alternative-r-learning-resources">Alternative R Learning Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_quick_reference.html">Quick Reference Table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html">Computer Assignments and Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-structure">Assignment Structure</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html">Function Reference Part 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#simulation-functions">Simulation Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html">Function Reference Part 2: Inference Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html#diagnostic-plots-for-assumptions">Diagnostic Plots for Assumptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#tables-reporting">Tables &amp; Reporting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#data-import-validation">Data Import &amp; Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#statistical-assumptions">Statistical Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#common-errors-to-avoid">Common Errors to Avoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#workflow-template">Workflow Template</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html">Course Datasets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#primary-course-dataset-apprating">Primary Course Dataset - AppRating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#tutorial-support-datasets">Tutorial Support Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#loading-datasets-in-r">Loading Datasets in R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#built-in-r-datasets-used-in-course">Built-in R Datasets Used in Course</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#data-download-and-organization">Data Download and Organization</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Sequential Bayesian Updating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. The Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">9. Confidence Intervals and Bounds</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. The Foundation of Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Connecting CI and HT; <em>t</em>-Test for μ When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. The Four Steps to Hypothesis Testing and Understanding the Result</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Statistical Inference for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Independent Two-Sample Analysis When Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Independent Two-Sample Analysis - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Independent Two-Sample Analysis - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Paired Two-Sample Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. ANOVA F-Test and Its Relationship to Two-Sample <em>t</em>-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction and Robustness</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">9. </span>Confidence Intervals and Bounds</a></li>
      <li class="breadcrumb-item active"><span class="section-number">9.1. </span>Introduction to Statistical Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter9/lectures/9-1-intro-statistical-inference.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch7-1">
   <iframe
      id="video-ch7-1"
      title="STAT 350 – Chapter 7.1 Statistics and Sampling Distributions Video"
      src="https://www.youtube.com/embed/P3Nyg84h0A8?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><div class="tip admonition">
<p class="admonition-title">Slides 📊</p>
<p><a class="reference external" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%209%20Confidence%20Intervals/L19-21%20Confidence%20Intervals%20for%20Single%20Sample_AC.pptx">Download Chapter 9 slides (PPTX)</a></p>
</div>
<section id="introduction-to-statistical-inference">
<h1><span class="section-number">9.1. </span>Introduction to Statistical Inference<a class="headerlink" href="#introduction-to-statistical-inference" title="Link to this heading"></a></h1>
<p>After developing the foundational tools of probability theory, exploring random variables, and
understanding sampling distributions, we have finally arrived at the core of statistical practice:
<strong>statistical inference</strong>. This exciting chapter marks our transition from describing uncertainty to
making decisions under uncertainty—the essence of statistics as a discipline.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p>Recall the relationship between a <strong>population parameter</strong> and its <strong>estimator</strong>. Estimator yields
<strong>estimates</strong> that vary from sample to sample, and their behavior is described by the <strong>sampling distribution</strong>.</p></li>
<li><p>Select an optimal estimator out of many candidates by evaluating their distributional properties.
Know the definitions of <strong>bias and variance</strong>, and use them appropriately as selection criteria.
Be able to compute bias for some simple estimators.</p></li>
<li><p>Know the definition of <strong>Minimum Variance Unbiased Estimator (MVUE)</strong>.</p></li>
</ul>
</div>
<section id="from-population-parameters-to-estimators">
<h2><span class="section-number">9.1.1. </span>From Population Parameters to Estimators<a class="headerlink" href="#from-population-parameters-to-estimators" title="Link to this heading"></a></h2>
<p>In statistical research, we aim to understand certain characteristics of a population that are fixed but
unknown to us. These characteristics, called <strong>parameters</strong>, include:</p>
<ul class="simple">
<li><p>The population mean (<span class="math notranslate nohighlight">\(\mu\)</span>),</p></li>
<li><p>The population variance (<span class="math notranslate nohighlight">\(\sigma^2\)</span>), and</p></li>
<li><p>Other quantities describing the population’s distribution.</p></li>
</ul>
<p>The fundamental challenge we face is that examining every member of a population is typically
impractical or impossible, even though doing so would be required to determine these characteristics with certainty.
Instead, we rely on a representative sample to make inferences about the popoulation and
specify <em>how uncertain</em> we are about the result.</p>
<figure class="align-center" id="id2" style="width: 75%">
<img alt="Diagram showing relationship between population parameters and sample estimates" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/parameter-estimator.png" />
<figcaption>
<p><span class="caption-number">Fig. 9.1 </span><span class="caption-text">Relationship of Parameters, estimators, and estimates</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
<section id="point-estimators-and-estimates">
<h3>Point Estimators and Estimates<a class="headerlink" href="#point-estimators-and-estimates" title="Link to this heading"></a></h3>
<p>An <strong>estimator</strong> is a <strong>random variable</strong> which contains instructions on how to use sample data to calculate
an estimate of a population parameter. When an estimator is designed to yield a
single numerical value as an outcome, it is called a <strong>point estimator</strong>.
The single-valued outcome is called a <strong>point estimate</strong>.</p>
<div class="note admonition">
<p class="admonition-title">Example💡: <span class="math notranslate nohighlight">\(\bar{X}\)</span> is a Point Estimator of <span class="math notranslate nohighlight">\(\mu\)</span></p>
<p>One possible <strong>point estimator</strong> of the population mean <span class="math notranslate nohighlight">\(\mu\)</span> is the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span>.
Its definition contains instructions on the calculation procedure—adding all
observed values and dividing by the sample size.
A <strong>point estimate</strong> <span class="math notranslate nohighlight">\(\bar{x}\)</span> is obtained as a single concrete numerical value
(e.g., <span class="math notranslate nohighlight">\(\bar{x} = 42.7\)</span>) by applying these instructions to an observed sample.</p>
</div>
</section>
<section id="a-parameter-has-many-point-estimators">
<h3>A Parameter Has Many Point Estimators<a class="headerlink" href="#a-parameter-has-many-point-estimators" title="Link to this heading"></a></h3>
<p>There are many different ways to guess a parameter value using data. For example,
we can choose to estimate the population mean <span class="math notranslate nohighlight">\(\mu\)</span> with</p>
<ul class="simple">
<li><p>The sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> (the typical choice),</p></li>
<li><p>The sample median <span class="math notranslate nohighlight">\(\tilde{X}\)</span> (for symmetric distributions whose true mean and true median are
equal, this is reasonable),</p></li>
<li><p>The mean of all data points except <span class="math notranslate nohighlight">\(m\)</span> most extreme values, etc.</p></li>
</ul>
<p>It is easy to generate many <em>reasonable</em> candidates. The key question is, then:
<strong>What objective criteria can we use to determine which estimator is better than others?</strong></p>
<p>Recall from Chapter 7 that each estimator has its own distribution, called
the <strong>sampling distribution</strong>. To answer the question, we focus on two key properties
of the sampling distribution: <strong>bias and variance</strong>.
For the remainder of this section, we use <span class="math notranslate nohighlight">\(\theta\)</span> (Greek letter “theta”) to denote a population parameter,
and <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> (“theta hat”) for an estimator of <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</section>
</section>
<section id="evaluating-estimators">
<h2><span class="section-number">9.1.2. </span>Evaluating Estimators<a class="headerlink" href="#evaluating-estimators" title="Link to this heading"></a></h2>
<section id="bias-does-the-estimator-target-the-right-value">
<h3>Bias: Does the Estimator Target the Right Value?<a class="headerlink" href="#bias-does-the-estimator-target-the-right-value" title="Link to this heading"></a></h3>
<p>The <strong>bias</strong> of an estimator measures whether it systematically overestimates or underestimates
the parameter of interest. It is mathematically defined as</p>
<div class="math notranslate nohighlight">
\[\text{Bias}(\hat{\theta}) = E[\hat{\theta}] - \theta.\]</div>
<p>An estimator <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is <strong>unbiased</strong> if <span class="math notranslate nohighlight">\(\text{Bias}(\hat{\theta})=0\)</span>, or equivalently,
if its expected value equals the parameter it aims to estimate:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\hat{\theta}] = \theta.\]</div>
<div class="note admonition">
<p class="admonition-title">Example 💡: Is the Sample Mean Unbiased?</p>
<p>We know that <span class="math notranslate nohighlight">\(\mathbb{E}[\bar{X}] = \mu\)</span>. So the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> is an <strong>unbiased
estimator</strong> of <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
</div>
</section>
<section id="variance-how-precise-is-the-estimator">
<h3>Variance: How Precise is the Estimator?<a class="headerlink" href="#variance-how-precise-is-the-estimator" title="Link to this heading"></a></h3>
<p>The <strong>variance</strong> of an estimator quantifies the spread of its sampling distribution—essentially how much the estimator fluctuates
from sample to sample. Lower variance indicates greater precision and reliability.</p>
<p><strong>Minimum-Variance Unbiased Estimator (MVUE)</strong></p>
<p>When choosing froom a set of unbiased estimators, we typically prefer the one with the smaller variance,
as this reduces the expected “distance” between the estimate and the true parameter.
An ideal estimator is called <strong>minimum-variance unbiased estimator (MVUE)</strong>—that is,
an estimator with the <strong>smallest possible variance among all unbiased estimators</strong> for a given parameter.</p>
<p>Whether an estimator is MVUE depends on the population distribution, and proving this property generally requires
advanced theoretical tools. Nonetheless, we will encounter several examples as we explore the properties
of key estimators.</p>
</section>
<section id="bias-variance-tradeoff">
<h3>Bias-Variance Tradeoff<a class="headerlink" href="#bias-variance-tradeoff" title="Link to this heading"></a></h3>
<p>An unbiased estimator is not always a better choice than a biased estimator. If an estimator
is slightly biased but has a significantly lower variance than its unbiased competitor,
then there may be situations where
the former is more practical. In fact, bias and variance often exhibit a trade-off relationship;
reducing bias in an estimator may increase its variance, and vice versa.
We should always take the <strong>degree</strong> of both bias and variance into consideration when
choosing an estimator. See Figure <a class="reference internal" href="#bias-variance"><span class="std std-numref">Fig. 9.2</span></a> for a visual illustratiion:</p>
<figure class="align-center" id="id3" style="width: 90%">
<span id="bias-variance"></span><img alt="Comparison of biased versus unbiased estimators" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter9/bias-variance-tradeoff.png" />
<figcaption>
<p><span class="caption-number">Fig. 9.2 </span><span class="caption-text">Comparison of biased and unbiabsed estimators</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
</section>
<section id="important-estimators-and-their-properties">
<h2><span class="section-number">9.1.3. </span>Important Estimators and Their Properties<a class="headerlink" href="#important-estimators-and-their-properties" title="Link to this heading"></a></h2>
<p>To solidify the concepts of bias and variance in estimators, let’s examine several common estimators
and their properties. In all cases below, suppose <span class="math notranslate nohighlight">\(X_1, X_2, \cdots, X_n\)</span> form an <em>iid</em> sample from
the same population.</p>
<section id="a-sample-mean-for-population-mean">
<h3>A. Sample Mean for Population Mean<a class="headerlink" href="#a-sample-mean-for-population-mean" title="Link to this heading"></a></h3>
<p>The sample mean <span class="math notranslate nohighlight">\(\bar{X} = \frac{1}{n}\sum_{i=1}^{n}X_i\)</span>
serves as an estimator for the population mean <span class="math notranslate nohighlight">\(\mu\)</span>. We know that <span class="math notranslate nohighlight">\(\mathbb{E}[\bar{X}] = \mu\)</span>,
which makes it an unbiased estimator of <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p>When sampling from a normal distribution, the sample mean is also a minimum-variance unbiased estimator (MVUE).</p>
</section>
<section id="b-sample-proportion-for-true-probability">
<h3>B. Sample Proportion for True Probability<a class="headerlink" href="#b-sample-proportion-for-true-probability" title="Link to this heading"></a></h3>
<p>Suppose identical trials are performed <span class="math notranslate nohighlight">\(n\)</span> times, and whether an event <span class="math notranslate nohighlight">\(A\)</span> occurs or not in each trial
is recorded using Bernoulli random variables of the following form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}I_i(A) =
\begin{cases}
1, &amp; \text{with probability } P(A) \\
0, &amp; \text{with probability } 1 - P(A)
\end{cases}\end{split}\]</div>
<p>for <span class="math notranslate nohighlight">\(i=1,2, \cdots, n\)</span>.</p>
<p>Define <span class="math notranslate nohighlight">\(\hat{p} = \frac{1}{n}\sum_{i=1}^n I_i(A)\)</span>. Then <span class="math notranslate nohighlight">\(\hat{p}\)</span> is an unbiased
estimator for <span class="math notranslate nohighlight">\(P(A)\)</span> because</p>
<div class="math notranslate nohighlight">
\[\begin{split}E[\hat{p}] &amp;= E\left[\frac{1}{n}\sum_{i=1}^n I_i(A)\right] = \frac{1}{n}\sum_{i=1}^n E[I_i(A)]\\
&amp;=\frac{1}{n}\sum_{i=1}^n (1 \cdot P(A) + 0 \cdot (1-P(A))) \\
&amp;= \frac{n}{n}P(A) = P(A).\end{split}\]</div>
<p>This result can be used to define an unbiased estimator for an entire probability distribution.</p>
<section id="a-estimating-a-pmf">
<h4>(a) Estimating a PMF<a class="headerlink" href="#a-estimating-a-pmf" title="Link to this heading"></a></h4>
<blockquote>
<div><p>Suppose <span class="math notranslate nohighlight">\(X_1, X_2, \cdots, X_n\)</span> form an <em>iid</em> sample of a discrete population <span class="math notranslate nohighlight">\(X\)</span>.
For each value <span class="math notranslate nohighlight">\(x \in \text{supp}(X)\)</span>, define:</p>
<div class="math notranslate nohighlight">
\[\hat{p}_X(x) = \frac{1}{n}\sum_{i=1}^{n}I(X_i = x),\]</div>
<p>where <span class="math notranslate nohighlight">\(I(X_i = x)=1\)</span> if the <span class="math notranslate nohighlight">\(i\)</span>-th sample point equals <span class="math notranslate nohighlight">\(x\)</span>, and <span class="math notranslate nohighlight">\(0\)</span> otherwise.
Then, by the same logic as the general case, <span class="math notranslate nohighlight">\(\hat{p}_X(x)\)</span> is an unbiased estimator
of <span class="math notranslate nohighlight">\(p_X(x)\)</span> for each <span class="math notranslate nohighlight">\(x \in \text{supp}(X)\)</span>:</p>
<div class="math notranslate nohighlight">
\[E[\hat{p}_X(x)] = p_X(x) = P(X = x).\]</div>
</div></blockquote>
</section>
<section id="b-estimating-a-cdf">
<h4>(b) Estimating a CDF<a class="headerlink" href="#b-estimating-a-cdf" title="Link to this heading"></a></h4>
<blockquote>
<div><p>For continuous random variables, we can estimate the cumulative distribution function (CDF) at
any <span class="math notranslate nohighlight">\(x \in \text{supp}(X)\)</span> using:</p>
<div class="math notranslate nohighlight">
\[\hat{F}_X(x) = \frac{1}{n}\sum_{i=1}^{n}I(X_i \leq x).\]</div>
<p><span class="math notranslate nohighlight">\(\hat{F}_X(x)\)</span> represents the proportion of observations less than or equal to <span class="math notranslate nohighlight">\(x\)</span>.
As another special application of the general case, this is an unbiased
estimator of the true CDF <span class="math notranslate nohighlight">\(F_X(x)\)</span>. That is,</p>
<div class="math notranslate nohighlight">
\[E[\hat{F}_X(x)] = P(X \leq x) = F_X(x).\]</div>
</div></blockquote>
</section>
</section>
<section id="c-sample-variance">
<h3>C. Sample Variance<a class="headerlink" href="#c-sample-variance" title="Link to this heading"></a></h3>
<p>The sample variance:</p>
<div class="math notranslate nohighlight">
\[S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2\]</div>
<p>is an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span>. To see how, let us compute the expected value.</p>
<ol class="arabic">
<li><p>Add and subtract <span class="math notranslate nohighlight">\(\mu\)</span> inside each squared term:
<span class="math notranslate nohighlight">\((X_i - \bar{X})^2 = ((X_i - \mu) - (\bar{X} - \mu))^2\)</span>.</p></li>
<li><p>Using Step 1,</p>
<div class="math notranslate nohighlight">
\[\begin{split}E[S^2]=&amp;E\left[\frac{1}{n-1}\sum_{i=1}^n ((X_i - \mu) - (\bar{X} - \mu))^2\right]\\
=&amp;\frac{1}{n-1}\sum_{i=1}^nE[((X_i - \mu) - (\bar{X} - \mu))^2]\\
=&amp;\frac{1}{n-1}\sum_{i=1}^n E[(X_i - \mu)^2 -2(X_i - \mu)(\bar{X} - \mu) + (\bar{X} - \mu)^2]\\
=&amp;\frac{1}{n-1}\sum_{i=1}^n E[(X_i - \mu)^2] -2E[(X_i - \mu)(\bar{X} - \mu)] + E[(\bar{X} - \mu)^2]\\\end{split}\]</div>
</li>
<li><p>The first and third expecations are respectively the variances of <span class="math notranslate nohighlight">\(X_i\)</span> and <span class="math notranslate nohighlight">\(\bar{X}\)</span>
by definition.</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;E[(X_i - \mu)^2] = Var(X_i) = \sigma^2\\
&amp;E[(\bar{X} - \mu)^2] = Var(\bar{X}) = \frac{\sigma^2}{n}\end{split}\]</div>
</li>
<li><p>The expectation <span class="math notranslate nohighlight">\(E[(X_i - \mu)(\bar{X} - \mu)]\)</span> can be simplified to</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;E[(X_i - \mu)\cdot \frac{1}{n}\sum_{j}(X_j - \mu)]= \frac{1}{n} \sum_{j=1}^n E[(X_i - \mu)(X_j - \mu)]\\
&amp;= \frac{1}{n}E[(X_i - \mu)(X_i - \mu)] = \frac{1}{n}E[(X_i -\mu)^2] = \frac{\sigma^2}{n}\end{split}\]</div>
<p>All terms involving indices <span class="math notranslate nohighlight">\(j\neq i\)</span> disappear in the final steps since
<span class="math notranslate nohighlight">\(Cov(X_i, X_j) = E[(X_i-\mu)(X_j - \mu)] =0\)</span> due to their independnce.</p>
</li>
<li><p>Substituting the results back to the final line of Step 2,
we can verify that the sum simplifies to <span class="math notranslate nohighlight">\((n-1)\sigma^2\)</span>. Therefore,</p>
<div class="math notranslate nohighlight">
\[E[S^2] = \frac{1}{n-1} (n-1)\sigma^2 = \sigma^2.\]</div>
</li>
</ol>
<p>This shows why we devide by <span class="math notranslate nohighlight">\(n-1\)</span> instead of <span class="math notranslate nohighlight">\(n\)</span> when computing a sample variance;
this is key to making the estimator unbiased.</p>
<p>When sampling from normal populations, the sample variance <span class="math notranslate nohighlight">\(S^2\)</span> is also the MVUE for the
population variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<div class="note admonition">
<p class="admonition-title">Additional Exercise 💡: Sample Variance When <span class="math notranslate nohighlight">\(\mu\)</span> is Known</p>
<p>In an unrealistic situation where <span class="math notranslate nohighlight">\(\sigma^2\)</span> is not known but <span class="math notranslate nohighlight">\(\mu\)</span> is,
we must incorporate the known information into our variance estimation. Show that</p>
<div class="math notranslate nohighlight">
\[\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n}(X_i - \mu)^2\]</div>
<p>is an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
</div>
<div class="important admonition">
<p class="admonition-title">The Biased Case of Sample Standard Deviation</p>
<p>While the sample variance <span class="math notranslate nohighlight">\(S^2\)</span> is an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span>,
the sample standard deviation <span class="math notranslate nohighlight">\(S = \sqrt{S^2}\)</span> is a <strong>biased estimator</strong> of the
population standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p>Its biasedness can be shown using a concept called <em>Jensen’s inequality</em> and the fact that the square root
is a concave function. The details are beyond the scope of this course, but you are encouraged to
read about the topic independently.</p>
<p>We still use <span class="math notranslate nohighlight">\(S\)</span> as our estimator for <span class="math notranslate nohighlight">\(\sigma\)</span> because the formula is
straightforward and intuitive, while the bias is typically small, especially for larger sample sizes.</p>
</div>
</section>
</section>
<section id="brining-it-all-together">
<h2><span class="section-number">9.1.4. </span>Brining It All Together<a class="headerlink" href="#brining-it-all-together" title="Link to this heading"></a></h2>
<p>In this chapter, we’ve transitioned from probability theory to statistical inference by exploring the
properties of point estimators.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaway 📝</p>
<ol class="arabic simple">
<li><p><strong>Estimators</strong> yield <strong>estimates</strong> intended to approximate a fixed but unknown <strong>population parameter</strong>.
Estimates vary from sample to sample according to their <strong>sampling distribution</strong>.</p></li>
<li><p>The two most important distributional characteristics of an estimator are <strong>bias and variance</strong>.
Unbiased estimators target the correct parameter on average, while low-variance
estimators provide more consistent results across samples.</p></li>
<li><p><strong>Minimum Variance Unbiased Estimators (MVUEs)</strong> have the smallest variance among all unbiased estimators of
a target parameter.</p></li>
<li><p>We can show that <span class="math notranslate nohighlight">\(\bar{X}\)</span> are <span class="math notranslate nohighlight">\(S^2\)</span> are unbiased estimators of their respective targets,
<span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span>. When the population is normal, they are also the MVUEs.</p></li>
</ol>
</div>
<div class="info admonition">
<p class="admonition-title">Learning Objectives 🎯</p>
<p>These exercises will help you:</p>
<ul class="simple">
<li><p>Distinguish between <strong>parameters</strong> and <strong>statistics/estimators</strong></p></li>
<li><p>Understand and interpret the <strong>bias</strong> of an estimator</p></li>
<li><p>Understand <strong>variance</strong> and <strong>standard error</strong> as measures of estimator precision</p></li>
<li><p>Recognize that among unbiased estimators, <strong>lower variance is preferred</strong></p></li>
<li><p>Connect sample size to the <strong>precision</strong> of the sample mean</p></li>
</ul>
</div>
<div class="tip admonition">
<p class="admonition-title">Key Terminology</p>
<ul class="simple">
<li><p><strong>Parameter</strong>: A fixed (but often unknown) numerical value describing a population (e.g., μ, σ)</p></li>
<li><p><strong>Statistic</strong>: A numerical summary computed from sample data (e.g., x̄, s)</p></li>
<li><p><strong>Estimator</strong>: A statistic used to estimate a specific population parameter</p></li>
<li><p><strong>Bias</strong>: <span class="math notranslate nohighlight">\(\text{Bias}(\hat{\theta}) = E[\hat{\theta}] - \theta\)</span>; an unbiased estimator has <span class="math notranslate nohighlight">\(E[\hat{\theta}] = \theta\)</span></p></li>
<li><p><strong>Standard Error</strong>: The standard deviation of an estimator’s sampling distribution; for <span class="math notranslate nohighlight">\(\bar{X}\)</span>: <span class="math notranslate nohighlight">\(SE = \sigma/\sqrt{n}\)</span></p></li>
</ul>
</div>
</section>
<section id="id1">
<h2><span class="section-number">9.1.5. </span>Exercises<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<div class="note admonition">
<p class="admonition-title">Exercise 1: Parameter vs Statistic Identification</p>
<p>For each of the following, identify whether the quantity described is a <strong>parameter</strong> (fixed, unknown population characteristic) or a <strong>statistic</strong> (calculated from sample data).</p>
<ol class="loweralpha simple">
<li><p>The average response time of all requests to a company’s web server over the past year.</p></li>
<li><p>The sample mean CPU temperature calculated from 50 randomly selected measurements during a stress test.</p></li>
<li><p>The proportion of all manufactured semiconductors from a production line that contain defects.</p></li>
<li><p>The median battery life observed in a sample of 30 laptops tested under standard conditions.</p></li>
<li><p>The true variance of tensile strength for all steel cables produced by a manufacturer.</p></li>
<li><p>The sample standard deviation of fuel efficiency measurements from 25 test vehicles.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Parameter</strong></p>
<p class="sd-card-text">This describes the average for the <em>entire population</em> of web server requests over the year. It is a fixed value, denoted <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p class="sd-card-text"><strong>Part (b): Statistic</strong></p>
<p class="sd-card-text">This is computed from <em>sample data</em> (50 measurements). It will vary depending on which measurements are selected, denoted <span class="math notranslate nohighlight">\(\bar{x}\)</span>.</p>
<p class="sd-card-text"><strong>Part (c): Parameter</strong></p>
<p class="sd-card-text">This describes a characteristic of the <em>entire population</em> of semiconductors. It is a fixed proportion, denoted <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p class="sd-card-text"><strong>Part (d): Statistic</strong></p>
<p class="sd-card-text">This is the median from a <em>sample</em> of 30 laptops. It is computed from sample data and would vary with different samples.</p>
<p class="sd-card-text"><strong>Part (e): Parameter</strong></p>
<p class="sd-card-text">This is the true variance for <em>all</em> steel cables—the entire population. It is denoted <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<p class="sd-card-text"><strong>Part (f): Statistic</strong></p>
<p class="sd-card-text">This is computed from a <em>sample</em> of 25 vehicles. It is denoted <span class="math notranslate nohighlight">\(s\)</span> and serves as an estimate of <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p class="sd-card-text"><strong>Key distinction</strong>: Parameters describe populations and are typically unknown; statistics are computed from samples and serve as estimates of parameters.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 2: Understanding Estimators</p>
<p>A quality control engineer wants to estimate the mean diameter <span class="math notranslate nohighlight">\(\mu\)</span> of ball bearings produced by a manufacturing process. She considers using the following estimators based on a random sample <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span>:</p>
<ul class="simple">
<li><p><strong>Estimator A</strong>: <span class="math notranslate nohighlight">\(\hat{\mu}_A = \bar{X} = \frac{1}{n}\sum_{i=1}^{n} X_i\)</span> (sample mean)</p></li>
<li><p><strong>Estimator B</strong>: <span class="math notranslate nohighlight">\(\hat{\mu}_B = \tilde{X}\)</span> (sample median)</p></li>
<li><p><strong>Estimator C</strong>: <span class="math notranslate nohighlight">\(\hat{\mu}_C = \frac{X_{(1)} + X_{(n)}}{2}\)</span> (midrange: average of min and max)</p></li>
</ul>
<ol class="loweralpha simple">
<li><p>The sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> is always unbiased for <span class="math notranslate nohighlight">\(\mu\)</span>. For symmetric distributions, the median and midrange are also reasonable estimators that target the center. If multiple estimators target the same parameter, what property would you use to choose between them?</p></li>
<li><p>Which estimator uses all <span class="math notranslate nohighlight">\(n\)</span> observations in its calculation? Which uses only 2 observations?</p></li>
<li><p>The midrange (Estimator C) uses only the minimum and maximum values. What does this suggest about its reliability compared to the sample mean?</p></li>
<li><p>If you had to choose one estimator for a symmetric population, which would you choose and why?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Choosing among estimators</strong></p>
<p class="sd-card-text">When multiple estimators target the same parameter, we choose based on <strong>variance</strong> (or equivalently, standard error). Among estimators that are centered on the parameter, we prefer the one with the <strong>smallest variance</strong> because it produces estimates that are more consistently close to the true value.</p>
<p class="sd-card-text"><strong>Important note</strong>: <span class="math notranslate nohighlight">\(\bar{X}\)</span> is unbiased for <span class="math notranslate nohighlight">\(\mu\)</span> always. For symmetric distributions, the median and midrange are centered on the distribution’s midpoint, but finite-sample unbiasedness for <span class="math notranslate nohighlight">\(\mu\)</span> is not guaranteed in general.</p>
<p class="sd-card-text"><strong>Part (b): Observations used</strong></p>
<ul class="simple">
<li><p class="sd-card-text"><strong>Sample mean</strong> (Estimator A): Uses all <span class="math notranslate nohighlight">\(n\)</span> observations</p></li>
<li><p class="sd-card-text"><strong>Sample median</strong> (Estimator B): Uses all <span class="math notranslate nohighlight">\(n\)</span> observations (though only the middle values directly determine the result)</p></li>
<li><p class="sd-card-text"><strong>Midrange</strong> (Estimator C): Uses only 2 observations (the minimum and maximum)</p></li>
</ul>
<p class="sd-card-text"><strong>Part (c): Reliability of midrange</strong></p>
<p class="sd-card-text">The midrange uses only the two most extreme observations, making it:</p>
<ul class="simple">
<li><p class="sd-card-text">Highly sensitive to outliers</p></li>
<li><p class="sd-card-text">More variable from sample to sample</p></li>
<li><p class="sd-card-text">Less reliable than estimators that use all the data</p></li>
</ul>
<p class="sd-card-text">The sample mean “averages out” individual variations across all observations, leading to more stable (lower variance) estimates.</p>
<p class="sd-card-text"><strong>Part (d): Best choice</strong></p>
<p class="sd-card-text">The <strong>sample mean</strong> is the best choice because:</p>
<ul class="simple">
<li><p class="sd-card-text">It uses all available information (all <span class="math notranslate nohighlight">\(n\)</span> observations)</p></li>
<li><p class="sd-card-text">It is guaranteed unbiased for <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
<li><p class="sd-card-text">It has the lowest variance among common estimators for normal populations</p></li>
<li><p class="sd-card-text">It is not unduly influenced by any single observation (unlike the midrange)</p></li>
</ul>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 3: Understanding Bias</p>
<ol class="loweralpha simple">
<li><p>Define what it means for an estimator to be <strong>unbiased</strong>.</p></li>
<li><p>The sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> is an unbiased estimator of the population mean <span class="math notranslate nohighlight">\(\mu\)</span>. Explain what this means in practical terms.</p></li>
<li><p>Consider using the sample maximum <span class="math notranslate nohighlight">\(X_{(n)}\)</span> to estimate the population mean. Would this be biased or unbiased? If biased, in which direction (overestimate or underestimate)?</p></li>
<li><p>A researcher uses <span class="math notranslate nohighlight">\(\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X})^2\)</span> instead of <span class="math notranslate nohighlight">\(S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2\)</span> to estimate variance.</p>
<ol class="lowerroman simple">
<li><p>Which formula is unbiased for <span class="math notranslate nohighlight">\(\sigma^2\)</span>?</p></li>
<li><p>Does the biased formula overestimate or underestimate <span class="math notranslate nohighlight">\(\sigma^2\)</span> on average?</p></li>
<li><p>For <span class="math notranslate nohighlight">\(n = 10\)</span>, by approximately what percentage does the biased formula underestimate <span class="math notranslate nohighlight">\(\sigma^2\)</span>?</p></li>
</ol>
</li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Definition of unbiased</strong></p>
<p class="sd-card-text">An estimator is <strong>unbiased</strong> if its expected value equals the parameter it’s estimating:</p>
<div class="math notranslate nohighlight">
\[E[\hat{\theta}] = \theta\]</div>
<p class="sd-card-text">In other words, if we could take many, many samples and compute the estimator each time, the average of all those estimates would equal the true parameter value.</p>
<p class="sd-card-text"><strong>Part (b): Practical meaning</strong></p>
<p class="sd-card-text">Saying <span class="math notranslate nohighlight">\(\bar{X}\)</span> is unbiased for <span class="math notranslate nohighlight">\(\mu\)</span> means:</p>
<ul class="simple">
<li><p class="sd-card-text">On average, the sample mean equals the population mean</p></li>
<li><p class="sd-card-text">There’s no systematic tendency to overestimate or underestimate</p></li>
<li><p class="sd-card-text">Individual samples may give <span class="math notranslate nohighlight">\(\bar{x}\)</span> above or below <span class="math notranslate nohighlight">\(\mu\)</span>, but these errors balance out in the long run</p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(E[\bar{X}] = \mu\)</span> regardless of sample size</p></li>
</ul>
<p class="sd-card-text"><strong>Part (c): Sample maximum as estimator</strong></p>
<p class="sd-card-text">The sample maximum <span class="math notranslate nohighlight">\(X_{(n)}\)</span> would be a <strong>biased</strong> estimator of <span class="math notranslate nohighlight">\(\mu\)</span>:</p>
<ul class="simple">
<li><p class="sd-card-text">It would <strong>overestimate</strong> <span class="math notranslate nohighlight">\(\mu\)</span> on average</p></li>
<li><p class="sd-card-text">The maximum of a sample is typically above the center of the distribution</p></li>
<li><p class="sd-card-text">Only in unusual samples would the maximum be below <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
</ul>
<p class="sd-card-text"><strong>Part (d): Variance formula comparison</strong></p>
<p class="sd-card-text"><strong>(i)</strong> The formula with <span class="math notranslate nohighlight">\(n-1\)</span> in the denominator (<span class="math notranslate nohighlight">\(S^2\)</span>) is <strong>unbiased</strong> for <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<p class="sd-card-text"><strong>(ii)</strong> The formula with <span class="math notranslate nohighlight">\(n\)</span> in the denominator <strong>underestimates</strong> <span class="math notranslate nohighlight">\(\sigma^2\)</span> on average.</p>
<p class="sd-card-text"><strong>(iii)</strong> For <span class="math notranslate nohighlight">\(n = 10\)</span>:</p>
<p class="sd-card-text">The biased formula gives <span class="math notranslate nohighlight">\(\frac{n-1}{n} = \frac{9}{10} = 0.9\)</span> of the true variance on average.</p>
<p class="sd-card-text">This is an underestimate of <span class="math notranslate nohighlight">\(1 - 0.9 = 0.1 = 10\%\)</span>.</p>
<p class="sd-card-text"><strong>Note</strong>: This is why statistical software uses <span class="math notranslate nohighlight">\(n-1\)</span> by default—the correction ensures we get unbiased estimates of population variance.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 4: Why n-1 in Sample Variance?</p>
<p>A data scientist is analyzing algorithm runtimes and debates whether to use <span class="math notranslate nohighlight">\(n\)</span> or <span class="math notranslate nohighlight">\(n-1\)</span> in the denominator when computing sample variance.</p>
<ol class="loweralpha">
<li><p>Define both estimators:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{\sigma}^2_{biased} = \frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X})^2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2\)</span></p></li>
</ul>
<p>Which one is unbiased for <span class="math notranslate nohighlight">\(\sigma^2\)</span>?</p>
</li>
<li><p>Express <span class="math notranslate nohighlight">\(\hat{\sigma}^2_{biased}\)</span> in terms of <span class="math notranslate nohighlight">\(S^2\)</span>.</p></li>
<li><p>For a sample of size <span class="math notranslate nohighlight">\(n = 5\)</span>, by what percentage does <span class="math notranslate nohighlight">\(\hat{\sigma}^2_{biased}\)</span> underestimate <span class="math notranslate nohighlight">\(\sigma^2\)</span> on average?</p></li>
<li><p>As <span class="math notranslate nohighlight">\(n \to \infty\)</span>, what happens to the difference between these two estimators? Why does this make the choice less important for large samples?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Unbiased estimator</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(S^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2\)</span> is <strong>unbiased</strong> for <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<p class="sd-card-text">The formula with <span class="math notranslate nohighlight">\(n\)</span> in the denominator is biased (underestimates <span class="math notranslate nohighlight">\(\sigma^2\)</span>).</p>
<p class="sd-card-text"><strong>Part (b): Relationship</strong></p>
<div class="math notranslate nohighlight">
\[\hat{\sigma}^2_{biased} = \frac{n-1}{n} S^2\]</div>
<p class="sd-card-text"><strong>Part (c): Percentage underestimate for n = 5</strong></p>
<div class="math notranslate nohighlight">
\[E[\hat{\sigma}^2_{biased}] = \frac{n-1}{n} \sigma^2 = \frac{4}{5} \sigma^2 = 0.8 \sigma^2\]</div>
<p class="sd-card-text">The biased estimator underestimates by <span class="math notranslate nohighlight">\(1 - 0.8 = 0.2 = 20\%\)</span> on average.</p>
<p class="sd-card-text"><strong>Part (d): Large sample behavior</strong></p>
<p class="sd-card-text">As <span class="math notranslate nohighlight">\(n \to \infty\)</span>:</p>
<div class="math notranslate nohighlight">
\[\frac{n-1}{n} \to 1\]</div>
<p class="sd-card-text">The two estimators become essentially identical. For <span class="math notranslate nohighlight">\(n = 100\)</span>, the difference is only 1%. For <span class="math notranslate nohighlight">\(n = 1000\)</span>, it’s 0.1%.</p>
<p class="sd-card-text">This makes the choice less important for large samples because the bias becomes negligible compared to the sampling variability.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 5: Variance of Estimators</p>
<p>An aerospace engineer is estimating the mean thrust <span class="math notranslate nohighlight">\(\mu\)</span> of a rocket engine. Two different sampling strategies yield the following estimators:</p>
<ul class="simple">
<li><p><strong>Strategy 1</strong>: Take <span class="math notranslate nohighlight">\(n = 16\)</span> independent measurements and compute <span class="math notranslate nohighlight">\(\hat{\mu}_1 = \bar{X}_{16}\)</span>.</p></li>
<li><p><strong>Strategy 2</strong>: Take <span class="math notranslate nohighlight">\(n = 64\)</span> independent measurements and compute <span class="math notranslate nohighlight">\(\hat{\mu}_2 = \bar{X}_{64}\)</span>.</p></li>
</ul>
<p>Assume the population standard deviation is <span class="math notranslate nohighlight">\(\sigma = 200\)</span> Newtons.</p>
<ol class="loweralpha simple">
<li><p>Both estimators are unbiased. Compute the variance of each estimator.</p></li>
<li><p>Compute the standard error (standard deviation of the sampling distribution) for each estimator.</p></li>
<li><p>By what factor does the standard error decrease when going from Strategy 1 to Strategy 2?</p></li>
<li><p>If the engineer wants to reduce the standard error by half (compared to Strategy 1), how many measurements are needed?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Variance of each estimator</strong></p>
<p class="sd-card-text">For <span class="math notranslate nohighlight">\(\bar{X}\)</span>: <span class="math notranslate nohighlight">\(Var(\bar{X}) = \frac{\sigma^2}{n}\)</span></p>
<ul class="simple">
<li><p class="sd-card-text">Strategy 1 (<span class="math notranslate nohighlight">\(n = 16\)</span>): <span class="math notranslate nohighlight">\(Var(\hat{\mu}_1) = \frac{200^2}{16} = \frac{40000}{16} = 2500\)</span> N²</p></li>
<li><p class="sd-card-text">Strategy 2 (<span class="math notranslate nohighlight">\(n = 64\)</span>): <span class="math notranslate nohighlight">\(Var(\hat{\mu}_2) = \frac{200^2}{64} = \frac{40000}{64} = 625\)</span> N²</p></li>
</ul>
<p class="sd-card-text"><strong>Part (b): Standard error</strong></p>
<ul class="simple">
<li><p class="sd-card-text">Strategy 1: <span class="math notranslate nohighlight">\(SE_1 = \sqrt{2500} = 50\)</span> N</p></li>
<li><p class="sd-card-text">Strategy 2: <span class="math notranslate nohighlight">\(SE_2 = \sqrt{625} = 25\)</span> N</p></li>
</ul>
<p class="sd-card-text"><strong>Part (c): Factor of decrease</strong></p>
<div class="math notranslate nohighlight">
\[\frac{SE_1}{SE_2} = \frac{50}{25} = 2\]</div>
<p class="sd-card-text">The standard error decreased by a factor of <strong>2</strong>.</p>
<p class="sd-card-text">Note: Sample size increased by factor of 4, and <span class="math notranslate nohighlight">\(\sqrt{4} = 2\)</span>.</p>
<p class="sd-card-text"><strong>Part (d): Sample size to halve SE</strong></p>
<p class="sd-card-text">To halve the SE from Strategy 1 (from 50 to 25 N), we need:</p>
<div class="math notranslate nohighlight">
\[\frac{200}{\sqrt{n}} = 25 \implies \sqrt{n} = 8 \implies n = 64\]</div>
<p class="sd-card-text">This confirms Strategy 2. In general, to halve SE, <strong>quadruple</strong> the sample size.</p>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">200</span>

<span class="c1"># Variance</span>
<span class="n">sigma</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">16</span><span class="w">  </span><span class="c1"># 2500</span>
<span class="n">sigma</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">64</span><span class="w">  </span><span class="c1"># 625</span>

<span class="c1"># Standard error</span>
<span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">16</span><span class="p">)</span><span class="w">  </span><span class="c1"># 50</span>
<span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">64</span><span class="p">)</span><span class="w">  </span><span class="c1"># 25</span>
</pre></div>
</div>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 6: Bias vs Variance Tradeoff (Conceptual)</p>
<p>Consider two estimators for a parameter <span class="math notranslate nohighlight">\(\theta\)</span>:</p>
<ul class="simple">
<li><p><strong>Estimator A</strong>: Unbiased (hits the target on average), but high variability</p></li>
<li><p><strong>Estimator B</strong>: Slightly biased (consistently a bit off), but very low variability</p></li>
</ul>
<ol class="loweralpha simple">
<li><p>Draw (or describe) what the sampling distributions of these two estimators might look like relative to the true value <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
<li><p>If Estimator A gives values that range from 80 to 120 (centered at 100), and Estimator B gives values that range from 98 to 104 (centered at 102), and the true value is <span class="math notranslate nohighlight">\(\theta = 100\)</span>, which estimator would you prefer for a single estimate? Explain.</p></li>
<li><p>A dartboard analogy is often used: Estimator A hits all around the bullseye (unbiased but imprecise), while Estimator B consistently hits the same spot slightly off-center (biased but precise). Which pattern would give you a better score on average?</p></li>
<li><p>In practice, why do statisticians often prefer unbiased estimators even when a biased estimator might occasionally be more accurate?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Sampling distributions</strong></p>
<ul class="simple">
<li><p class="sd-card-text"><strong>Estimator A</strong>: A wide, spread-out distribution centered exactly at <span class="math notranslate nohighlight">\(\theta = 100\)</span>. Values could be far from 100 in either direction, but they average to 100.</p></li>
<li><p class="sd-card-text"><strong>Estimator B</strong>: A narrow, concentrated distribution centered at 102 (slightly off from <span class="math notranslate nohighlight">\(\theta = 100\)</span>). Values are consistently close to 102, never exactly hitting 100.</p></li>
</ul>
<p class="sd-card-text"><strong>Part (b): Preference for single estimate</strong></p>
<ul class="simple">
<li><p class="sd-card-text"><strong>Estimator A</strong> (80-120, centered at 100): Could give you anything from 80 to 120. Highly unpredictable.</p></li>
<li><p class="sd-card-text"><strong>Estimator B</strong> (98-104, centered at 102): Will give you something between 98 and 104. Very predictable, but always slightly high.</p></li>
</ul>
<p class="sd-card-text">For a single estimate, <strong>Estimator B</strong> might be preferred because:</p>
<ul class="simple">
<li><p class="sd-card-text">The worst case (104) is closer to 100 than Estimator A’s worst cases (80 or 120)</p></li>
<li><p class="sd-card-text">Even though it’s biased, the estimates are all “in the ballpark”</p></li>
<li><p class="sd-card-text">Estimator A has a wide range where individual estimates could be quite wrong</p></li>
</ul>
<p class="sd-card-text"><strong>Part (c): Dartboard analogy</strong></p>
<ul class="simple">
<li><p class="sd-card-text"><strong>Estimator A</strong> (all around bullseye): Some darts hit close to center, but many are far away</p></li>
<li><p class="sd-card-text"><strong>Estimator B</strong> (consistent off-center): All darts land in a tight cluster, just not at the center</p></li>
</ul>
<p class="sd-card-text">For overall accuracy, <strong>Estimator B</strong> would typically score better because the consistent small miss beats the highly variable hits and misses of Estimator A.</p>
<p class="sd-card-text"><strong>Part (d): Why prefer unbiased estimators</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>Systematic errors compound</strong>: In repeated use or when combining estimates, bias doesn’t cancel out, but random errors do</p></li>
<li><p class="sd-card-text"><strong>Interpretability</strong>: Unbiased estimates are easier to explain and trust</p></li>
<li><p class="sd-card-text"><strong>Unknown bias</strong>: We often don’t know the size of the bias, so we can’t correct for it</p></li>
<li><p class="sd-card-text"><strong>Statistical theory</strong>: Many confidence interval and hypothesis testing procedures assume unbiased estimators</p></li>
<li><p class="sd-card-text"><strong>Scientific standards</strong>: Many fields require unbiased methods for credibility</p></li>
</ol>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 7: Standard Error of the Sample Mean</p>
<p>A software company tests <span class="math notranslate nohighlight">\(n = 100\)</span> randomly selected user sessions to estimate the mean session duration. Based on historical data, the population standard deviation is known to be <span class="math notranslate nohighlight">\(\sigma = 8\)</span> minutes.</p>
<ol class="loweralpha simple">
<li><p>What is the standard error of the sample mean?</p></li>
<li><p>If the company increases the sample size to <span class="math notranslate nohighlight">\(n = 400\)</span>, what is the new standard error?</p></li>
<li><p>By what factor did the standard error decrease when <span class="math notranslate nohighlight">\(n\)</span> increased from 100 to 400?</p></li>
<li><p>How large should <span class="math notranslate nohighlight">\(n\)</span> be to achieve a standard error of at most 0.5 minutes?</p></li>
<li><p>A colleague suggests that doubling the sample size will halve the standard error. Is this correct? Explain.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Given: <span class="math notranslate nohighlight">\(\sigma = 8\)</span> minutes</p>
<p class="sd-card-text"><strong>Part (a): SE with n = 100</strong></p>
<div class="math notranslate nohighlight">
\[SE = \frac{\sigma}{\sqrt{n}} = \frac{8}{\sqrt{100}} = \frac{8}{10} = 0.8 \text{ minutes}\]</div>
<p class="sd-card-text"><strong>Part (b): SE with n = 400</strong></p>
<div class="math notranslate nohighlight">
\[SE = \frac{8}{\sqrt{400}} = \frac{8}{20} = 0.4 \text{ minutes}\]</div>
<p class="sd-card-text"><strong>Part (c): Factor of decrease</strong></p>
<div class="math notranslate nohighlight">
\[\frac{SE_{n=100}}{SE_{n=400}} = \frac{0.8}{0.4} = 2\]</div>
<p class="sd-card-text">The SE decreased by a factor of 2. Note: <span class="math notranslate nohighlight">\(n\)</span> increased by a factor of 4, and <span class="math notranslate nohighlight">\(\sqrt{4} = 2\)</span>.</p>
<p class="sd-card-text"><strong>Part (d): Required n for SE ≤ 0.5</strong></p>
<div class="math notranslate nohighlight">
\[\frac{8}{\sqrt{n}} \leq 0.5\]</div>
<div class="math notranslate nohighlight">
\[\sqrt{n} \geq \frac{8}{0.5} = 16\]</div>
<div class="math notranslate nohighlight">
\[n \geq 256\]</div>
<p class="sd-card-text">Need at least <strong>n = 256</strong> sessions.</p>
<p class="sd-card-text"><strong>Part (e): Doubling sample size</strong></p>
<p class="sd-card-text"><strong>Incorrect</strong>. Doubling the sample size reduces the standard error by a factor of <span class="math notranslate nohighlight">\(\sqrt{2} \approx 1.41\)</span>, not by half.</p>
<p class="sd-card-text">To halve the standard error, you must <strong>quadruple</strong> the sample size because:</p>
<div class="math notranslate nohighlight">
\[SE \propto \frac{1}{\sqrt{n}}\]</div>
<p class="sd-card-text">If you want <span class="math notranslate nohighlight">\(SE_{new} = \frac{1}{2} SE_{old}\)</span>, then <span class="math notranslate nohighlight">\(\sqrt{n_{new}} = 2\sqrt{n_{old}}\)</span>, so <span class="math notranslate nohighlight">\(n_{new} = 4n_{old}\)</span>.</p>
<p class="sd-card-text"><strong>R verification:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">8</span>

<span class="c1"># SE for different n</span>
<span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">100</span><span class="p">)</span><span class="w">   </span><span class="c1"># 0.8</span>
<span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">400</span><span class="p">)</span><span class="w">   </span><span class="c1"># 0.4</span>

<span class="c1"># Required n for SE = 0.5</span>
<span class="p">(</span><span class="n">sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w">     </span><span class="c1"># 256</span>
</pre></div>
</div>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 8: True/False Conceptual Questions</p>
<p>Determine whether each statement is <strong>True</strong> or <strong>False</strong>. Provide a brief justification.</p>
<ol class="loweralpha simple">
<li><p>An unbiased estimator will always give the exact value of the parameter.</p></li>
<li><p>The sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span> is an unbiased estimator of the population mean <span class="math notranslate nohighlight">\(\mu\)</span> for any sample size.</p></li>
<li><p>If two estimators are both unbiased, the one with smaller variance is generally preferred.</p></li>
<li><p>The sample variance <span class="math notranslate nohighlight">\(S^2 = \frac{1}{n-1}\sum(X_i - \bar{X})^2\)</span> is an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p></li>
<li><p>Increasing sample size reduces the variance of the sample mean.</p></li>
<li><p>A biased estimator is always worse than an unbiased estimator.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): False</strong></p>
<p class="sd-card-text">Being unbiased means the estimator is correct <em>on average</em> across many samples. Any single sample’s estimate may be above or below the true parameter. Unbiased ≠ perfect.</p>
<p class="sd-card-text"><strong>Part (b): True</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(E[\bar{X}] = \mu\)</span> regardless of the population distribution or sample size. This is a fundamental property of the sample mean.</p>
<p class="sd-card-text"><strong>Part (c): True</strong></p>
<p class="sd-card-text">Among unbiased estimators, lower variance means estimates are more consistently close to the true parameter value. We want precision along with accuracy.</p>
<p class="sd-card-text"><strong>Part (d): True</strong></p>
<p class="sd-card-text">The formula <span class="math notranslate nohighlight">\(S^2 = \frac{1}{n-1}\sum(X_i - \bar{X})^2\)</span> is unbiased for <span class="math notranslate nohighlight">\(\sigma^2\)</span> regardless of the underlying distribution, as long as the observations are independent with the same variance.</p>
<p class="sd-card-text"><strong>Part (e): True</strong></p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(Var(\bar{X}) = \frac{\sigma^2}{n}\)</span>, which decreases as <span class="math notranslate nohighlight">\(n\)</span> increases. Larger samples give more precise estimates.</p>
<p class="sd-card-text"><strong>Part (f): False</strong></p>
<p class="sd-card-text">A biased estimator with very low variance might actually give estimates that are, on average, closer to the true value than an unbiased estimator with high variance. The “best” estimator depends on the context and what properties matter most.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 9: Application - Sensor Calibration</p>
<p>A biomedical engineer is calibrating a blood pressure sensor. She tests the sensor against a known reference standard with true value <span class="math notranslate nohighlight">\(\mu = 120\)</span> mmHg. After <span class="math notranslate nohighlight">\(n = 20\)</span> independent measurements, she records the following data:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>118.2, 121.5, 119.8, 122.1, 117.9, 120.4, 123.2, 118.6, 121.0, 119.5,
120.8, 117.5, 122.8, 119.2, 121.7, 118.9, 120.1, 122.4, 119.6, 120.5
</pre></div>
</div>
<ol class="loweralpha simple">
<li><p>Compute the sample mean <span class="math notranslate nohighlight">\(\bar{x}\)</span> and sample standard deviation <span class="math notranslate nohighlight">\(s\)</span>.</p></li>
<li><p>The observed “bias” in this sample is <span class="math notranslate nohighlight">\(\bar{x} - \mu\)</span>. Calculate this value. Does the sensor appear to overestimate or underestimate?</p></li>
<li><p>If the engineer wanted to correct for this observed bias, how might she adjust future readings?</p></li>
<li><p>Can we conclude from this single sample that the estimator <span class="math notranslate nohighlight">\(\bar{X}\)</span> is biased? Explain why or why not.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Summary statistics</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">measurements</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">118.2</span><span class="p">,</span><span class="w"> </span><span class="m">121.5</span><span class="p">,</span><span class="w"> </span><span class="m">119.8</span><span class="p">,</span><span class="w"> </span><span class="m">122.1</span><span class="p">,</span><span class="w"> </span><span class="m">117.9</span><span class="p">,</span><span class="w"> </span><span class="m">120.4</span><span class="p">,</span><span class="w"> </span><span class="m">123.2</span><span class="p">,</span><span class="w"> </span><span class="m">118.6</span><span class="p">,</span>
<span class="w">                  </span><span class="m">121.0</span><span class="p">,</span><span class="w"> </span><span class="m">119.5</span><span class="p">,</span><span class="w"> </span><span class="m">120.8</span><span class="p">,</span><span class="w"> </span><span class="m">117.5</span><span class="p">,</span><span class="w"> </span><span class="m">122.8</span><span class="p">,</span><span class="w"> </span><span class="m">119.2</span><span class="p">,</span><span class="w"> </span><span class="m">121.7</span><span class="p">,</span><span class="w"> </span><span class="m">118.9</span><span class="p">,</span>
<span class="w">                  </span><span class="m">120.1</span><span class="p">,</span><span class="w"> </span><span class="m">122.4</span><span class="p">,</span><span class="w"> </span><span class="m">119.6</span><span class="p">,</span><span class="w"> </span><span class="m">120.5</span><span class="p">)</span>

<span class="nf">mean</span><span class="p">(</span><span class="n">measurements</span><span class="p">)</span><span class="w">  </span><span class="c1"># 120.285</span>
<span class="nf">sd</span><span class="p">(</span><span class="n">measurements</span><span class="p">)</span><span class="w">    </span><span class="c1"># 1.704</span>
</pre></div>
</div>
<ul class="simple">
<li><p class="sd-card-text">Sample mean: <span class="math notranslate nohighlight">\(\bar{x} = 120.285\)</span> mmHg</p></li>
<li><p class="sd-card-text">Sample standard deviation: <span class="math notranslate nohighlight">\(s = 1.704\)</span> mmHg</p></li>
</ul>
<p class="sd-card-text"><strong>Part (b): Observed bias</strong></p>
<div class="math notranslate nohighlight">
\[\bar{x} - \mu = 120.285 - 120 = 0.285 \text{ mmHg}\]</div>
<p class="sd-card-text">The sensor appears to be <strong>slightly overestimating</strong> the true pressure, but the difference is small.</p>
<p class="sd-card-text"><strong>Part (c): Calibration correction</strong></p>
<p class="sd-card-text">If this bias is consistent, the engineer could apply a <strong>calibration correction</strong>:</p>
<ul class="simple">
<li><p class="sd-card-text">Corrected reading = Raw reading − 0.285</p></li>
<li><p class="sd-card-text">Or equivalently, use an adjusted estimator: <span class="math notranslate nohighlight">\(\hat{\mu}_{corrected} = \bar{X} - 0.285\)</span></p></li>
</ul>
<p class="sd-card-text"><strong>Part (d): Can we conclude bias?</strong></p>
<p class="sd-card-text">We cannot conclude the estimator <span class="math notranslate nohighlight">\(\bar{X}\)</span> is biased because:</p>
<ul class="simple">
<li><p class="sd-card-text"><strong>Bias is a property of the sampling distribution</strong>, not a single sample</p></li>
<li><p class="sd-card-text">Even an unbiased estimator will not equal <span class="math notranslate nohighlight">\(\mu\)</span> exactly in any given sample</p></li>
<li><p class="sd-card-text">The deviation <span class="math notranslate nohighlight">\(\bar{x} - \mu = 0.285\)</span> is well within the expected sampling variability</p></li>
<li><p class="sd-card-text">With estimated <span class="math notranslate nohighlight">\(SE = s/\sqrt{n} = 1.704/\sqrt{20} \approx 0.38\)</span> mmHg (using <span class="math notranslate nohighlight">\(s\)</span> since <span class="math notranslate nohighlight">\(\sigma\)</span> is unknown), a deviation of 0.285 is not unusual</p></li>
<li><p class="sd-card-text">To assess true bias, we would need <strong>repeated calibration tests</strong> and examine whether the average of many <span class="math notranslate nohighlight">\(\bar{x}\)</span> values systematically differs from <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
</ul>
</div>
</details></div>
</section>
<hr class="docutils" />
<section id="additional-practice-problems">
<h2><span class="section-number">9.1.6. </span>Additional Practice Problems<a class="headerlink" href="#additional-practice-problems" title="Link to this heading"></a></h2>
<p><strong>True/False Questions</strong> (1 point each)</p>
<ol class="arabic">
<li><p>The population mean <span class="math notranslate nohighlight">\(\mu\)</span> is a random variable.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>Different samples from the same population will yield different values of <span class="math notranslate nohighlight">\(\bar{x}\)</span>.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>An estimator with zero bias will always produce estimates equal to the true parameter.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>The standard error of <span class="math notranslate nohighlight">\(\bar{X}\)</span> depends on the sample size.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>Among unbiased estimators, we prefer the one with the smallest variance.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>Quadrupling the sample size will halve the standard error.</p>
<p>Ⓣ or Ⓕ</p>
</li>
</ol>
<p><strong>Multiple Choice Questions</strong> (2 points each)</p>
<ol class="arabic" start="7">
<li><p>Which of the following is a parameter?</p>
<p>Ⓐ The average height of 50 randomly selected students</p>
<p>Ⓑ The standard deviation of test scores for all students in a school</p>
<p>Ⓒ The sample proportion of defective items in a shipment</p>
<p>Ⓓ The median income from a survey of 1,000 households</p>
</li>
<li><p>The sample variance formula uses <span class="math notranslate nohighlight">\(n-1\)</span> instead of <span class="math notranslate nohighlight">\(n\)</span> in the denominator because:</p>
<p>Ⓐ It makes calculations easier</p>
<p>Ⓑ It produces an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span></p>
<p>Ⓒ It produces larger variance estimates</p>
<p>Ⓓ It is required for the normal distribution</p>
</li>
<li><p>If <span class="math notranslate nohighlight">\(\sigma = 20\)</span> and <span class="math notranslate nohighlight">\(n = 100\)</span>, the standard error of <span class="math notranslate nohighlight">\(\bar{X}\)</span> is:</p>
<p>Ⓐ 20</p>
<p>Ⓑ 2</p>
<p>Ⓒ 0.2</p>
<p>Ⓓ 200</p>
</li>
<li><p>To reduce the standard error by a factor of 3, the sample size must be increased by a factor of:</p>
<p>Ⓐ 3</p>
<p>Ⓑ 6</p>
<p>Ⓒ 9</p>
<p>Ⓓ <span class="math notranslate nohighlight">\(\sqrt{3}\)</span></p>
</li>
<li><p>Which quantity describes the precision of an estimator?</p>
<p>Ⓐ Bias</p>
<p>Ⓑ Variance</p>
<p>Ⓒ Expected value</p>
<p>Ⓓ Sample size</p>
</li>
<li><p>An unbiased estimator with variance 100 vs. a biased estimator (bias = 2) with variance 25. Which has smaller expected squared error from the true parameter?</p>
<p>Ⓐ The unbiased estimator (expected squared error = 100)</p>
<p>Ⓑ The biased estimator (expected squared error = 29)</p>
<p>Ⓒ They are equal</p>
<p>Ⓓ Cannot be determined</p>
</li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Answers to Practice Problems</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>True/False Answers:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>False</strong> — <span class="math notranslate nohighlight">\(\mu\)</span> is a fixed (though unknown) population constant, not a random variable.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — Due to sampling variability, different samples produce different sample means.</p></li>
<li><p class="sd-card-text"><strong>False</strong> — Zero bias means correct <em>on average</em> over many samples, not correct every time.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — <span class="math notranslate nohighlight">\(SE = \sigma/\sqrt{n}\)</span>, which depends on <span class="math notranslate nohighlight">\(n\)</span>.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — Lower variance means more precision (estimates cluster more tightly around the parameter).</p></li>
<li><p class="sd-card-text"><strong>True</strong> — <span class="math notranslate nohighlight">\(SE \propto 1/\sqrt{n}\)</span>, so if <span class="math notranslate nohighlight">\(n\)</span> increases by 4, SE decreases by <span class="math notranslate nohighlight">\(\sqrt{4} = 2\)</span>.</p></li>
</ol>
<p class="sd-card-text"><strong>Multiple Choice Answers:</strong></p>
<ol class="arabic simple" start="7">
<li><p class="sd-card-text"><strong>Ⓑ</strong> — “All students in a school” indicates this is a population characteristic, making it a parameter.</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — The <span class="math notranslate nohighlight">\(n-1\)</span> correction (Bessel’s correction) makes <span class="math notranslate nohighlight">\(S^2\)</span> unbiased for <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — <span class="math notranslate nohighlight">\(SE = \sigma/\sqrt{n} = 20/\sqrt{100} = 20/10 = 2\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓒ</strong> — To reduce SE by factor of 3, need <span class="math notranslate nohighlight">\(\sqrt{n_{new}/n_{old}} = 3\)</span>, so <span class="math notranslate nohighlight">\(n_{new}/n_{old} = 9\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — Variance measures how spread out the estimates are around their expected value (precision).</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — Expected squared error = Variance + Bias². Unbiased: 100 + 0 = 100. Biased: 25 + 4 = 29. The biased estimator has smaller expected squared error.</p></li>
</ol>
</div>
</details></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="9. Confidence Intervals and Bounds" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="9-2-ci-sigma-known.html" class="btn btn-neutral float-right" title="9.2. Confidence Intervals for the Population Mean, When σ is Known" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
  <p class="footer-credits-inline">
    <strong>Website Credits:</strong>
    Website development by Dr. Timothy Reese and Halin Shin.
    Generative AI tools were used to draft and refine some prose, code, and documentation; all content was reviewed by the instructors.
    Models: OpenAI o3 (2025-04-16 release) and Anthropic Claude Opus 4.1 (2025-08-05).
  </p>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 

<!-- Floating Chat Button -->
<button id="chatbot-toggle" class="chatbot-fab" aria-label="Open AI Course Assistant" aria-expanded="false">
  <span class="chatbot-fab-badge">BETA</span>
  <svg class="chatbot-fab-icon chatbot-icon-open" fill="none" stroke="currentColor" viewBox="0 0 24 24">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
          d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"/>
  </svg>
  <svg class="chatbot-fab-icon chatbot-icon-close" fill="none" stroke="currentColor" viewBox="0 0 24 24" style="display:none;">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
  </svg>
  <span class="chatbot-fab-text">Ask AI Assistant</span>
</button>

<!-- Chat Panel - Fullscreen -->
<div id="chatbot-panel" class="chatbot-panel" aria-hidden="true">
  <div class="chatbot-panel-topbar">
    <button id="chatbot-close" class="chatbot-panel-close-minimal" aria-label="Close chat">
      <svg width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
      </svg>
    </button>
    <a href="https://advert-cingular-employer-humor.trycloudflare.com/" 
       target="_blank" 
       rel="noopener noreferrer" 
       class="chatbot-newtab">
      <svg width="16" height="16" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
              d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"/>
      </svg>
      Open in new tab
    </a>
  </div>
  <iframe id="chatbot-iframe" class="chatbot-iframe" title="STAT 350 AI Course Assistant"></iframe>
</div>

<script>
(function() {
  const CHATBOT_BASE_URL = 'https://advert-cingular-employer-humor.trycloudflare.com/';
  
  const toggle = document.getElementById('chatbot-toggle');
  const panel = document.getElementById('chatbot-panel');
  const closeBtn = document.getElementById('chatbot-close');
  const iframe = document.getElementById('chatbot-iframe');
  const iconOpen = toggle.querySelector('.chatbot-icon-open');
  const iconClose = toggle.querySelector('.chatbot-icon-close');
  
  let isOpen = false;
  let iframeLoaded = false;
  
  function getPageContext() {
    const pageTitle = document.title || '';
    const pageUrl = window.location.href;
    const pagePath = window.location.pathname;
    
    const h1 = document.querySelector('.rst-content h1, h1');
    const heading = h1 ? h1.textContent.replace(/[¶#]/g, '').trim() : '';
    
    const breadcrumbs = document.querySelectorAll('.wy-breadcrumbs li a');
    const breadcrumbPath = Array.from(breadcrumbs).map(a => a.textContent.trim()).join(' > ');
    
    const chapterMatch = pagePath.match(/chapter(\d+)/i);
    const chapter = chapterMatch ? 'Chapter ' + chapterMatch[1] : '';
    
    return {
      title: heading || pageTitle,
      url: pageUrl,
      path: pagePath,
      breadcrumbs: breadcrumbPath,
      chapter: chapter
    };
  }
  
  function buildChatbotUrl(context) {
    const params = new URLSearchParams();
    if (context.title) params.set('page_title', context.title);
    if (context.url) params.set('page_url', context.url);
    if (context.chapter) params.set('chapter', context.chapter);
    if (context.breadcrumbs) params.set('breadcrumbs', context.breadcrumbs);
    
    const queryString = params.toString();
    return queryString ? CHATBOT_BASE_URL + '?' + queryString : CHATBOT_BASE_URL;
  }
  
  function openChat() {
    const context = getPageContext();
    
    const newUrl = buildChatbotUrl(context);
    if (!iframeLoaded || iframe.dataset.lastUrl !== context.url) {
      iframe.src = newUrl;
      iframe.dataset.lastUrl = context.url;
      iframeLoaded = true;
    }
    
    panel.classList.add('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'false');
    toggle.setAttribute('aria-expanded', 'true');
    iconOpen.style.display = 'none';
    iconClose.style.display = 'block';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Close';
    isOpen = true;
    
    toggle.classList.add('chatbot-fab-opened');
    
    // Prevent body scroll when panel is open
    document.body.style.overflow = 'hidden';
  }
  
  function closeChat() {
    panel.classList.remove('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'true');
    toggle.setAttribute('aria-expanded', 'false');
    iconOpen.style.display = 'block';
    iconClose.style.display = 'none';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Ask AI Assistant';
    isOpen = false;
    
    // Restore body scroll
    document.body.style.overflow = '';
  }
  
  function toggleChat() {
    if (isOpen) {
      closeChat();
    } else {
      openChat();
    }
  }
  
  toggle.addEventListener('click', toggleChat);
  closeBtn.addEventListener('click', closeChat);
  
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape' && isOpen) {
      closeChat();
    }
  });
})();
</script>


</body>
</html>