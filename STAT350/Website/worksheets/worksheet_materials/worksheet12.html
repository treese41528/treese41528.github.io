

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Worksheet 12: Point Estimators and Unbiased Estimation &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=d9cab97b" />
      <link rel="stylesheet" type="text/css" href="../../_static/credits.css?v=f7efa099" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/Website/worksheets/worksheet_materials/worksheet12.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=3cc62c56"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Worksheet 13: Introduction to Confidence Intervals" href="worksheet13.html" />
    <link rel="prev" title="Worksheet 11: The Central Limit Theorem" href="worksheet11.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../worksheets_index.html">Course Worksheets</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../worksheets_index.html#worksheets">Worksheets</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#troubleshooting-guide">Troubleshooting Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#part-1-the-bernoulli-and-binomial-distributions">Part 1: The Bernoulli and Binomial Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#the-binomial-distribution">The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#part-2-the-poisson-distribution">Part 2: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#part-3-other-named-discrete-distributions">Part 3: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#part-2-the-standard-normal-table">Part 2: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#part-3-z-score-transformation">Part 3: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet11.html">Worksheet 11: The Central Limit Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#tutorial-generating-the-sampling-distribution-of-bar-x">Tutorial: Generating the Sampling Distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#part-1-exploring-clt-with-skewed-distributions">Part 1: Exploring CLT with Skewed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#part-2-application-of-the-clt">Part 2: Application of the CLT</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#part-3-beyond-mean-and-sum">Part 3: Beyond Mean and Sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#part-4-exploring-clt-generalizability-with-ai-assistance-exploration">Part 4: Exploring CLT Generalizability with AI Assistance (Exploration)</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Worksheet 12: Point Estimators and Unbiased Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-1-estimating-parameters-of-the-exponential-distribution">Part 1: Estimating Parameters of the Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-2-estimating-the-maximum-of-a-uniform-distribution">Part 2: Estimating the Maximum of a Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-3-minimum-variance-unbiased-estimators-mvue">Part 3: Minimum Variance Unbiased Estimators (MVUE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet13.html">Worksheet 13: Introduction to Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#part-1-pivotal-quantities-and-deriving-confidence-intervals">Part 1: Pivotal Quantities and Deriving Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#part-2-sample-size-determination">Part 2: Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#part-3-one-sided-confidence-bounds">Part 3: One-Sided Confidence Bounds</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#part-4-confidence-intervals-when-is-unknown">Part 4: Confidence Intervals When σ is Unknown</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet14.html">Worksheet 14: Student’s t-Distribution and Statistical Power</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#assumptions-for-t-distribution-inference">Assumptions for t-Distribution Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#part-1-analyzing-chick-growth-with-confidence-intervals">Part 1: Analyzing Chick Growth with Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#part-2-introduction-to-hypothesis-testing">Part 2: Introduction to Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#part-3-sample-size-determination-and-power-analysis">Part 3: Sample Size Determination and Power Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html">Worksheet 15: Hypothesis Testing for Population Means</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#introduction-to-hypothesis-testing">Introduction to Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#part-1-simulating-test-statistics-and-p-values">Part 1: Simulating Test Statistics and P-values</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#the-t-test-when-is-unknown">The t-Test When σ is Unknown</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#relationship-between-confidence-intervals-and-hypothesis-tests">Relationship Between Confidence Intervals and Hypothesis Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#part-2-epa-ozone-concentration-analysis">Part 2: EPA Ozone Concentration Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html">Getting Started with R and RStudio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#getting-started-with-swirl">Getting Started with swirl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#alternative-r-learning-resources">Alternative R Learning Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_quick_reference.html">Quick Reference Table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html">Computer Assignments and Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-structure-by-session">Assignment Structure by Session</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html">Function Reference Part 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#simulation-functions">Simulation Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html">Function Reference Part 2: Inference Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html#diagnostic-plots-for-assumptions">Diagnostic Plots for Assumptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#tables-reporting">Tables &amp; Reporting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#data-import-validation">Data Import &amp; Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#statistical-assumptions">Statistical Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#common-errors-to-avoid">Common Errors to Avoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#workflow-template">Workflow Template</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html">Course Datasets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#primary-course-dataset-apprating">Primary Course Dataset - AppRating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#tutorial-support-datasets">Tutorial Support Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#loading-datasets-in-r">Loading Datasets in R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#built-in-r-datasets-used-in-course">Built-in R Datasets Used in Course</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#data-download-and-organization">Data Download and Organization</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Sequential Bayesian Updating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. The Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. The Foundation of Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Connecting CI and HT; <em>t</em>-Test for μ When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. The Four Steps to Hypothesis Testing and Understanding the Result</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Statistical Inference for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Independent Two-Sample Analysis When Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Independent Two-Sample Analysis - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Independent Two-Sample Analysis - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Paired Two-Sample Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../worksheets_index.html">Course Worksheets</a></li>
      <li class="breadcrumb-item active">Worksheet 12: Point Estimators and Unbiased Estimation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/worksheets/worksheet_materials/worksheet12.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="worksheet-12-point-estimators-and-unbiased-estimation">
<span id="worksheet12"></span><h1>Worksheet 12: Point Estimators and Unbiased Estimation<a class="headerlink" href="#worksheet-12-point-estimators-and-unbiased-estimation" title="Link to this heading"></a></h1>
<div class="info admonition">
<p class="admonition-title">Learning Objectives 🎯</p>
<ul class="simple">
<li><p><strong>Master</strong> the concept of point estimators and distinguish between parameters and statistics</p></li>
<li><p><strong>Apply</strong> the definition of bias to evaluate whether an estimator is unbiased</p></li>
<li><p><strong>Calculate</strong> expected values and variances of estimators mathematically and through simulation</p></li>
<li><p><strong>Analyze</strong> the trade-offs between bias and variance in estimator selection</p></li>
<li><p><strong>Implement R simulations</strong> to verify theoretical properties of estimators and compare their performance</p></li>
</ul>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<p>In previous lessons, we studied sampling distributions and how they describe the variability of statistics computed from samples. We focused on scenarios involving Normal distributions or approximate Normality via the Central Limit Theorem (CLT). Now, we turn our attention specifically to <strong>estimating unknown parameters</strong> using sample data.</p>
<p>When analyzing data, we often want to estimate unknown numerical characteristics (parameters) of a population. Examples of parameters include:</p>
<ul class="simple">
<li><p>Population mean <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
<li><p>Population variance <span class="math notranslate nohighlight">\(\sigma^2\)</span></p></li>
<li><p>Probability of success <span class="math notranslate nohighlight">\(p\)</span></p></li>
<li><p>Rate parameter of a Poisson or Exponential distribution <span class="math notranslate nohighlight">\(\lambda\)</span></p></li>
</ul>
<p>A <strong>point estimator</strong> is a rule or formula that uses sample data to produce a single “best guess” for the unknown parameter.</p>
<div class="info admonition">
<p class="admonition-title">Key Definitions 📚</p>
<p><strong>Parameter</strong> <span class="math notranslate nohighlight">\(\theta\)</span>: A fixed, unknown number describing a population characteristic</p>
<p><strong>Point Estimator</strong> <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>: A statistic computed from a sample, intended to approximate <span class="math notranslate nohighlight">\(\theta\)</span></p>
<p><strong>Bias</strong>: The difference between the expected value of an estimator and the true parameter value:</p>
<div class="math notranslate nohighlight">
\[\text{bias}(\hat{\theta}) = E[\hat{\theta}] - \theta\]</div>
<p><strong>Unbiased Estimator</strong>: An estimator <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is unbiased if <span class="math notranslate nohighlight">\(E[\hat{\theta}] = \theta\)</span></p>
</div>
<p>For example, if we wish to estimate the population mean <span class="math notranslate nohighlight">\(\mu\)</span>, a natural estimator is the sample mean <span class="math notranslate nohighlight">\(\overline{X}\)</span>. Similarly, to estimate a probability of success <span class="math notranslate nohighlight">\(p\)</span>, the sample proportion <span class="math notranslate nohighlight">\(\hat{p}\)</span> can be used.</p>
<p>An unbiased estimator does not consistently underestimate or overestimate the parameter it targets. Instead, the estimation errors “balance out” across many samples.</p>
</section>
<section id="part-1-estimating-parameters-of-the-exponential-distribution">
<h2>Part 1: Estimating Parameters of the Exponential Distribution<a class="headerlink" href="#part-1-estimating-parameters-of-the-exponential-distribution" title="Link to this heading"></a></h2>
<p>The exponential distribution is commonly used to model waiting times and lifetimes. Understanding the properties of its estimators is crucial for reliable inference.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Recall that for <span class="math notranslate nohighlight">\(X \sim \text{Exponential}(\lambda)\)</span>, we have:</p>
<ul class="simple">
<li><p>Population mean: <span class="math notranslate nohighlight">\(\mu = E[X] = \frac{1}{\lambda}\)</span></p></li>
<li><p>Population variance: <span class="math notranslate nohighlight">\(\sigma^2 = \text{Var}(X) = \frac{1}{\lambda^2}\)</span></p></li>
</ul>
</div>
<p><strong>Question 1:</strong> Consider a random variable <span class="math notranslate nohighlight">\(X \sim \text{Exponential}(\lambda)\)</span>, where <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span> is the rate parameter. Suppose we take <span class="math notranslate nohighlight">\(n\)</span> independent random samples from this distribution, i.e., <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n \overset{\text{i.i.d.}}{\sim} \text{Exponential}(\lambda)\)</span>.</p>
<p>We wish to estimate the parameter <span class="math notranslate nohighlight">\(\mu\)</span> (the mean) and the parameter <span class="math notranslate nohighlight">\(\lambda\)</span> (the rate) using these samples.</p>
<p><strong>a) Mathematical Proof of Unbiasedness</strong></p>
<p>Show mathematically that the sample mean <span class="math notranslate nohighlight">\(\overline{X}\)</span> is an unbiased estimator for <span class="math notranslate nohighlight">\(\mu = 1/\lambda\)</span>. In other words, show that <span class="math notranslate nohighlight">\(\text{bias}(\overline{X}) = 0\)</span>.</p>
<p><strong>Hint:</strong> Use the linearity of expectation and the fact that <span class="math notranslate nohighlight">\(E[X_i] = \mu\)</span> for each observation.</p>
<div class="math notranslate nohighlight">
\[E[\overline{X}] = E\left[\frac{1}{n}\sum_{i=1}^{n} X_i\right] =\]</div>
<p><strong>Conclusion about bias:</strong></p>
<div class="math notranslate nohighlight">
\[\text{bias}(\overline{X}) = E[\overline{X}] - \mu =\]</div>
<p><strong>b) Simulation Verification</strong></p>
<p>Show by simulation that the sample mean <span class="math notranslate nohighlight">\(\overline{X}\)</span> is an unbiased estimator for <span class="math notranslate nohighlight">\(\mu = 1/\lambda\)</span> when <span class="math notranslate nohighlight">\(\lambda = 10\)</span>.</p>
<p>Generate 1500 random samples of size <span class="math notranslate nohighlight">\(n = 25\)</span> from <span class="math notranslate nohighlight">\(\text{Exponential}(\lambda = 10)\)</span> and compute 1500 sample means. Compute and report the following summary statistics:</p>
<ol class="lowerroman simple">
<li><p>The average of the sample means = ____</p></li>
<li><p>The standard deviation of the sample means = ____</p></li>
<li><p>The proportion of sample means that exceed the true mean <span class="math notranslate nohighlight">\(\mu = 1/10\)</span> = ____</p></li>
<li><p>The proportion of sample means that are at most <span class="math notranslate nohighlight">\(\mu = 1/10\)</span> = ____</p></li>
</ol>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set seed for reproducibility</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">350</span><span class="p">)</span>

<span class="c1"># Parameters</span>
<span class="n">lambda</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10</span>
<span class="n">true_mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="n">lambda</span>
<span class="n">n_samples</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">25</span>
<span class="n">n_simulations</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1500</span>

<span class="c1"># Generate samples and compute sample means</span>
<span class="n">sample_means</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">replicate</span><span class="p">(</span><span class="n">n_simulations</span><span class="p">,</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1"># Generate one sample of size n_samples</span>
<span class="w">  </span><span class="n">sample_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rexp</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span><span class="w"> </span><span class="n">rate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda</span><span class="p">)</span>
<span class="w">  </span><span class="c1"># Compute and return the sample mean</span>
<span class="w">  </span><span class="nf">mean</span><span class="p">(</span><span class="n">sample_data</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># i. Average of sample means</span>
<span class="n">avg_sample_means</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">sample_means</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;i. Average of sample means:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">avg_sample_means</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># ii. Standard deviation of sample means</span>
<span class="n">sd_sample_means</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">sample_means</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;ii. Standard deviation of sample means:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">sd_sample_means</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># iii. Proportion exceeding true mean</span>
<span class="n">prop_exceed</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">sample_means</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">true_mu</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;iii. Proportion exceeding mu:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">prop_exceed</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># iv. Proportion at most true mean</span>
<span class="n">prop_at_most</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">sample_means</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">true_mu</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;iv. Proportion at most mu:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">prop_at_most</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># Visualization</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="nf">data.frame</span><span class="p">(</span><span class="n">sample_means</span><span class="p">),</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample_means</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">after_stat</span><span class="p">(</span><span class="n">density</span><span class="p">)),</span><span class="w"> </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">40</span><span class="p">,</span>
<span class="w">                 </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_density</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dnorm</span><span class="p">,</span>
<span class="w">                </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_mu</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)),</span>
<span class="w">                </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_mu</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkred&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">avg_sample_means</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkblue&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;solid&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Distribution of Sample Means&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Red dashed = True μ, Blue solid = Avg of sample means\n&quot;</span><span class="p">,</span>
<span class="w">                       </span><span class="s">&quot;Red curve = Theoretical N(μ, σ²/n), Blue curve = Empirical density&quot;</span><span class="p">),</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Sample Mean&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Density&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>c) Interpretation</strong></p>
<p>Using your summary statistics, do you think that the sample means were <strong>close</strong> to the expected value <span class="math notranslate nohighlight">\(\mu = 1/10\)</span>? Does the sample mean appear to be unbiased? Provide evidence from your simulation to support your conclusion.</p>
<p><strong>d) 🔍 Estimating the Rate Parameter</strong></p>
<p>Next, suppose instead we want to estimate the rate parameter <span class="math notranslate nohighlight">\(\lambda\)</span>. Consider the estimator <span class="math notranslate nohighlight">\(\hat{\lambda} = \frac{1}{\overline{X}}\)</span>.</p>
<p>Using your simulation data from part <strong>b)</strong>, compute <span class="math notranslate nohighlight">\(\hat{\lambda} = \frac{1}{\overline{X}}\)</span> for each of your 1500 samples. Based on your results, is <span class="math notranslate nohighlight">\(\hat{\lambda}\)</span> likely unbiased as an estimator of <span class="math notranslate nohighlight">\(\lambda\)</span>?</p>
<p>If you think the estimator is biased, approximate that bias using your simulated data. Repeat the bias approximation for different values of <span class="math notranslate nohighlight">\(n\)</span>. Do you observe that the bias remains roughly constant, or does it change with <span class="math notranslate nohighlight">\(n\)</span>?</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute lambda_hat for each sample mean</span>
<span class="n">lambda_hat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sample_means</span>

<span class="c1"># True lambda</span>
<span class="n">true_lambda</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10</span>

<span class="c1"># Average of lambda_hat estimates</span>
<span class="n">avg_lambda_hat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">lambda_hat</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Average of lambda_hat:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">avg_lambda_hat</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;True lambda:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">true_lambda</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># Approximate bias</span>
<span class="n">approx_bias</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">avg_lambda_hat</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">true_lambda</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Approximate bias:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">approx_bias</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># Visualization</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="nf">data.frame</span><span class="p">(</span><span class="n">lambda_hat</span><span class="p">),</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lambda_hat</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">after_stat</span><span class="p">(</span><span class="n">density</span><span class="p">)),</span><span class="w"> </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">40</span><span class="p">,</span>
<span class="w">                 </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lightcoral&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_density</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_lambda</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">avg_lambda_hat</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkblue&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;solid&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Distribution of Lambda Hat Estimates&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Red dashed = True λ, Blue solid = Avg of estimates\n&quot;</span><span class="p">,</span>
<span class="w">                       </span><span class="s">&quot;Blue curve = Empirical density (note the bias)&quot;</span><span class="p">),</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Lambda Hat&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Density&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
<div class="tip admonition">
<p class="admonition-title">Extension: Investigating Sample Size Effects 🖥️</p>
<p><strong>Explore how bias changes with sample size</strong></p>
<p>Repeat the bias calculation for <span class="math notranslate nohighlight">\(n = 5, 10, 25, 50, 100\)</span>. Create a plot showing how the bias of <span class="math notranslate nohighlight">\(\hat{\lambda}\)</span> changes as <span class="math notranslate nohighlight">\(n\)</span> increases.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sample sizes to investigate</span>
<span class="n">sample_sizes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="m">25</span><span class="p">,</span><span class="w"> </span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="m">100</span><span class="p">)</span>
<span class="n">bias_results</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">numeric</span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">))</span>

<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="nf">seq_along</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="w">  </span><span class="c1"># Generate samples and compute lambda_hat</span>
<span class="w">  </span><span class="n">lambda_hats</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">replicate</span><span class="p">(</span><span class="m">1500</span><span class="p">,</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sample_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rexp</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">rate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">)</span>
<span class="w">    </span><span class="m">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">sample_data</span><span class="p">)</span>
<span class="w">  </span><span class="p">})</span>

<span class="w">  </span><span class="c1"># Compute bias</span>
<span class="w">  </span><span class="n">bias_results</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">lambda_hats</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">10</span>
<span class="p">}</span>

<span class="c1"># Plot bias vs sample size</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="nf">data.frame</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample_sizes</span><span class="p">,</span><span class="w"> </span><span class="n">bias</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bias_results</span><span class="p">),</span>
<span class="w">       </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bias</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_line</span><span class="p">(</span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkblue&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkred&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;gray&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Bias of Lambda Hat vs Sample Size&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Gray dashed line = zero bias (unbiased estimator)&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Sample Size (n)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Bias&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p><strong>Your conclusions about :math:`hat{lambda}` as an estimator:</strong></p>
</section>
<section id="part-2-estimating-the-maximum-of-a-uniform-distribution">
<h2>Part 2: Estimating the Maximum of a Uniform Distribution<a class="headerlink" href="#part-2-estimating-the-maximum-of-a-uniform-distribution" title="Link to this heading"></a></h2>
<p>When dealing with uniform distributions, estimating the upper bound presents unique challenges. This problem illustrates how intuitive estimators can be biased and how we can correct them.</p>
<p><strong>Question 2:</strong> Suppose we have <span class="math notranslate nohighlight">\(n\)</span> i.i.d. random variables from a Uniform distribution:</p>
<div class="math notranslate nohighlight">
\[X_1, X_2, \ldots, X_n \overset{\text{i.i.d.}}{\sim} \text{Uniform}(0, \theta),\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta &gt; 0\)</span> is an unknown parameter representing the largest value that the random variables can possibly take on. Suppose we are able to obtain samples from this population and wish to estimate <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>A natural estimator is the sample maximum:</p>
<div class="math notranslate nohighlight">
\[\mathcal{M} = \max\{X_1, X_2, \ldots, X_n\}.\]</div>
<p>In this exercise, you will show that this estimator is biased but can be corrected to produce an unbiased estimator.</p>
<p><strong>a) Deriving the Distribution of the Sample Maximum</strong></p>
<p>We will work through deriving the distribution of <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> to determine whether it is unbiased.</p>
<p><strong>Step 1: Cumulative Distribution Function</strong></p>
<p>Determine the cumulative distribution function for <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For a Uniform(0, θ) random variable X, the CDF is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}F_X(x) = \begin{cases}
0 &amp; \text{if } x &lt; 0 \\
\frac{x}{\theta} &amp; \text{if } 0 \leq x \leq \theta \\
1 &amp; \text{if } x &gt; \theta
\end{cases}\end{split}\]</div>
</div>
<p>The event <span class="math notranslate nohighlight">\(\{\mathcal{M} \leq x\}\)</span> means that the maximum of the sample is at most <span class="math notranslate nohighlight">\(x\)</span>. In other words, if the largest observation is at most <span class="math notranslate nohighlight">\(x\)</span>, then <strong>all</strong> observations must be at most <span class="math notranslate nohighlight">\(x\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(\mathcal{M} \leq x) = P(\{X_1 \leq x\} \cap \{X_2 \leq x\} \cap \ldots \cap \{X_n \leq x\})\]</div>
<p>Using the independence of the random variables and the known CDF of the <span class="math notranslate nohighlight">\(\text{Uniform}(0, \theta)\)</span> distribution, write out the full piecewise function for the CDF of <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}F_{\mathcal{M}}(x) = P(\mathcal{M} \leq x) = \begin{cases}
\text{____} &amp; \text{if } x &lt; 0 \\
\text{____} &amp; \text{if } 0 \leq x \leq \theta \\
\text{____} &amp; \text{if } x &gt; \theta
\end{cases}\end{split}\]</div>
<p><strong>Step 2: Probability Density Function</strong></p>
<p>After you have obtained the CDF for <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>, determine the corresponding probability density function <span class="math notranslate nohighlight">\(f_{\mathcal{M}}(x)\)</span>.</p>
<p>The PDF can be obtained by taking the derivative of the CDF with respect to <span class="math notranslate nohighlight">\(x\)</span>:</p>
<div class="math notranslate nohighlight">
\[f_{\mathcal{M}}(x) = \frac{d}{dx}F_{\mathcal{M}}(x)\]</div>
<p>For the region <span class="math notranslate nohighlight">\((0, \theta)\)</span>, compute the derivative:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f_{\mathcal{M}}(x) = \begin{cases}
\text{____} &amp; \text{if } 0 &lt; x &lt; \theta \\
\text{____} &amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Common mistake: Don’t forget to consider the full piecewise structure of the PDF. The function should be defined for all values of x.</p>
</div>
<p><strong>Step 3: Expected Value</strong></p>
<p>Using the probability density function, calculate the expected value of the estimator <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>:</p>
<div class="math notranslate nohighlight">
\[E[\mathcal{M}] = \int_{-\infty}^{\infty} x \cdot f_{\mathcal{M}}(x) \, dx =\]</div>
<p><strong>Step 4: Bias Calculation</strong></p>
<p>Using your result from Step 3, determine the bias of your estimator <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\text{bias}(\mathcal{M}) = E[\mathcal{M}] - \theta =\]</div>
<p><strong>Is :math:`mathcal{M}` an unbiased estimator?</strong></p>
<p><strong>b) Constructing an Unbiased Estimator</strong></p>
<p>Since the estimator <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> is biased, propose a simple modification to <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> that results in an unbiased estimator, and denote this estimator as <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>.</p>
<p><strong>Hint:</strong> You want to find a constant <span class="math notranslate nohighlight">\(c\)</span> such that <span class="math notranslate nohighlight">\(E[c \cdot \mathcal{M}] = \theta\)</span>.</p>
<div class="math notranslate nohighlight">
\[\hat{\theta} = \text{____}\]</div>
<p>Verify that your proposed estimator is unbiased:</p>
<div class="math notranslate nohighlight">
\[E[\hat{\theta}] =\]</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simulation to verify the unbiased estimator</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">350</span><span class="p">)</span>

<span class="c1"># True parameter</span>
<span class="n">true_theta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">20</span>
<span class="n">n_samples</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10</span>
<span class="n">n_simulations</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2000</span>

<span class="c1"># Generate samples and compute both M and theta_hat</span>
<span class="n">M_values</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">replicate</span><span class="p">(</span><span class="n">n_simulations</span><span class="p">,</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sample_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_theta</span><span class="p">)</span>
<span class="w">  </span><span class="nf">max</span><span class="p">(</span><span class="n">sample_data</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># YOUR TURN: Define theta_hat based on your formula from part b</span>
<span class="n">theta_hat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span>___<span class="w">  </span><span class="c1"># Fill in your correction formula</span>

<span class="c1"># Compare results</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;True theta:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">true_theta</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Average of M:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">M_values</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Average of theta_hat:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">theta_hat</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Bias of M:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">M_values</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">true_theta</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Bias of theta_hat:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">theta_hat</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">true_theta</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># Check proportion exceeding theta</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;\nProportion of theta_hat exceeding theta:&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nf">mean</span><span class="p">(</span><span class="n">theta_hat</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">true_theta</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># Visualization</span>
<span class="c1"># Create stacked data frame manually without tidyr</span>
<span class="n">results_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="w">  </span><span class="n">Value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">M_values</span><span class="p">,</span><span class="w"> </span><span class="n">theta_hat</span><span class="p">),</span>
<span class="w">  </span><span class="n">Estimator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;M&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;theta_hat&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">M_values</span><span class="p">))</span>
<span class="p">)</span>

<span class="nf">ggplot</span><span class="p">(</span><span class="n">results_df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Value</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Estimator</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">after_stat</span><span class="p">(</span><span class="n">density</span><span class="p">)),</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.6</span><span class="p">,</span>
<span class="w">                 </span><span class="n">position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;identity&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">40</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_density</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Estimator</span><span class="p">),</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NA</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_theta</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Comparison of M and Corrected Estimator&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Red line = True θ, Density curves show empirical distributions&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Estimated Value&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Density&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_fill_manual</span><span class="p">(</span><span class="n">values</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;M&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lightblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;theta_hat&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lightgreen&quot;</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;M&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;theta_hat&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkgreen&quot;</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
<div class="warning admonition">
<p class="admonition-title">Important: Unbiased ≠ Symmetric! 🎯</p>
<p><strong>You may notice that more than 50% of your θ̂ values exceed the true θ.</strong> This is <strong>not</strong> evidence of bias!</p>
<ul class="simple">
<li><p><strong>Unbiased</strong> means: E[θ̂] = θ (the average equals θ) ✓</p></li>
<li><p><strong>Symmetric</strong> would mean: P(θ̂ &gt; θ) = 50%</p></li>
</ul>
<p>These are different properties! The distribution of θ̂ is <strong>left-skewed</strong> because:</p>
<ol class="arabic simple">
<li><p>It’s derived from M, which has a hard boundary at θ</p></li>
<li><p>Multiplying by (n+1)/n shifts the mean to θ but doesn’t change the shape</p></li>
<li><p>In left-skewed distributions: mode &gt; median &gt; mean</p></li>
<li><p>Therefore: P(θ̂ &gt; θ) ≈ 0.60-0.65 (varies with n)</p></li>
</ol>
<p><strong>Check your results:</strong>
- Is mean(theta_hat) ≈ θ? → Then it’s unbiased! ✓
- Is proportion exceeding θ around 60-65%? → That’s the skewness! ✓</p>
</div>
</section>
<section id="part-3-minimum-variance-unbiased-estimators-mvue">
<h2>Part 3: Minimum Variance Unbiased Estimators (MVUE)<a class="headerlink" href="#part-3-minimum-variance-unbiased-estimators-mvue" title="Link to this heading"></a></h2>
<p>While unbiasedness is a desirable property, there could be multiple unbiased estimators for the same parameter. Among all unbiased estimators, we typically prefer the one with the smallest variability (variance).</p>
<div class="info admonition">
<p class="admonition-title">Definition: MVUE 🎯</p>
<p>An estimator <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is a <strong>Minimum Variance Unbiased Estimator (MVUE)</strong> if:</p>
<ol class="arabic simple">
<li><p>It is <strong>unbiased</strong>: <span class="math notranslate nohighlight">\(E[\hat{\theta}] = \theta\)</span></p></li>
<li><p>It has the <strong>smallest variance</strong> among all possible unbiased estimators for <span class="math notranslate nohighlight">\(\theta\)</span></p></li>
</ol>
<p>The MVUE is the “best” unbiased estimator in the sense that it provides estimates consistently closest to the true parameter, on average.</p>
</div>
<p><strong>Question 3:</strong> Suppose you collect data from a population that follows a Normal distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Specifically, consider the population distribution:</p>
<div class="math notranslate nohighlight">
\[X \sim N(\mu = 50, \sigma^2 = 25)\]</div>
<p>Two natural and commonly used estimators for the population mean <span class="math notranslate nohighlight">\(\mu\)</span> are:</p>
<ul class="simple">
<li><p><strong>Estimator A</strong>: The sample mean <span class="math notranslate nohighlight">\(\overline{X}\)</span></p></li>
<li><p><strong>Estimator B</strong>: The sample median <span class="math notranslate nohighlight">\(\tilde{X}\)</span></p></li>
</ul>
<p>Both estimators intuitively seem plausible, and indeed both are unbiased for the mean when the population is Normal.</p>
<p><strong>a) Simulation Comparison</strong></p>
<p>Generate 2000 independent samples, each of size <span class="math notranslate nohighlight">\(n = 15\)</span>, from the distribution <span class="math notranslate nohighlight">\(N(\mu = 50, \sigma^2 = 25)\)</span>. Compute the sample mean and median for each of the 2000 independent samples.</p>
<p>Compute and report:</p>
<ol class="lowerroman simple">
<li><p>Average of the 2000 sample means = ____</p></li>
<li><p>Standard deviation of the 2000 sample means = ____</p></li>
<li><p>Average of the 2000 sample medians = ____</p></li>
<li><p>Standard deviation of the 2000 sample medians = ____</p></li>
</ol>
<p><strong>Were they both close to the true mean :math:`mu = 50` on average? Which estimator had less variability?</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set seed for reproducibility</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">350</span><span class="p">)</span>

<span class="c1"># Population parameters</span>
<span class="n">true_mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">50</span>
<span class="n">true_sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">25</span><span class="p">)</span>
<span class="n">sample_size</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">15</span>
<span class="n">n_simulations</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2000</span>

<span class="c1"># Initialize vectors to store estimates</span>
<span class="n">sample_means</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">numeric</span><span class="p">(</span><span class="n">n_simulations</span><span class="p">)</span>
<span class="n">sample_medians</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">numeric</span><span class="p">(</span><span class="n">n_simulations</span><span class="p">)</span>

<span class="c1"># Generate samples and compute both estimators</span>
<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n_simulations</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">sample_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_sigma</span><span class="p">)</span>
<span class="w">  </span><span class="n">sample_means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">sample_data</span><span class="p">)</span>
<span class="w">  </span><span class="n">sample_medians</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">median</span><span class="p">(</span><span class="n">sample_data</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Compute summary statistics</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;=== Sample Mean ===\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;i. Average of sample means:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">sample_means</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;ii. SD of sample means:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">sample_means</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;\n=== Sample Median ===\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;iii. Average of sample medians:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">sample_medians</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;iv. SD of sample medians:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">sample_medians</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># Comparison</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;\n=== Comparison ===\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Variance of sample means:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span><span class="n">sample_means</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Variance of sample medians:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span><span class="n">sample_medians</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Ratio (Var(Median)/Var(Mean)):&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nf">var</span><span class="p">(</span><span class="n">sample_medians</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span><span class="n">sample_means</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># Visualization</span>
<span class="c1"># Create stacked data frame manually without tidyr</span>
<span class="n">estimator_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="w">  </span><span class="n">Value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">sample_means</span><span class="p">,</span><span class="w"> </span><span class="n">sample_medians</span><span class="p">),</span>
<span class="w">  </span><span class="n">Estimator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Mean&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Median&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">sample_means</span><span class="p">))</span>
<span class="p">)</span>

<span class="c1"># Calculate theoretical SDs for overlay</span>
<span class="n">theoretical_sd_mean</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">true_sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span>
<span class="n">theoretical_sd_median</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1.253</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">true_sigma</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span><span class="w">  </span><span class="c1"># Median efficiency factor</span>

<span class="nf">ggplot</span><span class="p">(</span><span class="n">estimator_df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Value</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Estimator</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_density</span><span class="p">(</span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dnorm</span><span class="p">,</span>
<span class="w">                </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">theoretical_sd_mean</span><span class="p">),</span>
<span class="w">                </span><span class="nf">aes</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Mean (theoretical)&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dnorm</span><span class="p">,</span>
<span class="w">                </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">theoretical_sd_median</span><span class="p">),</span>
<span class="w">                </span><span class="nf">aes</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Median (theoretical)&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">true_mu</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Distribution of Sample Mean vs Sample Median&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Red line = True μ =&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">true_mu</span><span class="p">,</span>
<span class="w">                       </span><span class="s">&quot;\nSolid curves = Empirical, Dashed curves = Theoretical N(μ, σ²/n)&quot;</span><span class="p">),</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Estimated Value&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Density&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_fill_manual</span><span class="p">(</span><span class="n">values</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Mean&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Median&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lightcoral&quot;</span><span class="p">),</span>
<span class="w">                   </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Estimator&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Mean (theoretical)&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkblue&quot;</span><span class="p">,</span>
<span class="w">                                </span><span class="s">&quot;Median (theoretical)&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkred&quot;</span><span class="p">),</span>
<span class="w">                    </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Theoretical&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Your observations:</strong></p>
<div class="tip admonition">
<p class="admonition-title">What to Look For 🔍</p>
<p>When comparing the two estimators, pay attention to:</p>
<ol class="arabic simple">
<li><p><strong>Centering</strong>: Are both distributions centered near the true μ = 50? (This checks unbiasedness)</p></li>
<li><p><strong>Spread</strong>: Which distribution is narrower? (This indicates lower variance)</p></li>
<li><p><strong>Theoretical curves</strong>: Do the dashed lines match the empirical densities? (This validates theory)</p></li>
</ol>
<p>The estimator with lower variance gives more precise estimates - this is the MVUE!</p>
</div>
<p><strong>b) Practical Implications</strong></p>
<p>In practice, we will never have access to 2000 samples; instead, we will only have a single sample of size <span class="math notranslate nohighlight">\(n\)</span>. If you have a good reason to assume that the population you sampled from is Normal or nearly Normal, which estimator would you prefer for estimating the central tendency? Use your exploration in part <strong>a)</strong> to justify your answer.</p>
<p><strong>Your recommendation and justification:</strong></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Important Consideration</strong>: While unbiased estimators are generally desirable, sometimes an estimator with slight bias but much smaller variability can provide better estimates overall. In practice, small bias may be an acceptable tradeoff for reduced uncertainty. This leads to concepts like Mean Squared Error (MSE) which we may explore in future lessons.</p>
</div>
</section>
<section id="key-takeaways">
<h2>Key Takeaways<a class="headerlink" href="#key-takeaways" title="Link to this heading"></a></h2>
<div class="important admonition">
<p class="admonition-title">Summary 📝</p>
<ul class="simple">
<li><p><strong>Unbiased estimators</strong> satisfy <span class="math notranslate nohighlight">\(E[\hat{\theta}] = \theta\)</span>, meaning they hit the true parameter value on average across many samples</p></li>
<li><p><strong>Bias can sometimes be corrected</strong> through algebraic adjustments, as seen with the sample maximum for Uniform distributions</p></li>
<li><p><strong>Simulation provides powerful verification</strong> of theoretical properties and helps build intuition about estimator behavior</p></li>
<li><p><strong>Among unbiased estimators, prefer lower variance</strong> - the MVUE balances unbiasedness with minimum variability</p></li>
<li><p><strong>For Normal populations, the sample mean is MVUE</strong> and outperforms the sample median in terms of efficiency</p></li>
<li><p><strong>R simulations enable exploration</strong> of estimator properties across different sample sizes and parameter values, revealing insights that may be difficult to derive theoretically</p></li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="worksheet11.html" class="btn btn-neutral float-left" title="Worksheet 11: The Central Limit Theorem" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="worksheet13.html" class="btn btn-neutral float-right" title="Worksheet 13: Introduction to Confidence Intervals" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
  <p class="footer-credits-inline">
    <strong>Website Credits:</strong>
    Website development by Dr. Timothy Reese and Halin Shin.
    Generative AI tools were used to draft and refine some prose, code, and documentation; all content was reviewed by the instructors.
    Models: OpenAI o3 (2025-04-16 release) and Anthropic Claude Opus 4.1 (2025-08-05).
  </p>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>