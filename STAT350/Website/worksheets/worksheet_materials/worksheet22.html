

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Worksheet 22: Model Assessment and Prediction in Regression &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=2f168d12" />
      <link rel="stylesheet" type="text/css" href="../../_static/credits.css?v=f7efa099" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/Website/worksheets/worksheet_materials/worksheet22.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script>window.MathJax = {"options": {"enableMenu": true, "menuOptions": {"settings": {"enrich": true, "speech": true, "braille": true, "collapsible": true, "assistiveMml": false}}}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=7e0058eb"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="R / RStudio Guide and Function Reference" href="../../R_computerAssignments/r_computer_assignments.html" />
    <link rel="prev" title="Worksheet 21: Inference for Simple Linear Regression" href="worksheet21.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../worksheets_index.html">Course Worksheets</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../worksheets_index.html#worksheets">Worksheets</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#troubleshooting-guide">Troubleshooting Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#part-1-the-bernoulli-and-binomial-distributions">Part 1: The Bernoulli and Binomial Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#the-binomial-distribution">The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#part-2-the-poisson-distribution">Part 2: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#part-3-other-named-discrete-distributions">Part 3: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#part-2-the-standard-normal-table">Part 2: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#part-3-z-score-transformation">Part 3: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet11.html">Worksheet 11: The Central Limit Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#tutorial-generating-the-sampling-distribution-of-bar-x">Tutorial: Generating the Sampling Distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#part-1-exploring-clt-with-skewed-distributions">Part 1: Exploring CLT with Skewed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#part-2-application-of-the-clt">Part 2: Application of the CLT</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#part-3-beyond-mean-and-sum">Part 3: Beyond Mean and Sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#part-4-exploring-clt-generalizability-with-ai-assistance-exploration">Part 4: Exploring CLT Generalizability with AI Assistance (Exploration)</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet11.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet12.html">Worksheet 12: Point Estimators and Unbiased Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet12.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet12.html#part-1-estimating-parameters-of-the-exponential-distribution">Part 1: Estimating Parameters of the Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet12.html#part-2-estimating-the-maximum-of-a-uniform-distribution">Part 2: Estimating the Maximum of a Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet12.html#part-3-minimum-variance-unbiased-estimators-mvue">Part 3: Minimum Variance Unbiased Estimators (MVUE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet12.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet13.html">Worksheet 13: Introduction to Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#part-1-pivotal-quantities-and-deriving-confidence-intervals">Part 1: Pivotal Quantities and Deriving Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#part-2-sample-size-determination">Part 2: Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#part-3-one-sided-confidence-bounds">Part 3: One-Sided Confidence Bounds</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#part-4-confidence-intervals-when-is-unknown">Part 4: Confidence Intervals When σ is Unknown</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet13.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet14.html">Worksheet 14: Student’s t-Distribution and Statistical Power</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#assumptions-for-t-distribution-inference">Assumptions for t-Distribution Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#part-1-analyzing-chick-growth-with-confidence-intervals">Part 1: Analyzing Chick Growth with Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#part-2-introduction-to-hypothesis-testing">Part 2: Introduction to Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#part-3-sample-size-determination-and-power-analysis">Part 3: Sample Size Determination and Power Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet14.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html">The Hypothesis Testing Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#the-test-statistic-known">The Test Statistic (Known σ)</a></li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#distribution-of-the-test-statistic">Distribution of the Test Statistic</a></li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#the-p-value">The p-value</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#part-1-simulating-test-statistics-and-p-values">Part 1: Simulating Test Statistics and P-values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#question-1a-simulation-when-null-hypothesis-is-true">Question 1a: Simulation When Null Hypothesis is True</a></li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#question-1b-simulation-when-null-hypothesis-is-false">Question 1b: Simulation When Null Hypothesis is False</a></li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#question-1c-comparing-the-two-scenarios">Question 1c: Comparing the Two Scenarios</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#the-t-test-when-is-unknown">The t-Test When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#the-t-test-statistic">The t-Test Statistic</a></li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#properties-of-the-t-distribution">Properties of the t-Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#relationship-between-confidence-intervals-and-hypothesis-tests">Relationship Between Confidence Intervals and Hypothesis Tests</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#part-2-epa-ozone-concentration-analysis">Part 2: EPA Ozone Concentration Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#question-2a-assumptions-and-exploratory-analysis">Question 2a: Assumptions and Exploratory Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#question-2b-full-hypothesis-testing-procedure">Question 2b: Full Hypothesis Testing Procedure</a></li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#question-2c-manual-verification">Question 2c: Manual Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#question-2d-confidence-bound">Question 2d: Confidence Bound</a></li>
<li class="toctree-l3"><a class="reference internal" href="worksheet15.html#question-2e-power-calculation">Question 2e: Power Calculation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet15.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet16.html">Worksheet 16: Two-Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet16.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet16.html#part-1-independent-vs-paired-designs">Part 1: Independent vs. Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet16.html#part-2-independent-samples-with-known-variances">Part 2: Independent Samples with Known Variances</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet16.html#part-3-pooled-two-sample-t-test-equal-variances">Part 3: Pooled Two-Sample t-Test (Equal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet16.html#part-4-welch-s-two-sample-t-test-unequal-variances">Part 4: Welch’s Two-Sample t-Test (Unequal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet16.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet17.html">Worksheet 17: Paired Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet17.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet17.html#part-1-theory-and-procedure-for-paired-samples">Part 1: Theory and Procedure for Paired Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet17.html#part-2-sleep-study-analysis">Part 2: Sleep Study Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet17.html#part-3-sample-size-calculation-for-paired-designs">Part 3: Sample Size Calculation for Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet17.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet18.html">Worksheet 18: One-Way ANOVA (Analysis of Variance)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#why-use-one-way-anova">Why Use One-Way ANOVA?</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#one-way-anova-assumptions">One-Way ANOVA Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#one-way-anova-f-test-statistic-and-sources-of-variation">One-Way ANOVA F-test Statistic and Sources of Variation</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#notation-and-setup">Notation and Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-1-computing-the-overall-sample-mean">Part 1: Computing the Overall Sample Mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-2-checking-the-equal-variance-assumption">Part 2: Checking the Equal Variance Assumption</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-3-pooled-variance-estimator">Part 3: Pooled Variance Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-4-within-group-variability-sum-of-squares-within-sse">Part 4: Within-Group Variability (Sum of Squares Within, SSE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-5-between-group-variability-sum-of-squares-among-ssa">Part 5: Between-Group Variability (Sum of Squares Among, SSA)</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-6-total-variability-and-partitioning">Part 6: Total Variability and Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-7-degrees-of-freedom">Part 7: Degrees of Freedom</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-8-mean-squares">Part 8: Mean Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-9-the-f-test-statistic">Part 9: The F-Test Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-10-computing-the-p-value-and-making-a-decision">Part 10: Computing the P-Value and Making a Decision</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-11-completing-the-anova-table">Part 11: Completing the ANOVA Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#part-12-limitations-and-follow-up-questions">Part 12: Limitations and Follow-Up Questions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet18.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet19.html">Worksheet 19: Multiple Comparisons and Post-Hoc Testing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet19.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet19.html#the-multiple-comparisons-problem">The Multiple Comparisons Problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet19.html#methods-to-control-the-family-wise-error-rate">Methods to Control the Family-Wise Error Rate</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet19.html#part-1-simulation-study-type-i-error-with-multiple-comparison-methods">Part 1: Simulation Study - Type I Error with Multiple Comparison Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet19.html#part-2-applying-tukey-s-hsd-to-worksheet-18-data">Part 2: Applying Tukey’s HSD to Worksheet 18 Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet19.html#part-3-comprehensive-anova-analysis-toothgrowth-dataset">Part 3: Comprehensive ANOVA Analysis - ToothGrowth Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet19.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet20.html">Worksheet 20: Introduction to Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet20.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet20.html#from-anova-to-regression-same-core-ideas-new-application">From ANOVA to Regression: Same Core Ideas, New Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet20.html#the-simple-linear-regression-model">The Simple Linear Regression Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet20.html#least-squares">Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet20.html#part-1-deriving-least-squares-estimators">Part 1: Deriving Least Squares Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet20.html#part-2-the-general-simple-linear-regression-estimators">Part 2: The General Simple Linear Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet20.html#part-3-sampling-distributions-of-regression-estimators">Part 3: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet20.html#part-4-practice-problems">Part 4: Practice Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet20.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet21.html">Worksheet 21: Inference for Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet21.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet21.html#part-1-sampling-distributions-of-regression-estimators">Part 1: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet21.html#part-2-checking-regression-assumptions">Part 2: Checking Regression Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet21.html#part-3-bird-data-analysis">Part 3: Bird Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet21.html#part-4-regression-anova">Part 4: Regression ANOVA</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet21.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Worksheet 22: Model Assessment and Prediction in Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-1-the-coefficient-of-determination">Part 1: The Coefficient of Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-2-confidence-intervals-vs-prediction-intervals">Part 2: Confidence Intervals vs. Prediction Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-3-simulation-study-ci-vs-pi-coverage">Part 3: Simulation Study — CI vs. PI Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-4-prediction-with-the-bird-data">Part 4: Prediction with the Bird Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-5-diamonds-data-analysis">Part 5: Diamonds Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html">Getting Started with R and RStudio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#getting-started-with-swirl">Getting Started with swirl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#alternative-r-learning-resources">Alternative R Learning Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_quick_reference.html">Quick Reference Table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html">Computer Assignments and Tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-structure-by-session">Assignment Structure by Session</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html">Function Reference Part 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#simulation-functions">Simulation Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html">Function Reference Part 2: Inference Functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html#diagnostic-plots-for-assumptions">Diagnostic Plots for Assumptions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#tables-reporting">Tables &amp; Reporting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#data-import-validation">Data Import &amp; Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#statistical-assumptions">Statistical Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#common-errors-to-avoid">Common Errors to Avoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#workflow-template">Workflow Template</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html">Course Datasets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#primary-course-dataset-apprating">Primary Course Dataset - AppRating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#tutorial-support-datasets">Tutorial Support Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#loading-datasets-in-r">Loading Datasets in R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#built-in-r-datasets-used-in-course">Built-in R Datasets Used in Course</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#data-download-and-organization">Data Download and Organization</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Sequential Bayesian Updating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. The Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. The Foundation of Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Connecting CI and HT; <em>t</em>-Test for μ When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. The Four Steps to Hypothesis Testing and Understanding the Result</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Statistical Inference for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Independent Two-Sample Analysis When Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Independent Two-Sample Analysis - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Independent Two-Sample Analysis - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Paired Two-Sample Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. ANOVA F-Test and Its Relationship to Two-Sample <em>t</em>-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction and Robustness</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../worksheets_index.html">Course Worksheets</a></li>
      <li class="breadcrumb-item active">Worksheet 22: Model Assessment and Prediction in Regression</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/worksheets/worksheet_materials/worksheet22.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="worksheet-22-model-assessment-and-prediction-in-regression">
<span id="worksheet22"></span><h1>Worksheet 22: Model Assessment and Prediction in Regression<a class="headerlink" href="#worksheet-22-model-assessment-and-prediction-in-regression" title="Link to this heading"></a></h1>
<div class="info admonition">
<p class="admonition-title">Learning Objectives 🎯</p>
<ul class="simple">
<li><p>Understand the coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> and its interpretation</p></li>
<li><p>Distinguish between confidence intervals for the mean response and prediction intervals for individual observations</p></li>
<li><p>Explore through simulation how the Central Limit Theorem affects CIs differently than PIs</p></li>
<li><p>Compute and interpret prediction intervals and confidence intervals at specific values of <span class="math notranslate nohighlight">\(x\)</span></p></li>
<li><p>Apply comprehensive regression diagnostics to real-world data</p></li>
<li><p><strong>Implement model assessment and prediction tools using R</strong></p></li>
</ul>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<p>Building upon what we’ve learned over the last two worksheets, you’ve developed a solid foundation in <strong>simple linear regression</strong>:</p>
<ul class="simple">
<li><p><a class="reference internal" href="worksheet20.html#worksheet20"><span class="std std-ref">Worksheet 20: Introduction to Simple Linear Regression</span></a>: You learned how to estimate the regression line by minimizing squared residuals (least squares method). You derived formulas for the special univariate calculus examples gaining insights into how the slope and intercept are derived in the multivariate case, explored their statistical properties via simulation, and saw how these estimators behave in repeated sampling scenarios.</p></li>
<li><p><a class="reference internal" href="worksheet21.html#worksheet21"><span class="std std-ref">Worksheet 21: Inference for Simple Linear Regression</span></a>: You moved from estimation to formal statistical inference. You learned how to test hypotheses about the slope (<span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span>) and intercept (<span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span>), construct confidence intervals, and connect regression inference to the ANOVA framework. Additionally, you examined critical regression assumptions using residual diagnostics, including scatterplots, residual plots, histograms, and QQ-plots.</p></li>
</ul>
<p>Now that you understand how to estimate the line and conduct inference about its parameters, you must address two essential follow-up questions:</p>
<div class="important admonition">
<p class="admonition-title">Key Questions for This Worksheet 🎯</p>
<p><strong>How well does our regression line actually explain the observed data?</strong></p>
<p><strong>How can we accurately predict future observations, and quantify our uncertainty about those predictions?</strong></p>
</div>
<p>Having statistically significant slope or intercept parameters is necessary, but <strong>not sufficient</strong>, for practical usefulness. A model can show a statistically significant relationship and yet fail to explain much variability in the data or be unsuitable for accurate predictions. Therefore, the evaluation of a regression model involves more than just testing parameters; it involves quantifying the explanatory power, verifying assumptions, and assessing predictive accuracy and reliability. To do this, we will introduce new quantitative measures and deepen our diagnostic understanding of the regression model’s fit.</p>
</section>
<section id="part-1-the-coefficient-of-determination">
<h2>Part 1: The Coefficient of Determination<a class="headerlink" href="#part-1-the-coefficient-of-determination" title="Link to this heading"></a></h2>
<p>To answer these questions rigorously, we rely on additional metrics and diagnostics. One central measure you’ll examine closely is the <strong>Coefficient of Determination</strong> (<span class="math notranslate nohighlight">\(R^2\)</span>).</p>
<div class="math notranslate nohighlight">
\[R^2 = \frac{\text{SS}_R}{\text{SS}_T} = \frac{\sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}\]</div>
<p>Intuitively, <span class="math notranslate nohighlight">\(R^2\)</span> quantifies the proportion of the total variability in the response variable (<span class="math notranslate nohighlight">\(Y\)</span>) explained by your regression model. Yet, it’s crucial to understand not only <strong>what</strong> <span class="math notranslate nohighlight">\(R^2\)</span> <strong>indicates</strong> but also <strong>what it does not indicate</strong>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(R^2\)</span> provides a <strong>global measure of explanatory power</strong> for your fitted regression model. A high <span class="math notranslate nohighlight">\(R^2\)</span> indicates that the regression line effectively summarizes the observed data.</p></li>
<li><p>However, a high <span class="math notranslate nohighlight">\(R^2\)</span> alone doesn’t confirm a causal relationship, nor does it ensure that predictions will always be accurate. It simply measures how closely the data points cluster around your fitted regression line.</p></li>
<li><p>You should also recognize the direct relationship between <span class="math notranslate nohighlight">\(R^2\)</span> and the <strong>sample Pearson correlation coefficient</strong> (<span class="math notranslate nohighlight">\(r\)</span>):</p></li>
</ul>
<div class="math notranslate nohighlight">
\[r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}\]</div>
<p>While <span class="math notranslate nohighlight">\(r\)</span> specifically quantifies the linear association between two quantitative variables, in simple linear regression, the relationship is even clearer: <span class="math notranslate nohighlight">\(R^2\)</span> is simply <span class="math notranslate nohighlight">\(r^2\)</span>. Thus, in this specific context, understanding one measure directly informs your understanding of the other.</p>
</section>
<section id="part-2-confidence-intervals-vs-prediction-intervals">
<h2>Part 2: Confidence Intervals vs. Prediction Intervals<a class="headerlink" href="#part-2-confidence-intervals-vs-prediction-intervals" title="Link to this heading"></a></h2>
<p>Given a fitted regression model, your next step is often to use it for <strong>predictive purposes</strong>. To do this responsibly, you must quantify not only your best predictions, but also how confident you can be in these predictions.</p>
<p>You will explore two distinct types of intervals:</p>
<section id="confidence-intervals-for-the-mean-response">
<h3><strong>Confidence Intervals for the Mean Response</strong><a class="headerlink" href="#confidence-intervals-for-the-mean-response" title="Link to this heading"></a></h3>
<p>These intervals measure uncertainty around the regression line itself—the estimated <strong>average</strong> response at a given value of <span class="math notranslate nohighlight">\(x^*\)</span>.</p>
<ul>
<li><p><strong>Estimated Mean Response:</strong></p>
<div class="math notranslate nohighlight">
\[\hat{\mu}^* = b_0 + b_1 x^*\]</div>
</li>
<li><p><strong>Standard Error of the Mean Response:</strong></p>
<div class="math notranslate nohighlight">
\[\text{SE}_{\hat{\mu}^*} = \sqrt{\text{MS}_E \cdot \left(\frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{xx}}\right)}\]</div>
</li>
<li><p><strong>A</strong> <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> <strong>CI for the mean response at</strong> <span class="math notranslate nohighlight">\(x^*\)</span>:</p>
<div class="math notranslate nohighlight">
\[(b_0 + b_1 x^*) \pm t_{\alpha/2, n-2} \sqrt{\text{MS}_E \cdot \left(\frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{xx}}\right)}\]</div>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The CLT applies for <span class="math notranslate nohighlight">\(\hat{\mu}^* = b_0 + b_1 x^* = \sum_{i=1}^{n}\left(\frac{1}{n} + \frac{(x^* - \bar{x})}{S_{xx}}(x_i - \bar{x})\right)y_i\)</span>, therefore quantification of uncertainty using <span class="math notranslate nohighlight">\(t_{\alpha/2, n-2}\)</span> is reasonably accurate even if the population errors deviate from normality.</p>
</div>
</section>
<section id="prediction-intervals-for-individual-observations">
<h3><strong>Prediction Intervals for Individual Observations</strong><a class="headerlink" href="#prediction-intervals-for-individual-observations" title="Link to this heading"></a></h3>
<p>These intervals reflect not only uncertainty in the regression line, but also the added variability inherent in predicting a <strong>single new data point</strong>.</p>
<ul>
<li><p><strong>Predicted individual response:</strong></p>
<div class="math notranslate nohighlight">
\[\hat{Y}^* = b_0 + b_1 x^* + \varepsilon_{\text{new}}\]</div>
</li>
<li><p><strong>Standard Error for individual prediction:</strong></p>
<div class="math notranslate nohighlight">
\[\text{SE}_{\hat{Y}^*} = \sqrt{\text{MS}_E \cdot \left(1 + \frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{xx}}\right)}\]</div>
</li>
<li><p><strong>A</strong> <span class="math notranslate nohighlight">\(100(1-\alpha)\%\)</span> <strong>PI for an individual response at</strong> <span class="math notranslate nohighlight">\(x^*\)</span>:</p>
<div class="math notranslate nohighlight">
\[(b_0 + b_1 x^*) \pm t_{\alpha/2, n-2} \sqrt{\text{MS}_E \cdot \left(1 + \frac{1}{n} + \frac{(x^* - \bar{x})^2}{S_{xx}}\right)}\]</div>
</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The CLT does <strong>not</strong> apply if <span class="math notranslate nohighlight">\(\varepsilon_{\text{new}}\)</span> is not Normal for <span class="math notranslate nohighlight">\(\hat{Y}^* = b_0 + b_1 x^* + \varepsilon = \sum_{i=1}^{n}\left(\frac{1}{n} + \frac{(x^* - \bar{x})}{S_{xx}}(x_i - \bar{x})\right)y_i + \varepsilon_{\text{new}}\)</span>. The new error term <span class="math notranslate nohighlight">\(\varepsilon_{\text{new}}\)</span> is not averaged over and retains its original distribution.</p>
</div>
<p>These intervals highlight the crucial distinction between <strong>estimating average responses</strong> and <strong>predicting individual observations</strong>. The latter always requires wider intervals to account for additional uncertainty.</p>
</section>
</section>
<section id="part-3-simulation-study-ci-vs-pi-coverage">
<h2>Part 3: Simulation Study — CI vs. PI Coverage<a class="headerlink" href="#part-3-simulation-study-ci-vs-pi-coverage" title="Link to this heading"></a></h2>
<p><strong>Question 1:</strong> In this problem, you’ll explore through simulation how confidence intervals for the mean response differ from prediction intervals for individual responses, specifically examining their sensitivity to the underlying error distribution and sample size.</p>
<p><strong>Instructions:</strong></p>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Copy the R simulation script provided below into an R file (e.g., <code class="docutils literal notranslate"><span class="pre">CI_PI_simulation.R</span></code>) and save it.</p></li>
<li><p>Start with a fresh R session (e.g., restart R in RStudio). Then run the simulation by sourcing the script: <code class="docutils literal notranslate"><span class="pre">source(&quot;CI_PI_simulation.R&quot;)</span></code>.</p></li>
<li><p>This script performs the following:</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>Simulates data for three error distributions (<strong>Normal, Uniform, and Lognormal</strong>) and three sample sizes (<strong>n = 3, 30, 500</strong>).</p></li>
<li><p>Computes 95% confidence intervals (CIs) for the mean response and 95% prediction intervals (PIs) for individual responses.</p></li>
<li><p>Reports empirical coverage probabilities in the console.</p></li>
<li><p>Produces side-by-side histograms and QQ-plots for the sampling distributions of the mean predictions and individual predictions.</p></li>
</ul>
</div></blockquote>
</div></blockquote>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1">#------------------------------------------------------------------</span>
<span class="c1">#  Simulation: CI for Mean Response vs PI for Individual Response</span>
<span class="c1">#  (single x0)  — STAT 350 Worksheet 22</span>
<span class="c1">#------------------------------------------------------------------</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">gridExtra</span><span class="p">)</span>
<span class="nf">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span>

<span class="c1"># ------------------ 1. USER SETTINGS -----------------------------</span>
<span class="n">Nsim</span><span class="w">     </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5000</span><span class="w">                 </span><span class="c1"># simulations per scenario</span>
<span class="n">n_vec</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="m">500</span><span class="p">)</span><span class="w">        </span><span class="c1"># sample sizes</span>
<span class="n">beta0</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5</span><span class="w">                    </span><span class="c1"># true intercept</span>
<span class="n">beta1</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w">                    </span><span class="c1"># true slope</span>
<span class="n">sigma</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w">                    </span><span class="c1"># SD of errors</span>
<span class="n">alpha</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.05</span><span class="w">                 </span><span class="c1"># 95% intervals</span>
<span class="n">err_list</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;normal&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;uniform&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;lognormal&quot;</span><span class="p">)</span>
<span class="c1"># -----------------------------------------------------------------</span>

<span class="c1"># ------------------ 2. HELPER FUNCTIONS --------------------------</span>
<span class="n">make_errors</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">dist</span><span class="p">,</span><span class="w"> </span><span class="n">sigma</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kr">switch</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span>
<span class="w">         </span><span class="n">normal</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">rnorm</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sigma</span><span class="p">),</span><span class="w"> </span><span class="n">N</span><span class="p">),</span>
<span class="w">         </span><span class="n">uniform</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">rng</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">12</span><span class="p">)</span><span class="o">*</span><span class="n">sigma</span><span class="p">;</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">runif</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="n">rng</span><span class="o">/</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">rng</span><span class="o">/</span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">N</span><span class="p">)},</span>
<span class="w">         </span><span class="n">lognormal</span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">sdlog</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">log</span><span class="p">(</span><span class="m">1</span><span class="o">+</span><span class="n">sigma</span><span class="o">^</span><span class="m">2</span><span class="p">));</span>
<span class="w">         </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">rlnorm</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sdlog</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">exp</span><span class="p">(</span><span class="n">sdlog</span><span class="o">^</span><span class="m">2</span><span class="o">/</span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">N</span><span class="p">)},</span>
<span class="w">         </span><span class="nf">stop</span><span class="p">(</span><span class="s">&quot;Unknown distribution&quot;</span><span class="p">))</span>
<span class="p">}</span>

<span class="n">ls_est</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">xbar</span><span class="p">,</span><span class="w"> </span><span class="n">Sxx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">b1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">drop</span><span class="p">(</span><span class="n">Y</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">xbar</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">Sxx</span><span class="p">)</span><span class="w">    </span><span class="c1"># N x n %*% n x 1  -&gt; N x 1</span>
<span class="w">  </span><span class="n">b0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rowMeans</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">xbar</span>
<span class="w">  </span><span class="nf">list</span><span class="p">(</span><span class="n">b0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b0</span><span class="p">,</span><span class="w"> </span><span class="n">b1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b1</span><span class="p">)</span>
<span class="p">}</span>
<span class="c1"># -----------------------------------------------------------------</span>

<span class="c1"># ------------------ 3. MAIN SIMULATION LOOP ----------------------</span>
<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">dist</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="n">err_list</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nf">cat</span><span class="p">(</span><span class="s">&quot;\n==============================\nError distribution:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">dist</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="w">  </span><span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="n">n_vec</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="n">x_vec</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">)</span>
<span class="w">    </span><span class="n">xbar</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">x_vec</span><span class="p">)</span>
<span class="w">    </span><span class="n">Sxx</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">((</span><span class="n">x_vec</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">xbar</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">x0</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">xbar</span><span class="w">               </span><span class="c1"># prediction point x0 = mean(x)</span>

<span class="w">    </span><span class="c1"># simulate responses</span>
<span class="w">    </span><span class="n">E_mat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">make_errors</span><span class="p">(</span><span class="n">Nsim</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">dist</span><span class="p">,</span><span class="w"> </span><span class="n">sigma</span><span class="p">)</span>
<span class="w">    </span><span class="n">Y_mat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sweep</span><span class="p">(</span><span class="n">E_mat</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">beta0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x_vec</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;+&quot;</span><span class="p">)</span><span class="w">  </span><span class="c1"># Nsim x n</span>

<span class="w">    </span><span class="c1"># least-squares estimates</span>
<span class="w">    </span><span class="n">est</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">ls_est</span><span class="p">(</span><span class="n">Y_mat</span><span class="p">,</span><span class="w"> </span><span class="n">x_vec</span><span class="p">,</span><span class="w"> </span><span class="n">xbar</span><span class="p">,</span><span class="w"> </span><span class="n">Sxx</span><span class="p">)</span>
<span class="w">    </span><span class="n">b0</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">est</span><span class="o">$</span><span class="n">b0</span><span class="p">;</span><span class="w">  </span><span class="n">b1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">est</span><span class="o">$</span><span class="n">b1</span>

<span class="w">    </span><span class="c1"># fitted values for residual MS</span>
<span class="w">    </span><span class="n">fits</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="n">b0</span><span class="p">,</span><span class="w"> </span><span class="n">Nsim</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span><span class="w"> </span><span class="n">Nsim</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="n">x_vec</span><span class="p">,</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Nsim</span><span class="p">)</span>
<span class="w">    </span><span class="n">SSE</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rowSums</span><span class="p">((</span><span class="n">Y_mat</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">fits</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="n">s</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">SSE</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="m">-2</span><span class="p">))</span><span class="w">                      </span><span class="c1"># Nsim-vector</span>

<span class="w">    </span><span class="c1"># point predictions</span>
<span class="w">    </span><span class="n">yhat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">b0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x0</span><span class="w">                         </span><span class="c1"># mean response</span>

<span class="w">    </span><span class="c1"># ------------------ intervals -------------------------------</span>
<span class="w">    </span><span class="n">se_mean</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">x0</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">xbar</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">Sxx</span><span class="p">)</span>
<span class="w">    </span><span class="n">se_pred</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">x0</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">xbar</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">Sxx</span><span class="p">)</span>
<span class="w">    </span><span class="n">t_mult</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">qt</span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">alpha</span><span class="o">/</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">2</span><span class="p">)</span>

<span class="w">    </span><span class="n">CI_low</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">yhat</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_mult</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">se_mean</span>
<span class="w">    </span><span class="n">CI_high</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">yhat</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">t_mult</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">se_mean</span>

<span class="w">    </span><span class="n">PI_low</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">yhat</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">t_mult</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">se_pred</span>
<span class="w">    </span><span class="n">PI_high</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">yhat</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">t_mult</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">se_pred</span>

<span class="w">    </span><span class="c1"># simulate ONE future error &amp; future observation</span>
<span class="w">    </span><span class="n">eps_new</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">make_errors</span><span class="p">(</span><span class="n">Nsim</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">dist</span><span class="p">,</span><span class="w"> </span><span class="n">sigma</span><span class="p">)[,</span><span class="m">1</span><span class="p">]</span>
<span class="w">    </span><span class="n">y_indiv</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">yhat</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">eps_new</span><span class="w">          </span><span class="c1"># what you&#39;d predict for one new case</span>
<span class="w">    </span><span class="n">y_true</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">beta0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">eps_new</span><span class="w">  </span><span class="c1"># population truth for coverage</span>

<span class="w">    </span><span class="c1"># coverage</span>
<span class="w">    </span><span class="n">mu_true</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">beta0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x0</span>
<span class="w">    </span><span class="n">cover_CI</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">CI_low</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">mu_true</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mu_true</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">CI_high</span><span class="p">)</span>
<span class="w">    </span><span class="n">cover_PI</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">PI_low</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">y_true</span><span class="w">  </span><span class="o">&amp;</span><span class="w"> </span><span class="n">y_true</span><span class="w">  </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">PI_high</span><span class="p">)</span>

<span class="w">    </span><span class="c1"># ------------------ plotting -------------------------------</span>
<span class="w">    </span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">mean_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">yhat</span><span class="p">,</span><span class="w"> </span><span class="n">indiv_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_indiv</span><span class="p">)</span>

<span class="w">    </span><span class="n">p1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">mean_pred</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">after_stat</span><span class="p">(</span><span class="n">density</span><span class="p">)),</span>
<span class="w">                     </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;grey&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">geom_density</span><span class="p">(</span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">stat_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dnorm</span><span class="p">,</span>
<span class="w">                    </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">yhat</span><span class="p">),</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">yhat</span><span class="p">)),</span>
<span class="w">                    </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Mean predictions&quot;</span><span class="p">,</span>
<span class="w">           </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">paste0</span><span class="p">(</span><span class="s">&quot;CI cover = &quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">cover_CI</span><span class="p">,</span><span class="m">3</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">theme</span><span class="p">(</span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">9</span><span class="p">))</span>

<span class="w">    </span><span class="n">p2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">sample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean_pred</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">geom_qq</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">.</span><span class="m">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">geom_qq_line</span><span class="p">(</span><span class="n">col</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">&quot;QQ-Mean&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">theme</span><span class="p">(</span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">9</span><span class="p">))</span>

<span class="w">    </span><span class="n">p3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">indiv_pred</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">after_stat</span><span class="p">(</span><span class="n">density</span><span class="p">)),</span>
<span class="w">                     </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;grey&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">geom_density</span><span class="p">(</span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkgreen&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">stat_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dnorm</span><span class="p">,</span>
<span class="w">                    </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">indiv_pred</span><span class="p">),</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">indiv_pred</span><span class="p">)),</span>
<span class="w">                    </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Individual predictions&quot;</span><span class="p">,</span>
<span class="w">           </span><span class="n">subtitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">paste0</span><span class="p">(</span><span class="s">&quot;PI cover = &quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">cover_PI</span><span class="p">,</span><span class="m">3</span><span class="p">)))</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">theme</span><span class="p">(</span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">9</span><span class="p">))</span>

<span class="w">    </span><span class="n">p4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">sample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">indiv_pred</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">geom_qq</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">.</span><span class="m">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">geom_qq_line</span><span class="p">(</span><span class="n">col</span><span class="o">=</span><span class="s">&quot;darkgreen&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">&quot;QQ-Individual&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">      </span><span class="nf">theme</span><span class="p">(</span><span class="n">plot.title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">element_text</span><span class="p">(</span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">9</span><span class="p">))</span>

<span class="w">    </span><span class="nf">grid.arrange</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span><span class="n">p2</span><span class="p">,</span><span class="n">p3</span><span class="p">,</span><span class="n">p4</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span>
<span class="w">                 </span><span class="n">top</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Error:&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">dist</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;| n =&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;| x0 =&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span><span class="m">2</span><span class="p">)))</span>

<span class="w">    </span><span class="c1"># console summary</span>
<span class="w">    </span><span class="nf">cat</span><span class="p">(</span><span class="s">&quot;n =&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="s">&quot; CI cover =&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">cover_CI</span><span class="p">,</span><span class="m">3</span><span class="p">),</span>
<span class="w">        </span><span class="s">&quot; PI cover =&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">cover_PI</span><span class="p">,</span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>a) Report your findings:</strong></p>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>When errors are Normal, how close are the observed CI and PI coverages to the nominal 95%?</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<ol class="lowerroman simple" start="2">
<li><p>Identify which distribution consistently produced intervals with coverage noticeably above or below 95%. Provide a brief explanation for these observations.</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<ol class="lowerroman simple" start="3">
<li><p>Compare the shapes of the histograms and QQ-plots for the mean predictions and individual predictions. Which appear approximately Normal, and which clearly reflect the shape of the original error distribution?</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div></blockquote>
<p><strong>b) Answer the following questions:</strong></p>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Use these observations to explain how the Central Limit Theorem affects confidence intervals differently than prediction intervals.</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<ol class="lowerroman simple" start="2">
<li><p>Describe clearly how increasing the sample size influences CI and PI coverage, as well as the normality of their distributions.</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<ol class="lowerroman simple" start="3">
<li><p>Why does the distribution of individual predictions remain noticeably skewed even for very large sample sizes?</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div></blockquote>
</section>
<section id="part-4-prediction-with-the-bird-data">
<h2>Part 4: Prediction with the Bird Data<a class="headerlink" href="#part-4-prediction-with-the-bird-data" title="Link to this heading"></a></h2>
<p><strong>Question 2:</strong> Use your own estimated coefficients <span class="math notranslate nohighlight">\(b_0\)</span>, <span class="math notranslate nohighlight">\(b_1\)</span>, <span class="math notranslate nohighlight">\(\bar{x}\)</span>, and <span class="math notranslate nohighlight">\(\text{MS}_E\)</span> from your fitted model regarding the bird data to answer the following:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Weight (grams)</p></th>
<th class="head"><p>WingLength (cm)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>130.8</p></td>
<td><p>24.9</p></td>
</tr>
<tr class="row-odd"><td><p>125.8</p></td>
<td><p>24.5</p></td>
</tr>
<tr class="row-even"><td><p>155.2</p></td>
<td><p>27.1</p></td>
</tr>
<tr class="row-odd"><td><p>105.6</p></td>
<td><p>22.3</p></td>
</tr>
<tr class="row-even"><td><p>146.9</p></td>
<td><p>25.4</p></td>
</tr>
<tr class="row-odd"><td><p>148.4</p></td>
<td><p>26.5</p></td>
</tr>
<tr class="row-even"><td><p>181.2</p></td>
<td><p>32.4</p></td>
</tr>
<tr class="row-odd"><td><p>137.0</p></td>
<td><p>25.7</p></td>
</tr>
</tbody>
</table>
<p><strong>Your regression equation:</strong> <span class="math notranslate nohighlight">\(\hat{y}_{\text{wingspan}} = b_0 + b_1 \cdot x_{\text{weight}} =\)</span> ____________________</p>
<p><strong>a)</strong> Use your fitted line to compute the predicted wing length at Point A and Point B. Give a clear reason why the prediction at Point B is much less trustworthy than that for Point A.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 20.0%" />
<col style="width: 30.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Point</p></th>
<th class="head"><p>Weight (grams)</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\hat{y}_{\text{wingspan}}\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>140</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>B</p></td>
<td><p>210</p></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Why is the prediction at Point B less trustworthy?</strong></p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<p><strong>b)</strong> Work only with <strong>Point A (140 g)</strong> in this part.</p>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Obtain and report the <strong>95% confidence interval</strong> for the mean wing length at 140 g.</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<ol class="lowerroman simple" start="2">
<li><p>Obtain and report the <strong>95% prediction interval</strong> for an individual bird’s wing length at 140 g.</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<ol class="lowerroman simple" start="3">
<li><p>Which interval is wider, and by how many centimeters? Provide a clear statistical interpretation of each interval.</p></li>
</ol>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div></blockquote>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Verification code for bird data predictions</span>
<span class="n">bird_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="w">  </span><span class="n">Weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">130.8</span><span class="p">,</span><span class="w"> </span><span class="m">125.8</span><span class="p">,</span><span class="w"> </span><span class="m">155.2</span><span class="p">,</span><span class="w"> </span><span class="m">105.6</span><span class="p">,</span><span class="w"> </span><span class="m">146.9</span><span class="p">,</span><span class="w"> </span><span class="m">148.4</span><span class="p">,</span><span class="w"> </span><span class="m">181.2</span><span class="p">,</span><span class="w"> </span><span class="m">137.0</span><span class="p">),</span>
<span class="w">  </span><span class="n">WingLength</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">24.9</span><span class="p">,</span><span class="w"> </span><span class="m">24.5</span><span class="p">,</span><span class="w"> </span><span class="m">27.1</span><span class="p">,</span><span class="w"> </span><span class="m">22.3</span><span class="p">,</span><span class="w"> </span><span class="m">25.4</span><span class="p">,</span><span class="w"> </span><span class="m">26.5</span><span class="p">,</span><span class="w"> </span><span class="m">32.4</span><span class="p">,</span><span class="w"> </span><span class="m">25.7</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">bird_lm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">WingLength</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Weight</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bird_data</span><span class="p">)</span>

<span class="c1"># Create new data for prediction</span>
<span class="n">newdata</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">Weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">140</span><span class="p">,</span><span class="w"> </span><span class="m">210</span><span class="p">))</span>

<span class="c1"># Point predictions</span>
<span class="nf">predict</span><span class="p">(</span><span class="n">bird_lm</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">newdata</span><span class="p">)</span>

<span class="c1"># Confidence interval for mean response</span>
<span class="nf">predict</span><span class="p">(</span><span class="n">bird_lm</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">newdata</span><span class="p">,</span><span class="w"> </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;confidence&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span>

<span class="c1"># Prediction interval for individual response</span>
<span class="nf">predict</span><span class="p">(</span><span class="n">bird_lm</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">newdata</span><span class="p">,</span><span class="w"> </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;prediction&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="part-5-diamonds-data-analysis">
<h2>Part 5: Diamonds Data Analysis<a class="headerlink" href="#part-5-diamonds-data-analysis" title="Link to this heading"></a></h2>
<p><strong>Question 3:</strong> The <strong>diamonds</strong> data set, included in the <code class="docutils literal notranslate"><span class="pre">ggplot2</span></code> package, contains detailed information on 53,940 round-cut diamonds. Each observation corresponds to a single diamond and includes both physical characteristics and pricing information.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15.0%" />
<col style="width: 55.0%" />
<col style="width: 30.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Variable</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>carat</p></td>
<td><p>Weight of the diamond (in carats)</p></td>
<td><p>Quantitative</p></td>
</tr>
<tr class="row-odd"><td><p>cut</p></td>
<td><p>Quality of the cut (Fair, Good, Very Good, Premium, Ideal)</p></td>
<td><p>Categorical</p></td>
</tr>
<tr class="row-even"><td><p>color</p></td>
<td><p>Diamond color (graded from J (worst) to D (best))</p></td>
<td><p>Categorical</p></td>
</tr>
<tr class="row-odd"><td><p>clarity</p></td>
<td><p>A measurement of how clear the diamond is</p></td>
<td><p>Categorical</p></td>
</tr>
<tr class="row-even"><td><p>depth</p></td>
<td><p>Total depth percentage</p></td>
<td><p>Quantitative</p></td>
</tr>
<tr class="row-odd"><td><p>table</p></td>
<td><p>Width of the top of the diamond relative to the widest point</p></td>
<td><p>Quantitative</p></td>
</tr>
<tr class="row-even"><td><p>price</p></td>
<td><p>Price in US dollars</p></td>
<td><p>Quantitative</p></td>
</tr>
<tr class="row-odd"><td><p>x</p></td>
<td><p>Length in mm</p></td>
<td><p>Quantitative</p></td>
</tr>
<tr class="row-even"><td><p>y</p></td>
<td><p>Width in mm</p></td>
<td><p>Quantitative</p></td>
</tr>
<tr class="row-odd"><td><p>z</p></td>
<td><p>Depth in mm</p></td>
<td><p>Quantitative</p></td>
</tr>
</tbody>
</table>
<p>For this exercise, we will focus on a <strong>subset of the diamonds data</strong>, specifically those diamonds with <strong>carat strictly less than 1.00</strong>. This yields a more focused analysis by excluding the influence of very large diamonds and narrowing the prediction space.</p>
<p>We are interested in exploring how <strong>carat</strong> (<span class="math notranslate nohighlight">\(x\)</span>) influences <strong>price</strong> (<span class="math notranslate nohighlight">\(Y\)</span>) for diamonds under 1 carat. We will treat carat as the explanatory variable and price as the response variable in a simple linear regression framework.</p>
<p>While linearity may be a reasonable approximation in this limited range, we will examine the model assumptions carefully and explore how to compute and interpret interval estimates (confidence and prediction intervals).</p>
<p><strong>a) Checking Assumptions:</strong></p>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Subset the data to include only diamonds where carat &lt; 1.00.</p></li>
<li><p>Create the following diagnostic plots based on your fitted simple linear regression:</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>Scatterplot of <strong>carat</strong> (<span class="math notranslate nohighlight">\(x\)</span>) vs <strong>price</strong> (<span class="math notranslate nohighlight">\(y\)</span>), with the least squares regression line</p></li>
<li><p>Residual plot (residuals vs. carat)</p></li>
<li><p>Histogram of residuals with density and Normal curve overlay</p></li>
<li><p>QQ-plot of residuals</p></li>
</ul>
</div></blockquote>
<ol class="lowerroman simple" start="3">
<li><p>After reviewing the plots, evaluate the assumptions by completing the table below.</p></li>
</ol>
</div></blockquote>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>

<span class="c1"># Load and subset the data</span>
<span class="nf">data</span><span class="p">(</span><span class="n">diamonds</span><span class="p">,</span><span class="w"> </span><span class="n">package</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;ggplot2&quot;</span><span class="p">)</span>
<span class="n">d_small</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">diamonds</span><span class="p">[</span><span class="n">diamonds</span><span class="o">$</span><span class="n">carat</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="p">]</span>

<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Number of observations:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">nrow</span><span class="p">(</span><span class="n">d_small</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># Fit the model</span>
<span class="n">fit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">price</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">carat</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">d_small</span><span class="p">)</span>

<span class="c1"># Add residuals and fitted values to data</span>
<span class="n">d_small</span><span class="o">$</span><span class="n">resids</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">resid</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="n">d_small</span><span class="o">$</span><span class="n">fitted</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">fitted</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># 1. Scatterplot with regression line</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">d_small</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">carat</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">price</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_smooth</span><span class="p">(</span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lm&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">se</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Price vs. Carat (&lt;1 carat)&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Carat&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Price (US$)&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>

<span class="c1"># 2. Residual plot</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">d_small</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">carat</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resids</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Residuals vs. Carat&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Carat&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Residual (y - y-hat)&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>

<span class="c1"># 3. Histogram of residuals</span>
<span class="n">res_mu</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">d_small</span><span class="o">$</span><span class="n">resids</span><span class="p">)</span>
<span class="n">res_sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">d_small</span><span class="o">$</span><span class="n">resids</span><span class="p">)</span>

<span class="nf">ggplot</span><span class="p">(</span><span class="n">d_small</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resids</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">after_stat</span><span class="p">(</span><span class="n">density</span><span class="p">)),</span><span class="w"> </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">40</span><span class="p">,</span>
<span class="w">                 </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;grey&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_density</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dnorm</span><span class="p">,</span>
<span class="w">                </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">res_mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">res_sigma</span><span class="p">),</span>
<span class="w">                </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Histogram of Residuals&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Residual&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Density&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>

<span class="c1"># 4. QQ-plot of residuals</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">d_small</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">sample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resids</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_qq</span><span class="p">(</span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_qq_line</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;QQ-plot of Residuals&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
<table class="docutils align-default">
<colgroup>
<col style="width: 25.0%" />
<col style="width: 20.0%" />
<col style="width: 55.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Assumption</p></th>
<th class="head"><p>OK / Violated</p></th>
<th class="head"><p>Brief justification (one sentence)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Linearity</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Constant variance (homoscedasticity)</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Normality of errors</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Independence</p></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>b) Applying the Log-Log Transformation:</strong></p>
<p>The diagnostics from part (a) likely revealed serious assumption violations. When the relationship between <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> follows a <strong>power law</strong> (i.e., <span class="math notranslate nohighlight">\(Y \propto x^\beta\)</span>), applying a <strong>log-log transformation</strong> can simultaneously:</p>
<ul class="simple">
<li><p>Linearize the relationship</p></li>
<li><p>Stabilize variance (reduce heteroscedasticity)</p></li>
<li><p>Improve Normality of errors</p></li>
</ul>
<p>The transformation works because if <span class="math notranslate nohighlight">\(Y = \alpha \cdot x^\beta \cdot \varepsilon\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[\log(Y) = \log(\alpha) + \beta \cdot \log(x) + \log(\varepsilon)\]</div>
<p>This is now a linear relationship between <span class="math notranslate nohighlight">\(\log(Y)\)</span> and <span class="math notranslate nohighlight">\(\log(x)\)</span>.</p>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Create new variables <code class="docutils literal notranslate"><span class="pre">log_carat</span> <span class="pre">=</span> <span class="pre">log(carat)</span></code> and <code class="docutils literal notranslate"><span class="pre">log_price</span> <span class="pre">=</span> <span class="pre">log(price)</span></code>.</p></li>
<li><p>Fit a simple linear regression of <strong>log(price)</strong> on <strong>log(carat)</strong>.</p></li>
<li><p>Create the same four diagnostic plots as in part (a), but now for the log-log model.</p></li>
<li><p>Re-evaluate the assumptions using the table below.</p></li>
</ol>
</div></blockquote>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create log-transformed variables</span>
<span class="n">d_small</span><span class="o">$</span><span class="n">log_carat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">log</span><span class="p">(</span><span class="n">d_small</span><span class="o">$</span><span class="n">carat</span><span class="p">)</span>
<span class="n">d_small</span><span class="o">$</span><span class="n">log_price</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">log</span><span class="p">(</span><span class="n">d_small</span><span class="o">$</span><span class="n">price</span><span class="p">)</span>

<span class="c1"># Fit the model on log-log scale</span>
<span class="n">fit_log</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">log_price</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">log_carat</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">d_small</span><span class="p">)</span>

<span class="c1"># Add residuals and fitted values</span>
<span class="n">d_small</span><span class="o">$</span><span class="n">resids_log</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">resid</span><span class="p">(</span><span class="n">fit_log</span><span class="p">)</span>
<span class="n">d_small</span><span class="o">$</span><span class="n">fitted_log</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">fitted</span><span class="p">(</span><span class="n">fit_log</span><span class="p">)</span>

<span class="c1"># 1. Scatterplot with regression line (log-log scale)</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">d_small</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log_carat</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log_price</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_smooth</span><span class="p">(</span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lm&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">se</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Log(Price) vs. Log(Carat)&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Log(Carat)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Log(Price)&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>

<span class="c1"># 2. Residual plot (log-log scale)</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">d_small</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log_carat</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resids_log</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_hline</span><span class="p">(</span><span class="n">yintercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Residuals vs. Log(Carat)&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Log(Carat)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Residual&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>

<span class="c1"># 3. Histogram of residuals (log-log scale)</span>
<span class="n">res_mu_log</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">d_small</span><span class="o">$</span><span class="n">resids_log</span><span class="p">)</span>
<span class="n">res_sigma_log</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sd</span><span class="p">(</span><span class="n">d_small</span><span class="o">$</span><span class="n">resids_log</span><span class="p">)</span>

<span class="nf">ggplot</span><span class="p">(</span><span class="n">d_small</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resids_log</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_histogram</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">after_stat</span><span class="p">(</span><span class="n">density</span><span class="p">)),</span><span class="w"> </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">40</span><span class="p">,</span>
<span class="w">                 </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;grey&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_density</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_function</span><span class="p">(</span><span class="n">fun</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dnorm</span><span class="p">,</span>
<span class="w">                </span><span class="n">args</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">res_mu_log</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">res_sigma_log</span><span class="p">),</span>
<span class="w">                </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">linetype</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dashed&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Histogram of Residuals — Log-Log Model&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Residual&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Density&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>

<span class="c1"># 4. QQ-plot of residuals (log-log scale)</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">d_small</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">sample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resids_log</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_qq</span><span class="p">(</span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">stat_qq_line</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;QQ-plot of Residuals — Log-Log Model&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Assumption Assessment (Log-Log Scale):</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 25.0%" />
<col style="width: 20.0%" />
<col style="width: 55.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Assumption</p></th>
<th class="head"><p>OK / Violated</p></th>
<th class="head"><p>Brief justification (one sentence)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Linearity</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Constant variance (homoscedasticity)</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Normality of errors</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Independence</p></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Comparison:</strong> In one or two sentences, describe how the log-log transformation affected the assumption diagnostics.</p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For the remaining parts (c–f), use the <strong>log-log transformed model</strong> since it better satisfies the regression assumptions.</p>
</div>
<p><strong>c)</strong> Write down the estimated regression equation for the log-log model.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Model summary (log-log)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit_log</span><span class="p">)</span>
</pre></div>
</div>
<p><span class="math notranslate nohighlight">\(\widehat{\log(\text{price})} =\)</span> ____________________</p>
<p><strong>Interpretation of the slope (elasticity):</strong> In a log-log model, the slope <span class="math notranslate nohighlight">\(b_1\)</span> represents the <strong>elasticity</strong> — the percent change in <span class="math notranslate nohighlight">\(Y\)</span> for a 1% change in <span class="math notranslate nohighlight">\(x\)</span>. Complete the interpretation:</p>
<blockquote>
<div><p><em>“A 1% increase in carat is associated with approximately a ____% increase in price.”</em></p>
</div></blockquote>
<p><strong>d)</strong> Perform the full four-step hypothesis test for the slope of the log-log model at <span class="math notranslate nohighlight">\(\alpha = 0.01\)</span>.</p>
<p><strong>Step 1:</strong> State the parameter of interest. (Skip)</p>
<p><strong>Step 2:</strong> State the hypotheses.</p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<p><strong>Step 3:</strong> Calculate the test statistic and p-value.</p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<p><strong>Step 4:</strong> State your conclusion in context.</p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<p><strong>e)</strong> Complete the ANOVA table for the log-log model.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># ANOVA table (log-log model)</span>
<span class="nf">anova</span><span class="p">(</span><span class="n">fit_log</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-default">
<colgroup>
<col style="width: 18.0%" />
<col style="width: 15.0%" />
<col style="width: 22.0%" />
<col style="width: 20.0%" />
<col style="width: 15.0%" />
<col style="width: 10.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Source</p></th>
<th class="head"><p>Degrees of Freedom</p></th>
<th class="head"><p>Sum of Squares</p></th>
<th class="head"><p>Mean Squares</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(F\)</span>-test statistic</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(p\)</span>-value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Regression</p></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Residual</p></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Total</p></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>f)</strong> Compute the coefficient of determination for the log-log model and compare it to the original model.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare R-squared values</span>
<span class="n">R2_orig</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">fit_orig</span><span class="p">)</span><span class="o">$</span><span class="n">r.squared</span>
<span class="n">R2_log</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">fit_log</span><span class="p">)</span><span class="o">$</span><span class="n">r.squared</span>

<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Original model (price ~ carat):     R² =&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">R2_orig</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Log-log model (log_price ~ log_carat): R² =&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="n">R2_log</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[R^2_{\text{original}} = \qquad\qquad\qquad R^2_{\text{log-log}} =\]</div>
<p><strong>Interpretation:</strong> Which model explains more variability in the response? Why might <span class="math notranslate nohighlight">\(R^2\)</span> values not be directly comparable between the two models?</p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<p><strong>g)</strong> Graphically construct confidence and prediction bands for the <strong>log-log model</strong>.</p>
<blockquote>
<div><ol class="lowerroman simple">
<li><p>Construct <strong>90% confidence bands</strong> for the mean log(price) across the observed range of log(carat).</p></li>
<li><p>Construct <strong>90% prediction bands</strong> for individual log(price) values across the same range.</p></li>
<li><p>Superimpose on one plot: scatterplot of the log-transformed data, fitted line, and both bands.</p></li>
<li><p><strong>Compare</strong> the bands to those you would have obtained from the original model. Why are prediction intervals from the log-log model more trustworthy?</p></li>
</ol>
</div></blockquote>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create prediction grid on log scale</span>
<span class="n">log_carat_grid</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">log_carat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">d_small</span><span class="o">$</span><span class="n">log_carat</span><span class="p">),</span>
<span class="w">                                              </span><span class="nf">max</span><span class="p">(</span><span class="n">d_small</span><span class="o">$</span><span class="n">log_carat</span><span class="p">),</span>
<span class="w">                                              </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">400</span><span class="p">))</span>

<span class="c1"># Get confidence and prediction bands</span>
<span class="n">conf_band</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">fit_log</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log_carat_grid</span><span class="p">,</span>
<span class="w">                     </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;confidence&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.90</span><span class="p">)</span>
<span class="n">pred_band</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">fit_log</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log_carat_grid</span><span class="p">,</span>
<span class="w">                     </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;prediction&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.90</span><span class="p">)</span>

<span class="c1"># Combine into data frame</span>
<span class="n">band_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cbind</span><span class="p">(</span><span class="n">log_carat_grid</span><span class="p">,</span>
<span class="w">                 </span><span class="n">fit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">conf_band</span><span class="p">[,</span><span class="w"> </span><span class="s">&quot;fit&quot;</span><span class="p">],</span>
<span class="w">                 </span><span class="n">conf_lwr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">conf_band</span><span class="p">[,</span><span class="w"> </span><span class="s">&quot;lwr&quot;</span><span class="p">],</span>
<span class="w">                 </span><span class="n">conf_upr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">conf_band</span><span class="p">[,</span><span class="w"> </span><span class="s">&quot;upr&quot;</span><span class="p">],</span>
<span class="w">                 </span><span class="n">pred_lwr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred_band</span><span class="p">[,</span><span class="w"> </span><span class="s">&quot;lwr&quot;</span><span class="p">],</span>
<span class="w">                 </span><span class="n">pred_upr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred_band</span><span class="p">[,</span><span class="w"> </span><span class="s">&quot;upr&quot;</span><span class="p">])</span>

<span class="c1"># Create the plot</span>
<span class="nf">ggplot</span><span class="p">()</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="c1"># Scatter points (log-log scale)</span>
<span class="w">  </span><span class="nf">geom_point</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">d_small</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log_carat</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log_price</span><span class="p">),</span>
<span class="w">             </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.25</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="c1"># Prediction band (wide, light blue) — plot first so it&#39;s behind</span>
<span class="w">  </span><span class="nf">geom_ribbon</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">band_df</span><span class="p">,</span>
<span class="w">              </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log_carat</span><span class="p">,</span><span class="w"> </span><span class="n">ymin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred_lwr</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred_upr</span><span class="p">),</span>
<span class="w">              </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;lightblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="c1"># Confidence band (narrow, dark blue)</span>
<span class="w">  </span><span class="nf">geom_ribbon</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">band_df</span><span class="p">,</span>
<span class="w">              </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log_carat</span><span class="p">,</span><span class="w"> </span><span class="n">ymin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">conf_lwr</span><span class="p">,</span><span class="w"> </span><span class="n">ymax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">conf_upr</span><span class="p">),</span>
<span class="w">              </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;darkblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.6</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="c1"># Fitted line</span>
<span class="w">  </span><span class="nf">geom_line</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">band_df</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log_carat</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="p">),</span>
<span class="w">            </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.5</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;black&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;90% Confidence (dark) &amp; Prediction (light) Bands — Log-Log Model&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Log(Carat)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Log(Price)&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Your comparison of the bands and discussion of trustworthiness:</strong></p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<p><strong>h) (Bonus)</strong> Back-transform the predictions to the original scale.</p>
<p>When we predict on the log scale, we get <span class="math notranslate nohighlight">\(\widehat{\log(\text{price})}\)</span>. To convert back to dollars, we exponentiate: <span class="math notranslate nohighlight">\(\widehat{\text{price}} = e^{\widehat{\log(\text{price})}}\)</span>.</p>
<p>However, there is a subtlety: <span class="math notranslate nohighlight">\(E[\log(Y)] \neq \log(E[Y])\)</span>. The back-transformed prediction <span class="math notranslate nohighlight">\(e^{\widehat{\log(Y)}}\)</span> is actually an estimate of the <strong>median</strong> of <span class="math notranslate nohighlight">\(Y\)</span>, not the mean. For the mean, a bias correction is needed (beyond the scope of this course).</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predict for a specific diamond: 0.5 carats</span>
<span class="n">new_diamond</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">log_carat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">log</span><span class="p">(</span><span class="m">0.5</span><span class="p">))</span>

<span class="c1"># Get prediction on log scale</span>
<span class="n">pred_log</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">fit_log</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new_diamond</span><span class="p">,</span>
<span class="w">                    </span><span class="n">interval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;prediction&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span>

<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Prediction on log scale:\n&quot;</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">pred_log</span><span class="p">)</span>

<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;\nBack-transformed to dollars (median prediction):\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;Point estimate:&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">exp</span><span class="p">(</span><span class="n">pred_log</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;fit&quot;</span><span class="p">]),</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;95% PI: (&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">exp</span><span class="p">(</span><span class="n">pred_log</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;lwr&quot;</span><span class="p">]),</span><span class="w"> </span><span class="s">&quot;,&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">exp</span><span class="p">(</span><span class="n">pred_log</span><span class="p">[</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;upr&quot;</span><span class="p">]),</span><span class="w"> </span><span class="s">&quot;)\n&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Predicted median price for a 0.5-carat diamond:</strong> $______</p>
<p><strong>95% prediction interval (back-transformed):</strong> ($______, $______)</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>What Can We Trust When Assumptions Are Violated? ⚠️</p>
<p>When regression assumptions are violated, not all of our inference procedures fail equally. Understanding what remains trustworthy and what becomes unreliable is critical for responsible statistical practice.</p>
<p><strong>WHAT WE CAN STILL TRUST:</strong></p>
<ul class="simple">
<li><p><strong>Point estimates</strong> <span class="math notranslate nohighlight">\(b_0\)</span> and <span class="math notranslate nohighlight">\(b_1\)</span> <strong>are unbiased</strong>: The least squares estimators are <strong>unbiased</strong> as long as (1) the model is correctly specified (linearity holds) and (2) <span class="math notranslate nohighlight">\(E[\varepsilon_i] = 0\)</span>. Normality is NOT required for unbiasedness. However, to be <strong>BLUE</strong> (Best Linear Unbiased Estimators), the Gauss-Markov theorem additionally requires (3) homoscedasticity (constant variance) and (4) uncorrelated errors. When heteroscedasticity is present, the estimators are still unbiased but no longer “best” (minimum variance)—other estimators like weighted least squares would be more efficient.</p></li>
<li><p><strong>Confidence intervals for parameters</strong> (with large <span class="math notranslate nohighlight">\(n\)</span>): Due to the CLT, confidence intervals for <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span> achieve approximately nominal coverage even when errors are non-Normal, provided the sample size is sufficiently large AND variance is constant. With heteroscedasticity, even large samples don’t fully fix the problem.</p></li>
<li><p><strong>Confidence intervals for the mean response</strong> <span class="math notranslate nohighlight">\(\mu_{Y|X=x^*}\)</span>: These also benefit from the CLT because the estimated mean response is a weighted average of the <span class="math notranslate nohighlight">\(y_i\)</span> values. With large samples and constant variance, these intervals are reasonably trustworthy even with non-Normal errors.</p></li>
<li><p><strong>Direction of the relationship</strong>: If you find a significant positive (or negative) slope, the direction of the association is reliable even if the exact p-value or interval width is not.</p></li>
</ul>
<p><strong>WHAT WE CANNOT TRUST:</strong></p>
<ul class="simple">
<li><p><strong>Standard error estimates under heteroscedasticity</strong>: When variance is not constant (funnel/fan patterns in residuals), the standard errors for <span class="math notranslate nohighlight">\(b_0\)</span> and <span class="math notranslate nohighlight">\(b_1\)</span> are <strong>biased</strong>. This means confidence intervals may be too wide or too narrow, and p-values are unreliable. The estimates themselves are still unbiased, but we cannot trust our uncertainty quantification.</p></li>
<li><p><strong>Prediction intervals with non-Normal errors</strong>: The CLT does <strong>NOT</strong> save prediction intervals. Since <span class="math notranslate nohighlight">\(\hat{Y}^* = b_0 + b_1 x^* + \varepsilon_{\text{new}}\)</span>, the new error term <span class="math notranslate nohighlight">\(\varepsilon_{\text{new}}\)</span> is not averaged over and retains its original (possibly non-Normal) distribution. Prediction intervals can have coverage far from the nominal level.</p></li>
<li><p><strong>Prediction intervals under heteroscedasticity</strong>: Even worse than for CIs—the prediction interval formula assumes constant variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> across all <span class="math notranslate nohighlight">\(x\)</span>. If variance increases with <span class="math notranslate nohighlight">\(x\)</span>, prediction intervals will be too narrow at high <span class="math notranslate nohighlight">\(x\)</span> values and too wide at low <span class="math notranslate nohighlight">\(x\)</span> values.</p></li>
<li><p><strong>Inference with small samples and non-Normal errors</strong>: The CLT requires sufficient sample size. With small <span class="math notranslate nohighlight">\(n\)</span> and skewed or heavy-tailed errors, even confidence intervals for parameters may have poor coverage.</p></li>
<li><p><strong>Any inference when independence is violated</strong>: If observations are not independent (e.g., time series data, clustered observations), standard errors are typically <strong>underestimated</strong>, leading to inflated Type I error rates. This is often the most serious violation.</p></li>
</ul>
<p><strong>GAUSS-MARKOV CONDITIONS FOR BLUE:</strong></p>
<p>For <span class="math notranslate nohighlight">\(b_0\)</span> and <span class="math notranslate nohighlight">\(b_1\)</span> to be the <strong>Best</strong> Linear Unbiased Estimators:</p>
<ol class="arabic simple">
<li><p><strong>Linearity</strong>: <span class="math notranslate nohighlight">\(Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\)</span> (correct model specification)</p></li>
<li><p><strong>Zero mean errors</strong>: <span class="math notranslate nohighlight">\(E[\varepsilon_i] = 0\)</span></p></li>
<li><p><strong>Homoscedasticity</strong>: <span class="math notranslate nohighlight">\(\text{Var}(\varepsilon_i) = \sigma^2\)</span> (constant variance)</p></li>
<li><p><strong>Uncorrelated errors</strong>: <span class="math notranslate nohighlight">\(\text{Cov}(\varepsilon_i, \varepsilon_j) = 0\)</span> for <span class="math notranslate nohighlight">\(i \neq j\)</span></p></li>
</ol>
<p>Note: Normality is <strong>not</strong> required for BLUE—it is only needed for exact <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(F\)</span> distributions in finite samples. With large samples, the CLT provides approximate Normality for the estimators.</p>
<p><strong>THE DIAMONDS EXAMPLE — WHAT YOU OBSERVED:</strong></p>
<p>In the diamonds analysis (Question 3), you compared two models:</p>
<p><strong>Original Model (price ~ carat):</strong></p>
<ul class="simple">
<li><p><strong>Linearity violation</strong> (curvature): The residual plot showed a U-shaped pattern — residuals systematically positive at low and high carat values, negative in the middle. This means <span class="math notranslate nohighlight">\(b_0\)</span> and <span class="math notranslate nohighlight">\(b_1\)</span> are <strong>biased</strong>.</p></li>
<li><p><strong>Severe heteroscedasticity</strong>: Variance increased dramatically with carat (fanning pattern). Standard errors and p-values are unreliable.</p></li>
<li><p><strong>Non-Normal residuals</strong>: Heavy tails and skewness. Prediction intervals have poor coverage.</p></li>
</ul>
<p><strong>Log-Log Model (log(price) ~ log(carat)):</strong></p>
<ul class="simple">
<li><p><strong>Linearity</strong>: ✓ Much better — the relationship is approximately linear on the log-log scale.</p></li>
<li><p><strong>Homoscedasticity</strong>: ✓ Much better — variance is approximately constant across log(carat).</p></li>
<li><p><strong>Normality</strong>: ✓ Much better — residuals are approximately Normal (slight heavy tails remain).</p></li>
</ul>
<p><strong>THE LESSON:</strong> When the original model violates assumptions, the solution is often to <strong>transform the variables</strong> rather than proceeding with unreliable inference. The log-log transformation is particularly effective when the underlying relationship follows a power law (<span class="math notranslate nohighlight">\(Y \propto x^\beta\)</span>), which is common in economics, biology, and physics.</p>
<p><strong>BOTTOM LINE:</strong></p>
<p>✓ Use the log-log model for inference — its assumptions are reasonably satisfied</p>
<p>✓ Interpret the slope as an <strong>elasticity</strong> (% change in price per % change in carat)</p>
<p>✓ Prediction intervals from the log-log model are trustworthy; those from the original model are not</p>
<p>✗ Do NOT use inference from the original model — biased estimates and unreliable standard errors</p>
</div>
</section>
<section id="key-takeaways">
<h2>Key Takeaways<a class="headerlink" href="#key-takeaways" title="Link to this heading"></a></h2>
<div class="important admonition">
<p class="admonition-title">Summary 📝</p>
<ul class="simple">
<li><p>The <strong>coefficient of determination</strong> <span class="math notranslate nohighlight">\(R^2\)</span> measures the proportion of variability in <span class="math notranslate nohighlight">\(Y\)</span> explained by the regression model; in simple linear regression, <span class="math notranslate nohighlight">\(R^2 = r^2\)</span></p></li>
<li><p><strong>Confidence intervals for the mean response</strong> quantify uncertainty about the average <span class="math notranslate nohighlight">\(Y\)</span> at a given <span class="math notranslate nohighlight">\(x^*\)</span>; the CLT helps these intervals achieve nominal coverage even with non-Normal errors</p></li>
<li><p><strong>Prediction intervals for individual observations</strong> must account for both uncertainty in the regression line AND the inherent variability of a single new observation</p></li>
<li><p>Prediction intervals are <strong>always wider</strong> than confidence intervals because they include the additional <span class="math notranslate nohighlight">\(\text{MS}_E \cdot 1\)</span> term in the standard error</p></li>
<li><p>The <strong>CLT does not apply</strong> to prediction intervals when errors are non-Normal, because the new error <span class="math notranslate nohighlight">\(\varepsilon_{\text{new}}\)</span> is not averaged over</p></li>
<li><p><strong>Extrapolation</strong> (predicting beyond the range of observed <span class="math notranslate nohighlight">\(x\)</span> values) is unreliable because we have no data to support the assumed linear relationship in that region</p></li>
<li><p><strong>Transformations</strong> (such as log-log) can simultaneously fix multiple assumption violations: linearizing the relationship, stabilizing variance, and improving Normality</p></li>
<li><p>In a <strong>log-log model</strong>, the slope is an <strong>elasticity</strong>: a 1% increase in <span class="math notranslate nohighlight">\(x\)</span> is associated with approximately a <span class="math notranslate nohighlight">\(b_1\)</span>% change in <span class="math notranslate nohighlight">\(Y\)</span></p></li>
<li><p><strong>Heteroscedasticity</strong> (non-constant variance) biases standard error estimates, making confidence intervals and p-values unreliable even when point estimates remain valid</p></li>
<li><p><strong>Linearity violations</strong> cause bias in the point estimates themselves — this is the only assumption whose violation directly biases <span class="math notranslate nohighlight">\(b_0\)</span> and <span class="math notranslate nohighlight">\(b_1\)</span></p></li>
<li><p><strong>R functions</strong> <code class="docutils literal notranslate"><span class="pre">predict()</span></code> with <code class="docutils literal notranslate"><span class="pre">interval</span> <span class="pre">=</span> <span class="pre">&quot;confidence&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">interval</span> <span class="pre">=</span> <span class="pre">&quot;prediction&quot;</span></code> efficiently compute interval estimates at specified values of <span class="math notranslate nohighlight">\(x\)</span></p></li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="worksheet21.html" class="btn btn-neutral float-left" title="Worksheet 21: Inference for Simple Linear Regression" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../R_computerAssignments/r_computer_assignments.html" class="btn btn-neutral float-right" title="R / RStudio Guide and Function Reference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
  <p class="footer-credits-inline">
    <strong>Website Credits:</strong>
    Website development by Dr. Timothy Reese and Halin Shin.
    Generative AI tools were used to draft and refine some prose, code, and documentation; all content was reviewed by the instructors.
    Models: OpenAI o3 (2025-04-16 release) and Anthropic Claude Opus 4.1 (2025-08-05).
  </p>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 

<!-- Floating Chat Button -->
<button id="chatbot-toggle" class="chatbot-fab" aria-label="Open AI Course Assistant" aria-expanded="false">
  <span class="chatbot-fab-badge">BETA</span>
  <svg class="chatbot-fab-icon chatbot-icon-open" fill="none" stroke="currentColor" viewBox="0 0 24 24">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
          d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"/>
  </svg>
  <svg class="chatbot-fab-icon chatbot-icon-close" fill="none" stroke="currentColor" viewBox="0 0 24 24" style="display:none;">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
  </svg>
  <span class="chatbot-fab-text">Ask AI Assistant</span>
</button>

<!-- Chat Panel - Fullscreen -->
<div id="chatbot-panel" class="chatbot-panel" aria-hidden="true">
  <div class="chatbot-panel-topbar">
    <button id="chatbot-close" class="chatbot-panel-close-minimal" aria-label="Close chat">
      <svg width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
      </svg>
    </button>
    <a href="https://advert-cingular-employer-humor.trycloudflare.com/" 
       target="_blank" 
       rel="noopener noreferrer" 
       class="chatbot-newtab">
      <svg width="16" height="16" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
              d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"/>
      </svg>
      Open in new tab
    </a>
  </div>
  <iframe id="chatbot-iframe" class="chatbot-iframe" title="STAT 350 AI Course Assistant"></iframe>
</div>

<script>
(function() {
  const CHATBOT_BASE_URL = 'https://advert-cingular-employer-humor.trycloudflare.com/';
  
  const toggle = document.getElementById('chatbot-toggle');
  const panel = document.getElementById('chatbot-panel');
  const closeBtn = document.getElementById('chatbot-close');
  const iframe = document.getElementById('chatbot-iframe');
  const iconOpen = toggle.querySelector('.chatbot-icon-open');
  const iconClose = toggle.querySelector('.chatbot-icon-close');
  
  let isOpen = false;
  let iframeLoaded = false;
  
  function getPageContext() {
    const pageTitle = document.title || '';
    const pageUrl = window.location.href;
    const pagePath = window.location.pathname;
    
    const h1 = document.querySelector('.rst-content h1, h1');
    const heading = h1 ? h1.textContent.replace(/[¶#]/g, '').trim() : '';
    
    const breadcrumbs = document.querySelectorAll('.wy-breadcrumbs li a');
    const breadcrumbPath = Array.from(breadcrumbs).map(a => a.textContent.trim()).join(' > ');
    
    const chapterMatch = pagePath.match(/chapter(\d+)/i);
    const chapter = chapterMatch ? 'Chapter ' + chapterMatch[1] : '';
    
    return {
      title: heading || pageTitle,
      url: pageUrl,
      path: pagePath,
      breadcrumbs: breadcrumbPath,
      chapter: chapter
    };
  }
  
  function buildChatbotUrl(context) {
    const params = new URLSearchParams();
    if (context.title) params.set('page_title', context.title);
    if (context.url) params.set('page_url', context.url);
    if (context.chapter) params.set('chapter', context.chapter);
    if (context.breadcrumbs) params.set('breadcrumbs', context.breadcrumbs);
    
    const queryString = params.toString();
    return queryString ? CHATBOT_BASE_URL + '?' + queryString : CHATBOT_BASE_URL;
  }
  
  function openChat() {
    const context = getPageContext();
    
    const newUrl = buildChatbotUrl(context);
    if (!iframeLoaded || iframe.dataset.lastUrl !== context.url) {
      iframe.src = newUrl;
      iframe.dataset.lastUrl = context.url;
      iframeLoaded = true;
    }
    
    panel.classList.add('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'false');
    toggle.setAttribute('aria-expanded', 'true');
    iconOpen.style.display = 'none';
    iconClose.style.display = 'block';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Close';
    isOpen = true;
    
    toggle.classList.add('chatbot-fab-opened');
    
    // Prevent body scroll when panel is open
    document.body.style.overflow = 'hidden';
  }
  
  function closeChat() {
    panel.classList.remove('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'true');
    toggle.setAttribute('aria-expanded', 'false');
    iconOpen.style.display = 'block';
    iconClose.style.display = 'none';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Ask AI Assistant';
    isOpen = false;
    
    // Restore body scroll
    document.body.style.overflow = '';
  }
  
  function toggleChat() {
    if (isOpen) {
      closeChat();
    } else {
      openChat();
    }
  }
  
  toggle.addEventListener('click', toggleChat);
  closeBtn.addEventListener('click', closeChat);
  
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape' && isOpen) {
      closeChat();
    }
  });
})();
</script>


</body>
</html>