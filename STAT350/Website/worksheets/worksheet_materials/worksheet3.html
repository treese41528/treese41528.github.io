

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Worksheet 3: Conditional Probability and Bayes’ Theorem &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=3c686048" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/worksheets/worksheet_materials/worksheet3.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=8512422d"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Worksheet 4: Independence and Random Variables" href="worksheet4.html" />
    <link rel="prev" title="Worksheet 2: Set Theory and Probability Fundamentals" href="worksheet2.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../worksheets_index.html">Course Worksheets</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../worksheets_index.html#worksheets">Worksheets</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet1.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#simulation-exercise">Simulation Exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Shape &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Discrete Random Variables and the CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../worksheets_index.html">Course Worksheets</a></li>
      <li class="breadcrumb-item active">Worksheet 3: Conditional Probability and Bayes’ Theorem</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/worksheets/worksheet_materials/worksheet3.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="worksheet-3-conditional-probability-and-bayes-theorem">
<span id="worksheet3"></span><h1>Worksheet 3: Conditional Probability and Bayes’ Theorem<a class="headerlink" href="#worksheet-3-conditional-probability-and-bayes-theorem" title="Link to this heading"></a></h1>
<div class="info admonition">
<p class="admonition-title">Learning Objectives 🎯</p>
<ul class="simple">
<li><p>Understand conditional probability and its notation</p></li>
<li><p>Create and interpret tree diagrams for multi-stage experiments</p></li>
<li><p>Apply the multiplication rule and law of total probability</p></li>
<li><p>Use Bayes’ theorem to update probabilities with new information</p></li>
<li><p>Implement probability calculations in R</p></li>
</ul>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<p>Conditional probability allows us to understand how the likelihood of one event changes when we have additional information about another event. It does not assume one event causes another. Instead, it refines our understanding of probabilities by narrowing down the possibilities based on what we know.</p>
<p><strong>Examples:</strong></p>
<ul class="simple">
<li><p>If you know it is cloudy, the likelihood of rain may increase because clouds are often associated with rain</p></li>
<li><p>If you know the card drawn from a deck is a spade, it impacts the probability that the card is a face card</p></li>
</ul>
<p>For example, imagine you are selecting a gummy bear from one of several jars. The probability of selecting a red gummy depends on which jar you chose. If you know the jar you picked, you can narrow down the probability of getting a red gummy. Conditional probability helps us formalize this reasoning.</p>
<p>We write the conditional probability of drawing a red gummy from the i-th jar as:</p>
<div class="math notranslate nohighlight">
\[P(\text{Red Gummy}|\text{Jar}_i)\]</div>
<p>Here, the vertical bar | means “given that.” It indicates that we are finding the probability of the event drawing a Red Gummy, given that the jar selected is Jar<sub>i</sub>.</p>
</section>
<section id="part-1-understanding-conditional-probability">
<h2>Part 1: Understanding Conditional Probability<a class="headerlink" href="#part-1-understanding-conditional-probability" title="Link to this heading"></a></h2>
<p><strong>Question 1:</strong> To understand the concept of conditional probability, consider three jars filled with gummy bears:</p>
<ul class="simple">
<li><p><strong>Jar₁</strong> contains 30 red, 10 green, and 10 blue gummies</p></li>
<li><p><strong>Jar₂</strong> contains 20 red and 40 green gummies</p></li>
<li><p><strong>Jar₃</strong> contains 35 yellow gummies</p></li>
</ul>
<p>Answer the following questions using formal probability statements and clearly show your work:</p>
<ol class="loweralpha simple">
<li><p>Suppose you were handed Jar₃ and you randomly sample a single gummy bear. Compute the probability that the gummy bear you sampled would be red.</p></li>
<li><p>Suppose instead you were handed Jar₂ and you randomly sample a single gummy bear. Compute the probability that the gummy bear you sampled would be red.</p></li>
<li><p>Suppose you were handed Jar₁ and you randomly sample a single gummy bear. Compute the probability that the gummy bear you sampled would be either red or blue.</p></li>
<li><p>Instead suppose you were not allowed to see the contents of the selected jar but are aware of the distribution of colors in each jar. You randomly sample one gummy, and it is yellow. Determine the probability that the gummy came from each of the three jars (Jar₁, Jar₂, or Jar₃).</p></li>
</ol>
<p><strong>R Code for Visualization:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define jar contents</span>
<span class="n">jar1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">red</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">)</span>
<span class="n">jar2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">red</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">40</span><span class="p">)</span>
<span class="n">jar3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">yellow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">35</span><span class="p">)</span>

<span class="c1"># Create a visualization of jar contents</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>

<span class="c1"># Prepare data for plotting</span>
<span class="n">jar_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="w">  </span><span class="n">jar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="s">&quot;Jar 1&quot;</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">),</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="s">&quot;Jar 2&quot;</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;Jar 3&quot;</span><span class="p">),</span>
<span class="w">  </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">jar1</span><span class="p">),</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">jar2</span><span class="p">),</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">jar3</span><span class="p">)),</span>
<span class="w">  </span><span class="n">count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">jar1</span><span class="p">,</span><span class="w"> </span><span class="n">jar2</span><span class="p">,</span><span class="w"> </span><span class="n">jar3</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Create bar plot</span>
<span class="nf">ggplot</span><span class="p">(</span><span class="n">jar_data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">jar</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">count</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">color</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_bar</span><span class="p">(</span><span class="n">stat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;identity&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;stack&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">scale_fill_manual</span><span class="p">(</span><span class="n">values</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;red&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;green&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;green&quot;</span><span class="p">,</span>
<span class="w">                               </span><span class="s">&quot;blue&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;yellow&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;gold&quot;</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Gummy Bear Distribution in Jars&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Jar&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Number of Gummies&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="part-2-tree-diagrams-and-sequential-sampling">
<h2>Part 2: Tree Diagrams and Sequential Sampling<a class="headerlink" href="#part-2-tree-diagrams-and-sequential-sampling" title="Link to this heading"></a></h2>
<p>A tree diagram is a visual representation of the general multiplication rule. It illustrates all possible outcomes of a sequence of events, where each branch of the tree represents a possible event, and probabilities are assigned to these branches. By following the branches of the tree, we can calculate the probabilities of different outcomes by multiplying the conditional probabilities along the paths.</p>
<p>Tree diagrams also rely on the principles of mutual exclusivity and exhaustiveness:</p>
<ul class="simple">
<li><p><strong>Mutual exclusivity</strong> ensures that each complete path through the tree represents a distinct and non-overlapping outcome</p></li>
<li><p><strong>Exhaustiveness</strong> ensures that all possible outcomes are represented exactly once in the tree, so the probabilities of the mutually exclusive outcomes add up to 1</p></li>
</ul>
<p>Together, these two properties ensure that the tree diagram forms a partition of the sample space, dividing it into distinct and complete subsets of outcomes.</p>
<p><strong>Question 2:</strong> Considering the same jars of gummy bears, suppose you randomly select one jar, with each jar being “equally likely” to be chosen:</p>
<div class="math notranslate nohighlight">
\[P(\text{Jar}_1) = P(\text{Jar}_2) = P(\text{Jar}_3) = \frac{1}{3}\]</div>
<p>Next you sample two gummies from the selected jar <strong>without replacement</strong>.</p>
<ol class="loweralpha simple">
<li><p>Create a tree diagram to represent all possible outcomes of sampling two gummies. The tree diagram should convey all probabilities clearly, showing:</p>
<ul class="simple">
<li><p>Unconditional probabilities (e.g., the probability of selecting each jar)</p></li>
<li><p>Conditional probabilities (e.g., the probabilities of drawing specific gummy colors on the first and second draws, accounting for the reduced contents of the jar after the first draw)</p></li>
<li><p>Intersection probabilities (e.g., the probabilities at the end of each path, representing the probability of a specific sequence of events occurring)</p></li>
</ul>
</li>
<li><p>Logically explain why your tree diagram satisfies both mutual exclusivity (each complete path represents a distinct, non-overlapping outcome) and exhaustiveness (all possible outcomes of the experiment are included in the diagram, and their probabilities sum to 1).</p></li>
<li><p>Using your tree diagram, compute the following probabilities (try to maintain mathematical formalism):</p>
<ol class="lowerroman simple">
<li><p>The probability of drawing two yellow gummies</p></li>
<li><p>The probability of drawing two blue gummies</p></li>
<li><p>The probability of drawing two green gummies given that you know the samples came from Jar₁</p></li>
<li><p>The probability of drawing two green gummies given that you know the samples came from Jar₂</p></li>
<li><p>Use the law of total probability to determine the probability of sampling two green gummies and relate it to the paths of the tree diagram</p></li>
</ol>
</li>
</ol>
<p><strong>R Code for Tree Diagram Calculations:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Function to calculate probability of drawing two gummies of same color</span>
<span class="c1"># without replacement from a specific jar</span>
<span class="n">prob_two_same</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">jar_contents</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">total</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">jar_contents</span><span class="p">)</span>
<span class="w">  </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">jar_contents</span><span class="p">)))</span><span class="w"> </span><span class="kr">return</span><span class="p">(</span><span class="m">0</span><span class="p">)</span>

<span class="w">  </span><span class="n">n_color</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">jar_contents</span><span class="p">[</span><span class="n">color</span><span class="p">]</span>
<span class="w">  </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="n">n_color</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="kr">return</span><span class="p">(</span><span class="m">0</span><span class="p">)</span>

<span class="w">  </span><span class="c1"># P(first is color) * P(second is color | first was color)</span>
<span class="w">  </span><span class="n">prob</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">n_color</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">((</span><span class="n">n_color</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">total</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">))</span>
<span class="w">  </span><span class="kr">return</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Calculate specific probabilities</span>
<span class="c1"># P(two yellow gummies | Jar 3)</span>
<span class="n">p_yy_given_jar3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">prob_two_same</span><span class="p">(</span><span class="n">jar3</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;yellow&quot;</span><span class="p">)</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;P(YY|Jar3) =&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">p_yy_given_jar3</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>

<span class="c1"># P(two blue gummies | each jar)</span>
<span class="n">p_bb_given_jar1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">prob_two_same</span><span class="p">(</span><span class="n">jar1</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">p_bb_given_jar2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">prob_two_same</span><span class="p">(</span><span class="n">jar2</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">)</span><span class="w">  </span><span class="c1"># Will be 0</span>
<span class="n">p_bb_given_jar3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">prob_two_same</span><span class="p">(</span><span class="n">jar3</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;blue&quot;</span><span class="p">)</span><span class="w">  </span><span class="c1"># Will be 0</span>

<span class="c1"># Law of total probability for two blue gummies</span>
<span class="n">p_bb_total</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">p_bb_given_jar1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">p_bb_given_jar2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="m">3</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">p_bb_given_jar3</span>
<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;P(BB) =&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">p_bb_total</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;\n&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="part-3-bayes-theorem-and-sequential-updating">
<h2>Part 3: Bayes’ Theorem and Sequential Updating<a class="headerlink" href="#part-3-bayes-theorem-and-sequential-updating" title="Link to this heading"></a></h2>
<p>Bayes’ Theorem provides a way to compute conditional probabilities when directly calculating them is difficult. In particular, it allows us to express a probability in terms of its reverse conditional, which is often easier to determine. It helps answer questions like:</p>
<p><em>“Given an observed outcome, how should we determine the probability of an event that may have led to it?”</em></p>
<p>Beyond this basic use, Bayes’ Theorem also provides a framework for updating probabilities when additional evidence is observed, refining our estimates step by step.</p>
<p><em>“Given an initial observation, how should we revise our probabilities after receiving additional evidence?”</em></p>
<p>The first application focuses on computing a conditional probability when its direct computation is complex, while the second extends this concept to sequential updating, where each new observation refines our understanding of the underlying probabilities.</p>
<p><strong>Question 3:</strong> To understand the concept of Bayes formula, consider the same three jars filled with gummy bears:</p>
<ul class="simple">
<li><p>Jar₁ contains 30 red, 10 green, and 10 blue gummies</p></li>
<li><p>Jar₂ contains 20 red and 40 green gummies</p></li>
<li><p>Jar₃ contains 35 yellow gummies</p></li>
</ul>
<p>Suppose you randomly select one jar, with each jar being “equally likely” to be chosen. Next, you draw one gummy bear without looking at the contents of the jar and observe that it is red.</p>
<ol class="loweralpha simple">
<li><p>Compute the probability that the red gummy bear came from each jar (Jar₁, Jar₂, or Jar₃).</p></li>
<li><p>Now assume you draw a second gummy bear from the same jar, and it is also red. Compute the updated probabilities that the jar you sampled from was from Jar₁, Jar₂, or Jar₃. Your tree diagram may be helpful in answering this question.</p></li>
</ol>
<p><strong>R Implementation of Bayes’ Theorem:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Bayes&#39; theorem implementation</span>
<span class="n">bayes_update</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span><span class="w"> </span><span class="n">likelihoods</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1"># Calculate posterior probabilities</span>
<span class="w">  </span><span class="n">joint</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">prior</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">likelihoods</span>
<span class="w">  </span><span class="n">posterior</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">joint</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">joint</span><span class="p">)</span>
<span class="w">  </span><span class="kr">return</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Initial setup</span>
<span class="n">prior_probs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="m">3</span><span class="p">)</span><span class="w">  </span><span class="c1"># P(Jar_i)</span>

<span class="c1"># Likelihoods of observing red from each jar</span>
<span class="n">p_red_given_jar</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span>
<span class="w">  </span><span class="n">jar1</span><span class="p">[</span><span class="s">&quot;red&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">jar1</span><span class="p">),</span><span class="w">      </span><span class="c1"># P(Red|Jar1) = 30/50</span>
<span class="w">  </span><span class="n">jar2</span><span class="p">[</span><span class="s">&quot;red&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">jar2</span><span class="p">),</span><span class="w">      </span><span class="c1"># P(Red|Jar2) = 20/60</span>
<span class="w">  </span><span class="m">0</span><span class="w">                             </span><span class="c1"># P(Red|Jar3) = 0/35</span>
<span class="p">)</span>

<span class="c1"># First update: observed one red gummy</span>
<span class="n">posterior_1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">bayes_update</span><span class="p">(</span><span class="n">prior_probs</span><span class="p">,</span><span class="w"> </span><span class="n">p_red_given_jar</span><span class="p">)</span>
<span class="nf">names</span><span class="p">(</span><span class="n">posterior_1</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Jar1&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Jar2&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Jar3&quot;</span><span class="p">)</span>

<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;After observing one red gummy:\n&quot;</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">posterior_1</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">))</span>

<span class="c1"># For second update, calculate P(Red|Jar_i, first was red)</span>
<span class="c1"># This accounts for sampling without replacement</span>
<span class="n">p_red2_given_jar_red1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span>
<span class="w">  </span><span class="p">(</span><span class="n">jar1</span><span class="p">[</span><span class="s">&quot;red&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">jar1</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">),</span><span class="w">   </span><span class="c1"># 29/49 for Jar1</span>
<span class="w">  </span><span class="p">(</span><span class="n">jar2</span><span class="p">[</span><span class="s">&quot;red&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">jar2</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">),</span><span class="w">   </span><span class="c1"># 19/59 for Jar2</span>
<span class="w">  </span><span class="m">0</span><span class="w">                                       </span><span class="c1"># Still 0 for Jar3</span>
<span class="p">)</span>

<span class="c1"># Second update: observed another red gummy</span>
<span class="n">posterior_2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">bayes_update</span><span class="p">(</span><span class="n">posterior_1</span><span class="p">,</span><span class="w"> </span><span class="n">p_red2_given_jar_red1</span><span class="p">)</span>

<span class="nf">cat</span><span class="p">(</span><span class="s">&quot;\nAfter observing two red gummies:\n&quot;</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">posterior_2</span><span class="p">,</span><span class="w"> </span><span class="m">4</span><span class="p">))</span>

<span class="c1"># Visualization of belief updating</span>
<span class="n">update_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span>
<span class="w">  </span><span class="n">jar</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Jar1&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Jar2&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Jar3&quot;</span><span class="p">),</span><span class="w"> </span><span class="m">3</span><span class="p">),</span>
<span class="w">  </span><span class="n">stage</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Prior&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;After 1 Red&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;After 2 Red&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">),</span>
<span class="w">  </span><span class="n">probability</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">prior_probs</span><span class="p">,</span><span class="w"> </span><span class="n">posterior_1</span><span class="p">,</span><span class="w"> </span><span class="n">posterior_2</span><span class="p">)</span>
<span class="p">)</span>

<span class="nf">ggplot</span><span class="p">(</span><span class="n">update_data</span><span class="p">,</span><span class="w"> </span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">jar</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">probability</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stage</span><span class="p">))</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">geom_bar</span><span class="p">(</span><span class="n">stat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;identity&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">position</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dodge&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Bayesian Updating with Sequential Observations&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Jar&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Probability&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Stage&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">theme_minimal</span><span class="p">()</span><span class="w"> </span><span class="o">+</span>
<span class="w">  </span><span class="nf">ylim</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="key-takeaways">
<h2>Key Takeaways<a class="headerlink" href="#key-takeaways" title="Link to this heading"></a></h2>
<div class="important admonition">
<p class="admonition-title">Summary 📝</p>
<ul class="simple">
<li><p><strong>Conditional probability</strong> P(A|B) represents the probability of A given that B has occurred</p></li>
<li><p><strong>Tree diagrams</strong> visualize multi-stage experiments and help calculate complex probabilities</p></li>
<li><p>The <strong>multiplication rule</strong> states that P(A ∩ B) = P(A) × P(B|A)</p></li>
<li><p>The <strong>law of total probability</strong> allows us to find P(B) by summing over all possible ways B can occur</p></li>
<li><p><strong>Bayes’ theorem</strong> provides a way to reverse conditional probabilities: P(A|B) = P(B|A) × P(A) / P(B)</p></li>
<li><p>Bayes’ theorem can be applied <strong>sequentially</strong> to update beliefs as new evidence arrives</p></li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="worksheet2.html" class="btn btn-neutral float-left" title="Worksheet 2: Set Theory and Probability Fundamentals" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="worksheet4.html" class="btn btn-neutral float-right" title="Worksheet 4: Independence and Random Variables" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>