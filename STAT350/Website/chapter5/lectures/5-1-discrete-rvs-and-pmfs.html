

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>5.1. Discrete Random Variables and Probability Mass Distributions &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=bac617f8" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter5/lectures/5-1-discrete-rvs-and-pmfs.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.2. Joint Probability Mass Functions" href="5-2-joint-pmfs.html" />
    <link rel="prev" title="5. Discrete Distributions" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Shape &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">5. Discrete Distributions</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Discrete Random Variables and the CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">5. </span>Discrete Distributions</a></li>
      <li class="breadcrumb-item active"><span class="section-number">5.1. </span>Discrete Random Variables and Probability Mass Distributions</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter5/lectures/5-1-discrete-rvs-and-pmfs.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch5-1">
  <iframe
    id="video-ch5-1"
    title="STAT 350 – Chapter 5.1 Random Variables and Discrete Probability Distributions Video"
    src="https://www.youtube.com/embed/Inkj1RtLA_Q?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
    allowfullscreen>
  </iframe>
</div><section id="discrete-random-variables-and-probability-mass-distributions">
<h1><span class="section-number">5.1. </span>Discrete Random Variables and Probability Mass Distributions<a class="headerlink" href="#discrete-random-variables-and-probability-mass-distributions" title="Link to this heading"></a></h1>
<p>In previous chapters, we used set theory to describe events and their probabilities.
While this approach provides a rigorous foundation, it can become cumbersome when dealing with
complex scenarios. Random variables offer a more elegant solution by mapping outcomes directly
to numbers.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p>Define <strong>random variables</strong> as functions that map real-life events of
arbitrary complexity to their numerical representations.</p></li>
<li><p>Distinguish between <strong>discrete</strong> and <strong>continuous</strong> random variables.</p></li>
<li><p>Formalize <strong>probability mass functions</strong> (PMFs) for discrete random variables.</p></li>
<li><p>Apply PMFs to calculate probabilities for complex events.</p></li>
</ul>
</div>
<section id="random-variables-from-sets-to-numbers">
<h2><span class="section-number">5.1.1. </span>Random Variables: From Sets to Numbers<a class="headerlink" href="#random-variables-from-sets-to-numbers" title="Link to this heading"></a></h2>
<section id="definition">
<h3>Definition<a class="headerlink" href="#definition" title="Link to this heading"></a></h3>
<p>A random variable (RV) <span class="math notranslate nohighlight">\(X\)</span> is a function that maps each outcome
in the sample space <span class="math notranslate nohighlight">\(\omega \in \Omega\)</span> to a numerical value.
Formally, <span class="math notranslate nohighlight">\(X: \Omega \to \mathbb{R}\)</span>.</p>
</section>
<section id="why-is-a-random-variable-needed">
<h3>Why is a random variable needed?<a class="headerlink" href="#why-is-a-random-variable-needed" title="Link to this heading"></a></h3>
<p>Outcomes of random experiments are often multi-faceted and tend to
introduce more complexity than necessary. For example,
suppose we flip a coin 10 times and count how many heads appear
in the sequence. The complete sample
space of ten coin flips contains <span class="math notranslate nohighlight">\(2^{10} = 1,024\)</span> different possible sequences.</p>
<p>However, if we’re only interested in the total number of heads,
we do not need to examine each sequence individually. For instance,
instead of interpreting ‘HHHHHHHHTH’ as a unique sequence, we can view
it simply as an outcome that yields the numerical value 9.</p>
<p>This is where a random variable becomes useful.
We can define a random variable, say <span class="math notranslate nohighlight">\(X\)</span>, to map the outcome ‘HHHHHHHHTH’ to a
numerical value that reflects the focus of our interest:</p>
<div class="math notranslate nohighlight">
\[X('HHHHHHHHTH') = 9,\]</div>
<p>and all other 1,023 outcomes in a similar manner. By using a random variable, we
reduced our focus from 1,024 sequences to just 11 possible
values (0 through 10).</p>
</section>
<section id="expressing-events-with-random-variables">
<h3>Expressing events with random variables<a class="headerlink" href="#expressing-events-with-random-variables" title="Link to this heading"></a></h3>
<p>One of the key advantages of introducing a random variable is <strong>conciseness</strong>.
Once an appropriate random variable is defined,
most events can be expressed as equalities or inequalities involving the variable.
See the table below for some examples:</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 40.0%" />
<col style="width: 40.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Description</p></th>
<th class="head"><p>Using set notations</p></th>
<th class="head"><p>Using random variable <span class="math notranslate nohighlight">\(X\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Event that there are three heads in the sequence</p></td>
<td><p>Define <span class="math notranslate nohighlight">\(A_3\)</span> as the name of the event. List all sequences
with three heads in <span class="math notranslate nohighlight">\(A_3 = \{\cdots\}\)</span>.</p></td>
<td><p><span class="math notranslate nohighlight">\(X=3\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Event that there are more than 7 heads in the sequence</p></td>
<td><p>Define <span class="math notranslate nohighlight">\(A_8, A_9, A_{10}\)</span> as the events of sequences with
8, 9, and 10 heads, respectively. The event of interest is
<span class="math notranslate nohighlight">\(A_8 \cup A_9 \cup A_{10}\)</span>.</p></td>
<td><p><span class="math notranslate nohighlight">\(X &gt; 7\)</span></p></td>
</tr>
</tbody>
</table>
<p>We no longer need to define a new event for every new question. Instead, we can
express various situations compactly using the random variable <span class="math notranslate nohighlight">\(X\)</span>.</p>
</section>
</section>
<section id="types-of-random-variables">
<h2><span class="section-number">5.1.2. </span>Types of Random Variables<a class="headerlink" href="#types-of-random-variables" title="Link to this heading"></a></h2>
<p>Random variables fall into two main categories based on the nature of their possible values:</p>
<section id="discrete-random-variables">
<h3>Discrete Random Variables<a class="headerlink" href="#discrete-random-variables" title="Link to this heading"></a></h3>
<p>A random variable is discrete if it can take on only a countable number of possible values.
Discrete random variables typically arise when <strong>counting</strong> things, such as:</p>
<ul class="simple">
<li><p>The number of heads in coin flips</p></li>
<li><p>The number of times someone swipes right out of 100 profile views</p></li>
<li><p>The number of website hits during a specific time period</p></li>
<li><p>The number of customers until the first big-ticket item is sold</p></li>
</ul>
</section>
<section id="continuous-random-variables">
<h3>Continuous Random Variables<a class="headerlink" href="#continuous-random-variables" title="Link to this heading"></a></h3>
<p>A random variable is continuous if it can take on any value within a continuous
range or interval. Continuous random variables typically arise when <strong>measuring</strong> quantities,
such as:</p>
<ul class="simple">
<li><p>Height, weight, or other physical measurements</p></li>
<li><p>Time until a particular event occurs</p></li>
<li><p>Temperature, pressure, or other environmental measurements</p></li>
</ul>
</section>
</section>
<section id="probability-distributions">
<h2><span class="section-number">5.1.3. </span>Probability Distributions<a class="headerlink" href="#probability-distributions" title="Link to this heading"></a></h2>
<p>To describe the probabilistic behavior of a random variable, we must specify
the probabilities associated with all its possible values. This complete description
is called a probability distribution.</p>
<p>Discrete and continuous random variables have different types of probability distributions.
Discrete random variables is described by a <strong>probability mass function</strong> (PMF), while a
continuous random variables is described by  a <strong>probability density function</strong> (PDF).</p>
<p>In this chapter, we will focus on discrete random variables and PMFs. As we progress through the course,
we will see how PMFs and PDFs share some foundational ideas, while differing
in important ways.</p>
</section>
<section id="probability-mass-functions">
<h2><span class="section-number">5.1.4. </span>Probability Mass Functions<a class="headerlink" href="#probability-mass-functions" title="Link to this heading"></a></h2>
<section id="id1">
<h3>Definition<a class="headerlink" href="#id1" title="Link to this heading"></a></h3>
<p>The probability mass function of a discrete random variable <span class="math notranslate nohighlight">\(X\)</span> is denoted by
<span class="math notranslate nohighlight">\(p_X\)</span>. For each possible value <span class="math notranslate nohighlight">\(x\)</span> that <span class="math notranslate nohighlight">\(X\)</span> can take, it gives</p>
<div class="math notranslate nohighlight">
\[p_X(x) = P(X = x).\]</div>
</section>
<section id="different-forms-of-a-pmf">
<h3>Different forms of a PMF<a class="headerlink" href="#different-forms-of-a-pmf" title="Link to this heading"></a></h3>
<p>A PMF can be represented in several different forms:</p>
<ol class="arabic">
<li><p>A PMF can be organized into a <strong>table</strong> by listing the possible values
with their corresponding probabilities.</p>
<figure class="align-center" id="id2" style="width: 60%">
<img alt="A table form of PMF" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter5/table-pmf-general.png" />
<figcaption>
<p><span class="caption-number">Fig. 5.1 </span><span class="caption-text">Exapmle of a PMF in table form</span><a class="headerlink" href="#id2" title="Link to this image"></a></p>
</figcaption>
</figure>
</li>
<li><p>Dot plots or bar graphs that display the probability of each possible value can serve as
visual representations of a PMF. However, they are not typically used on their own, as it can
be difficult to determine exact probabilities unless the plot is very simple.</p></li>
<li><p>For some special random variables, a mathematical formula is used to describe the PMF.
For example,</p>
<div class="math notranslate nohighlight">
\[p_X(x) = \frac{e^{-\lambda} \lambda^x}{x!}, \text{ for } x \geq 0\]</div>
<p>is a PMF.</p>
</li>
</ol>
</section>
<section id="support">
<h3>Support<a class="headerlink" href="#support" title="Link to this heading"></a></h3>
<p>The <strong>support</strong> of a discrete random variable is the set of all possible values that
have a positive probability:</p>
<div class="math notranslate nohighlight">
\[\text{supp}(X) = \{x \in \mathbb{R} \mid p_X(x) &gt; 0\}.\]</div>
</section>
<section id="validity-of-a-pmf">
<h3>Validity of a PMF<a class="headerlink" href="#validity-of-a-pmf" title="Link to this heading"></a></h3>
<p>For a probability mass function to be <strong>valid</strong>, the following conditions must be satisfied:</p>
<ol class="arabic">
<li><p><strong>Non-negativity</strong></p>
<p>For all <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(0 \leq p_X(x) \leq 1.\)</span></p>
</li>
<li><p><strong>Total probability of 1</strong></p>
<p>The sum of probabilities over all values in the support must equal 1:</p>
<div class="math notranslate nohighlight">
\[\sum_{x \in \text{supp}(X)} p_X(x) = 1\]</div>
</li>
</ol>
</section>
</section>
<section id="important-types-of-problems-involving-pmfs">
<h2><span class="section-number">5.1.5. </span>Important Types of Problems Involving PMFs<a class="headerlink" href="#important-types-of-problems-involving-pmfs" title="Link to this heading"></a></h2>
<section id="a-constructing-a-pmf-from-scracth">
<h3>A. Constructing a PMF from Scracth<a class="headerlink" href="#a-constructing-a-pmf-from-scracth" title="Link to this heading"></a></h3>
<p>It is an important skill for statisticians to be able to
“translate” descriptions of a random experiment in plain language
to mathematical language involving a random variable and its PMF.</p>
<div class="note admonition">
<p class="admonition-title">Example💡: Flipping a Biased Coin</p>
<p>Let us try constructing a PMF from scratch, only using descriptions of
the experimental setting.</p>
<p>Suppose we flip a biased coin four times, where the probability of heads on each flip is 0.7 (and tails is 0.3).
We define a random variable <strong>H to count the number of heads in the four flips</strong>. Find the
complete PMF for H. Verify that the PMF is valid.</p>
<p>First, let’s identify the sample space. There are <span class="math notranslate nohighlight">\(2^4 = 16\)</span> possible sequences of heads and tails over four
flips. However, rather than working with all 16 sequences individually, we can group them based on the
number of heads:</p>
<ul class="simple">
<li><p>H = 0: Only one sequence has zero heads (all tails: TTTT)</p></li>
<li><p>H = 1: Four sequences have exactly one head (HTTT, THTT, TTHT, TTTH)</p></li>
<li><p>H = 2: Six sequences have exactly two heads</p></li>
<li><p>H = 3: Four sequences have exactly three heads</p></li>
<li><p>H = 4: Only one sequence has all four heads (HHHH)</p></li>
</ul>
<p>Using the independence of the coin flips and the given probabilities,</p>
<ul class="simple">
<li><p>P(H = 0) = P(TTTT) = (0.3)⁴ = 0.0081</p></li>
<li><p>P(H = 1) = 4 × (0.3)³ × (0.7) = 0.0756</p></li>
<li><p>P(H = 2) = 6 × (0.3)² × (0.7)² = 0.2646</p></li>
<li><p>P(H = 3) = 4 × (0.3) × (0.7)³ = 0.4116</p></li>
<li><p>P(H = 4) = (0.7)⁴ = 0.2401</p></li>
</ul>
<p>All probabilities are betwen 0 and 1, satisfying the first condition for validity.
The probabilities also sum to 1: 0.0081 + 0.0756 + 0.2646 + 0.4116 + 0.2401 = 1.
This gives us the complete PMF for our random variable H.</p>
<figure class="align-center" id="id3">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter5/coin-table-pmf.png"><img alt="PMF for biased coin example in table format" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter5/coin-table-pmf.png" style="width: 70%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 5.2 </span><span class="caption-text">Probability mass function for the number of heads in four flips</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter5/coin-graph-pmf.png"><img alt="PMF for biased coin example in graph format" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter5/coin-graph-pmf.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 5.3 </span><span class="caption-text">Visualization of the PMF for the number of heads in four flips</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>The PMF reveals that getting three heads is the most likely outcome, with a probability of approximately 0.41,
while getting zero heads is very unlikely, with a probability of only about 0.008.</p>
</div>
</section>
<section id="b-completing-a-partially-known-pmf">
<h3>B. Completing a Partially Known PMF<a class="headerlink" href="#b-completing-a-partially-known-pmf" title="Link to this heading"></a></h3>
<p>Completing a partially specified PMF is a common task in statistics. Typical scenarios include:</p>
<ul class="simple">
<li><p>The probability is unknown for one value in the support.</p></li>
<li><p>Multiple probabilities are unknown, with
additional constraints provided.</p></li>
<li><p>The coefficient <span class="math notranslate nohighlight">\(k\)</span> that turns a non-negative function <span class="math notranslate nohighlight">\(f(x)\)</span>
into a valid PMF <span class="math notranslate nohighlight">\(p_X(x) = kf(x)\)</span> is unknown.
This constant <span class="math notranslate nohighlight">\(k\)</span> is called the <strong>normalization constant</strong>.</p></li>
</ul>
<p>In all such cases, we must “fill in the blanks” by applying
the conditions of a valid PMF.</p>
<div class="note admonition">
<p class="admonition-title">Example💡:  Finding the normalization constant</p>
<p>Consider a potential PMF:</p>
<div class="math notranslate nohighlight">
\[\begin{split}p_X(x) = \begin{cases}
\frac{k}{16} &amp; \text{for } x = 0, 1 \\
\frac{k}{32} &amp; \text{for } x = 2, 3, 4 \\
\frac{k}{64} &amp; \text{for } x = 5, 6\\
0 &amp; \text{for all other} x
\end{cases}\end{split}\]</div>
<p>To make this a valid PMF, we need to find the value of k that ensures the probabilities sum to 1:</p>
<div class="math notranslate nohighlight">
\[\frac{k}{16} + \frac{k}{16} + \frac{k}{32} + \frac{k}{32} + \frac{k}{32} + \frac{k}{64} + \frac{k}{64} = 1\]</div>
<p>Multiplying both sides by 64 and solving for <span class="math notranslate nohighlight">\(k\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;4k + 4k + 2k + 2k + 2k + k + k = 64\\
&amp;16k = 64 \\
&amp;k = 4\end{split}\]</div>
<p>Therefore, the valid PMF is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}p_X(x) = \begin{cases}
\frac{1}{4} &amp; \text{for } x = 0, 1 \\
\frac{1}{8} &amp; \text{for } x = 2, 3, 4 \\
\frac{1}{16} &amp; \text{for } x = 5, 6\\
0 &amp; \text{for all other} x
\end{cases}\end{split}\]</div>
</div>
</section>
<section id="c-calculating-probabilities-with-pmfs">
<h3>C. Calculating Probabilities with PMFs<a class="headerlink" href="#c-calculating-probabilities-with-pmfs" title="Link to this heading"></a></h3>
<p>Once we have a complete PMF, we can calculate probabilities for various events
related to the random variable.</p>
<p>Viewing events as equalities and inequalities involving a random variable,
we can express probablities of unions, intersections, and complements
concisely in terms of <span class="math notranslate nohighlight">\(p_X(x)\)</span>. Let us first get some practice
writing proability statements correctly in terms of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p><strong>Example</strong>: Consider a random variable <span class="math notranslate nohighlight">\(X\)</span> which has the set of <strong>positive integers
as its support</strong>.</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 20.0%" />
<col style="width: 40.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head" colspan="3"><p> Probability statements for discrete RVs</p></th>
</tr>
<tr class="row-even"><th class="head"><p>Description</p></th>
<th class="head"><p>Expresssion in terms of <span class="math notranslate nohighlight">\(p_X(x)\)</span></p></th>
<th class="head"><p>Comment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd"><td><p>Probability that X is less than 4</p></td>
<td><div class="math notranslate nohighlight">
\[\begin{split}&amp;P(X &lt; 4) \\
&amp;= P(X=1 \text{ OR } X=2 \text{ OR } X=3) \\
&amp;= P(X=1 \cup X=2 \cup X=3)\\
&amp;= P(X=1) + P(X=2) + P(X=3)\\
&amp;= p_X(1) + p_X(2) + p_X(3)\end{split}\]</div>
</td>
<td><p>The transition from the third to the fourth line works because
the events <span class="math notranslate nohighlight">\(\{X=x\}\)</span> are <strong>disjoint</strong> for different values of <span class="math notranslate nohighlight">\(x.\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Probability that X is less than 4 <strong>and</strong> at least 2</p></td>
<td><div class="math notranslate nohighlight">
\[\begin{split}&amp;P(X &lt; 4 \cap X \geq 2)\\
&amp;= P(2 \leq X &lt; 4)\\
&amp; = p_X(2) + p_X(3)\end{split}\]</div>
</td>
<td><p>For intersections and unions of non-disjoint events, think of ways to combine
the two separate (in)equalities into one.</p></td>
</tr>
<tr class="row-odd"><td><p>Probability that X is at least than 4 <strong>or</strong> greater than 6</p></td>
<td><div class="math notranslate nohighlight">
\[\begin{split}&amp;P(X4 \geq \cup X&gt;6) \\
&amp;= P(X \geq 4) \\
&amp;= 1 - P(X &lt; 4)\end{split}\]</div>
</td>
<td><p>To compute <span class="math notranslate nohighlight">\(P(X \geq 4)\)</span> directly, we would have to sum
infinitely many terms. Using the complement rule simplifies computation.</p></td>
</tr>
</tbody>
</table>
<p>Now, let us apply these skills to solve a problem.</p>
<div class="note admonition">
<p class="admonition-title">Example💡: Computing probabilities using PMF</p>
<p>Using the PMF we just derived, let’s calculate some probabilities.</p>
<div class="math notranslate nohighlight">
\[\begin{split}p_X(x) = \begin{cases}
\frac{1}{4} &amp; \text{for } x = 0, 1 \\
\frac{1}{8} &amp; \text{for } x = 2, 3, 4 \\
\frac{1}{16} &amp; \text{for } x = 5, 6\\
0 &amp; \text{for all other} x
\end{cases}\end{split}\]</div>
<ol class="arabic">
<li><p>The probability that X is even:</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(X \text{ is even}) &amp;= P(X = 0) + P(X = 2) + P(X = 4) + P(X = 6) \\
&amp;= 1/4 + 1/8 + 1/8 + 1/16 = 9/16\end{split}\]</div>
</li>
<li><p>The probability that X is greater than 3:</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(X &gt; 3) &amp;= P(X = 4) + P(X = 5) + P(X = 6) \\
&amp;= 1/8 + 1/16 + 1/16 = 1/4\end{split}\]</div>
</li>
<li><p>Are the events “X = 5 or X = 6” and “X &gt; 3” <strong>independent</strong>?</p>
<p>To show independence between two events <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>,
we must show that they meet the definition of idependence. That is,
we must show <span class="math notranslate nohighlight">\(P(A|B) = P(A)\)</span> or <span class="math notranslate nohighlight">\(P(B|A)P(A).\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}P(X = 5 \text{ or } X = 6 | X &gt; 3) &amp;= \frac{P((X = 5 \cup X = 6) \cap (X &gt; 3))}{P(X &gt; 3)}\\
&amp;= \frac{P(X = 5 \cup X = 6)}{P(X &gt; 3)}\\
&amp;= (1/16 + 1/16)/(1/4) = 1/2\\
P(X = 5 \cup X = 6) &amp;= 1/16 + 1/16 = 1/8\end{split}\]</div>
<p>Since 1/2 ≠ 1/8, these events are not independent.</p>
</li>
</ol>
</div>
</section>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">5.1.6. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>Random variables</strong> map outcomes from the sample space to numerical values, allowing
us to focus on quantities of interest rather than complex sets.</p></li>
<li><p><strong>Discrete random variables</strong> take on countable values and are typically used when
counting things, while <strong>continuous random variables</strong> can take any value in a continuum
and are used for measurements.</p></li>
<li><p>A <strong>probability mass function (PMF)</strong> specifies the probability that a discrete random
variable equals each possible value in its support.</p></li>
<li><p>Valid PMFs must satisfy two conditions:</p>
<ol class="arabic simple">
<li><p>all probabilities are between 0 and 1, and</p></li>
<li><p>the sum of all probabilities equals 1.</p></li>
</ol>
</li>
<li><p>We can calculate probabilities for various events by rewriting the probability
statements in terms of the PMF.</p></li>
</ol>
</div>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p><strong>Terminology Check</strong>: Explain the difference between a discrete and a
continuous random variable. Give two examples of each that were not mentioned in the chapter.</p></li>
<li><p><strong>Dice Sum</strong>: Two fair dice are rolled. Let X be the random variable that represents the
sum of the two values.</p>
<ol class="loweralpha simple">
<li><p>What is the support of X?</p></li>
<li><p>Construct the PMF for X.</p></li>
<li><p>Find P(X is odd).</p></li>
<li><p>Find P(X &gt; 8).</p></li>
</ol>
</li>
<li><p><strong>Card Draw</strong>: A card is drawn randomly from a standard deck. Define the random variable X as follows:</p>
<ul class="simple">
<li><p>X = 1 if the card is an ace</p></li>
<li><p>X = 11 if the card is a face card (jack, queen, or king)</p></li>
<li><p>X = the number on the card for all other cards (2 through 10)</p></li>
</ul>
<ol class="loweralpha simple">
<li><p>Construct the PMF for X.</p></li>
<li><p>What is P(X ≥ 5)?</p></li>
<li><p>Find P(X = 11 | X &gt; 5).</p></li>
</ol>
</li>
<li><p><strong>PMF Validation</strong>: Determine if the following functions are valid PMFs for a
discrete random variable X. If not, explain why.</p>
<ol class="loweralpha simple">
<li><p>p_X(x) = 0.2 for x = 1, 2, 3, 4, 5</p></li>
<li><p>p_X(x) = x/15 for x = 1, 2, 3, 4, 5</p></li>
<li><p>p_X(x) = 1/(x+1) for x = 1, 2, 3, 4</p></li>
</ol>
</li>
<li><p><strong>Independence Check</strong>: For the biased coin example in the chapter
(with P(Heads) = 0.7), let H be the random variable counting the number
of heads in four flips.</p>
<ol class="loweralpha simple">
<li><p>Are the events “H is odd” and “H &gt; 2” independent? Show your work.</p></li>
<li><p>Find two other events defined in terms of H that are independent.</p></li>
</ol>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="5. Discrete Distributions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="5-2-joint-pmfs.html" class="btn btn-neutral float-right" title="5.2. Joint Probability Mass Functions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>