

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>12.2. Different Sources of Variability in an ANOVA Model &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=581abb6a" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter12/lectures/12-2-sources-of-variability.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=de5959cf"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests" href="12-3-f-test-and-relationship-to-t-test.html" />
    <link rel="prev" title="12.1. Introduction to One-Way ANOVA" href="12-1-intro-one-way-anova.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#simulation-exercise">Simulation Exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">12. ANOVA</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">12. </span>ANOVA</a></li>
      <li class="breadcrumb-item active"><span class="section-number">12.2. </span>Different Sources of Variability in an ANOVA Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter12/lectures/12-2-sources-of-variability.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch12-2">
   <iframe
      id="video-ch12-2"
      title="STAT 350 – Chapter 12.2 One-Way ANOVA Model and the Sources of Variability Video"
      src="https://www.youtube.com/embed/BKEQadpmPzw?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="different-sources-of-variability-in-an-anova-model">
<h1><span class="section-number">12.2. </span>Different Sources of Variability in an ANOVA Model<a class="headerlink" href="#different-sources-of-variability-in-an-anova-model" title="Link to this heading"></a></h1>
<p>When we want to test for differences between means in several populations, we can no longer use
our familiar test statistic format of “point estimator minus null value, divided by standard error.”
The challenge is that we’re dealing with multiple populations simultaneously, so we need a completely
different approach to construct a test statistic that can compare all groups at once.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p><strong>Problem we will solve</strong> – How to construct a test statistic for comparing multiple population means by breaking down total variability into meaningful pieces</p></li>
<li><p><strong>Tools we’ll learn</strong> – The ANOVA model framework and sum of squares decomposition that forms the mathematical foundation for F-tests</p></li>
<li><p><strong>How it fits</strong> – This provides the theoretical groundwork for ANOVA hypothesis testing and introduces variance analysis concepts used throughout advanced statistics</p></li>
</ul>
</div>
<section id="from-visual-intuition-to-mathematical-framework">
<h2><span class="section-number">12.2.1. </span>From Visual Intuition to Mathematical Framework<a class="headerlink" href="#from-visual-intuition-to-mathematical-framework" title="Link to this heading"></a></h2>
<p>In our previous exploration using side-by-side boxplots, we intuitively looked for group differences by considering both the separation between group centers and the spread within each group. We weren’t just comparing means in isolation—we were also taking into account how much variability existed within each group. This visual approach gives us the conceptual foundation for the mathematical framework we’ll now develop.</p>
<p>The key insight is that we need to decompose the total variability in our data into different sources. If groups truly come from populations with different means, then the variability between group sample means should be large relative to the natural variability within groups. If all groups come from the same population, then the between-group variability should be similar to the within-group variability.</p>
</section>
<section id="the-one-way-anova-model">
<h2><span class="section-number">12.2.2. </span>The One-Way ANOVA Model<a class="headerlink" href="#the-one-way-anova-model" title="Link to this heading"></a></h2>
<p>We can think of one-way ANOVA as assuming our data comes from a specific statistical model. This model-based thinking will reappear when we study regression analysis, but for now let’s understand what it means in the ANOVA context.</p>
<p>Our data consists of observations <span class="math notranslate nohighlight">\(X_{ij}\)</span> where <span class="math notranslate nohighlight">\(i\)</span> represents the group index (<span class="math notranslate nohighlight">\(i = 1, 2, \ldots, k\)</span>) and <span class="math notranslate nohighlight">\(j\)</span> represents the observation number within group <span class="math notranslate nohighlight">\(i\)</span> (<span class="math notranslate nohighlight">\(j = 1, 2, \ldots, n_i\)</span>).</p>
<section id="the-anova-model-equation">
<h3>The ANOVA Model Equation<a class="headerlink" href="#the-anova-model-equation" title="Link to this heading"></a></h3>
<p>Each observation can be broken down into two components:</p>
<div class="math notranslate nohighlight">
\[X_{ij} = \mu_i + \varepsilon_{ij}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\mu_i\)</span> is the true population mean for group <span class="math notranslate nohighlight">\(i\)</span>, and <span class="math notranslate nohighlight">\(\varepsilon_{ij}\)</span> is the error term that captures everything not explained by the group mean.</p>
<p>The population means <span class="math notranslate nohighlight">\(\mu_i\)</span> represent the average tendencies for each group—these capture the systematic differences between populations that we’re trying to detect. The error terms <span class="math notranslate nohighlight">\(\varepsilon_{ij}\)</span> represent the random variation within each population that cannot be explained by the group mean alone.</p>
<p>We assume the error terms follow a normal distribution:</p>
<div class="math notranslate nohighlight">
\[\varepsilon_{ij} \sim N(0, \sigma^2) \text{ independently}\]</div>
<p>This assumption states that errors are normally distributed with mean zero and the same variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> across all groups—this is our equal variance assumption made explicit in the model.</p>
</section>
<section id="understanding-what-we-re-testing">
<h3>Understanding What We’re Testing<a class="headerlink" href="#understanding-what-we-re-testing" title="Link to this heading"></a></h3>
<p>This model framework helps clarify what we’re actually testing. Under the null hypothesis <span class="math notranslate nohighlight">\(H_0: \mu_1 = \mu_2 = \cdots = \mu_k\)</span>, all observations come from populations with the same mean, so the only differences between observations are due to random error. Under the alternative hypothesis, systematic differences between population means create additional sources of variation beyond just random error.</p>
</section>
</section>
<section id="three-types-of-sum-of-squares">
<h2><span class="section-number">12.2.3. </span>Three Types of Sum of Squares<a class="headerlink" href="#three-types-of-sum-of-squares" title="Link to this heading"></a></h2>
<p>The genius of ANOVA lies in decomposing the total variability in our data into meaningful components. We’ll develop three different “sum of squares” that measure different sources of variation.</p>
<p>Before diving in, let’s establish the pattern we’ll see repeatedly. Any sample variance can be written in the form:</p>
<div class="math notranslate nohighlight">
\[S^2 = \frac{\text{Sum of Squares}}{\text{Degrees of Freedom}}\]</div>
<p>We’ll have different types of sum of squares for different sources of variation, and we’ll convert each to a “mean square” by dividing by the appropriate degrees of freedom.</p>
<section id="sum-of-squares-between-groups-ssa">
<h3>Sum of Squares Between Groups (SSA)<a class="headerlink" href="#sum-of-squares-between-groups-ssa" title="Link to this heading"></a></h3>
<p>The first source of variability we consider is how much the group sample means deviate from the overall sample mean. This measures the between-group variability.</p>
<p>In our coffeehouse example, imagine we have sample means for each of the five coffeehouses. If these sample means are spread far apart from the overall mean, this suggests the groups come from populations with different means.</p>
<div class="math notranslate nohighlight">
\[\text{SSA} = \sum_{i=1}^k n_i (\bar{X}_{i \cdot} - \bar{X}_{\cdot \cdot})^2\]</div>
<p>Here <span class="math notranslate nohighlight">\(\bar{X}_{i \cdot}\)</span> is the sample mean for group <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(\bar{X}_{\cdot \cdot}\)</span> is the overall sample mean, and <span class="math notranslate nohighlight">\(n_i\)</span> is the sample size for group <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>Large SSA indicates that group means are spread far apart, suggesting different population means. Small SSA indicates that group means are close to the overall mean, suggesting similar population means.</p>
<p>Since we’re comparing <span class="math notranslate nohighlight">\(k\)</span> group means and estimating one overall mean, we have <span class="math notranslate nohighlight">\(k - 1\)</span> degrees of freedom for SSA.</p>
</section>
<section id="sum-of-squares-within-groups-sse">
<h3>Sum of Squares Within Groups (SSE)<a class="headerlink" href="#sum-of-squares-within-groups-sse" title="Link to this heading"></a></h3>
<p>The second source of variability measures how observations within each group deviate from their respective group means. This captures the within-group or error variability.</p>
<div class="math notranslate nohighlight">
\[\text{SSE} = \sum_{i=1}^k \sum_{j=1}^{n_i} (X_{ij} - \bar{X}_{i \cdot})^2\]</div>
<p>This can also be written using sample variances:</p>
<div class="math notranslate nohighlight">
\[\text{SSE} = \sum_{i=1}^k (n_i - 1) S^2_i\]</div>
<p>This shows that SSE is essentially a weighted sum of the sample variances from each group—it’s like the pooled variance concept from two-sample procedures, but extended to multiple groups.</p>
<p>SSE measures the natural variability within populations and provides an estimate of the common variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> under our equal variance assumption. Importantly, SSE doesn’t depend on whether the null hypothesis is true or false—it only depends on the within-group variability.</p>
<p>We have <span class="math notranslate nohighlight">\(n\)</span> total observations and estimate <span class="math notranslate nohighlight">\(k\)</span> group means, giving us <span class="math notranslate nohighlight">\(n - k\)</span> degrees of freedom for SSE.</p>
</section>
<section id="sum-of-squares-total-sst">
<h3>Sum of Squares Total (SST)<a class="headerlink" href="#sum-of-squares-total-sst" title="Link to this heading"></a></h3>
<p>The third component represents the total variability in the data, as if we ignored group structure entirely.</p>
<div class="math notranslate nohighlight">
\[\text{SST} = \sum_{i=1}^k \sum_{j=1}^{n_i} (X_{ij} - \bar{X}_{\cdot \cdot})^2\]</div>
<p>SST measures how much observations deviate from the overall mean—this is the baseline variability if we treated all data as coming from one population. We have <span class="math notranslate nohighlight">\(n\)</span> total observations and estimate one overall mean, giving us <span class="math notranslate nohighlight">\(n - 1\)</span> degrees of freedom.</p>
</section>
</section>
<section id="the-fundamental-anova-identity">
<h2><span class="section-number">12.2.4. </span>The Fundamental ANOVA Identity<a class="headerlink" href="#the-fundamental-anova-identity" title="Link to this heading"></a></h2>
<p>The remarkable mathematical result that makes ANOVA possible is that these three sum of squares components are related by:</p>
<div class="math notranslate nohighlight">
\[\text{SST} = \text{SSA} + \text{SSE}\]</div>
<p>In words: Total variability equals between-group variability plus within-group variability.</p>
<p>The degrees of freedom also decompose in the same way:</p>
<div class="math notranslate nohighlight">
\[(n - 1) = (k - 1) + (n - k)\]</div>
<section id="why-this-decomposition-works">
<h3>Why This Decomposition Works<a class="headerlink" href="#why-this-decomposition-works" title="Link to this heading"></a></h3>
<p>We can demonstrate this decomposition by a clever algebraic trick. Starting with SST, we add and subtract the group means (which doesn’t change anything since we’re adding zero):</p>
<div class="math notranslate nohighlight">
\[\text{SST} = \sum_{i=1}^k \sum_{j=1}^{n_i} (X_{ij} - \bar{X}_{\cdot \cdot})^2\]</div>
<div class="math notranslate nohighlight">
\[= \sum_{i=1}^k \sum_{j=1}^{n_i} [(X_{ij} - \bar{X}_{i \cdot}) + (\bar{X}_{i \cdot} - \bar{X}_{\cdot \cdot})]^2\]</div>
<p>When we expand this squared expression, we get three terms: the SSE term, the SSA term, and a cross-product term. The remarkable result is that the cross-product term equals zero, leaving us with exactly SST = SSA + SSE.</p>
<p>The cross-product term equals zero because <span class="math notranslate nohighlight">\((\bar{X}_{i \cdot} - \bar{X}_{\cdot \cdot})\)</span> doesn’t depend on <span class="math notranslate nohighlight">\(j\)</span>, so we can factor it out, leaving <span class="math notranslate nohighlight">\(\sum_{j=1}^{n_i} (X_{ij} - \bar{X}_{i \cdot})\)</span>, which always equals zero since deviations from a sample mean sum to zero.</p>
</section>
</section>
<section id="from-sum-of-squares-to-mean-squares">
<h2><span class="section-number">12.2.5. </span>From Sum of Squares to Mean Squares<a class="headerlink" href="#from-sum-of-squares-to-mean-squares" title="Link to this heading"></a></h2>
<p>Sum of squares by themselves aren’t directly useful for hypothesis testing because they depend on sample sizes. We need to convert them to mean squares by dividing by appropriate degrees of freedom to create unbiased estimators.</p>
<section id="mean-square-between-groups-msa">
<h3>Mean Square Between Groups (MSA)<a class="headerlink" href="#mean-square-between-groups-msa" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight">
\[\text{MSA} = \frac{\text{SSA}}{k - 1}\]</div>
<p>MSA has a special property: if <span class="math notranslate nohighlight">\(H_0\)</span> is true (all <span class="math notranslate nohighlight">\(\mu_i\)</span> are equal) and the equal variance assumption holds, then MSA is an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span>. However, if <span class="math notranslate nohighlight">\(H_0\)</span> is false (some <span class="math notranslate nohighlight">\(\mu_i\)</span> differ), then MSA estimates <span class="math notranslate nohighlight">\(\sigma^2\)</span> plus additional variation due to differences in population means.</p>
<p>This means MSA gets larger when group means are more spread apart, making it sensitive to violations of the null hypothesis.</p>
</section>
<section id="mean-square-error-mse">
<h3>Mean Square Error (MSE)<a class="headerlink" href="#mean-square-error-mse" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight">
\[\text{MSE} = \frac{\text{SSE}}{n - k}\]</div>
<p>MSE is an unbiased estimator of <span class="math notranslate nohighlight">\(\sigma^2\)</span> regardless of whether <span class="math notranslate nohighlight">\(H_0\)</span> is true or false. It only requires the equal variance assumption to hold. MSE is essentially the ANOVA version of pooled variance from two-sample procedures—it represents our best estimate of the natural variability within populations.</p>
</section>
</section>
<section id="building-the-test-statistic-logic">
<h2><span class="section-number">12.2.6. </span>Building the Test Statistic Logic<a class="headerlink" href="#building-the-test-statistic-logic" title="Link to this heading"></a></h2>
<p>The key insight for constructing an ANOVA test statistic comes from comparing these mean squares. We can think of the ratio:</p>
<div class="math notranslate nohighlight">
\[\frac{\text{MSA}}{\text{MSE}} = \frac{\text{Between-group variability}}{\text{Within-group variability}}\]</div>
<p>When <span class="math notranslate nohighlight">\(H_0\)</span> is true, both MSA and MSE estimate <span class="math notranslate nohighlight">\(\sigma^2\)</span>, so their ratio should be close to 1. When <span class="math notranslate nohighlight">\(H_0\)</span> is false, MSE still estimates <span class="math notranslate nohighlight">\(\sigma^2\)</span>, but MSA estimates something larger, so their ratio should be substantially greater than 1.</p>
<p>This suggests that large values of MSA/MSE provide evidence against <span class="math notranslate nohighlight">\(H_0\)</span>. The larger this ratio, the stronger the evidence for group differences.</p>
</section>
<section id="understanding-through-the-coffeehouse-example">
<h2><span class="section-number">12.2.7. </span>Understanding Through the Coffeehouse Example<a class="headerlink" href="#understanding-through-the-coffeehouse-example" title="Link to this heading"></a></h2>
<p>In our coffeehouse study, the variance decomposition tells this story:</p>
<p><strong>SST</strong> asks: How much do all customer ages vary from the overall average age across all coffeehouses?</p>
<p><strong>SSA</strong> asks: How much do the average ages at different coffeehouses vary from the overall average? If coffeehouses attract similar demographics, this should be small. If they attract different age groups, this should be large.</p>
<p><strong>SSE</strong> asks: How much do individual customer ages vary within each coffeehouse? This represents the natural variation in customer ages that exists regardless of systematic differences between coffeehouses.</p>
<p>If SSA is large relative to SSE, it suggests coffeehouses do attract systematically different age demographics.</p>
</section>
<section id="what-makes-the-ratios-large-or-small">
<h2><span class="section-number">12.2.8. </span>What Makes the Ratios Large or Small?<a class="headerlink" href="#what-makes-the-ratios-large-or-small" title="Link to this heading"></a></h2>
<p>MSA becomes large when:</p>
<ul class="simple">
<li><p>Group means are spread far apart</p></li>
<li><p>Sample sizes are large (making sample means more precise)</p></li>
<li><p>Within-group variability is small (making differences more detectable)</p></li>
</ul>
<p>MSE becomes large when:</p>
<ul class="simple">
<li><p>There’s high natural variability within populations</p></li>
<li><p>There’s measurement error</p></li>
<li><p>Other sources of variation aren’t controlled in the study design</p></li>
</ul>
<p>The ratio MSA/MSE becomes large when we have well-separated group means relative to the natural variability within groups—exactly what we were looking for visually in our boxplots.</p>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">12.2.9. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<p>We now have the building blocks for ANOVA hypothesis testing. In the next section, we’ll see how the ratio
MSA/MSE follows an F-distribution under the null hypothesis, allowing us to compute p-values and make formal
decisions about group differences. We’ll also see how this approach controls our overall Type I error rate
while comparing multiple groups simultaneously.</p>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>The ANOVA model</strong> <span class="math notranslate nohighlight">\(X_{ij} = \mu_i + \varepsilon_{ij}\)</span> decomposes each observation into a group effect plus random error, providing the theoretical foundation for variance analysis.</p></li>
<li><p><strong>Total variability decomposes exactly</strong> into between-group and within-group components: SST = SSA + SSE, with degrees of freedom that also add up: (n-1) = (k-1) + (n-k).</p></li>
<li><p><strong>Mean squares create unbiased estimators</strong>: MSE always estimates <span class="math notranslate nohighlight">\(\sigma^2\)</span>, while MSA estimates <span class="math notranslate nohighlight">\(\sigma^2\)</span> when <span class="math notranslate nohighlight">\(H_0\)</span> is true but estimates more when <span class="math notranslate nohighlight">\(H_0\)</span> is false.</p></li>
<li><p><strong>The ratio MSA/MSE</strong> compares between-group to within-group variability, forming the foundation for ANOVA test statistics.</p></li>
<li><p><strong>This framework formalizes our visual intuition</strong> from boxplots—groups that are well-separated relative to their internal spread suggest different population means.</p></li>
</ol>
</div>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p><strong>Model Understanding</strong>: Consider the ANOVA model <span class="math notranslate nohighlight">\(X_{ij} = \mu_i + \varepsilon_{ij}\)</span> for a study comparing four different exercise programs with 12 participants per program.</p>
<ol class="loweralpha simple">
<li><p>How many <span class="math notranslate nohighlight">\(\mu_i\)</span> parameters are there and what do they represent?</p></li>
<li><p>How many <span class="math notranslate nohighlight">\(\varepsilon_{ij}\)</span> terms are there and what assumptions do we make about them?</p></li>
<li><p>If <span class="math notranslate nohighlight">\(\mu_1 = 8.2\)</span>, <span class="math notranslate nohighlight">\(\mu_2 = 7.5\)</span>, <span class="math notranslate nohighlight">\(\mu_3 = 8.8\)</span>, and <span class="math notranslate nohighlight">\(\mu_4 = 7.9\)</span>, what would it mean for <span class="math notranslate nohighlight">\(H_0\)</span> to be true?</p></li>
</ol>
</li>
<li><p><strong>Sum of Squares Calculation</strong>: Given summary data for three groups:</p>
<ul class="simple">
<li><p>Group 1: <span class="math notranslate nohighlight">\(n_1 = 8\)</span>, <span class="math notranslate nohighlight">\(\bar{x}_1 = 15.2\)</span>, <span class="math notranslate nohighlight">\(s_1 = 2.3\)</span></p></li>
<li><p>Group 2: <span class="math notranslate nohighlight">\(n_2 = 10\)</span>, <span class="math notranslate nohighlight">\(\bar{x}_2 = 12.8\)</span>, <span class="math notranslate nohighlight">\(s_2 = 1.9\)</span></p></li>
<li><p>Group 3: <span class="math notranslate nohighlight">\(n_3 = 7\)</span>, <span class="math notranslate nohighlight">\(\bar{x}_3 = 18.1\)</span>, <span class="math notranslate nohighlight">\(s_3 = 2.7\)</span></p></li>
</ul>
<ol class="loweralpha simple">
<li><p>Calculate the overall sample mean <span class="math notranslate nohighlight">\(\bar{x}_{\cdot \cdot}\)</span></p></li>
<li><p>Calculate SSA</p></li>
<li><p>Calculate SSE</p></li>
<li><p>Verify that the degrees of freedom add up correctly</p></li>
</ol>
</li>
<li><p><strong>Conceptual Questions</strong>:</p>
<ol class="loweralpha simple">
<li><p>Explain why SSA measures “between-group variability”</p></li>
<li><p>Explain why SSE measures “within-group variability”</p></li>
<li><p>Why do we divide sum of squares by degrees of freedom to get mean squares?</p></li>
</ol>
</li>
<li><p><strong>Interpretation</strong>: A researcher studying plant growth obtains MSA = 34.7 and MSE = 8.2.</p>
<ol class="loweralpha simple">
<li><p>Calculate the ratio MSA/MSE and explain what this suggests</p></li>
<li><p>Would you expect this ratio to be larger or smaller if the treatments had no effect?</p></li>
</ol>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="12-1-intro-one-way-anova.html" class="btn btn-neutral float-left" title="12.1. Introduction to One-Way ANOVA" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="12-3-f-test-and-relationship-to-t-test.html" class="btn btn-neutral float-right" title="12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>