

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>12.4. Multiple Comparison Procedures and Family-Wise Error Rates &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=581abb6a" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/course_site/chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=de5959cf"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="13. Simple Linear Regression" href="../../chapter13/index.html" />
    <link rel="prev" title="12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests" href="12-3-f-test-and-relationship-to-t-test.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#additional-resources">Additional Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#post-exam-2-preparation-materials">Post Exam 2 Preparation Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#simulation-exercise">Simulation Exercise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-distribution">Part 1: The Bernoulli Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-binomial-distribution">Part 2: The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-the-poisson-distribution">Part 3: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-4-other-named-discrete-distributions">Part 4: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-empirical-rule">Part 2: The Empirical Rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-the-standard-normal-table">Part 3: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-4-z-score-transformation">Part 4: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#quick-reference-table">Quick Reference Table</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#recommended-workflow">Recommended workflow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#getting-started-with-swirl">Getting Started with swirl</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#setup-and-use-swirl">Setup and Use swirl</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#alternative-r-learning-resources">Alternative R Learning Resources</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#base-r">Base R</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#tidyverse">tidyverse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#r-markdown">R Markdown</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#statistical-computing">Statistical Computing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#video-resources">Video Resources</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#function-reference-alphabetized-within-category">Function Reference (Alphabetized within Category)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#simulation-functions">Simulation Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#inference-functions">Inference Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#graphics-ggplot2">Graphics (ggplot2)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#tables-reporting">Tables &amp; Reporting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#best-practices-common-pitfalls">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#appendix-quick-links">Appendix: Quick Links</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#assignments">Assignments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html#getting-help">Getting Help</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Bayesian Updating: Sequential Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter6/index.html">6. Continuous Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-4-normal-distribution.html">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter6/lectures/6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval and Sample Size Calculation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. Type I Error, Type II Error, and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Hypothesis Test for the Population Mean When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. P-values, Statistical Significance, and Formal Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Confidence Interval/Bound and Hypothesis Test for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Comparing the Means of Two Independent Populations - Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Comparing the Means of Two Independent Populations - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Comparing the Means of Two Independent Populations - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Analyzing the Mean of Paired Differences Between two Dependent Populations</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">12. ANOVA</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="12-2-sources-of-variability.html">12.2. Different Sources of Variability in an ANOVA Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="12-3-f-test-and-relationship-to-t-test.html">12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">12.4. Multiple Comparison Procedures and Family-Wise Error Rates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression: Correlation and Scatter Plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction, Robustness, and Applied Examples</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">12. </span>ANOVA</a></li>
      <li class="breadcrumb-item active"><span class="section-number">12.4. </span>Multiple Comparison Procedures and Family-Wise Error Rates</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch12-4">
   <iframe
      id="video-ch12-4"
      title="STAT 350 – Chapter 12.4 Multiple Comparison Procedures and Family-Wise Error Rates Video"
      src="https://www.youtube.com/embed/9BK1PxNtNjc?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
      allowfullscreen>
   </iframe>
</div><section id="multiple-comparison-procedures-and-family-wise-error-rates">
<h1><span class="section-number">12.4. </span>Multiple Comparison Procedures and Family-Wise Error Rates<a class="headerlink" href="#multiple-comparison-procedures-and-family-wise-error-rates" title="Link to this heading"></a></h1>
<p>After obtaining statistical significance in our analysis of variance procedure, we have determined
that at least one of the means are different from the rest. However, this doesn’t tell us which
means are different, and it doesn’t tell us that it’s only one mean that’s different from the rest—it
could be that all of them are different. We need to explore further after we have obtained statistical
significance to identify which means are different, which results in us performing what’s called multiple
comparison procedures.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p><strong>Problem we will solve</strong> – How to make multiple pairwise comparisons after ANOVA while controlling the overall probability of making Type I errors across all tests</p></li>
<li><p><strong>Tools we’ll learn</strong> – Family-wise error rate concepts, Šidák and Bonferroni corrections, Tukey’s HSD method, Dunnett’s method, and graphical display techniques for post-hoc comparisons</p></li>
<li><p><strong>How it fits</strong> – This completes the ANOVA procedure by providing rigorous methods to identify specific group differences while maintaining statistical control, bridging the gap between detecting overall differences and understanding the structure of those differences</p></li>
</ul>
</div>
<section id="the-foundation-why-we-need-multiple-comparisons">
<h2><span class="section-number">12.4.1. </span>The Foundation: Why We Need Multiple Comparisons<a class="headerlink" href="#the-foundation-why-we-need-multiple-comparisons" title="Link to this heading"></a></h2>
<p>When ANOVA indicates statistical significance with a small p-value from our F-test statistic, we have rejected the null hypothesis <span class="math notranslate nohighlight">\(H_0: \mu_1 = \mu_2 = \cdots = \mu_k\)</span>. This tells us that at least one of the population means is different from the others, leading to the alternative hypothesis <span class="math notranslate nohighlight">\(H_a: \mu_i \neq \mu_j\)</span> for some <span class="math notranslate nohighlight">\(i \neq j\)</span>.</p>
<p>However, this global conclusion could mean several different things:</p>
<ul class="simple">
<li><p>Only one pair of means differs (e.g., <span class="math notranslate nohighlight">\(\mu_1 \neq \mu_2\)</span> but <span class="math notranslate nohighlight">\(\mu_3 = \mu_4 = \mu_5\)</span>)</p></li>
<li><p>Multiple pairs differ but some remain equal (e.g., <span class="math notranslate nohighlight">\(\mu_1 = \mu_2 \neq \mu_3 = \mu_4 \neq \mu_5\)</span>)</p></li>
<li><p>All means are completely different from each other</p></li>
<li><p>Any number of intermediate patterns</p></li>
</ul>
<p>To understand the specific structure of these differences, we need to perform <strong>multiple comparison procedures</strong>—essentially conducting a series of focused two-sample tests comparing pairs of groups.</p>
<section id="visual-exploration-before-formal-testing">
<h3>Visual Exploration Before Formal Testing<a class="headerlink" href="#visual-exploration-before-formal-testing" title="Link to this heading"></a></h3>
<p>Before diving into formal statistical procedures, we should return to our graphical displays to gain initial insights:</p>
<p><strong>Effects plots</strong> display the sample means for each group without considering variability, making it easy to see which means are most separated. These plots help us identify the groups that appear most different visually.</p>
<p><strong>Side-by-side boxplots</strong> allow us to consider both the separation of means and the variability within groups, helping us identify which differences are most likely to be statistically significant when we account for sampling variability.</p>
<p>In our coffeehouse example, the boxplots clearly showed that coffeehouses 2 and 4 had the most separated means relative to their within-group variability, suggesting these would likely be significantly different in formal testing.</p>
</section>
</section>
<section id="the-fundamental-challenge-the-multiple-testing-problem">
<h2><span class="section-number">12.4.2. </span>The Fundamental Challenge: The Multiple Testing Problem<a class="headerlink" href="#the-fundamental-challenge-the-multiple-testing-problem" title="Link to this heading"></a></h2>
<p>The most natural approach might be to simply perform individual two-sample t-tests for every pair of groups using the pooled variance approach (since we’ve already established the equal variance assumption in ANOVA). However, this naive approach creates a serious <strong>multiple testing problem</strong>.</p>
<section id="the-mathematical-setup">
<h3>The Mathematical Setup<a class="headerlink" href="#the-mathematical-setup" title="Link to this heading"></a></h3>
<p>For <span class="math notranslate nohighlight">\(k\)</span> groups, we need to perform <span class="math notranslate nohighlight">\(c = \binom{k}{2} = \frac{k!}{(k-2)!2!}\)</span> different pairwise comparisons. Each comparison tests:</p>
<div class="math notranslate nohighlight">
\[H_0^{(j)}: \mu_i = \mu_j \quad \text{vs} \quad H_a^{(j)}: \mu_i \neq \mu_j\]</div>
<p>for all pairs <span class="math notranslate nohighlight">\(i &gt; j\)</span>, where <span class="math notranslate nohighlight">\(j = 1, 2, \ldots, c\)</span>.</p>
<p>Since we’re building on ANOVA, we use the pooled variance confidence interval approach:</p>
<div class="math notranslate nohighlight">
\[(\bar{X}_i - \bar{X}_j) \pm t_{\alpha/2,n-k} \sqrt{\text{MSE}\left(\frac{1}{n_i} + \frac{1}{n_j}\right)}\]</div>
<p>where MSE comes from our ANOVA table and the degrees of freedom are <span class="math notranslate nohighlight">\(n-k\)</span> from our variance estimate.</p>
</section>
<section id="the-problem-type-i-error-inflation">
<h3>The Problem: Type I Error Inflation<a class="headerlink" href="#the-problem-type-i-error-inflation" title="Link to this heading"></a></h3>
<p>Each individual test controls Type I error at level <span class="math notranslate nohighlight">\(\alpha\)</span>. If we set <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span> for each test, then each test has a 5% chance of making a Type I error when its null hypothesis is true. However, when we perform many tests simultaneously, the overall probability of making <strong>at least one</strong> Type I error becomes much larger than 5%.</p>
<p>Let’s examine this mathematically. For a concrete example, consider 5 groups requiring <span class="math notranslate nohighlight">\(\binom{5}{2} = 10\)</span> pairwise comparisons. If we naively use <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span> for each test, what’s the probability of making at least one Type I error across all 10 tests?</p>
<p>To understand this, let’s think about the complementary event. The probability of making <strong>no</strong> Type I errors means that all 10 tests correctly fail to reject their respective null hypotheses. If we assume the tests are independent (a simplifying assumption we’ll discuss), then:</p>
<div class="math notranslate nohighlight">
\[P(\text{No Type I errors}) = P(\text{Test 1 correct}) \times P(\text{Test 2 correct}) \times \cdots \times P(\text{Test 10 correct})\]</div>
<div class="math notranslate nohighlight">
\[= (1 - 0.05)^{10} = (0.95)^{10} = 0.599\]</div>
<p>Therefore:</p>
<div class="math notranslate nohighlight">
\[P(\text{At least one Type I error}) = 1 - 0.599 = 0.401\]</div>
<p>This means we have about a 40% chance of making at least one false positive—far above our intended 5% level! This massive inflation of Type I error rate undermines our statistical control and can lead to false discoveries.</p>
</section>
<section id="visualizing-the-multiple-testing-problem">
<h3>Visualizing the Multiple Testing Problem<a class="headerlink" href="#visualizing-the-multiple-testing-problem" title="Link to this heading"></a></h3>
<p>Imagine we have two simultaneous tests, represented by their test statistic distributions under their respective null hypotheses. Each distribution has rejection regions in its tails corresponding to <span class="math notranslate nohighlight">\(\alpha/2\)</span> in each tail for a two-sided test.</p>
<p>The overall Type I error occurs when we reject at least one null hypothesis incorrectly. This happens in several scenarios:</p>
<ul class="simple">
<li><p>We make a Type I error in the first test but not the second</p></li>
<li><p>We make a Type I error in the second test but not the first</p></li>
<li><p>We make Type I errors in both tests simultaneously</p></li>
</ul>
<p>The total probability of “at least one error” encompasses all these scenarios and is much larger than the individual <span class="math notranslate nohighlight">\(\alpha\)</span> level for any single test.</p>
</section>
</section>
<section id="family-wise-error-rate-fwer-the-formal-framework">
<h2><span class="section-number">12.4.3. </span>Family-Wise Error Rate (FWER): The Formal Framework<a class="headerlink" href="#family-wise-error-rate-fwer-the-formal-framework" title="Link to this heading"></a></h2>
<p>The <strong>family-wise error rate (FWER)</strong> provides a rigorous framework for understanding and controlling the overall Type I error rate across multiple tests.</p>
<section id="formal-definition">
<h3>Formal Definition<a class="headerlink" href="#formal-definition" title="Link to this heading"></a></h3>
<p>The family-wise error rate is the probability of making at least one Type I error across all comparisons in a family of tests, assuming all null hypotheses in the family are true:</p>
<div class="math notranslate nohighlight">
\[\text{FWER} = P\left(\bigcup_{j=1}^c \{\text{Reject } H_0^{(j)}\} \Big| \text{All } H_0^{(j)} \text{ are true}\right)\]</div>
<p>This can be equivalently written as:</p>
<div class="math notranslate nohighlight">
\[\text{FWER} = P(\text{At least one false positive}) = 1 - P(\text{No false positives})\]</div>
</section>
<section id="independence-assumption-and-its-implications">
<h3>Independence Assumption and Its Implications<a class="headerlink" href="#independence-assumption-and-its-implications" title="Link to this heading"></a></h3>
<p>If we assume the <span class="math notranslate nohighlight">\(c\)</span> tests are statistically independent and each has Type I error rate <span class="math notranslate nohighlight">\(\alpha_{\text{single}}\)</span>, then:</p>
<div class="math notranslate nohighlight">
\[P(\text{No false positives}) = \prod_{j=1}^c P(\text{Test } j \text{ correct}) = (1 - \alpha_{\text{single}})^c\]</div>
<p>Therefore:</p>
<div class="math notranslate nohighlight">
\[\text{FWER} = 1 - (1 - \alpha_{\text{single}})^c\]</div>
<p><strong>Important caveat</strong>: The independence assumption is actually quite unrealistic in our setting. The pairwise comparisons use overlapping data and share the common MSE estimate, creating dependencies between the tests. However, this assumption provides a useful starting point for understanding the problem and developing solutions.</p>
</section>
<section id="the-general-formula-for-any-number-of-comparisons">
<h3>The General Formula for Any Number of Comparisons<a class="headerlink" href="#the-general-formula-for-any-number-of-comparisons" title="Link to this heading"></a></h3>
<p>For <span class="math notranslate nohighlight">\(k\)</span> groups requiring <span class="math notranslate nohighlight">\(c = \binom{k}{2}\)</span> comparisons, if each test uses significance level <span class="math notranslate nohighlight">\(\alpha_{\text{single}}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\text{FWER} = 1 - (1 - \alpha_{\text{single}})^c\]</div>
<p>This formula reveals how quickly the family-wise error rate grows as we increase either the number of groups or the individual test significance level.</p>
</section>
</section>
<section id="methods-for-controlling-fwer">
<h2><span class="section-number">12.4.4. </span>Methods for Controlling FWER<a class="headerlink" href="#methods-for-controlling-fwer" title="Link to this heading"></a></h2>
<p>Several statistical methods have been developed to control the family-wise error rate. We’ll examine three major approaches: the Šidák correction, the Bonferroni correction, and Tukey’s HSD method.</p>
<section id="the-sidak-correction">
<h3>The Šidák Correction<a class="headerlink" href="#the-sidak-correction" title="Link to this heading"></a></h3>
<p>The Šidák correction directly inverts the independence-based FWER formula to find the individual test level needed to achieve a desired overall level.</p>
<p><strong>Derivation</strong>: If we want <span class="math notranslate nohighlight">\(\text{FWER} = \alpha_{\text{overall}}\)</span>, we solve:</p>
<div class="math notranslate nohighlight">
\[\alpha_{\text{overall}} = 1 - (1 - \alpha_{\text{single}})^c\]</div>
<p>Rearranging:</p>
<div class="math notranslate nohighlight">
\[(1 - \alpha_{\text{single}})^c = 1 - \alpha_{\text{overall}}\]</div>
<p>Taking the <span class="math notranslate nohighlight">\(c\)</span>-th root:</p>
<div class="math notranslate nohighlight">
\[1 - \alpha_{\text{single}} = (1 - \alpha_{\text{overall}})^{1/c}\]</div>
<p>Therefore:</p>
<div class="math notranslate nohighlight">
\[\alpha_{\text{single}} = 1 - (1 - \alpha_{\text{overall}})^{1/c}\]</div>
<p><strong>Example calculation</strong>: For our coffeehouse study with 5 groups (<span class="math notranslate nohighlight">\(c = 10\)</span> comparisons) and desired <span class="math notranslate nohighlight">\(\alpha_{\text{overall}} = 0.05\)</span>:</p>
<div class="math notranslate nohighlight">
\[\alpha_{\text{single}} = 1 - (1 - 0.05)^{1/10} = 1 - (0.95)^{0.1} = 1 - 0.994884 = 0.005116\]</div>
<p>We would use <span class="math notranslate nohighlight">\(\alpha = 0.005116\)</span> for each individual test, making our critical values much more stringent.</p>
<p><strong>Verification</strong>: Using this corrected level:</p>
<div class="math notranslate nohighlight">
\[\text{FWER} = 1 - (1 - 0.005116)^{10} = 1 - (0.994884)^{10} = 1 - 0.95 = 0.05\]</div>
<p><strong>Limitations</strong>: The Šidák correction assumes complete independence between tests. In practice, pairwise comparisons using the same data and pooled variance estimate are correlated, making this assumption problematic.</p>
</section>
<section id="the-bonferroni-correction">
<h3>The Bonferroni Correction<a class="headerlink" href="#the-bonferroni-correction" title="Link to this heading"></a></h3>
<p>The Bonferroni correction takes a different approach, using an inequality to bound the family-wise error rate rather than assuming independence.</p>
<p><strong>Mathematical foundation</strong>: The correction relies on Boole’s inequality (also called the union bound):</p>
<div class="math notranslate nohighlight">
\[P\left(\bigcup_{j=1}^c A_j\right) \leq \sum_{j=1}^c P(A_j)\]</div>
<p>Applied to our context:</p>
<div class="math notranslate nohighlight">
\[P\left(\bigcup_{j=1}^c \{\text{Reject } H_0^{(j)}\}\right) \leq \sum_{j=1}^c P(\text{Reject } H_0^{(j)})\]</div>
<p>If each test uses significance level <span class="math notranslate nohighlight">\(\alpha_{\text{single}}\)</span>, then under the respective null hypotheses:</p>
<div class="math notranslate nohighlight">
\[\text{FWER} \leq c \times \alpha_{\text{single}}\]</div>
<p><strong>The Bonferroni correction</strong>: To ensure <span class="math notranslate nohighlight">\(\text{FWER} \leq \alpha_{\text{overall}}\)</span>, we set:</p>
<div class="math notranslate nohighlight">
\[\alpha_{\text{single}} = \frac{\alpha_{\text{overall}}}{c}\]</div>
<p><strong>Example calculation</strong>: For 10 comparisons with desired <span class="math notranslate nohighlight">\(\alpha_{\text{overall}} = 0.05\)</span>:</p>
<div class="math notranslate nohighlight">
\[\alpha_{\text{single}} = \frac{0.05}{10} = 0.005\]</div>
<p>Notice this is slightly more conservative than the Šidák correction (0.005 vs 0.005116).</p>
<p><strong>Key advantages</strong>:</p>
<ul class="simple">
<li><p>No independence assumption required</p></li>
<li><p>Simple to calculate and apply</p></li>
<li><p>Provides a true upper bound on FWER</p></li>
</ul>
<p><strong>Key disadvantages</strong>:</p>
<ul class="simple">
<li><p>More conservative than Šidák correction</p></li>
<li><p>Can be overly restrictive with many comparisons</p></li>
<li><p>Uses an inequality rather than an equality, potentially wasting statistical power</p></li>
</ul>
</section>
<section id="why-the-inequality-matters">
<h3>Why the Inequality Matters<a class="headerlink" href="#why-the-inequality-matters" title="Link to this heading"></a></h3>
<p>The Bonferroni correction uses an upper bound rather than the exact FWER. To see why this creates conservatism, consider the inclusion-exclusion principle for the union of events:</p>
<div class="math notranslate nohighlight">
\[P(A_1 \cup A_2) = P(A_1) + P(A_2) - P(A_1 \cap A_2)\]</div>
<p>The Bonferroni bound ignores the negative intersection term <span class="math notranslate nohighlight">\(P(A_1 \cap A_2)\)</span>, which represents the probability of making Type I errors in multiple tests simultaneously. Since this intersection probability is always non-negative, the bound overestimates the true FWER.</p>
<p>For more than two events, the inclusion-exclusion principle involves alternating sums of increasingly complex intersection terms. The Bonferroni bound uses only the first (positive) terms, making it increasingly conservative as the number of comparisons grows.</p>
</section>
<section id="conservative-nature-and-power-implications">
<h3>Conservative Nature and Power Implications<a class="headerlink" href="#conservative-nature-and-power-implications" title="Link to this heading"></a></h3>
<p>Both Šidák and Bonferroni corrections are <strong>conservative</strong>—they control the FWER at or below the desired level, often well below it. This conservatism comes at the cost of reduced statistical power (increased probability of Type II errors).</p>
<p>When we make the significance level more stringent for each comparison (from 0.05 to 0.005, for example), we make it more difficult to reject individual null hypotheses. This reduces our ability to detect true differences that actually exist in the population.</p>
<p>As the number of comparisons increases, these methods become increasingly restrictive. For example, with 15 groups requiring 105 pairwise comparisons, the Bonferroni correction would use <span class="math notranslate nohighlight">\(\alpha_{\text{single}} = 0.05/105 ≈ 0.0005\)</span> for each test—an extremely stringent criterion that would miss many real differences.</p>
</section>
</section>
<section id="tukey-s-honestly-significant-difference-hsd-method">
<h2><span class="section-number">12.4.5. </span>Tukey’s Honestly Significant Difference (HSD) Method<a class="headerlink" href="#tukey-s-honestly-significant-difference-hsd-method" title="Link to this heading"></a></h2>
<p>Tukey’s HSD method represents a major advance in multiple comparison procedures. Instead of adjusting individual significance levels, it uses a fundamentally different approach based on the studentized range distribution.</p>
<section id="the-philosophy-behind-tukey-s-hsd">
<h3>The Philosophy Behind Tukey’s HSD<a class="headerlink" href="#the-philosophy-behind-tukey-s-hsd" title="Link to this heading"></a></h3>
<p>Tukey’s method recognizes that the pairwise comparisons in ANOVA are not independent—they all use the same pooled variance estimate (MSE) and involve overlapping group comparisons. Rather than pretending independence or using conservative bounds, Tukey’s HSD explicitly accounts for this correlation structure.</p>
<p>The key insight is to control the family-wise error rate by focusing on the <strong>largest</strong> difference among all possible pairwise comparisons. If we can control the probability that the largest difference exceeds a certain threshold when all null hypotheses are true, then we automatically control the FWER for all comparisons.</p>
</section>
<section id="the-studentized-range-distribution">
<h3>The Studentized Range Distribution<a class="headerlink" href="#the-studentized-range-distribution" title="Link to this heading"></a></h3>
<p>The theoretical foundation of Tukey’s method rests on the <strong>studentized range statistic</strong>. Suppose we have <span class="math notranslate nohighlight">\(k\)</span> independent sample means <span class="math notranslate nohighlight">\(\bar{X}_1, \bar{X}_2, \ldots, \bar{X}_k\)</span> from normal populations with common variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>, each based on sample size <span class="math notranslate nohighlight">\(n\)</span>. The studentized range statistic is:</p>
<div class="math notranslate nohighlight">
\[Q = \frac{\max_i \bar{X}_i - \min_i \bar{X}_i}{\sqrt{\sigma^2/n}}\]</div>
<p>When <span class="math notranslate nohighlight">\(\sigma^2\)</span> is unknown and estimated by <span class="math notranslate nohighlight">\(s^2\)</span> with <span class="math notranslate nohighlight">\(\nu\)</span> degrees of freedom:</p>
<div class="math notranslate nohighlight">
\[Q = \frac{\max_i \bar{X}_i - \min_i \bar{X}_i}{\sqrt{s^2/n}}\]</div>
<p>follows the studentized range distribution with parameters <span class="math notranslate nohighlight">\(k\)</span> (number of groups) and <span class="math notranslate nohighlight">\(\nu\)</span> (degrees of freedom for the variance estimate).</p>
</section>
<section id="adaptation-to-unequal-sample-sizes">
<h3>Adaptation to Unequal Sample Sizes<a class="headerlink" href="#adaptation-to-unequal-sample-sizes" title="Link to this heading"></a></h3>
<p>In practice, we often have unequal sample sizes. The studentized range distribution theory extends to this case, where for any two groups <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>:</p>
<div class="math notranslate nohighlight">
\[Q_{ij} = \frac{|\bar{X}_i - \bar{X}_j|}{\sqrt{\frac{1}{2}\text{MSE}\left(\frac{1}{n_i} + \frac{1}{n_j}\right)}}\]</div>
<p>The factor <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> appears because the studentized range distribution is constructed for the difference between the maximum and minimum of <span class="math notranslate nohighlight">\(k\)</span> means, which involves a standard error of <span class="math notranslate nohighlight">\(\sqrt{\sigma^2/n}\)</span>, while the difference between any two specific means has standard error <span class="math notranslate nohighlight">\(\sqrt{\sigma^2(1/n_i + 1/n_j)}\)</span>. The relationship between these gives rise to the <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> factor.</p>
</section>
<section id="tukey-s-hsd-critical-value">
<h3>Tukey’s HSD Critical Value<a class="headerlink" href="#tukey-s-hsd-critical-value" title="Link to this heading"></a></h3>
<p>The critical value for Tukey’s HSD is:</p>
<div class="math notranslate nohighlight">
\[t^{**} = \frac{q_{\alpha,k,n-k}}{\sqrt{2}}\]</div>
<p>where <span class="math notranslate nohighlight">\(q_{\alpha,k,n-k}\)</span> is the <span class="math notranslate nohighlight">\((1-\alpha)\)</span>-quantile of the studentized range distribution with <span class="math notranslate nohighlight">\(k\)</span> groups and <span class="math notranslate nohighlight">\(n-k\)</span> degrees of freedom.</p>
</section>
<section id="the-confidence-interval-formula">
<h3>The Confidence Interval Formula<a class="headerlink" href="#the-confidence-interval-formula" title="Link to this heading"></a></h3>
<p>The Tukey HSD confidence interval for the difference <span class="math notranslate nohighlight">\(\mu_i - \mu_j\)</span> is:</p>
<div class="math notranslate nohighlight">
\[(\bar{X}_i - \bar{X}_j) \pm \frac{q_{\alpha,k,n-k}}{\sqrt{2}} \sqrt{\text{MSE}\left(\frac{1}{n_i} + \frac{1}{n_j}\right)}\]</div>
<p>This interval simultaneously controls the family-wise confidence level at <span class="math notranslate nohighlight">\(1 - \alpha\)</span> for all <span class="math notranslate nohighlight">\(\binom{k}{2}\)</span> pairwise comparisons.</p>
</section>
<section id="implementation-in-r">
<h3>Implementation in R<a class="headerlink" href="#implementation-in-r" title="Link to this heading"></a></h3>
<p><strong>Method 1: Using confidence level</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get critical value using confidence level</span>
<span class="n">q_crit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">qtukey</span><span class="p">(</span><span class="m">0.95</span><span class="p">,</span><span class="w"> </span><span class="n">nmeans</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="o">-</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Method 2: Using significance level</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get critical value using significance level</span>
<span class="n">q_crit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">qtukey</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">nmeans</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="o">-</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Complete procedure with raw data:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit ANOVA model</span>
<span class="n">fit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">aov</span><span class="p">(</span><span class="n">response</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">factor</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dataset</span><span class="p">)</span>

<span class="c1"># Perform Tukey&#39;s HSD</span>
<span class="n">tukey_results</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">TukeyHSD</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">ordered</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span>

<span class="c1"># View results</span>
<span class="n">tukey_results</span>
</pre></div>
</div>
<p><strong>Manual calculation for summary statistics:</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate critical value</span>
<span class="n">q_crit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">qtukey</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">nmeans</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="o">-</span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">2</span><span class="p">)</span>

<span class="c1"># For each pair (i,j)</span>
<span class="n">diff</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">x_bar_i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x_bar_j</span>
<span class="n">se_diff</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="n">MSE</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="o">/</span><span class="n">n_i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="o">/</span><span class="n">n_j</span><span class="p">))</span>
<span class="n">margin_error</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">q_crit</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">se_diff</span>

<span class="c1"># Confidence interval</span>
<span class="n">ci_lower</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">diff</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">margin_error</span>
<span class="n">ci_upper</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">diff</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">margin_error</span>
</pre></div>
</div>
</section>
<section id="interpreting-tukey-hsd-results">
<h3>Interpreting Tukey HSD Results<a class="headerlink" href="#interpreting-tukey-hsd-results" title="Link to this heading"></a></h3>
<p>A confidence interval that <strong>does not contain 0</strong> indicates a statistically significant difference between those two groups at the family-wise level <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p>The R output provides several components:</p>
<ul class="simple">
<li><p><strong>diff</strong>: Difference in sample means (<span class="math notranslate nohighlight">\(\bar{X}_i - \bar{X}_j\)</span>)</p></li>
<li><p><strong>lwr</strong>: Lower bound of confidence interval</p></li>
<li><p><strong>upr</strong>: Upper bound of confidence interval</p></li>
<li><p><strong>p adj</strong>: Adjusted p-value accounting for multiple comparisons</p></li>
</ul>
<p>The adjusted p-values can be compared directly to <span class="math notranslate nohighlight">\(\alpha\)</span> (e.g., 0.05) to determine significance, or you can examine whether 0 falls within each confidence interval.</p>
</section>
<section id="advantages-of-tukey-s-hsd">
<h3>Advantages of Tukey’s HSD<a class="headerlink" href="#advantages-of-tukey-s-hsd" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Exact FWER control</strong>: For balanced designs, Tukey’s HSD controls the FWER at exactly the specified level (not just an upper bound)</p></li>
<li><p><strong>Less conservative</strong>: Generally more powerful than Bonferroni or Šidák corrections because it accounts for the correlation structure among tests</p></li>
<li><p><strong>No independence assumption</strong>: The method is derived specifically for the correlated structure of pairwise comparisons using pooled variance</p></li>
<li><p><strong>Optimal for all pairwise comparisons</strong>: When the goal is to compare all possible pairs of groups, Tukey’s HSD is typically the most powerful method</p></li>
</ol>
</section>
</section>
<section id="alternative-dunnett-s-method-for-control-comparisons">
<h2><span class="section-number">12.4.6. </span>Alternative: Dunnett’s Method for Control Comparisons<a class="headerlink" href="#alternative-dunnett-s-method-for-control-comparisons" title="Link to this heading"></a></h2>
<p>When the research design includes a <strong>control group</strong> and the primary interest lies in comparing each treatment to the control (rather than all pairwise comparisons), <strong>Dunnett’s method</strong> provides a more powerful alternative.</p>
<section id="the-dunnett-setup">
<h3>The Dunnett Setup<a class="headerlink" href="#the-dunnett-setup" title="Link to this heading"></a></h3>
<p>Consider <span class="math notranslate nohighlight">\(k\)</span> groups where group 1 is a control and groups 2 through <span class="math notranslate nohighlight">\(k\)</span> are treatments. Instead of <span class="math notranslate nohighlight">\(\binom{k}{2}\)</span> pairwise comparisons, we perform only <span class="math notranslate nohighlight">\(k-1\)</span> comparisons:</p>
<div class="math notranslate nohighlight">
\[\mu_1 \text{ vs } \mu_2, \quad \mu_1 \text{ vs } \mu_3, \quad \ldots, \quad \mu_1 \text{ vs } \mu_k\]</div>
<p>This reduction in the number of comparisons (from <span class="math notranslate nohighlight">\(\binom{k}{2}\)</span> to <span class="math notranslate nohighlight">\(k-1\)</span>) leads to increased statistical power for detecting differences from the control.</p>
</section>
<section id="advantages-of-dunnett-s-method">
<h3>Advantages of Dunnett’s Method<a class="headerlink" href="#advantages-of-dunnett-s-method" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Fewer comparisons</strong>: <span class="math notranslate nohighlight">\(k-1\)</span> instead of <span class="math notranslate nohighlight">\(\binom{k}{2}\)</span>, dramatically reducing the multiple comparison penalty</p></li>
<li><p><strong>Increased power</strong>: More powerful for detecting treatment-vs-control differences</p></li>
<li><p><strong>Targeted inference</strong>: Focuses on the scientifically relevant comparisons when a control group exists</p></li>
<li><p><strong>Still controls FWER</strong>: Maintains proper family-wise error control</p></li>
</ol>
<p><strong>Example</strong>: With 5 groups, Tukey’s HSD requires 10 comparisons while Dunnett’s method requires only 4, leading to substantially less stringent critical values.</p>
</section>
<section id="implementation-considerations">
<h3>Implementation Considerations<a class="headerlink" href="#implementation-considerations" title="Link to this heading"></a></h3>
<p>Dunnett’s method is not implemented in base R but is available in various packages. The theoretical development parallels Tukey’s approach but uses a different multivariate distribution that accounts for the specific correlation structure among control-vs-treatment comparisons.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example using a hypothetical package</span>
<span class="c1"># install.packages(&quot;multcomp&quot;)  # or another package</span>
<span class="c1"># library(multcomp)</span>
<span class="c1"># dunnett_results &lt;- dunnett.test(fit, control = &quot;group1&quot;)</span>
</pre></div>
</div>
<p>The exact implementation details vary by package, but the conceptual approach remains the same: use a specialized distribution to set critical values that control the FWER for the specific set of control-vs-treatment comparisons.</p>
</section>
</section>
<section id="visual-display-of-multiple-comparison-results">
<h2><span class="section-number">12.4.7. </span>Visual Display of Multiple Comparison Results<a class="headerlink" href="#visual-display-of-multiple-comparison-results" title="Link to this heading"></a></h2>
<p>After obtaining multiple comparison results, creating an effective visual summary helps communicate the pattern of group differences clearly and intuitively.</p>
<section id="the-underline-method-step-by-step-process">
<h3>The Underline Method: Step-by-Step Process<a class="headerlink" href="#the-underline-method-step-by-step-process" title="Link to this heading"></a></h3>
<p>The standard approach uses an “underline” notation to show which groups cannot be distinguished statistically:</p>
<ol class="arabic simple">
<li><p><strong>Order groups by sample means</strong>: Arrange groups from smallest to largest sample mean</p></li>
<li><p><strong>Identify non-significant pairs</strong>: From your multiple comparison results, identify all pairs that are NOT significantly different</p></li>
<li><p><strong>Draw underlines for adjacent groups</strong>: Start by drawing lines under groups that are adjacent in your ordering and not significantly different</p></li>
<li><p><strong>Extend underlines when possible</strong>: If groups A and B are connected by an underline, and B and C are connected by an underline, and A and C are also not significantly different, extend the line to cover A, B, and C</p></li>
<li><p><strong>Interpret the grouping pattern</strong>: Groups connected by the same underline are statistically indistinguishable from each other</p></li>
</ol>
</section>
<section id="visual-example-1-simple-grouping">
<h3>Visual Example 1: Simple Grouping<a class="headerlink" href="#visual-example-1-simple-grouping" title="Link to this heading"></a></h3>
<p>Consider four groups A, B, C, D with sample means ordered as <span class="math notranslate nohighlight">\(\bar{X}_A &lt; \bar{X}_B &lt; \bar{X}_C &lt; \bar{X}_D\)</span>.</p>
<p>Suppose Tukey HSD results show:</p>
<ul class="simple">
<li><p>A vs B: not significant</p></li>
<li><p>B vs C: not significant</p></li>
<li><p>C vs D: not significant</p></li>
<li><p>A vs C: significant</p></li>
<li><p>A vs D: significant</p></li>
<li><p>B vs D: significant</p></li>
</ul>
<p>Visual display:</p>
<pre>
A ——— B ——— C ——— D
      |_______|
</pre><p><strong>Interpretation</strong>: Groups A and B form one cluster, groups C and D form another cluster, but these two clusters are significantly different from each other.</p>
</section>
<section id="visual-example-2-complex-overlapping-pattern">
<h3>Visual Example 2: Complex Overlapping Pattern<a class="headerlink" href="#visual-example-2-complex-overlapping-pattern" title="Link to this heading"></a></h3>
<p>Consider the same four groups with different significance results:</p>
<ul class="simple">
<li><p>A vs B: not significant</p></li>
<li><p>B vs C: not significant</p></li>
<li><p>C vs D: not significant</p></li>
<li><p>A vs C: not significant</p></li>
<li><p>A vs D: significant</p></li>
<li><p>B vs D: significant</p></li>
</ul>
<p>Visual display:</p>
<pre>
A ——————————— B ——— C ——— D
</pre><p><strong>Interpretation</strong>: Groups A, B, and C are all statistically indistinguishable from each other, but group D is significantly different from groups A and B (though not from group C).</p>
</section>
<section id="visual-example-3-ambiguous-transitivity">
<h3>Visual Example 3: Ambiguous Transitivity<a class="headerlink" href="#visual-example-3-ambiguous-transitivity" title="Link to this heading"></a></h3>
<p>Sometimes the results create apparent contradictions that require careful interpretation:</p>
<ul class="simple">
<li><p>A vs B: not significant</p></li>
<li><p>B vs C: significant</p></li>
<li><p>C vs D: not significant</p></li>
<li><p>A vs C: significant</p></li>
<li><p>A vs D: not significant</p></li>
<li><p>B vs D: significant</p></li>
</ul>
<p>Visual display:</p>
<pre>
A ——— B          C ——— D
</pre><p><strong>Interpretation</strong>: Groups A and B are similar; groups C and D are similar; but the statistical evidence suggests that A is more similar to D than to C, even though D and C are not significantly different. This illustrates the limitations of interpreting statistical significance as a perfect ordering—the underlying population means may have a different relationship than what our sample evidence suggests.</p>
</section>
</section>
<section id="complete-example-coffeehouse-analysis-revisited">
<h2><span class="section-number">12.4.8. </span>Complete Example: Coffeehouse Analysis Revisited<a class="headerlink" href="#complete-example-coffeehouse-analysis-revisited" title="Link to this heading"></a></h2>
<p>Let’s work through a comprehensive multiple comparison analysis using our coffeehouse customer age data.</p>
<section id="step-1-anova-foundation">
<h3>Step 1: ANOVA Foundation<a class="headerlink" href="#step-1-anova-foundation" title="Link to this heading"></a></h3>
<p>Our previous ANOVA analysis yielded:</p>
<ul class="simple">
<li><p>F-statistic = 22.14</p></li>
<li><p>p-value ≈ 0 (highly significant)</p></li>
<li><p>MSE = 99.8</p></li>
<li><p>Error degrees of freedom: <span class="math notranslate nohighlight">\(n - k = 200 - 5 = 195\)</span></p></li>
<li><p>Between-groups degrees of freedom: <span class="math notranslate nohighlight">\(k - 1 = 4\)</span></p></li>
</ul>
<p><strong>Conclusion</strong>: We have strong evidence that at least one coffeehouse differs in mean customer age. We proceed to multiple comparisons to identify the specific differences.</p>
</section>
<section id="step-2-choosing-the-appropriate-method">
<h3>Step 2: Choosing the Appropriate Method<a class="headerlink" href="#step-2-choosing-the-appropriate-method" title="Link to this heading"></a></h3>
<p>Since we want to compare all possible pairs of coffeehouses (no natural control group), Tukey’s HSD is the appropriate method. We’ll use a family-wise confidence level of 95% (<span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>).</p>
</section>
<section id="step-3-tukey-hsd-implementation">
<h3>Step 3: Tukey HSD Implementation<a class="headerlink" href="#step-3-tukey-hsd-implementation" title="Link to this heading"></a></h3>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assuming we have the fitted ANOVA model</span>
<span class="n">tukey_results</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">TukeyHSD</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">ordered</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">conf.level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.95</span><span class="p">)</span>
</pre></div>
</div>
<p>The critical value calculation:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Manual critical value calculation</span>
<span class="n">q_crit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">qtukey</span><span class="p">(</span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">nmeans</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">195</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">(</span><span class="m">2</span><span class="p">)</span>
<span class="c1"># q_crit ≈ 2.83</span>
</pre></div>
</div>
</section>
<section id="step-4-detailed-results-interpretation">
<h3>Step 4: Detailed Results Interpretation<a class="headerlink" href="#step-4-detailed-results-interpretation" title="Link to this heading"></a></h3>
<p><strong>Significant differences</strong> (confidence intervals not containing 0):</p>
<table class="docutils align-default" id="id1">
<caption><span class="caption-number">Table 12.4 </span><span class="caption-text">Significant Comparisons</span><a class="headerlink" href="#id1" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 15.0%" />
<col style="width: 15.0%" />
<col style="width: 15.0%" />
<col style="width: 15.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Comparison</p></th>
<th class="head"><p>Difference</p></th>
<th class="head"><p>95% CI Lower</p></th>
<th class="head"><p>95% CI Upper</p></th>
<th class="head"><p>Interpretation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>5-4</p></td>
<td><p>7.65</p></td>
<td><p>1.53</p></td>
<td><p>13.77</p></td>
<td><p>CH5 customers significantly older than CH4</p></td>
</tr>
<tr class="row-odd"><td><p>1-4</p></td>
<td><p>12.71</p></td>
<td><p>6.44</p></td>
<td><p>18.98</p></td>
<td><p>CH1 customers significantly older than CH4</p></td>
</tr>
<tr class="row-even"><td><p>3-4</p></td>
<td><p>14.08</p></td>
<td><p>7.92</p></td>
<td><p>20.24</p></td>
<td><p>CH3 customers significantly older than CH4</p></td>
</tr>
<tr class="row-odd"><td><p>2-4</p></td>
<td><p>20.24</p></td>
<td><p>13.93</p></td>
<td><p>26.55</p></td>
<td><p>CH2 customers significantly older than CH4</p></td>
</tr>
<tr class="row-even"><td><p>3-5</p></td>
<td><p>6.43</p></td>
<td><p>0.46</p></td>
<td><p>12.40</p></td>
<td><p>CH3 customers significantly older than CH5</p></td>
</tr>
<tr class="row-odd"><td><p>2-5</p></td>
<td><p>12.59</p></td>
<td><p>6.47</p></td>
<td><p>18.71</p></td>
<td><p>CH2 customers significantly older than CH5</p></td>
</tr>
<tr class="row-even"><td><p>2-1</p></td>
<td><p>7.53</p></td>
<td><p>1.26</p></td>
<td><p>13.80</p></td>
<td><p>CH2 customers significantly older than CH1</p></td>
</tr>
<tr class="row-odd"><td><p>2-3</p></td>
<td><p>6.16</p></td>
<td><p>0.0009</p></td>
<td><p>12.31</p></td>
<td><p>CH2 customers significantly older than CH3 (barely)</p></td>
</tr>
</tbody>
</table>
<p><strong>Non-significant differences</strong> (confidence intervals containing 0):</p>
<table class="docutils align-default" id="id2">
<caption><span class="caption-number">Table 12.5 </span><span class="caption-text">Non-Significant Comparisons</span><a class="headerlink" href="#id2" title="Link to this table"></a></caption>
<colgroup>
<col style="width: 15.0%" />
<col style="width: 15.0%" />
<col style="width: 15.0%" />
<col style="width: 15.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Comparison</p></th>
<th class="head"><p>Difference</p></th>
<th class="head"><p>95% CI Lower</p></th>
<th class="head"><p>95% CI Upper</p></th>
<th class="head"><p>Interpretation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1-5</p></td>
<td><p>5.06</p></td>
<td><p>-1.02</p></td>
<td><p>11.14</p></td>
<td><p>No significant difference</p></td>
</tr>
<tr class="row-odd"><td><p>3-1</p></td>
<td><p>1.37</p></td>
<td><p>-4.74</p></td>
<td><p>7.49</p></td>
<td><p>No significant difference</p></td>
</tr>
</tbody>
</table>
</section>
<section id="step-5-sample-mean-ordering-and-visual-display">
<h3>Step 5: Sample Mean Ordering and Visual Display<a class="headerlink" href="#step-5-sample-mean-ordering-and-visual-display" title="Link to this heading"></a></h3>
<p><strong>Sample means in ascending order</strong>:</p>
<div class="math notranslate nohighlight">
\[\bar{X}_{CH4} = 26.42 &lt; \bar{X}_{CH5} = 34.07 &lt; \bar{X}_{CH1} = 39.13 &lt; \bar{X}_{CH3} = 40.50 &lt; \bar{X}_{CH2} = 46.66\]</div>
<p><strong>Non-significant adjacent and non-adjacent pairs</strong>: 1-5, 3-1</p>
<p><strong>Visual representation</strong>:</p>
<pre>
CH4    CH5 ——— CH1 ——— CH3    CH2
</pre></section>
<section id="step-6-comprehensive-interpretation">
<h3>Step 6: Comprehensive Interpretation<a class="headerlink" href="#step-6-comprehensive-interpretation" title="Link to this heading"></a></h3>
<p><strong>Population mean relationships</strong>:</p>
<ul class="simple">
<li><p><strong>Coffeehouse 4</strong> has the youngest customer base, significantly different from all other coffeehouses</p></li>
<li><p><strong>Coffeehouse 2</strong> has the oldest customer base, significantly different from all other coffeehouses</p></li>
<li><p><strong>Coffeehouses 5, 1, and 3</strong> form an intermediate cluster where customers cannot be distinguished by age statistically, though their sample means suggest the ordering CH5 &lt; CH1 &lt; CH3</p></li>
</ul>
<p><strong>Statistical conclusion</strong>: The data suggests that Coffeehouse 4 might be popular with undergraduates (younger customers) while Coffeehouse 2 might attract graduate students and faculty (older customers). Coffeehouses 5, 1, and 3 have overlapping age demographics that cannot be statistically distinguished from each other.</p>
</section>
</section>
<section id="advanced-topics-in-multiple-comparisons">
<h2><span class="section-number">12.4.9. </span>Advanced Topics in Multiple Comparisons<a class="headerlink" href="#advanced-topics-in-multiple-comparisons" title="Link to this heading"></a></h2>
<section id="controlling-false-discovery-rate-fdr">
<h3>Controlling False Discovery Rate (FDR)<a class="headerlink" href="#controlling-false-discovery-rate-fdr" title="Link to this heading"></a></h3>
<p>While family-wise error rate provides strong control over Type I errors, it can be overly conservative when the number of comparisons is large. An alternative approach controls the <strong>false discovery rate (FDR)</strong>—the expected proportion of false discoveries among all rejected hypotheses.</p>
<p>The FDR approach is particularly useful in exploratory research where some false positives are acceptable in exchange for increased power to detect true effects. However, for the controlled experimental settings typical in introductory statistics courses, FWER control remains the standard approach.</p>
</section>
<section id="simultaneous-confidence-intervals">
<h3>Simultaneous Confidence Intervals<a class="headerlink" href="#simultaneous-confidence-intervals" title="Link to this heading"></a></h3>
<p>The multiple comparison methods we’ve discussed provide <strong>simultaneous confidence intervals</strong>—sets of intervals that jointly have the specified confidence level. This means we can be 95% confident that <strong>all</strong> intervals simultaneously contain their respective true population differences.</p>
<p>This simultaneity distinguishes these intervals from individual confidence intervals, each of which would have 95% confidence individually but would not maintain 95% confidence when considered together.</p>
</section>
<section id="power-considerations-in-multiple-comparisons">
<h3>Power Considerations in Multiple Comparisons<a class="headerlink" href="#power-considerations-in-multiple-comparisons" title="Link to this heading"></a></h3>
<p>The choice among multiple comparison methods involves a fundamental trade-off between Type I and Type II error control:</p>
<p><strong>Most conservative</strong> (lowest power): Bonferroni correction
<strong>Moderately conservative</strong>: Šidák correction
<strong>Least conservative</strong> (highest power): Tukey’s HSD (for all pairwise comparisons)
<strong>Most powerful</strong> (for specific designs): Dunnett’s method (for control comparisons)</p>
<p>When planning studies, researchers should consider:</p>
<ul class="simple">
<li><p>The number of planned comparisons</p></li>
<li><p>The relative costs of Type I vs Type II errors in their context</p></li>
<li><p>Whether all pairwise comparisons are scientifically meaningful</p></li>
<li><p>The availability of natural control groups</p></li>
</ul>
</section>
</section>
<section id="best-practices-for-multiple-comparisons">
<h2><span class="section-number">12.4.10. </span>Best Practices for Multiple Comparisons<a class="headerlink" href="#best-practices-for-multiple-comparisons" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p><strong>Always perform ANOVA first</strong> as a gatekeeper test</p></li>
<li><p><strong>Only proceed with multiple comparisons</strong> if ANOVA is significant</p></li>
<li><p><strong>Choose the appropriate method</strong> based on your research design:</p>
<ul class="simple">
<li><p>Tukey HSD for all pairwise comparisons</p></li>
<li><p>Dunnett’s method for treatment-vs-control designs</p></li>
</ul>
</li>
<li><p><strong>Avoid Bonferroni correction</strong> unless you have specific reasons to use it</p></li>
<li><p><strong>Create visual displays</strong> to communicate results clearly</p></li>
<li><p><strong>Report both statistical significance and effect sizes</strong></p></li>
</ol>
</section>
<section id="the-complete-anova-workflow">
<h2><span class="section-number">12.4.11. </span>The Complete ANOVA Workflow<a class="headerlink" href="#the-complete-anova-workflow" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p><strong>Exploratory analysis</strong>: Side-by-side boxplots, effects plots</p></li>
<li><p><strong>Check assumptions</strong>: Independence, normality, equal variances</p></li>
<li><p><strong>Perform ANOVA</strong>: Test for any group differences</p></li>
<li><p><strong>If ANOVA significant</strong>: Proceed to multiple comparisons</p></li>
<li><p><strong>Apply appropriate method</strong>: Usually Tukey HSD</p></li>
<li><p><strong>Create visual display</strong>: Show pattern of group differences</p></li>
<li><p><strong>Interpret results</strong>: Identify which groups differ and by how much</p></li>
</ol>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">12.4.12. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p><strong>Multiple comparisons are essential</strong> after significant ANOVA to identify which specific groups differ, but naive approaches inflate Type I error rates dangerously.</p></li>
<li><p><strong>Family-wise error rate (FWER)</strong> provides the theoretical framework for understanding and controlling the overall probability of making at least one Type I error across all comparisons.</p></li>
<li><p><strong>Bonferroni and Šidák corrections</strong> control FWER by adjusting individual test significance levels, but they tend to be overly conservative, especially with many comparisons.</p></li>
<li><p><strong>Tukey’s HSD method</strong> provides superior power while maintaining exact FWER control by using the studentized range distribution, which accounts for the correlation structure among pairwise comparisons.</p></li>
<li><p><strong>Dunnett’s method</strong> offers the most powerful approach when comparing multiple treatments to a single control group by reducing the number of required comparisons.</p></li>
<li><p><strong>Visual displays using underlines</strong> effectively communicate complex patterns of group similarities and differences, though they should be interpreted carefully regarding transitivity.</p></li>
<li><p><strong>The complete ANOVA workflow</strong> integrates exploratory analysis, assumption checking, overall F-testing, and targeted multiple comparisons to provide comprehensive understanding of group differences.</p></li>
<li><p><strong>Method selection matters</strong>: The choice among multiple comparison procedures should align with research questions, study design, and the relative costs of Type I vs Type II errors in the specific context.</p></li>
</ol>
</div>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h3>
<ol class="arabic">
<li><p><strong>FWER Calculation and Method Comparison</strong>: A researcher plans to compare 6 different teaching methods using all pairwise comparisons.</p>
<ol class="loweralpha simple">
<li><p>How many individual comparisons will be performed?</p></li>
<li><p>If each test uses <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, what is the family-wise error rate assuming independence?</p></li>
<li><p>What individual <span class="math notranslate nohighlight">\(\alpha\)</span> level should be used with Bonferroni correction to achieve FWER = 0.05?</p></li>
<li><p>What individual <span class="math notranslate nohighlight">\(\alpha\)</span> level should be used with Šidák correction?</p></li>
<li><p>Which correction is more powerful, and why?</p></li>
</ol>
</li>
<li><p><strong>Tukey HSD Interpretation</strong>: Consider these Tukey HSD confidence intervals for differences in means (all at 95% family-wise confidence level):</p>
<ul class="simple">
<li><p>A vs B: [-2.1, 4.8]</p></li>
<li><p>A vs C: [1.2, 8.1]</p></li>
<li><p>A vs D: [3.5, 10.4]</p></li>
<li><p>B vs C: [-1.5, 5.4]</p></li>
<li><p>B vs D: [0.8, 7.7]</p></li>
<li><p>C vs D: [-2.0, 4.9]</p></li>
</ul>
<ol class="loweralpha simple">
<li><p>Which pairs are significantly different at the 0.05 family-wise level?</p></li>
<li><p>Create a visual display showing group relationships using the underline method</p></li>
<li><p>Order the population means from smallest to largest based on the evidence</p></li>
<li><p>If these were individual confidence intervals (not simultaneous), would your conclusions change? Explain.</p></li>
</ol>
</li>
<li><p><strong>Method Selection and Design Considerations</strong>: For each scenario, identify the most appropriate multiple comparison method and justify your choice:</p>
<ol class="loweralpha simple">
<li><p>A pharmaceutical company tests 4 new drugs against a placebo for reducing blood pressure</p></li>
<li><p>A psychologist compares reaction times across 5 different age groups with no control condition</p></li>
<li><p>An agricultural researcher compares crop yields for 8 different fertilizer treatments</p></li>
<li><p>A marketing team compares customer satisfaction across 3 store locations</p></li>
<li><p>An education researcher compares test scores for students using 6 different learning apps vs traditional instruction</p></li>
</ol>
</li>
<li><p><strong>Complete Analysis with Real Data</strong>: A nutrition study compares the effectiveness of 5 different diets on weight loss over 12 weeks. ANOVA yields F = 8.2 with p-value = 0.0003. The summary data is:</p>
<ul class="simple">
<li><p>Diet A (Control): <span class="math notranslate nohighlight">\(n_1 = 20\)</span>, <span class="math notranslate nohighlight">\(\bar{x}_1 = 8.2\)</span> lbs, <span class="math notranslate nohighlight">\(s_1 = 3.1\)</span></p></li>
<li><p>Diet B (Low-carb): <span class="math notranslate nohighlight">\(n_2 = 18\)</span>, <span class="math notranslate nohighlight">\(\bar{x}_2 = 12.7\)</span> lbs, <span class="math notranslate nohighlight">\(s_2 = 2.8\)</span></p></li>
<li><p>Diet C (Low-fat): <span class="math notranslate nohighlight">\(n_3 = 22\)</span>, <span class="math notranslate nohighlight">\(\bar{x}_3 = 6.1\)</span> lbs, <span class="math notranslate nohighlight">\(s_3 = 3.4\)</span></p></li>
<li><p>Diet D (Mediterranean): <span class="math notranslate nohighlight">\(n_4 = 19\)</span>, <span class="math notranslate nohighlight">\(\bar{x}_4 = 15.3\)</span> lbs, <span class="math notranslate nohighlight">\(s_4 = 3.0\)</span></p></li>
<li><p>Diet E (Intermittent fasting): <span class="math notranslate nohighlight">\(n_5 = 21\)</span>, <span class="math notranslate nohighlight">\(\bar{x}_5 = 10.8\)</span> lbs, <span class="math notranslate nohighlight">\(s_5 = 2.9\)</span></p></li>
</ul>
<p>MSE = 9.12, total <span class="math notranslate nohighlight">\(n = 100\)</span></p>
<ol class="loweralpha simple">
<li><p>What can you conclude from the ANOVA results?</p></li>
<li><p>Should you proceed with multiple comparisons? Which method is most appropriate?</p></li>
<li><p>Which pairs of diets would you expect to be significantly different based on the sample means?</p></li>
<li><p>Calculate the Tukey HSD critical value for this study</p></li>
<li><p>Calculate the 95% family-wise confidence interval for the difference between Diet D and Diet C</p></li>
<li><p>If the research question focused on comparing each diet to the control (Diet A), which method would be more appropriate and why?</p></li>
</ol>
</li>
<li><p><strong>Power and Sample Size Considerations</strong>:</p>
<ol class="loweralpha simple">
<li><p>Explain why Tukey’s HSD becomes more conservative as the number of groups increases</p></li>
<li><p>A researcher is planning a study with 4 groups and wants 80% power to detect a difference of 2 units between any pair of means, assuming <span class="math notranslate nohighlight">\(\sigma = 3\)</span>. How would the required sample size change if they planned to use Bonferroni correction instead of Tukey’s HSD?</p></li>
<li><p>Under what circumstances might a researcher choose to use individual t-tests without multiple comparison correction, and what would be the statistical and ethical implications?</p></li>
</ol>
</li>
<li><p><strong>Interpretation Challenge</strong>: Given this underline display for 5 groups:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>A ——— B ——— C          D ——— E
      |______________|
</pre></div>
</div>
<ol class="loweralpha simple">
<li><p>Which pairs of groups are significantly different?</p></li>
<li><p>Which pairs are not significantly different?</p></li>
<li><p>Is it possible for A and D to be significantly different while C and D are not? Explain the statistical reasoning.</p></li>
<li><p>What does this pattern suggest about the underlying population means?</p></li>
</ol>
</li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="12-3-f-test-and-relationship-to-t-test.html" class="btn btn-neutral float-left" title="12.3. One-Way ANOVA F-Test and Its Relationship to Two-Sample t-Tests" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../chapter13/index.html" class="btn btn-neutral float-right" title="13. Simple Linear Regression" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>