

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>6.4. Normal Distribution &mdash; STAT 350</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=2f168d12" />
      <link rel="stylesheet" type="text/css" href="../../_static/credits.css?v=f7efa099" />

  
    <link rel="canonical" href="https://treese41528.github.io/STAT350/Website/chapter6/lectures/6-4-normal-distribution.html" />
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=30646c52"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
      <script src="../../_static/custom.js?v=7e0058eb"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="6.5. Uniform Distribution" href="6-5-uniform-distribution.html" />
    <link rel="prev" title="6.3. Cumulative Distribution Functions" href="6-3-cdfs.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            STAT 350: Introduction to Statistics
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Orientation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-intro.html">Course Introduction &amp; Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#why-statistics-why-now">Why Statistics? Why Now?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#office-hours">Office Hours</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#course-roadmap">Course Roadmap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#a-clear-note-on-using-ai">A Clear Note on Using AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-intro.html#getting-started-a-checklist">Getting Started: A Checklist</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#homework-assignments-on-edfinity">Homework Assignments on Edfinity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../course-intro.html#miscellaneous-tips">Miscellaneous Tips</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exam Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../exams/exams_index.html">Course Examinations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exams/exams_index.html#general-exam-policies">General Exam Policies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam1.html">Exam 1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam1.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/exam2.html">Exam 2</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-locations-by-section">Exam Locations by Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#exam-coverage">Exam Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/exam2.html#preparation-materials">Preparation Materials</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../exams/exam_materials/final_exam.html">Final Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#about-the-final-exam">About the Final Exam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#required-review-materials">Required Review Materials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../exams/exam_materials/final_exam.html#study-guide-resource">Study Guide Resource</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Worksheets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../worksheets/worksheets_index.html">Course Worksheets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#pedagogical-philosophy">Pedagogical Philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#implementation-guidelines">Implementation Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#why-these-worksheets-matter">Why These Worksheets Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#the-critical-role-of-simulation">The Critical Role of Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../worksheets/worksheets_index.html#worksheets">Worksheets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html">Worksheet 1: Exploring Data with R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-1-loading-and-understanding-the-dataset">Part 1: Loading and Understanding the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-2-initial-data-exploration">Part 2: Initial Data Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-3-frequency-tables">Part 3: Frequency Tables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-4-univariate-analysis-of-uptake">Part 4: Univariate Analysis of Uptake</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-5-grouped-statistics-with-tapply">Part 5: Grouped Statistics with tapply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-6-comparative-visualization-by-type">Part 6: Comparative Visualization by Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-7-exploring-the-concentration-effect">Part 7: Exploring the Concentration Effect</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#part-8-advanced-visualization-with-multiple-categories">Part 8: Advanced Visualization with Multiple Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#reference-key-functions">Reference: Key Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#troubleshooting-guide">Troubleshooting Guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet1.html#additional-resources">Additional Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html">Worksheet 2: Set Theory and Probability Fundamentals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-1-set-theory-foundations">Part 1: Set Theory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-2-probability-axioms">Part 2: Probability Axioms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-3-applying-probability-rules">Part 3: Applying Probability Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#part-4-the-inclusion-exclusion-principle">Part 4: The Inclusion-Exclusion Principle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#key-takeaways">Key Takeaways</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet2.html#submission-guidelines">Submission Guidelines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html">Worksheet 3: Conditional Probability and Bayes’ Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-1-understanding-conditional-probability">Part 1: Understanding Conditional Probability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-2-tree-diagrams-and-sequential-sampling">Part 2: Tree Diagrams and Sequential Sampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#part-3-bayes-theorem-and-sequential-updating">Part 3: Bayes’ Theorem and Sequential Updating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet3.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html">Worksheet 4: Independence and Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-1-independence-property">Part 1: Independence Property</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-2-independent-vs-mutually-exclusive-events">Part 2: Independent vs. Mutually Exclusive Events</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-3-introduction-to-random-variables">Part 3: Introduction to Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-4-probability-mass-functions">Part 4: Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#part-5-joint-probability-mass-functions">Part 5: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet4.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html">Worksheet 5: Expected Value and Variance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-1-expected-value-and-lotus">Part 1: Expected Value and LOTUS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-2-variance-and-its-properties">Part 2: Variance and Its Properties</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-3-sums-of-random-variables">Part 3: Sums of Random Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#part-4-joint-probability-mass-functions">Part 4: Joint Probability Mass Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet5.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html">Worksheet 6: Named Discrete Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-1-the-bernoulli-and-binomial-distributions">Part 1: The Bernoulli and Binomial Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#the-binomial-distribution">The Binomial Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-2-the-poisson-distribution">Part 2: The Poisson Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#part-3-other-named-discrete-distributions">Part 3: Other Named Discrete Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet6.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html">Worksheet 7: Continuous Random Variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-1-probability-density-functions">Part 1: Probability Density Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-2-finding-constants-for-valid-pdfs">Part 2: Finding Constants for Valid PDFs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-3-expected-value-and-variance">Part 3: Expected Value and Variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#part-4-cumulative-distribution-functions">Part 4: Cumulative Distribution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet7.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html">Worksheet 8: Uniform and Exponential Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-1-the-uniform-distribution">Part 1: The Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#part-2-the-exponential-distribution">Part 2: The Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet8.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html">Worksheet 9: The Normal Distribution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-1-the-normal-distribution">Part 1: The Normal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-2-the-standard-normal-table">Part 2: The Standard Normal Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#part-3-z-score-transformation">Part 3: Z-Score Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet9.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html">Worksheet 10: Checking Normality and Introduction to Sampling Distributions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-1-checking-normality">Part 1: Checking Normality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#part-2-introduction-to-sampling-distributions">Part 2: Introduction to Sampling Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet10.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html">Worksheet 11: The Central Limit Theorem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#tutorial-generating-the-sampling-distribution-of-bar-x">Tutorial: Generating the Sampling Distribution of <span class="math notranslate nohighlight">\(\bar{X}\)</span></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-1-exploring-clt-with-skewed-distributions">Part 1: Exploring CLT with Skewed Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-2-application-of-the-clt">Part 2: Application of the CLT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-3-beyond-mean-and-sum">Part 3: Beyond Mean and Sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#part-4-exploring-clt-generalizability-with-ai-assistance-exploration">Part 4: Exploring CLT Generalizability with AI Assistance (Exploration)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet11.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html">Worksheet 12: Point Estimators and Unbiased Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-1-estimating-parameters-of-the-exponential-distribution">Part 1: Estimating Parameters of the Exponential Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-2-estimating-the-maximum-of-a-uniform-distribution">Part 2: Estimating the Maximum of a Uniform Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#part-3-minimum-variance-unbiased-estimators-mvue">Part 3: Minimum Variance Unbiased Estimators (MVUE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet12.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html">Worksheet 13: Introduction to Confidence Intervals</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-1-pivotal-quantities-and-deriving-confidence-intervals">Part 1: Pivotal Quantities and Deriving Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-2-sample-size-determination">Part 2: Sample Size Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-3-one-sided-confidence-bounds">Part 3: One-Sided Confidence Bounds</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#part-4-confidence-intervals-when-is-unknown">Part 4: Confidence Intervals When σ is Unknown</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet13.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html">Worksheet 14: Student’s t-Distribution and Statistical Power</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#assumptions-for-t-distribution-inference">Assumptions for t-Distribution Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-1-analyzing-chick-growth-with-confidence-intervals">Part 1: Analyzing Chick Growth with Confidence Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-2-introduction-to-hypothesis-testing">Part 2: Introduction to Hypothesis Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#part-3-sample-size-determination-and-power-analysis">Part 3: Sample Size Determination and Power Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet14.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html">Worksheet 15: Hypothesis Testing for a Single Mean</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-hypothesis-testing-framework">The Hypothesis Testing Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-test-statistic-known">The Test Statistic (Known σ)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#distribution-of-the-test-statistic">Distribution of the Test Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-p-value">The p-value</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1a-simulation-when-null-hypothesis-is-true">Question 1a: Simulation When Null Hypothesis is True</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1b-simulation-when-null-hypothesis-is-false">Question 1b: Simulation When Null Hypothesis is False</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-1c-comparing-the-two-scenarios">Question 1c: Comparing the Two Scenarios</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#the-t-test-statistic">The t-Test Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#properties-of-the-t-distribution">Properties of the t-Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2a-assumptions-and-exploratory-analysis">Question 2a: Assumptions and Exploratory Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2b-full-hypothesis-testing-procedure">Question 2b: Full Hypothesis Testing Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2c-manual-verification">Question 2c: Manual Verification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2d-confidence-bound">Question 2d: Confidence Bound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet15.html#question-2e-power-calculation">Question 2e: Power Calculation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html">Worksheet 16: Two-Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-1-independent-vs-paired-designs">Part 1: Independent vs. Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-2-independent-samples-with-known-variances">Part 2: Independent Samples with Known Variances</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-3-pooled-two-sample-t-test-equal-variances">Part 3: Pooled Two-Sample t-Test (Equal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#part-4-welch-s-two-sample-t-test-unequal-variances">Part 4: Welch’s Two-Sample t-Test (Unequal Variances)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet16.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html">Worksheet 17: Paired Sample Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-1-theory-and-procedure-for-paired-samples">Part 1: Theory and Procedure for Paired Samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-2-sleep-study-analysis">Part 2: Sleep Study Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#part-3-sample-size-calculation-for-paired-designs">Part 3: Sample Size Calculation for Paired Designs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet17.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html">Worksheet 18: One-Way ANOVA (Analysis of Variance)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#why-use-one-way-anova">Why Use One-Way ANOVA?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#one-way-anova-assumptions">One-Way ANOVA Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#one-way-anova-f-test-statistic-and-sources-of-variation">One-Way ANOVA F-test Statistic and Sources of Variation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#notation-and-setup">Notation and Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-1-computing-the-overall-sample-mean">Part 1: Computing the Overall Sample Mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-2-checking-the-equal-variance-assumption">Part 2: Checking the Equal Variance Assumption</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-3-pooled-variance-estimator">Part 3: Pooled Variance Estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-4-within-group-variability-sum-of-squares-within-sse">Part 4: Within-Group Variability (Sum of Squares Within, SSE)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-5-between-group-variability-sum-of-squares-among-ssa">Part 5: Between-Group Variability (Sum of Squares Among, SSA)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-6-total-variability-and-partitioning">Part 6: Total Variability and Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-7-degrees-of-freedom">Part 7: Degrees of Freedom</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-8-mean-squares">Part 8: Mean Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-9-the-f-test-statistic">Part 9: The F-Test Statistic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-10-computing-the-p-value-and-making-a-decision">Part 10: Computing the P-Value and Making a Decision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-11-completing-the-anova-table">Part 11: Completing the ANOVA Table</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#part-12-limitations-and-follow-up-questions">Part 12: Limitations and Follow-Up Questions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet18.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html">Worksheet 19: Multiple Comparisons and Post-Hoc Testing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#the-multiple-comparisons-problem">The Multiple Comparisons Problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#methods-to-control-the-family-wise-error-rate">Methods to Control the Family-Wise Error Rate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-1-simulation-study-type-i-error-with-multiple-comparison-methods">Part 1: Simulation Study - Type I Error with Multiple Comparison Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-2-applying-tukey-s-hsd-to-worksheet-18-data">Part 2: Applying Tukey’s HSD to Worksheet 18 Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#part-3-comprehensive-anova-analysis-toothgrowth-dataset">Part 3: Comprehensive ANOVA Analysis - ToothGrowth Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet19.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html">Worksheet 20: Introduction to Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#from-anova-to-regression-same-core-ideas-new-application">From ANOVA to Regression: Same Core Ideas, New Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#the-simple-linear-regression-model">The Simple Linear Regression Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#least-squares">Least Squares</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-1-deriving-least-squares-estimators">Part 1: Deriving Least Squares Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-2-the-general-simple-linear-regression-estimators">Part 2: The General Simple Linear Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-3-sampling-distributions-of-regression-estimators">Part 3: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#part-4-practice-problems">Part 4: Practice Problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet20.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html">Worksheet 21: Inference for Simple Linear Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-1-sampling-distributions-of-regression-estimators">Part 1: Sampling Distributions of Regression Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-2-checking-regression-assumptions">Part 2: Checking Regression Assumptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-3-bird-data-analysis">Part 3: Bird Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#part-4-regression-anova">Part 4: Regression ANOVA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet21.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html">Worksheet 22: Model Assessment and Prediction in Regression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-1-the-coefficient-of-determination">Part 1: The Coefficient of Determination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-2-confidence-intervals-vs-prediction-intervals">Part 2: Confidence Intervals vs. Prediction Intervals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-3-simulation-study-ci-vs-pi-coverage">Part 3: Simulation Study — CI vs. PI Coverage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-4-prediction-with-the-bird-data">Part 4: Prediction with the Bird Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#part-5-diamonds-data-analysis">Part 5: Diamonds Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../worksheets/worksheet_materials/worksheet22.html#key-takeaways">Key Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Computer Assignments</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../R_computerAssignments/r_computer_assignments.html">R / RStudio Guide and Function Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html">Getting Started with R and RStudio</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#quick-start-r-rstudio-setup">Quick Start: R / RStudio Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#rstudio-orientation">RStudio Orientation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#packages-libraries-course-set">Packages / Libraries (Course Set)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#getting-started-with-swirl">Getting Started with swirl</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../R_computerAssignments/r_getting_started.html#setup-and-use-swirl">Setup and Use swirl</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html">Course Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#primary-course-dataset-apprating">Primary Course Dataset - AppRating</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#tutorial-support-datasets">Tutorial Support Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#loading-datasets-in-r">Loading Datasets in R</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#built-in-r-datasets-used-in-course">Built-in R Datasets Used in Course</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_datasets.html#data-download-and-organization">Data Download and Organization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html">Computer Assignments and Tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-structure">Assignment Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#assignment-tutorials-links">Assignment Tutorials (Links)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#course-pipeline-at-a-glance">Course Pipeline (At a Glance)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_tutorials_assignments.html#more-help-and-reference-pages">More Help and Reference Pages</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html">Best Practices &amp; Common Pitfalls</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#data-import-validation">Data Import &amp; Validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#statistical-assumptions">Statistical Assumptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#common-errors-to-avoid">Common Errors to Avoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_best_practices.html#workflow-template">Workflow Template</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html">Graphics (ggplot2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#core-components">Core Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#geoms-geometric-objects">Geoms (Geometric Objects)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#categorical-data-visualization">Categorical Data Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#plot-customization">Plot Customization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_ggplot2_guide.html#tables-reporting">Tables &amp; Reporting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html">Function Reference Part 1</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-i-o-housekeeping">Data I/O &amp; Housekeeping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-structures-creation">Data Structures &amp; Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#data-wrangling-utilities">Data Wrangling &amp; Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#descriptive-statistics-correlation">Descriptive Statistics &amp; Correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#probability-distributions">Probability &amp; Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part1.html#simulation-functions">Simulation Functions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html">Function Reference Part 2: Inference Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_function_reference_part2.html#diagnostic-plots-for-assumptions">Diagnostic Plots for Assumptions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html">Alternative Resources (Tutorials)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#general-r-data-science">General R &amp; Data Science</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#ggplot2-visualization">ggplot2 Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#tidyverse">Tidyverse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#video-content">Video Content</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#quick-reference">Quick Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../R_computerAssignments/r_alternative_resources.html#base-r">Base R</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../chapter1/index.html">1. Introduction to Statistics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-1-intro.html">1.1. What Is Statistics?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter1/lectures/1-2-probability-inference.html">1.2. Probability &amp; Statistical Inference: How Are They Associated?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter2/index.html">2. Graphical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-1-understanding-the-structure-of-data-set.html">2.1. Data Set Structure and Variable Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-2-tools-for-categorical-qualitative-data.html">2.2. Tools for Categorical (Qualitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-3-tools-for-numerical-quantitative-data.html">2.3. Tools for Numerical (Quantitative) Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter2/lectures/2-4-exploring-quantitative-distributions-modality-shape-and-outliers.html">2.4. Exploring Quantitative Distributions: Modality, Skewness &amp; Outliers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter3/index.html">3. Numerical Summaries</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-1-intro-numerical-summaries.html">3.1. Introduction to Numerical Summaries: Notation and Terminology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-2-measures-of-central-tendency.html">3.2. Measures of Central Tendency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-3-measures-of-variability-range-variance-and-SD.html">3.3. Measures of Variability - Range, Variance, and Standard Deviation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-4-measures-of-variability-IQR-and-5-number-summary.html">3.4. Measures of Variability - Interquartile Range and Five-Number Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter3/lectures/3-5-choosing-the-right-measure-resistance-to-extreme-values.html">3.5. Choosing the Right Measure &amp; Comparing Measures Across Data Sets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter4/index.html">4. Probability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-1-basic-set-theory.html">4.1. Basic Set Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-2-probability.html">4.2. Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-3-conditional-probability.html">4.3. Conditional Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-4-law-of-total-probability-and-bayes-rule.html">4.4. Law of Total Probability and Bayes’ Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-5-bayes-update-rule-example.html">4.5. Sequential Bayesian Updating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter4/lectures/4-6-independence-of-events.html">4.6. Independence of Events</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter5/index.html">5. Discrete Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-1-discrete-rvs-and-pmfs.html">5.1. Discrete Random Variables and Probability Mass Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-2-joint-pmfs.html">5.2. Joint Probability Mass Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-3-expected-value-of-discrete-rv.html">5.3. Expected Value of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-4-variance-of-discrete-rv.html">5.4. Varianace of a Discrete Random Variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-5-covariance-of-dependent-rvs.html">5.5. Covariance of Dependent Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-6-binomial-distribution.html">5.6. The Binomial Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter5/lectures/5-7-poisson-distribution.html">5.7. The Poisson Distribution</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">6. Continuous Distributions</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="6-1-continuous-rvs-and-pdfs.html">6.1. Continuous Random Variables and Probability Density Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="6-2-expected-value-and-variance-of-cts-rvs.html">6.2. Expected Value and Variance of Continuous Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="6-3-cdfs.html">6.3. Cumulative Distribution Functions</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">6.4. Normal Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="6-5-uniform-distribution.html">6.5. Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="6-6-exponential-distribution.html">6.6. Exponential Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter7/index.html">7. Sampling Distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-1-statistics-and-sampling-distributions.html">7.1. Statistics and Sampling Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-2-sampling-distribution-for-the-sample-mean.html">7.2. Sampling Distribution for the Sample Mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-3-clt.html">7.3. The Central Limit Theorem (CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter7/lectures/7-4-discret-rvs-and-clt.html">7.4. Understanding Binomial and Poisson Distributions through CLT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter8/index.html">8. Experimental Design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-1-experimental-and-sampling-designs.html">8.1. Experimental and Sampling Designs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-2-experimental-design-principles.html">8.2. Experimental Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-3-basic-types-of-experimental-design.html">8.3. Basic Types of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-4-addressing-potential-flaws-in-experimental-design.html">8.4. Addressing Potential Flaws in Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-5-examples-of-experimental-design.html">8.5. Examples of Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-6-sampling-design.html">8.6. Sampling Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter8/lectures/8-7-sampling-bias.html">8.7. Sampling Bias</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter9/index.html">9. Confidence Intervals and Bounds</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-1-intro-statistical-inference.html">9.1. Introduction to Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-2-ci-sigma-known.html">9.2. Confidence Intervals for the Population Mean, When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-3-precision-of-ci-and-sample-size-calculation.html">9.3. Precision of a Confidence Interval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-4-cb-sigma-known.html">9.4. Confidence Bounds for the Poulation Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter9/lectures/9-5-ci-cb-sigma-unknown.html">9.5. Confidence Intervals and Bounds When σ is Unknown</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter10/index.html">10. Hypothesis Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-1-ht-errors-and-power.html">10.1. The Foundation of Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-2-ht-for-mean-sigma-known.html">10.2. Hypothesis Test for the Population Mean When σ is Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-3-ht-for-mean-sigma-unknown.html">10.3. Connecting CI and HT; <em>t</em>-Test for μ When σ Is Unknown</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter10/lectures/10-4-pvalue-significance-conclusion.html">10.4. The Four Steps to Hypothesis Testing and Understanding the Result</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter11/index.html">11. Two Sample Procedures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-1-ci-ht-two-samples.html">11.1. Statistical Inference for Two Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-2-comparing-two-means-independent-sigmas-known.html">11.2. Independent Two-Sample Analysis When Population Variances Are Known</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-3-comparing-two-means-independent-pooled.html">11.3. Independent Two-Sample Analysis - Pooled Variance Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-4-comparing-two-means-independent-unpooled.html">11.4. Independent Two-Sample Analysis - No Equal Variance Assumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter11/lectures/11-5-mean-of-paired-differences-two-dependent-populations.html">11.5. Paired Two-Sample Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter12/index.html">12. ANOVA</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-1-intro-one-way-anova.html">12.1. Introduction to One-Way ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-2-sources-of-variability.html">12.2. Different Sources of Variability in ANOVA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-3-f-test-and-relationship-to-t-test.html">12.3. ANOVA F-Test and Its Relationship to Two-Sample <em>t</em>-Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter12/lectures/12-4-multiple-comparison-procedures-family-wise-error-rates.html">12.4. Multiple Comparison Procedures</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../chapter13/index.html">13. Simple Linear Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-1-intro-to-lr-correlation-scatter-plots.html">13.1. Introduction to Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-2-simple-linear-regression.html">13.2. Simple Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-3-diagnostics-inference.html">13.3. Model Diagnostics and Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chapter13/lectures/13-4-prediction-robustness.html">13.4. Prediction and Robustness</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">STAT 350: Introduction to Statistics</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><span class="section-number">6. </span>Continuous Distributions</a></li>
      <li class="breadcrumb-item active"><span class="section-number">6.4. </span>Normal Distribution</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/chapter6/lectures/6-4-normal-distribution.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="video-placeholder" role="group" aria-labelledby="video-ch6-4">
  <iframe
    id="video-ch6-4"
    title="STAT 350 – Chapter 6.4 Normal Distribution Video"
    src="https://www.youtube.com/embed/O3wz4JgtZsA?si=Qc7lm4xqwW_iUfey"
   allowfullscreen>
  </iframe>
</div><div class="tip admonition">
<p class="admonition-title">Slides 📊</p>
<p><a class="reference external" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/slides/Chapter%206%20Continuous%20Distributions/L12-14--ContinuousRandomVariablesProbabilityDensityCurves%28Chapter%206%29_AC.pptx">Download Chapter 6 slides (PPTX)</a></p>
</div>
<section id="id1">
<h1><span class="section-number">6.4. </span>Normal Distribution<a class="headerlink" href="#id1" title="Link to this heading"></a></h1>
<p>We now encounter the most important continuous distribution in all of statistics:
the normal distribution.</p>
<div class="important admonition">
<p class="admonition-title">Road Map 🧭</p>
<ul class="simple">
<li><p>Understand the <strong>historical development</strong> and significance of the normal distribution.</p></li>
<li><p>Master the <strong>mathematical definition</strong> and properties of the normal PDF.</p></li>
<li><p>Explore how the <strong>parameters</strong> <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> control location and shape.</p></li>
<li><p>Learn the famous <strong>empirical rule</strong> for quick probability estimates.</p></li>
<li><p>Understand why <strong>standardization</strong> is essential for normal computations.</p></li>
</ul>
</div>
<section id="the-historical-legacy-from-gauss-to-modern-statistics">
<h2><span class="section-number">6.4.1. </span>The Historical Legacy: From Gauss to Modern Statistics<a class="headerlink" href="#the-historical-legacy-from-gauss-to-modern-statistics" title="Link to this heading"></a></h2>
<p>The normal distribution carries a rich mathematical heritage spanning over two centuries.
While often called the “Gaussian distribution” in honor of Carl Friedrich Gauss (1777-1855),
the distribution’s development involved several brilliant mathematicians who recognized
patterns in natural variation.</p>
<section id="gauss-and-the-method-of-least-squares">
<h3>Gauss and the Method of Least Squares<a class="headerlink" href="#gauss-and-the-method-of-least-squares" title="Link to this heading"></a></h3>
<figure class="align-right" id="id3" style="width: 30%">
<img alt="Carl Friedrich Gauss" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/Gauss.jpg" />
<figcaption>
<p><span class="caption-number">Fig. 6.25 </span><span class="caption-text">Carl Friedrich Gauss (1777-1855)</span><a class="headerlink" href="#id3" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>In the late 1700s and early 1800s, Gauss was working on astronomical calculations and
geodetic surveys—problems requiring precise measurements where small errors were
inevitable. He sought to understand how these measurement errors behaved and how
to optimally combine multiple measurements of the same quantity.</p>
<p>Gauss discovered that measurement errors followed a specific pattern: most errors
were small and clustered around zero, with larger errors becoming increasingly rare.
More importantly, he found that this error distribution had a particular exponential
form with quadratic decay that optimized his least squares fitting procedure.</p>
</section>
<section id="the-connection-to-binomial-distributions">
<h3>The Connection to Binomial Distributions<a class="headerlink" href="#the-connection-to-binomial-distributions" title="Link to this heading"></a></h3>
<p>Gauss recognized that his continuous error distribution emerged as a limiting case
of discrete binomial distributions. When the number of trials becomes very large
while the probability of success becomes very small (in a specific balanced way),
the jagged, discrete binomial distribution smooths into the graceful bell curve we
now call the normal distribution.</p>
<p>This connection between discrete counting processes and continuous measurement errors
revealed a profound unity in probability theory—the same mathematical structure appears
whether we’re flipping coins or measuring stellar positions.</p>
</section>
<section id="a-universal-pattern-in-nature">
<h3>A Universal Pattern in Nature<a class="headerlink" href="#a-universal-pattern-in-nature" title="Link to this heading"></a></h3>
<p>What makes the normal distribution truly remarkable is its ubiquity.
It describes not just measurement errors, but heights and weights of organisms,
intelligence test scores, particle velocities in gases, and countless other
natural phenomena. This universality isn’t coincidental—it emerges from a deep
mathematical principle we’ll encounter later called the Central Limit Theorem.</p>
</section>
</section>
<section id="the-mathematical-definition-anatomy-of-the-bell-curve">
<h2><span class="section-number">6.4.2. </span>The Mathematical Definition: Anatomy of the Bell Curve<a class="headerlink" href="#the-mathematical-definition-anatomy-of-the-bell-curve" title="Link to this heading"></a></h2>
<section id="notation-and-parameters">
<h3>Notation and Parameters<a class="headerlink" href="#notation-and-parameters" title="Link to this heading"></a></h3>
<p>If a random variable <span class="math notranslate nohighlight">\(X\)</span> has a normal distribution, we write:</p>
<div class="math notranslate nohighlight">
\[X \sim N(\mu, \sigma^2) \quad \text{or} \quad X \sim N(\mu, \sigma).\]</div>
<p>A normal random variable takes two parameters:</p>
<table class="docutils align-center" style="width: 100%">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Mean <span class="math notranslate nohighlight">\(\mu\)</span></p></th>
<th class="head"><p>Standard Deviation <span class="math notranslate nohighlight">\(\sigma\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Possible values</strong></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu \in (-\infty, +\infty)\)</span>. It can be any real number.</p></td>
<td><p><span class="math notranslate nohighlight">\(\sigma &gt;0\)</span>. It must be a postive value.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Interpretation</strong></p></td>
<td><p>The <em>location parameter</em>. It represents the center of the distribution of <span class="math notranslate nohighlight">\(X\)</span>.</p></td>
<td><p>The <em>scale parameter</em>. It represents how spread out the distribution of <span class="math notranslate nohighlight">\(X\)</span> is.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Effect on the appearance of the PDF</strong></p></td>
<td><p>Slides the curve left or right, without changing the shape</p></td>
<td><p>Makes the graph tall and narrow (small <span class="math notranslate nohighlight">\(\sigma\)</span>) or wide and flat (large <span class="math notranslate nohighlight">\(\sigma\)</span>). It does not change the
location of the center.</p></td>
</tr>
</tbody>
</table>
<div class="important admonition">
<p class="admonition-title">Variance or Standard Deviation?</p>
<p>It is standard to describe a normal distribution using either variance or
standard deviation, but <strong>we must be explicit about which we’re using</strong>.</p>
<p>The constraints and interpretations of standard deviation transfer almost directly
to variance. Variance must be a positive number, and it controls how wide
the distribution is. The only difference is their scale—variance is in the squared scale,
while standard deviation is on the same scale as <span class="math notranslate nohighlight">\(X\)</span>.</p>
</div>
<figure class="align-center" id="id4" style="width: 60%">
<img alt="Normal pdfs for different sets of parameters mu and sigma" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/normal-pdfs.png" />
<figcaption>
<p><span class="caption-number">Fig. 6.26 </span><span class="caption-text">How different values of μ and σ affect the normal distribution’s appearance</span><a class="headerlink" href="#id4" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="the-normal-pdf">
<h3>The Normal PDF<a class="headerlink" href="#the-normal-pdf" title="Link to this heading"></a></h3>
<p>The PDF of a normal random variable <span class="math notranslate nohighlight">\(X\)</span> takes the form:</p>
<div class="math notranslate nohighlight">
\[f_X(x) = \frac{1}{\sqrt{2\pi \sigma}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2} \quad \text{for all } x \in \mathbb{R}\]</div>
<p>This elegant formula contains several key components:</p>
<ul class="simple">
<li><p>The <strong>normalizing constant</strong> <span class="math notranslate nohighlight">\(\frac{1}{\sqrt{2\pi \sigma}}\)</span> ensures the total
area under the curve equals 1.</p></li>
<li><p>The <strong>exponential function</strong> <span class="math notranslate nohighlight">\(e^{-(\cdot)}\)</span> creates the smooth, continuous decay.</p></li>
<li><p>The <strong>quadratic expression</strong> <span class="math notranslate nohighlight">\(\left(\frac{x-\mu}{\sigma}\right)^2\)</span> in the exponent
produces the symmetric, bell-shaped curve.</p></li>
<li><p>The <strong>parameters</strong> <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> control the distribution’s location and spread.</p></li>
</ul>
</section>
<section id="fundamental-properties">
<h3>Fundamental Properties<a class="headerlink" href="#fundamental-properties" title="Link to this heading"></a></h3>
<p>Regardless of its parameters, every normal distribution satisfies the following properties:</p>
<ol class="arabic">
<li><p>It is <strong>symmetrical</strong> about the mean <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p>It is <strong>unimodal</strong> with a single peak at <span class="math notranslate nohighlight">\(x = \mu\)</span>.</p></li>
<li><p>Since the distribution is perfectly symmetric, the <strong>mean equals the median</strong>:
<span class="math notranslate nohighlight">\(\mu = \tilde{\mu}\)</span>.</p></li>
<li><p>It is <strong>bell-shaped</strong> with smooth, continuous curves.</p></li>
<li><p>The two tails <strong>approach but never reach zero</strong> as <span class="math notranslate nohighlight">\(x \to \pm\infty\)</span>.
This implies that <span class="math notranslate nohighlight">\(\text{supp}(X) = (-\infty, +\infty)\)</span>.</p></li>
<li><p>The points where the normal curve changes from concave down to concave up (its <strong>inflection points</strong>) occur exactly at
<span class="math notranslate nohighlight">\(x = \mu - \sigma\)</span> and <span class="math notranslate nohighlight">\(x = \mu + \sigma\)</span>.</p>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/inflection-points.png"><img alt="Normal distribution showing inflection points at μ ± σ" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/inflection-points.png" style="width: 70%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.27 </span><span class="caption-text">The normal curve changes concavity at exactly one standard deviation from the mean</span><a class="headerlink" href="#id5" title="Link to this image"></a></p>
</figcaption>
</figure>
</li>
</ol>
</section>
</section>
<section id="the-empirical-rule-a-practical-tool">
<h2><span class="section-number">6.4.3. </span>The Empirical Rule: A Practical Tool<a class="headerlink" href="#the-empirical-rule-a-practical-tool" title="Link to this heading"></a></h2>
<p>One of the most useful properties of normal distributions is that they all follow the same probability
pattern, regardless of their specific parameter values. This universal pattern is called the
<strong>empirical rule</strong> or <strong>68-95-99.7 rule</strong>.</p>
<p>For any normal random variable <span class="math notranslate nohighlight">\(X \sim N(\mu, \sigma)\)</span>,</p>
<ol class="arabic simple">
<li><p><strong>68% of the probability</strong> lies within one standard deviation from the mean:
<span class="math notranslate nohighlight">\(P(\mu - \sigma &lt; X &lt; \mu + \sigma) \approx 0.68\)</span></p></li>
<li><p><strong>95% of the probability</strong> lies within two standard deviations:
<span class="math notranslate nohighlight">\(P(\mu - 2\sigma &lt; X &lt; \mu + 2\sigma) \approx 0.95\)</span></p></li>
<li><p><strong>99.7% of the probability</strong> lies within three standard deviations:
<span class="math notranslate nohighlight">\(P(\mu - 3\sigma &lt; X &lt; \mu + 3\sigma) \approx 0.997\)</span></p></li>
</ol>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/empirical-rule-labeled.png"><img alt="Empirical rule showing 68-95-99.7 percentages" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/empirical-rule-labeled.png" style="width: 80%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.28 </span><span class="caption-text">The empirical rule provides quick probability estimates for any normal distribution</span><a class="headerlink" href="#id6" title="Link to this image"></a></p>
</figcaption>
</figure>
<section id="extended-breakdown-of-the-empirical-rule">
<h3>Extended Breakdown of the Empirical Rule<a class="headerlink" href="#extended-breakdown-of-the-empirical-rule" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>34%</strong> of probability lies in each of <span class="math notranslate nohighlight">\((\mu, \mu + \sigma)\)</span>
and <span class="math notranslate nohighlight">\((\mu - \sigma, \mu)\)</span></p>
<ul class="simple">
<li><p>Each interval is half of 68%.</p></li>
</ul>
</li>
<li><p><strong>13.5%</strong> of probability lies in each of <span class="math notranslate nohighlight">\((\mu + \sigma, \mu + 2\sigma)\)</span>
and <span class="math notranslate nohighlight">\((\mu - 2\sigma, \mu - \sigma)\)</span></p>
<ul class="simple">
<li><p>Each interval is half of 95%, minus an interval from #1.</p></li>
</ul>
</li>
<li><p><strong>2.35%</strong> of probability lies in each of <span class="math notranslate nohighlight">\((\mu + 2\sigma, \mu + 3\sigma)\)</span>
and <span class="math notranslate nohighlight">\((\mu - 3\sigma, \mu - 2\sigma)\)</span>.</p>
<ul class="simple">
<li><p>Each interval is half of 99.7%, minus an interval from #2 and an interval from #1.</p></li>
</ul>
</li>
<li><p><strong>0.15%</strong> of probability lies beyond <span class="math notranslate nohighlight">\(\mu + 3\sigma\)</span> and
another <strong>0.15%</strong> beyond <span class="math notranslate nohighlight">\(\mu - 3\sigma\)</span>.</p>
<ul class="simple">
<li><p>Each region is half of 100% - 99.7%.</p></li>
</ul>
</li>
</ol>
</section>
<section id="insights-from-the-empirical-rule">
<h3>Insights from the Empirical Rule<a class="headerlink" href="#insights-from-the-empirical-rule" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>About <strong>2/3</strong> of values fall within one standard deviation of the mean.</p></li>
<li><p>About <strong>19 out of 20</strong> values fall within two standard deviations.</p></li>
<li><p><strong>Nearly all values</strong> (99.7%) fall within three standard deviations.</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title">Example💡: Computing Normal Probabilities Using Empirical Rules</p>
<p>A chemical lab reports that the amount of active ingredient in a single tablet of
a medication is normally distributed with a mean of 500 mg and a standard deviation of 5 mg.</p>
<p>Q1. What is the probability that a tablet contains between 490 mg and 505 mg of active ingredient?</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(490 = \mu - 2\sigma \text{ and } 505 = \mu + \sigma\)</span>. Therefore, we are looking for</p>
<div class="math notranslate nohighlight">
\[P(\mu -2\sigma \leq X \leq \mu + \sigma)\]</div>
<p>There are many different ways to solve this using the empirical rule. One way is to view
the probability as</p>
<div class="math notranslate nohighlight">
\[P(\mu -2\sigma \leq X \leq \mu + 2\sigma) - P(\mu+\sigma \leq X \leq \mu +2\sigma)\]</div>
<p>The first term is approximately 0.95 by the empirical rule,
and the second term is approximately 0.135. Then finally,</p>
<div class="math notranslate nohighlight">
\[P(\mu -2\sigma \leq X \leq \mu + \sigma) \approx 0.95 - 0.135 = 0.815\]</div>
</div></blockquote>
</div>
</section>
</section>
<section id="the-standard-normal-distribution-the-foundation-of-all-normal-computations">
<h2><span class="section-number">6.4.4. </span>The Standard Normal Distribution: The Foundation of All Normal Computations<a class="headerlink" href="#the-standard-normal-distribution-the-foundation-of-all-normal-computations" title="Link to this heading"></a></h2>
<p>While normal distributions can have any mean and standard deviation, there’s one particular
normal distribution that serves as the foundation for all normal probability calculations.</p>
<section id="definition-of-the-standard-normal-distribution">
<h3>Definition of the Standard Normal Distribution<a class="headerlink" href="#definition-of-the-standard-normal-distribution" title="Link to this heading"></a></h3>
<p>The <strong>standard normal distribution</strong> is the normal distribution with mean 0 and standard deviation 1.
When a random variable follows the standard normal distribution, we denote it with <span class="math notranslate nohighlight">\(Z\)</span> and write:</p>
<div class="math notranslate nohighlight">
\[Z \sim N(0, 1)\]</div>
<p>Its PDF is obtained by plugging in 0 and 1 for <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, respectively, in the
general form:</p>
<div class="math notranslate nohighlight">
\[f_Z(z) = \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}} \quad \text{for all } z \in \mathbb{R}\]</div>
<p>Because the standard normal is so important, it also gets <strong>special notations</strong> for its PDF and CDF:</p>
<ul class="simple">
<li><p><strong>PDF</strong>: <span class="math notranslate nohighlight">\(\phi(z) = f_Z(z)\)</span> (lowercase Greek letter <em>phi</em>)</p></li>
<li><p><strong>CDF</strong>: <span class="math notranslate nohighlight">\(\Phi(z) = P(Z \leq z)\)</span> (uppercase Greek letter <em>phi</em>)</p></li>
</ul>
</section>
<section id="standardization-of-normal-random-variables">
<h3>Standardization of Normal Random Variables<a class="headerlink" href="#standardization-of-normal-random-variables" title="Link to this heading"></a></h3>
<p>Any normal random variable can be converted to a standard normal random variable
using the <strong>standardization formula</strong>:</p>
<div class="math notranslate nohighlight">
\[Z = \frac{X - \mu}{\sigma}.\]</div>
<p>If <span class="math notranslate nohighlight">\(X \sim N(\mu, \sigma)\)</span>, then <span class="math notranslate nohighlight">\(Z \sim N(0, 1)\)</span>.</p>
<section id="why-standardization-works">
<h4>Why Standardization Works<a class="headerlink" href="#why-standardization-works" title="Link to this heading"></a></h4>
<blockquote>
<div><ol class="arabic simple">
<li><p>Standardization <strong>re-centers</strong> the distribution at 0 by subtracting the mean from <span class="math notranslate nohighlight">\(X\)</span> .</p></li>
<li><p>It <strong>rescales</strong> the distribution to have unit variance by dividing <span class="math notranslate nohighlight">\(X\)</span> by its own standard deviation.</p></li>
</ol>
<p>For a more concrete demonstration, we first need to know a special property of normal distribution:</p>
<ul class="simple">
<li><p>When a normal random variable is <strong>multiplied or added by a constant, the resulting random variable
will still be normal</strong>, just with a new set of mean and variance parameters.</p></li>
</ul>
<p>Since <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> are constants, the operation on <span class="math notranslate nohighlight">\(X\)</span> to get to <span class="math notranslate nohighlight">\(Z\)</span> leaves us
with another normal random variable. Also,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E[Z] = E\left[\frac{X-\mu}{\sigma}\right]= \frac{E[X]-\mu}{\sigma} = \frac{\mu - \mu}{\sigma}=0\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma^2[Z] = \text{Var}(Z) = \text{Var}\left(\frac{X-\mu}{\sigma}\right) = \frac{\text{Var}(X)}{\sigma^2}= \frac{\sigma^2}{\sigma^2} =1\)</span>.</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="why-do-we-standardize">
<h3>Why Do We Standardize?<a class="headerlink" href="#why-do-we-standardize" title="Link to this heading"></a></h3>
<p>The fundamental problem with normal distributions is that their CDFs cannot be expressed in terms of
elementary functions. There’s no simple formula for:</p>
<div class="math notranslate nohighlight">
\[P(X\leq x) = \int_{-\infty}^{x} \frac{1}{\sqrt{2\pi \sigma}} e^{-\frac{1}{2}\left(\frac{t-\mu}{\sigma}\right)^2} dt\]</div>
<p>However, we can <strong>numerically approximate these integrals for the standard normal distribution</strong> and tabulate the results.
Instead of creating tables of approximations for all possible pairs of parameters—which would be impossible—we standardize,
so that we can refer to one table for any normal random variables.</p>
</section>
</section>
<section id="forward-problems-x-to-probability">
<h2><span class="section-number">6.4.5. </span>Forward Problems: <span class="math notranslate nohighlight">\(x\)</span> to Probability<a class="headerlink" href="#forward-problems-x-to-probability" title="Link to this heading"></a></h2>
<div class="video-placeholder" role="group" aria-labelledby="video-ch6-4-1">
  <iframe
    id="video-ch6-4-1"
    title="STAT 350 – Chapter 6.4.1 Normal Distribution Forward Calculations Video"
    src="https://www.youtube.com/embed/IGnLAeROI44?si=LvBNyDUXV3hoPd8w"
    allowfullscreen>
  </iframe>
</div><p>Now that we understand the theoretical foundation, let’s learn how to actually compute probabilities
for normal distributions. Since we cannot integrate the normal PDF analytically, we rely on numerical
approximations tabulated in standard normal tables.</p>
<section id="the-standard-normal-table-z-table">
<h3>The Standard Normal Table (Z-Table)<a class="headerlink" href="#the-standard-normal-table-z-table" title="Link to this heading"></a></h3>
<p>Statisticians have computed high-precision numerical approximations for the standard normal CDF
<span class="math notranslate nohighlight">\(\Phi(z) = P(Z \leq z)\)</span> and compiled them into tables. These tables typically provide probabilities
accurate to four decimal places for z-values given to two decimal places.</p>
<p>For example, if we want to find <span class="math notranslate nohighlight">\(P(Z \leq -1.38)\)</span>, first locate <span class="math notranslate nohighlight">\(-1.3\)</span> from the row
labels. Then find the column with the label <span class="math notranslate nohighlight">\(0.08\)</span>. The intersection
of the row and the column gives the desired probability. <span class="math notranslate nohighlight">\(P(Z \leq -1.38)=0.0838\)</span>.</p>
<figure class="align-center">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/z-table-neg-z.png"><img alt="Half of the Z-table for negative z values" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/z-table-neg-z.png" style="width: 90%;" />
</a>
</figure>
<figure class="align-center">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/z-table-pos-z.png"><img alt="The other half of the Z-table for positive z- values" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/z-table-pos-z.png" style="width: 90%;" />
</a>
</figure>
</section>
<section id="the-strategy-for-non-standard-normal-rvs">
<h3>The Strategy for Non-standard Normal RVs<a class="headerlink" href="#the-strategy-for-non-standard-normal-rvs" title="Link to this heading"></a></h3>
<p>We said we would apply the standardization technique to use the Z-table for any normal distributions.
How will this work? The key steps are the following:</p>
<ol class="arabic">
<li><p>Recognize that subtracting the same value on both sides or multiplying by the same positive value on both sides
does not change the truth of an (in)equality. It follows that the probability of the
(in)equality also remains unchanged.</p></li>
<li><p>Using #1,</p>
<div class="math notranslate nohighlight">
\[P(X \leq a) = P\left(\frac{X-\mu}{\sigma} \leq \frac{a-\mu}{\sigma}\right)
= P\left(Z \leq \frac{a-\mu}{\sigma}\right) = \Phi\left(\frac{a-\mu}{\sigma}\right).\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\frac{a-\mu}{\sigma}\)</span>, the value obtained by <em>standardizing</em> <span class="math notranslate nohighlight">\(a\)</span>, is called the <strong>z-score</strong>
of <span class="math notranslate nohighlight">\(a\)</span>.</p></li>
</ul>
</li>
</ol>
</section>
<section id="the-strategy-for-probabilities-which-do-not-match-the-cdf">
<h3>The Strategy for Probabilities Which Do Not Match the CDF<a class="headerlink" href="#the-strategy-for-probabilities-which-do-not-match-the-cdf" title="Link to this heading"></a></h3>
<p>We are often interested in probabilities which are not in the form <span class="math notranslate nohighlight">\(\Phi(z) = P(Z \leq z)\)</span>.</p>
<ul class="simple">
<li><p>For <strong>“greater than” probabilities</strong>, use the complement rule:  <span class="math notranslate nohighlight">\(P(Z &gt; z) = 1 - \Phi(z)\)</span>.</p></li>
<li><p>For <strong>probabilities of intervals</strong>, use <span class="math notranslate nohighlight">\(P(a &lt; Z &lt; b) = \Phi(b) - \Phi(a)\)</span></p></li>
<li><p>Because the standard normal distribution is symmetric <strong>around zero</strong>, we have
an additional tool: <span class="math notranslate nohighlight">\(\Phi(-z) = 1 - \Phi(z)\)</span> (<a class="reference internal" href="#z-symmetry-property"><span class="std std-numref">Fig. 6.29</span></a>).</p></li>
</ul>
<figure class="align-center" id="id7">
<span id="z-symmetry-property"></span><a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/phi-symmetry.png"><img alt="Special property of standard normal CDF due to symmetry around 0" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/phi-symmetry.png" style="width: 40%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.29 </span><span class="caption-text">Due to symmetry around zero, the two grey regions have equal probability.</span><a class="headerlink" href="#id7" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="forward-problems">
<h3>Forward Problems<a class="headerlink" href="#forward-problems" title="Link to this heading"></a></h3>
<p>When a problem gives a value in the support and asks for a related probability, we call it a
<strong>forward problem</strong>. The systematic approach is:</p>
<ol class="arabic simple">
<li><p><strong>Identify</strong> the desired probability in correct probability notation.
<strong>Sketch</strong> the region on a normal PDF plot if needed.</p></li>
<li><p><strong>Standardize</strong> by converting <span class="math notranslate nohighlight">\(x\)</span> values to <span class="math notranslate nohighlight">\(z\)</span>-scores using <span class="math notranslate nohighlight">\(z = \frac{x-\mu}{\sigma}\)</span>.</p></li>
<li><p><strong>Modify the probability statement</strong> to an expression involving <span class="math notranslate nohighlight">\(P(Z \leq z)\)</span>
so the Z-table can be used directly.</p></li>
<li><p><strong>Round the z-score</strong> to two decimal places and look it up in the table.</p></li>
<li><p><strong>Write your conclusion</strong> in the context of the problem.</p></li>
</ol>
<div class="note admonition">
<p class="admonition-title">Example💡: Systolic Blood Pressure</p>
<p>Systolic blood pressure readings for healthy adults, in mmHg, follow a normal distribution
with <span class="math notranslate nohighlight">\(\mu=112\)</span> and <span class="math notranslate nohighlight">\(\sigma^2= 100\)</span>. Find the probability that a randomly
selected adult has blood pressure between 90 and 134 mmHg.</p>
<figure class="align-right" id="id8" style="width: 30%">
<img alt="Sketch of the probability P(90 &lt; X &lt; 134)." src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/forward-example-sketch.png" />
<figcaption>
<p><span class="caption-number">Fig. 6.30 </span><span class="caption-text">A sketch of <span class="math notranslate nohighlight">\(P(90 &lt; X &lt; 134)\)</span></span><a class="headerlink" href="#id8" title="Link to this image"></a></p>
</figcaption>
</figure>
<ul>
<li><p><strong>Step 1: Write the random variable and its distribution in correct notation</strong></p>
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be the blood pressure readings for healthy adults. <span class="math notranslate nohighlight">\(X \sim N(\mu=112, \sigma^2=100)\)</span>.</p>
</li>
<li><p><strong>Step 2: Find the correct probability statement</strong></p>
<p>We are looking for</p>
<div class="math notranslate nohighlight">
\[P(90 &lt; X &lt; 134) = P(X &lt; 134) - P(X &lt; 90).\]</div>
<p>We need to find <span class="math notranslate nohighlight">\(z_1\)</span> and <span class="math notranslate nohighlight">\(z_2\)</span> such that <span class="math notranslate nohighlight">\(P(X &lt; 134) = P(Z&lt; z_2)\)</span> and
<span class="math notranslate nohighlight">\(P(X&lt; 90)=P(Z&lt; z_1)\)</span>.</p>
</li>
<li><p><strong>Step 3: Standardize to find</strong> <span class="math notranslate nohighlight">\(z_1\)</span> <strong>and</strong> <span class="math notranslate nohighlight">\(z_2\)</span></p>
<p>Note that the spread parameter is given as variance. We must use <span class="math notranslate nohighlight">\(\sigma = \sqrt{100} = 10\)</span>
for standardization.</p>
<div class="math notranslate nohighlight">
\[z_1 = \frac{90 - 112}{10} = \frac{-22}{10} = -2.2 \text{ and }
z_2 = \frac{134 - 112}{10} = \frac{22}{10} = 2.2\]</div>
</li>
<li><p><strong>Step 4: Convert to standard normal probability</strong></p>
<div class="math notranslate nohighlight">
\[P(90 &lt; X &lt; 134) = P(Z&lt; z_2) - P(Z&lt; z_1) = \Phi(2.2) - \Phi(-2.2)\]</div>
</li>
<li><p><strong>Step 5: Use symmetry to simplify</strong></p>
<p>We can look up the CDF values for <span class="math notranslate nohighlight">\(z_1=-2.2\)</span> and <span class="math notranslate nohighlight">\(z_2=2.2\)</span>
separately, but when the two <span class="math notranslate nohighlight">\(z\)</span>-scores are negatives of each other,
we can also simplify the search step using <span class="math notranslate nohighlight">\(\Phi(-2.2) = 1 - \Phi(2.2)\)</span>.</p>
<div class="math notranslate nohighlight">
\[P(-2.2 &lt; Z &lt; 2.2) = \Phi(2.2) - (1 - \Phi(2.2)) = 2\Phi(2.2) - 1\]</div>
</li>
<li><p><strong>Step 6: Look up in the Z-table and calculate the final answer</strong></p>
<p>From the Z-table: <span class="math notranslate nohighlight">\(\Phi(2.2) = 0.9861\)</span>. Finally,</p>
<div class="math notranslate nohighlight">
\[P(90 &lt; X &lt; 134) = 2(0.9861) - 1 = 0.9722\]</div>
<p>There is approximately 0.9722 probability that a randomly selected healthy adult
will have systolic blood pressure between 90 and 134 mmHg.</p>
</li>
</ul>
</div>
</section>
</section>
<section id="backward-problems-probability-to-x-percentile">
<h2><span class="section-number">6.4.6. </span>Backward Problems: Probability to <span class="math notranslate nohighlight">\(x\)</span> (Percentile)<a class="headerlink" href="#backward-problems-probability-to-x-percentile" title="Link to this heading"></a></h2>
<div class="video-placeholder" role="group" aria-labelledby="video-ch6-4-2">
  <iframe
    id="video-ch6-4-2"
    title="STAT 350 – Chapter 6.4.2 Normal Distribution Backward Calculations Video"
    src="https://www.youtube.com/embed/nExxuvoX-gQ?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
    allowfullscreen>
  </iframe>
</div><p>Backward problems reverse the process: given a probability, we must find the corresponding value (percentile)
in the support.</p>
<section id="walkthrough-of-a-backward-problem">
<h3>Walkthrough of a Backward Problem<a class="headerlink" href="#walkthrough-of-a-backward-problem" title="Link to this heading"></a></h3>
<p>Consider a typical backward question:</p>
<ul class="simple">
<li><p>The gas price on a fixed date in State A follows normal distribution with
mean $3.30 and standard deviation $0.12. If Gas Station B has a price higher than 63% of all gas stations
in the state that day, what is the gas price in Gas Station B?</p></li>
</ul>
<p>In this problem, a <strong>probability is given (63% or 0.63)</strong>, and we are <strong>asked for the cutoff</strong> whose
left region under the PDF has an area of 0.63. This cutoff is the <strong>63th percentile</strong> of the gas price distribution.</p>
<p>To solve for this type of problems, we begin by setting up the correct probability statement.</p>
<div class="math notranslate nohighlight">
\[P(X \leq x_{0.63}) = 0.63.\]</div>
<p>Standardize to get a probability statement in terms of <span class="math notranslate nohighlight">\(Z\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(Z \leq \frac{x_{0.63}-\mu}{\sigma})=0.63.\]</div>
<p>The right-hand side of the inequality above now fits the definition of the 63th percentile of a <strong>standard normal random variable</strong>.
That is,</p>
<div class="math notranslate nohighlight">
\[z_{0.63} = \frac{x_{0.63}-\mu}{\sigma}.\]</div>
<p>We will look for <span class="math notranslate nohighlight">\(z_{0.63}\)</span> and convert back to <span class="math notranslate nohighlight">\(x_{0.63}\)</span> using this relationship.</p>
<p>To find <span class="math notranslate nohighlight">\(z_{0.63}\)</span>, we locate 0.63 (or the value closest to it) in the <strong>main body</strong> of the table,
then obtain the <span class="math notranslate nohighlight">\(z\)</span>- <strong>score from its margins</strong>. 0.6293 is the value closest to 0.63 in the main body,
and its margins give us <span class="math notranslate nohighlight">\(z_{0.63}=0.33\)</span>.</p>
<p>Converting back, <span class="math notranslate nohighlight">\(x_{0.63} = \sigma z_{0.63} +\mu = (0.12)(0.33) + 3.3 = 3.3396\)</span>.</p>
<p>Finally, the price at Gas Station B is around $3.34.</p>
</section>
<section id="summary-of-the-key-steps">
<h3>Summary of the Key Steps<a class="headerlink" href="#summary-of-the-key-steps" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p>Identify the value you need to find using correct probability notation. <strong>Sketch the region</strong>
if needed.</p></li>
<li><p><strong>Find the z-score</strong> by first locating the probability in the body of the Z-table
then going to its margins.</p></li>
<li><p><strong>Convert the z-score to the original scale</strong> using <span class="math notranslate nohighlight">\(x = \sigma z + \mu\)</span>.</p></li>
<li><p><strong>Write your conclusion</strong> in the correct context.</p></li>
</ol>
</section>
<section id="points-that-require-special-attention">
<h3>Points That Require Special Attention<a class="headerlink" href="#points-that-require-special-attention" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>Depending on the problem, the probability given may correspond to a <strong>right (upper) region</strong> rather than a left (lower)
one under the PDF. Since percentiles are always defined in terms of the lower region, you need to make adjustments accordingly.
For example, if Gas Station C has a price lower than 23 % of all other gas stations in the state,
its price corresponds to the (100 – 23)th percentile.</p></li>
<li><p>If the given probability does not have an exact match in the table, take the z-value for the <strong>closest entry</strong>.
If it is exactly in the middle of two values on the table, <strong>take the average between the z-scores of the two entries</strong>.</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title">Example💡: Systolic Blood Pressure, Continued</p>
<p>Continue with the RV of blood pressure measurements: <span class="math notranslate nohighlight">\(X \sim N(\mu = 112, \sigma^2 = 100)\)</span>.</p>
<ol class="arabic">
<li><p>find the 95th percentile.</p>
<p>We want to find <span class="math notranslate nohighlight">\(x_{0.95}\)</span> such that <span class="math notranslate nohighlight">\(P(X \leq x_{0.95}) = 0.95\)</span>
First, find <span class="math notranslate nohighlight">\(z_{0.95}\)</span> such that <span class="math notranslate nohighlight">\(\Phi(z_{0.95}) = 0.95\)</span></p>
<p>In the body of the Z-table, we find that 0.9495 and 0.9505 are the closest to 0.95.
Since 0.95 is exactly halfway between these values, we average the corresponding z-scores:</p>
<div class="math notranslate nohighlight">
\[z_{0.95} = \frac{1.64 + 1.65}{2} = 1.645.\]</div>
<p>Converting to the original scale,</p>
<p><span class="math notranslate nohighlight">\(x_{0.95} = \mu + \sigma z_{0.95} = 112 + 10(1.645) = 128.45\)</span>.</p>
<p><em>Conclusion</em>: The 95th percentile of systolic blood pressure is 128.45 mmHg.
This means that 95% of healthy adults have blood pressure at or below this value.</p>
</li>
<li><p>Find the cutoffs for the middle 50% of blood pressure measurements.
Using the cutoffs, also compute the interquartile range.</p>
<figure class="align-right" id="id9" style="width: 30%">
<img alt="Sketch of the cutoffs for middle 50%" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/backward-example-sketch.png" />
<figcaption>
<p><span class="caption-number">Fig. 6.31 </span><span class="caption-text">A sketch of problem 2</span><a class="headerlink" href="#id9" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>We need to find two cutoffs: the 25th percentile and the 75th percentile.</p>
<p><em>For the 25th percentile</em>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Phi(z_{0.25}) = 0.25\)</span></p></li>
<li><p>From the table: <span class="math notranslate nohighlight">\(z_{0.25} = -0.67\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_{0.25} = 112 + 10(-0.67) = 105.3\)</span> mmHg</p></li>
</ul>
<p><em>For the 75th percentile</em>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Phi(z_{0.75}) = 0.75\)</span></p></li>
<li><p>From the table (or using symmetry): <span class="math notranslate nohighlight">\(z_{0.75} = 0.67\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_{0.75} = 112 + 10(0.67) = 118.7\)</span> mmHg</p></li>
</ul>
<p><em>Conclusion</em>: The middle 50% of systolic blood pressure readings fall between 105.3 and 118.7 mmHg.
The interquartile range is <span class="math notranslate nohighlight">\(118.7 - 105.3 = 13.4\)</span> mmHg.</p>
</li>
</ol>
</div>
</section>
</section>
<section id="proving-the-theoretical-properties-of-normal-distribution">
<h2><span class="section-number">6.4.7. </span>Proving the Theoretical Properties of Normal Distribution<a class="headerlink" href="#proving-the-theoretical-properties-of-normal-distribution" title="Link to this heading"></a></h2>
<section id="validity-of-the-pdf">
<h3>Validity of the PDF<a class="headerlink" href="#validity-of-the-pdf" title="Link to this heading"></a></h3>
<p>To establish that a normal PDF is legitimate, we must verify that it satisfies the two fundamental
requirements for any probability density function.</p>
<section id="property-1-non-negativity">
<h4>Property 1: Non-Negativity<a class="headerlink" href="#property-1-non-negativity" title="Link to this heading"></a></h4>
<p>We need to show that <span class="math notranslate nohighlight">\(f_X(x) \geq 0\)</span> for all <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(\sigma &gt; 0\)</span>, we have <span class="math notranslate nohighlight">\(\frac{1}{\sqrt{2\pi \sigma}} &gt; 0\)</span>. The exponential function <span class="math notranslate nohighlight">\(e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}\)</span> is always positive because:</p>
<ul class="simple">
<li><p>The exponent <span class="math notranslate nohighlight">\(-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\)</span> is always negative (or zero).</p></li>
<li><p><span class="math notranslate nohighlight">\(e^{\text{negative number}}\)</span> is always positive.</p></li>
<li><p><span class="math notranslate nohighlight">\(e^0 = 1 &gt; 0\)</span>.</p></li>
</ul>
<p>Therefore, <span class="math notranslate nohighlight">\(f_X(x) &gt; 0\)</span> for all <span class="math notranslate nohighlight">\(x \in \mathbb{R}\)</span>. ✓</p>
</section>
<section id="property-2-integration-to-unity">
<h4>Property 2: Integration to Unity<a class="headerlink" href="#property-2-integration-to-unity" title="Link to this heading"></a></h4>
<p>We must prove that <span class="math notranslate nohighlight">\(\int_{-\infty}^{\infty} f_X(x) \, dx = 1\)</span>.</p>
<p><strong>Step 1: Change of Variables</strong></p>
<p>Let <span class="math notranslate nohighlight">\(z = \frac{x - \mu}{\sigma}\)</span>, so <span class="math notranslate nohighlight">\(x = \sigma z + \mu\)</span> and <span class="math notranslate nohighlight">\(dx = \sigma \, dz\)</span>.</p>
<p><span class="math notranslate nohighlight">\(z = -\infty\)</span> when <span class="math notranslate nohighlight">\(x = -\infty\)</span>, and <span class="math notranslate nohighlight">\(z = +\infty\)</span> when <span class="math notranslate nohighlight">\(x = +\infty\)</span>.
The integral becomes:</p>
<div class="math notranslate nohighlight">
\[I = \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi \sigma}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2} dx = \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}} dz\]</div>
<p><strong>Step 2: The Squaring Trick</strong></p>
<p>This integral has no elementary antiderivative, so we use a clever approach. Let’s compute <span class="math notranslate nohighlight">\(I^2\)</span>:</p>
<div class="math notranslate nohighlight">
\[I^2 = \left(\int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}} dz\right)\left(\int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} e^{-\frac{v^2}{2}} dv\right)\]</div>
<p>Since the integrals converge absolutely, we can rewrite this as a double integral:</p>
<div class="math notranslate nohighlight">
\[I^2 = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \frac{1}{2\pi} e^{-\frac{1}{2}(z^2 + v^2)} \, dz \, dv\]</div>
<p><strong>Step 3: Polar Coordinate Transformation</strong></p>
<p>Let:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(z = r\cos\theta\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(v = r\sin\theta\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(z^2 + v^2 = r^2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(dz \, dv = r \, dr \, d\theta\)</span></p></li>
</ul>
<p>The integration limits become:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(r\)</span>: from 0 to <span class="math notranslate nohighlight">\(\infty\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\theta\)</span>: from 0 to <span class="math notranslate nohighlight">\(2\pi\)</span></p></li>
</ul>
<p>Therefore:</p>
<div class="math notranslate nohighlight">
\[I^2 = \int_0^{2\pi} \int_0^{\infty} \frac{1}{2\pi} e^{-\frac{r^2}{2}} \cdot r \, dr \, d\theta\]</div>
<p><strong>Step 4: Separating the Integrals</strong></p>
<div class="math notranslate nohighlight">
\[I^2 = \frac{1}{2\pi} \int_0^{2\pi} d\theta \int_0^{\infty} r e^{-\frac{r^2}{2}} dr\]</div>
<p>The first integral gives us <span class="math notranslate nohighlight">\(2\pi\)</span>. For the second integral, use substitution <span class="math notranslate nohighlight">\(u = \frac{r^2}{2}\)</span>, so <span class="math notranslate nohighlight">\(du = r \, dr\)</span>:</p>
<div class="math notranslate nohighlight">
\[\int_0^{\infty} r e^{-\frac{r^2}{2}} dr = \int_0^{\infty} e^{-u} du = \left[-e^{-u}\right]_0^{\infty} = 0 - (-1) = 1\]</div>
<p><strong>Step 5: Final Result</strong></p>
<div class="math notranslate nohighlight">
\[I^2 = \frac{1}{2\pi} \cdot 2\pi \cdot 1 = 1\]</div>
<p>Since <span class="math notranslate nohighlight">\(I &gt; 0\)</span> (the integrand is positive), we have <span class="math notranslate nohighlight">\(I = 1\)</span>. ✓</p>
<p>This completes the proof that the normal PDF is a valid probability density function.</p>
</section>
</section>
<section id="the-parameter-relationships-expected-value-and-variance">
<h3>The Parameter Relationships: Expected Value and Variance<a class="headerlink" href="#the-parameter-relationships-expected-value-and-variance" title="Link to this heading"></a></h3>
<p>To complete our theoretical understanding, we must prove that the parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span> are indeed the mean and variance of the distribution.</p>
<section id="theorem-the-expected-value-is">
<h4>Theorem: The Expected Value is μ<a class="headerlink" href="#theorem-the-expected-value-is" title="Link to this heading"></a></h4>
<p>For <span class="math notranslate nohighlight">\(X \sim N(\mu, \sigma)\)</span>, <span class="math notranslate nohighlight">\(E[X] = \mu\)</span>.</p>
<p><em>Proof:</em></p>
<div class="math notranslate nohighlight">
\[E[X] = \int_{-\infty}^{\infty} x \cdot \frac{1}{\sqrt{2\pi \sigma}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2} dx\]</div>
<p>Using the standardization substitution <span class="math notranslate nohighlight">\(z = \frac{x-\mu}{\sigma}\)</span>, we have <span class="math notranslate nohighlight">\(x = \sigma z + \mu\)</span> and <span class="math notranslate nohighlight">\(dx = \sigma \, dz\)</span>.</p>
<div class="math notranslate nohighlight">
\[E[X] = \int_{-\infty}^{\infty} (\sigma z + \mu) \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}} dz\]</div>
<p>Distributing the integral,</p>
<div class="math notranslate nohighlight">
\[E[X] = \sigma \int_{-\infty}^{\infty} z \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}} dz + \mu \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}} dz\]</div>
<p>The second integral equals 1 since it’s the integral of the standard normal PDF.
For the first integral, note that <span class="math notranslate nohighlight">\(z \phi(z)\)</span> is an odd function, and we’re integrating over a symmetric interval, so:</p>
<div class="math notranslate nohighlight">
\[\int_{-\infty}^{\infty} z \cdot \phi(z) \, dz = 0\]</div>
<p>Therefore, <span class="math notranslate nohighlight">\(E[X] = \sigma \cdot 0 + \mu \cdot 1 = \mu\)</span>. ✓</p>
</section>
<section id="theorem-the-variance-is-sigma-2">
<h4>Theorem: The Variance is <span class="math notranslate nohighlight">\(\sigma^2\)</span><a class="headerlink" href="#theorem-the-variance-is-sigma-2" title="Link to this heading"></a></h4>
<p>For <span class="math notranslate nohighlight">\(X \sim N(\mu, \sigma)\)</span>, <span class="math notranslate nohighlight">\(\text{Var}(X) = \sigma^2\)</span> .</p>
<p><em>Proof:</em></p>
<p>Using the standardization <span class="math notranslate nohighlight">\(Z = \frac{X-\mu}{\sigma}\)</span>, we know that <span class="math notranslate nohighlight">\(X = \sigma Z + \mu\)</span>. By the properties of variance:</p>
<div class="math notranslate nohighlight">
\[\text{Var}(X) = \text{Var}(\sigma Z + \mu) = \sigma^2 \text{Var}(Z)\]</div>
<p>So we need to show that <span class="math notranslate nohighlight">\(\text{Var}(Z) = 1\)</span> for the standard normal.</p>
<div class="math notranslate nohighlight">
\[\text{Var}(Z) = E[Z^2] - (E[Z])^2 = E[Z^2] - 0^2 = E[Z^2]\]</div>
<div class="math notranslate nohighlight">
\[E[Z^2] = \int_{-\infty}^{\infty} z^2 \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}} dz\]</div>
<p>Using integration by parts with <span class="math notranslate nohighlight">\(u = z\)</span> and <span class="math notranslate nohighlight">\(dv = z e^{-\frac{z^2}{2}} dz\)</span>,
we have <span class="math notranslate nohighlight">\(du = dz\)</span> and <span class="math notranslate nohighlight">\(v = -e^{-\frac{z^2}{2}}\)</span>. Then:</p>
<div class="math notranslate nohighlight">
\[\int z^2 e^{-\frac{z^2}{2}} dz = z(-e^{-\frac{z^2}{2}}) - \int (-e^{-\frac{z^2}{2}}) dz = -ze^{-\frac{z^2}{2}} + \int e^{-\frac{z^2}{2}} dz\]</div>
<p>The boundary term <span class="math notranslate nohighlight">\(\left[-ze^{-\frac{z^2}{2}}\right]_{-\infty}^{\infty} = 0\)</span> since exponential decay dominates linear growth.
Therefore,</p>
<div class="math notranslate nohighlight">
\[E[Z^2] = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{-\frac{z^2}{2}} dz = \frac{1}{\sqrt{2\pi}} \cdot \sqrt{2\pi} = 1\]</div>
<p>Thus <span class="math notranslate nohighlight">\(\text{Var}(Z) = 1\)</span> and <span class="math notranslate nohighlight">\(\text{Var}(X) = \sigma^2\)</span>. ✓</p>
</section>
</section>
</section>
<section id="assessing-normality-in-practice-why-it-matters">
<h2><span class="section-number">6.4.8. </span>Assessing Normality in Practice: Why It Matters<a class="headerlink" href="#assessing-normality-in-practice-why-it-matters" title="Link to this heading"></a></h2>
<div class="video-placeholder" role="group" aria-labelledby="video-ch6-4-3">
  <iframe
    id="video-ch6-4-3"
    title="STAT 350 – Chapter 6.4.3 Checking Normality of Data Video"
    src="https://www.youtube.com/embed/iuWe6rxgNbI?list=PLHKEwTHXfbagA3ybKLAcEJriGT-6k89c6"
    allowfullscreen>
  </iframe>
</div><p>In statistical practice, we frequently need to determine whether observed data comes from a normal distribution.
This assessment is crucial because many statistical procedures—confidence intervals, t-tests, ANOVA, and
regression—assume normality or rely on estimators whose sampling distributions are approximately normal.</p>
<p>While we’ve established the theoretical foundation of the normal distribution, real data is messy.
Heights, weights, test scores, and measurement errors may approximately follow normal patterns,
but we need systematic methods to evaluate how close our data comes to this idealized mathematical model.</p>
<section id="the-challenge-of-real-world-assessment">
<h3>The Challenge of Real-World Assessment<a class="headerlink" href="#the-challenge-of-real-world-assessment" title="Link to this heading"></a></h3>
<p>Unlike our theoretical examples with known parameters, real data presents several challenges:</p>
<ul class="simple">
<li><p>We don’t know the true population parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>.</p></li>
<li><p>Sample sizes are finite, introducing sampling variability.</p></li>
<li><p>Real phenomena may deviate from perfect normality in subtle ways.</p></li>
<li><p>We need to distinguish between minor departures that don’t affect our analyses and serious violations that require different approaches.</p></li>
</ul>
</section>
<section id="a-multi-faceted-approach">
<h3>A Multi-Faceted Approach<a class="headerlink" href="#a-multi-faceted-approach" title="Link to this heading"></a></h3>
<p>Assessing normality requires multiple complementary methods because no single approach provides complete information.
We combine:</p>
<ol class="arabic simple">
<li><p><strong>Visual methods</strong> that reveal patterns and deviations at a glance,</p></li>
<li><p><strong>Numerical checks</strong> that quantify adherence to normal distribution properties, and</p></li>
<li><p><strong>Formal statistical tests</strong> that provide rigorous hypothesis testing frameworks.</p></li>
</ol>
</section>
</section>
<section id="visual-assessments-for-normality">
<h2><span class="section-number">6.4.9. </span>Visual Assessments for Normality<a class="headerlink" href="#visual-assessments-for-normality" title="Link to this heading"></a></h2>
<section id="a-histograms-with-overlaid-curves">
<h3>A. Histograms with Overlaid Curves<a class="headerlink" href="#a-histograms-with-overlaid-curves" title="Link to this heading"></a></h3>
<p>The most intuitive approach overlays three elements on a histogram of the data:</p>
<ul class="simple">
<li><p>The <strong>histogram</strong> itself, showing the actual distribution of observations,</p></li>
<li><p>A <strong>kernel density estimate</strong> (smooth red curve) that traces the data’s shape
without assuming any particular distribution, and</p></li>
<li><p>A <strong>normal density curve</strong> (blue curve) fitted using the sample mean and standard deviation.</p></li>
</ul>
<figure class="align-center" id="id10" style="width: 70%">
<img alt="Histogram with kernel density and normal curve overlay" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/histogram.png" />
<figcaption>
<p><span class="caption-number">Fig. 6.32 </span><span class="caption-text">Comparing actual data distribution (purple histogram) with its smooth estimate (red) and fitted normal curve (blue)*</span><a class="headerlink" href="#id10" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>When data follows a normal distribution, these three elements align closely. Deviations reveal specific patterns:</p>
<ul class="simple">
<li><p><strong>Skewness</strong>: The red curve shifts away from the blue curve</p></li>
<li><p><strong>Heavy tails</strong>: The red curve extends further than the blue curve</p></li>
<li><p><strong>Light tails</strong>: The red curve falls short of the blue curve’s extent</p></li>
<li><p><strong>Multimodality</strong>: The red curve shows multiple peaks while the blue curve shows only one</p></li>
</ul>
</section>
<section id="b-normal-probability-plots-a-sophisticated-diagnostic">
<h3>B. Normal Probability Plots: A Sophisticated Diagnostic<a class="headerlink" href="#b-normal-probability-plots-a-sophisticated-diagnostic" title="Link to this heading"></a></h3>
<p>Normal probability plots (also called QQ-plots for “quantile-quantile plots”) provide a more sensitive method for
detecting departures from normality. These plots directly compare the quantiles of our data with the quantiles we
would expect if the data truly came from a normal distribution.</p>
<section id="steps-of-constructing-a-qq-plot">
<h4>Steps of Constructing a QQ-Plot<a class="headerlink" href="#steps-of-constructing-a-qq-plot" title="Link to this heading"></a></h4>
<ol class="arabic">
<li><p>Order the Data</p>
<p>Arrange the <span class="math notranslate nohighlight">\(n\)</span> observations from smallest to largest: <span class="math notranslate nohighlight">\(x_{(1)} \leq x_{(2)} \leq \cdots \leq x_{(n)}\)</span>.</p>
</li>
<li><p>Assign Theoretical Probabilities</p>
<p>Each ordered observation <span class="math notranslate nohighlight">\(x_{(i)}\)</span> represents approximately the <span class="math notranslate nohighlight">\(\frac{i-0.5}{n}\)</span>
quantile of the data distribution. The adjustment of <span class="math notranslate nohighlight">\(-0.5\)</span> centers each data point within
its expected quantile interval, providing more accurate comparisons.</p>
</li>
<li><p>Find Corresponding Normal Quantiles</p>
<p>For each probability <span class="math notranslate nohighlight">\(p_i = \frac{i-0.5}{n}\)</span>, find the z-value <span class="math notranslate nohighlight">\(z_i\)</span> such that
<span class="math notranslate nohighlight">\(\Phi(z_i) = p_i\)</span>. These are the theoretical quantiles we would expect if the data came
from a standard normal distribution.</p>
</li>
<li><p>Create the Plot</p>
<p>Plot the ordered data values <span class="math notranslate nohighlight">\(x_{(i)}\)</span> (y-axis) against the theoretical quantiles <span class="math notranslate nohighlight">\(z_i\)</span> (x-axis).</p>
</li>
<li><p>Add a Reference Line</p>
<p>The reference line <span class="math notranslate nohighlight">\(y = \bar{x} + s \cdot z\)</span> shows where points would fall if the data
perfectly matched a normal distribution with the sample’s mean and standard deviation.</p>
</li>
</ol>
</section>
<section id="interpreting-qq-plots">
<h4>Interpreting QQ-Plots<a class="headerlink" href="#interpreting-qq-plots" title="Link to this heading"></a></h4>
<p>The power of QQ-plots lies in how different departures from normality create characteristic patterns.</p>
<p><strong>Perfect Normality</strong>: Points fall exactly on the reference line.</p>
<figure class="align-center" id="id11" style="width: 80%">
<img alt="QQ-plot showing perfectly normal data" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/qq-normal.png" />
<figcaption>
<p><span class="caption-number">Fig. 6.33 </span><span class="caption-text">Normal probability plot for normal data</span><a class="headerlink" href="#id11" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Long Tails</strong>: Points begin below the line but curves above for larger values.</p>
<ul class="simple">
<li><p>Data has more extreme values than a normal distribution would predict</p></li>
<li><p>The lower tail extends further left, upper tail extends further right</p></li>
<li><p>Common in financial data, measurement errors with occasional large mistakes</p></li>
</ul>
<figure class="align-center" id="id12" style="width: 80%">
<img alt="QQ-plot showing perfectly normal data" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/qq-long-tail.png" />
<figcaption>
<p><span class="caption-number">Fig. 6.34 </span><span class="caption-text">Normal probability plot for long-tailed data</span><a class="headerlink" href="#id12" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Short Tails</strong>: Points begin above the line but curves below for larger values.</p>
<ul class="simple">
<li><p>Data is more concentrated around the center than normal</p></li>
<li><p>Fewer extreme values than expected</p></li>
<li><p>Sometimes seen in truncated or bounded measurements</p></li>
</ul>
<figure class="align-center" id="id13" style="width: 80%">
<img alt="QQ-plot showing perfectly normal data" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/qq-short-tail.png" />
<figcaption>
<p><span class="caption-number">Fig. 6.35 </span><span class="caption-text">Normal probability plot for short-tailed data</span><a class="headerlink" href="#id13" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Right (Positive) Skewness</strong>: Concave-up curve</p>
<figure class="align-center" id="id14" style="width: 80%">
<img alt="QQ-plot showing perfectly normal data" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/qq-right-skew.png" />
<figcaption>
<p><span class="caption-number">Fig. 6.36 </span><span class="caption-text">Normal probability plot for right-skewed data</span><a class="headerlink" href="#id14" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Left (Negative) Skewness</strong>: Concave-down curve</p>
<figure class="align-center" id="id15" style="width: 80%">
<img alt="QQ-plot showing perfectly normal data" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/qq-left-skew.png" />
<figcaption>
<p><span class="caption-number">Fig. 6.37 </span><span class="caption-text">Normal probability plot for left-skewed data</span><a class="headerlink" href="#id15" title="Link to this image"></a></p>
</figcaption>
</figure>
<p><strong>Bimodality</strong>: S-shaped curve with plateaus</p>
<ul class="simple">
<li><p>Points cluster in the middle region of the plot</p></li>
<li><p>Suggests the data might come from a mixture of two populations</p></li>
</ul>
<figure class="align-center" id="id16" style="width: 80%">
<img alt="QQ-plot showing perfectly normal data" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/images/chapter6/qq-bimodal.png" />
<figcaption>
<p><span class="caption-number">Fig. 6.38 </span><span class="caption-text">Normal probability plot for bimodal data</span><a class="headerlink" href="#id16" title="Link to this image"></a></p>
</figcaption>
</figure>
</section>
</section>
</section>
<section id="numerical-assessments-for-normality">
<h2><span class="section-number">6.4.10. </span>Numerical Assessments for Normality<a class="headerlink" href="#numerical-assessments-for-normality" title="Link to this heading"></a></h2>
<p>While visual methods provide intuitive insights, numerical methods offer precise,
quantifiable assessments of normality.</p>
<section id="a-the-empirical-rule-in-reverse">
<h3>A. The Empirical Rule in Reverse<a class="headerlink" href="#a-the-empirical-rule-in-reverse" title="Link to this heading"></a></h3>
<p>Instead of using the 68-95-99.7 rule to predict probabilities, we can use it in reverse to check whether our data behaves as a normal distribution should:</p>
<p>For truly normal data,</p>
<ul class="simple">
<li><p>Approximately <strong>68%</strong> of observations should fall within one standard deviation: <span class="math notranslate nohighlight">\(\bar{x} \pm s\)</span>.</p></li>
<li><p>Approximately <strong>95%</strong> should fall within two standard deviations: <span class="math notranslate nohighlight">\(\bar{x} \pm 2s\)</span>.</p></li>
<li><p>Approximately <strong>99.7%</strong> should fall within three standard deviations: <span class="math notranslate nohighlight">\(\bar{x} \pm 3s\)</span>.</p></li>
</ul>
<section id="implementation-steps">
<h4>Implementation Steps<a class="headerlink" href="#implementation-steps" title="Link to this heading"></a></h4>
<ol class="arabic simple">
<li><p>Calculate the sample mean <span class="math notranslate nohighlight">\(\bar{x}\)</span> and sample standard deviation <span class="math notranslate nohighlight">\(s\)</span>.</p></li>
<li><p>Count observations within each interval.</p></li>
<li><p>Compare observed proportions to expected proportions (0.68, 0.95, 0.997).</p></li>
<li><p>Large deviations suggest non-normality.</p></li>
</ol>
</section>
</section>
<section id="b-the-iqr-to-standard-deviation-ratio">
<h3>B. The IQR-to-Standard Deviation Ratio<a class="headerlink" href="#b-the-iqr-to-standard-deviation-ratio" title="Link to this heading"></a></h3>
<p>For normal distributions, there’s a consistent relationship between the interquartile range and the
standard deviation. This relationship arises from the fixed positions of quantiles in any normal distribution.</p>
<p>For any normal distribution <span class="math notranslate nohighlight">\(N(\mu, \sigma)\)</span>:</p>
<ul class="simple">
<li><p>The first quartile (25th percentile) occurs at <span class="math notranslate nohighlight">\(\mu - 0.674\sigma\)</span>.</p></li>
<li><p>The third quartile (75th percentile) occurs at <span class="math notranslate nohighlight">\(\mu + 0.674\sigma\)</span>.</p></li>
<li><p>Therefore: <span class="math notranslate nohighlight">\(IQR = Q_3 - Q_1 = 1.348\sigma\)</span>.</p></li>
<li><p>The ratio <span class="math notranslate nohighlight">\(\frac{IQR}{\sigma} \approx 1.35\)</span> (often rounded to 1.4).</p></li>
</ul>
<section id="id2">
<h4>Implementation Steps<a class="headerlink" href="#id2" title="Link to this heading"></a></h4>
<ol class="arabic simple">
<li><p>Calculate the sample IQR and sample standard deviation <span class="math notranslate nohighlight">\(s\)</span>.</p></li>
<li><p>Compute the ratio <span class="math notranslate nohighlight">\(\frac{IQR}{s}\)</span>.</p></li>
<li><p>Values close to 1.35 suggest normality.</p></li>
<li><p>Values substantially different indicate departures from normality.</p></li>
</ol>
</section>
</section>
</section>
<section id="formal-statistical-tests-for-assessing-normality">
<h2><span class="section-number">6.4.11. </span>Formal Statistical Tests for Assessing Normality<a class="headerlink" href="#formal-statistical-tests-for-assessing-normality" title="Link to this heading"></a></h2>
<p>While visual and numerical methods provide insights, formal statistical tests
such as Shapiro-Wilk Test and Kolmovorov-Smirnov Tests offer rigorous
hypothesis testing frameworks for normality. These tests are covered in more advanced statistics courses.</p>
</section>
<section id="bringing-it-all-together">
<h2><span class="section-number">6.4.12. </span>Bringing It All Together<a class="headerlink" href="#bringing-it-all-together" title="Link to this heading"></a></h2>
<div class="important admonition">
<p class="admonition-title">Key Takeaways 📝</p>
<ol class="arabic simple">
<li><p>The <strong>normal distribution</strong> emerged from Gauss’s work on measurement errors and has
become the most important continuous distribution in statistics.</p></li>
<li><p>The <strong>PDF</strong> <span class="math notranslate nohighlight">\(f_X(x) = \frac{1}{\sqrt{2\pi \sigma}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}\)</span>
is completely determined by two parameters: location <span class="math notranslate nohighlight">\(\mu\)</span> and scale <span class="math notranslate nohighlight">\(\sigma\)</span>.</p></li>
<li><p><strong>All normal distributions</strong> are symmetric, unimodal, and bell-shaped, with inflection
points at <span class="math notranslate nohighlight">\(\mu \pm \sigma\)</span>.</p></li>
<li><p>The <strong>empirical rule</strong> (68-95-99.7) provides quick probability estimates and applies to every
normal distribution regardless of parameters.</p></li>
<li><p><strong>Mathematical rigor</strong>: We proved the normal PDF is valid through polar coordinate integration and
confirmed that <span class="math notranslate nohighlight">\(E[X] = \mu\)</span> and <span class="math notranslate nohighlight">\(\text{Var}(X) = \sigma^2\)</span>.</p></li>
<li><p>The <strong>standard normal distribution</strong> <span class="math notranslate nohighlight">\(N(0,1)\)</span> serves as the foundation for all normal computations.
The standardizing transformation <span class="math notranslate nohighlight">\(Z = \frac{X-\mu}{\sigma}\)</span> links any normal distribution to the standard one.</p></li>
<li><p><strong>Assessing normality</strong> requires multiple approaches: visual methods (histograms, QQ-plots),
numerical checks (empirical rule, IQR ratios), and formal tests (Shapiro-Wilk, Kolmogorov-Smirnov variants).</p></li>
</ol>
</div>
</section>
<section id="exercises">
<h2><span class="section-number">6.4.13. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading"></a></h2>
<p>These exercises develop your skills in working with normal distributions, including applying the empirical rule, standardization, computing probabilities (forward problems), finding percentiles (backward problems), and assessing normality.</p>
<div class="tip admonition">
<p class="admonition-title">Notation Convention</p>
<p>In this course, we write <span class="math notranslate nohighlight">\(X \sim N(\mu, \sigma^2)\)</span> where the second parameter is the <strong>variance</strong>. Always extract <span class="math notranslate nohighlight">\(\sigma = \sqrt{\sigma^2}\)</span> before standardizing. When using Z-tables, round z-scores to two decimal places. If a probability falls exactly between two table entries, average the corresponding z-values.</p>
</div>
<div class="note admonition">
<p class="admonition-title">Exercise 1: Empirical Rule Applications</p>
<p>A semiconductor manufacturer produces microprocessors with clock speeds that follow a normal distribution with mean <span class="math notranslate nohighlight">\(\mu = 3.2\)</span> GHz and variance <span class="math notranslate nohighlight">\(\sigma^2 = 0.0225\)</span> GHz².</p>
<ol class="loweralpha simple">
<li><p>State the intervals containing approximately 68%, 95%, and 99.7% of clock speeds.</p></li>
<li><p>What percentage of processors have clock speeds between 2.9 GHz and 3.5 GHz?</p></li>
<li><p>A processor is considered “premium grade” if its clock speed exceeds 3.5 GHz. Approximately what percentage qualifies?</p></li>
<li><p>Quality control flags processors with clock speeds below 2.75 GHz as defective. Approximately what percentage is flagged?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X\)</span> = clock speed (GHz), where <span class="math notranslate nohighlight">\(X \sim N(\mu = 3.2, \sigma^2 = 0.0225)\)</span>.</p>
<p class="sd-card-text">First, extract the standard deviation: <span class="math notranslate nohighlight">\(\sigma = \sqrt{0.0225} = 0.15\)</span> GHz.</p>
<p class="sd-card-text"><strong>Part (a): Empirical rule intervals</strong></p>
<ul class="simple">
<li><p class="sd-card-text"><strong>68% interval</strong>: <span class="math notranslate nohighlight">\(\mu \pm \sigma = 3.2 \pm 0.15 = (3.05, 3.35)\)</span> GHz</p></li>
<li><p class="sd-card-text"><strong>95% interval</strong>: <span class="math notranslate nohighlight">\(\mu \pm 2\sigma = 3.2 \pm 0.30 = (2.90, 3.50)\)</span> GHz</p></li>
<li><p class="sd-card-text"><strong>99.7% interval</strong>: <span class="math notranslate nohighlight">\(\mu \pm 3\sigma = 3.2 \pm 0.45 = (2.75, 3.65)\)</span> GHz</p></li>
</ul>
<figure class="align-center" id="id17">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig1_empirical_rule.png"><img alt="Empirical rule intervals for processor clock speeds" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig1_empirical_rule.png" style="width: 70%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.39 </span><span class="caption-text">The 68-95-99.7 rule applied to processor clock speeds.</span><a class="headerlink" href="#id17" title="Link to this image"></a></p>
</figcaption>
</figure>
<p class="sd-card-text"><strong>Part (b): P(2.9 &lt; X &lt; 3.5)</strong></p>
<p class="sd-card-text">Note that <span class="math notranslate nohighlight">\(2.9 = \mu - 2\sigma\)</span> and <span class="math notranslate nohighlight">\(3.5 = \mu + 2\sigma\)</span>.</p>
<p class="sd-card-text">By the empirical rule, <span class="math notranslate nohighlight">\(P(\mu - 2\sigma &lt; X &lt; \mu + 2\sigma) \approx 0.95\)</span> or <strong>95%</strong>.</p>
<p class="sd-card-text"><strong>Part (c): P(X &gt; 3.5)</strong></p>
<p class="sd-card-text">Since <span class="math notranslate nohighlight">\(3.5 = \mu + 2\sigma\)</span>, we need <span class="math notranslate nohighlight">\(P(X &gt; \mu + 2\sigma)\)</span>.</p>
<p class="sd-card-text">From the empirical rule, 95% falls within <span class="math notranslate nohighlight">\(\pm 2\sigma\)</span>, leaving 5% in both tails combined.</p>
<p class="sd-card-text">By symmetry, <span class="math notranslate nohighlight">\(P(X &gt; \mu + 2\sigma) \approx \frac{0.05}{2} = 0.025\)</span> or <strong>2.5%</strong>.</p>
<p class="sd-card-text"><strong>Part (d): P(X &lt; 2.75)</strong></p>
<p class="sd-card-text">Since <span class="math notranslate nohighlight">\(2.75 = \mu - 3\sigma\)</span>, we need <span class="math notranslate nohighlight">\(P(X &lt; \mu - 3\sigma)\)</span>.</p>
<p class="sd-card-text">From the empirical rule, 99.7% falls within <span class="math notranslate nohighlight">\(\pm 3\sigma\)</span>, leaving 0.3% in both tails.</p>
<p class="sd-card-text">By symmetry, <span class="math notranslate nohighlight">\(P(X &lt; \mu - 3\sigma) \approx \frac{0.003}{2} = 0.0015\)</span> or <strong>0.15%</strong>.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 2: Standardization and Z-Scores</p>
<p>The tensile strength of a carbon fiber composite follows a normal distribution with <span class="math notranslate nohighlight">\(\mu = 600\)</span> MPa and <span class="math notranslate nohighlight">\(\sigma^2 = 1600\)</span> MPa².</p>
<ol class="loweralpha simple">
<li><p>Find the z-score for a specimen with tensile strength 680 MPa. Interpret this value.</p></li>
<li><p>Find the z-score for a specimen with tensile strength 520 MPa. Interpret this value.</p></li>
<li><p>A specimen has a z-score of -0.75. What is its tensile strength?</p></li>
<li><p>Which is more unusual: a specimen with strength 700 MPa or one with strength 500 MPa? Justify using z-scores.</p></li>
<li><p>The specification requires tensile strength within 2 standard deviations of the mean. Express this requirement in terms of the original units (MPa).</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X\)</span> = tensile strength (MPa), where <span class="math notranslate nohighlight">\(X \sim N(\mu = 600, \sigma^2 = 1600)\)</span>.</p>
<p class="sd-card-text">First, extract the standard deviation: <span class="math notranslate nohighlight">\(\sigma = \sqrt{1600} = 40\)</span> MPa.</p>
<p class="sd-card-text"><strong>Part (a): Z-score for x = 680</strong></p>
<div class="math notranslate nohighlight">
\[z = \frac{x - \mu}{\sigma} = \frac{680 - 600}{40} = \frac{80}{40} = 2.0\]</div>
<p class="sd-card-text"><strong>Interpretation</strong>: A tensile strength of 680 MPa is <strong>2 standard deviations above the mean</strong>. This is an unusually high value—only about 2.5% of specimens exceed this strength.</p>
<p class="sd-card-text"><strong>Part (b): Z-score for x = 520</strong></p>
<div class="math notranslate nohighlight">
\[z = \frac{520 - 600}{40} = \frac{-80}{40} = -2.0\]</div>
<p class="sd-card-text"><strong>Interpretation</strong>: A tensile strength of 520 MPa is <strong>2 standard deviations below the mean</strong>. This is an unusually low value.</p>
<p class="sd-card-text"><strong>Part (c): Tensile strength for z = -0.75</strong></p>
<p class="sd-card-text">Solve for <span class="math notranslate nohighlight">\(x\)</span>: <span class="math notranslate nohighlight">\(x = \mu + z\sigma = 600 + (-0.75)(40) = 600 - 30 = 570\)</span> MPa.</p>
<p class="sd-card-text"><strong>Part (d): Compare unusualness</strong></p>
<p class="sd-card-text">For <span class="math notranslate nohighlight">\(x = 700\)</span>: <span class="math notranslate nohighlight">\(z = \frac{700 - 600}{40} = 2.5\)</span></p>
<p class="sd-card-text">For <span class="math notranslate nohighlight">\(x = 500\)</span>: <span class="math notranslate nohighlight">\(z = \frac{500 - 600}{40} = -2.5\)</span></p>
<p class="sd-card-text">Both have <span class="math notranslate nohighlight">\(|z| = 2.5\)</span>, so they are <strong>equally unusual</strong>—each is 2.5 standard deviations from the mean.</p>
<figure class="align-center" id="id18">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig2_zscore_comparison.png"><img alt="Z-scores showing symmetric unusualness" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig2_zscore_comparison.png" style="width: 70%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.40 </span><span class="caption-text">Both values are equally far from the mean in terms of standard deviations.</span><a class="headerlink" href="#id18" title="Link to this image"></a></p>
</figcaption>
</figure>
<p class="sd-card-text"><strong>Part (e): Specification in original units</strong></p>
<p class="sd-card-text">Within 2 standard deviations: <span class="math notranslate nohighlight">\(\mu \pm 2\sigma = 600 \pm 80 = (520, 680)\)</span> MPa.</p>
<p class="sd-card-text">The specification requires tensile strength between <strong>520 and 680 MPa</strong>.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 3: Forward Problem — Computing Probabilities</p>
<p>Response times for a web application follow a normal distribution with mean <span class="math notranslate nohighlight">\(\mu = 250\)</span> ms and variance <span class="math notranslate nohighlight">\(\sigma^2 = 1225\)</span> ms².</p>
<ol class="loweralpha simple">
<li><p>Find the probability that a randomly selected response takes less than 200 ms.</p></li>
<li><p>Find the probability that a response takes more than 300 ms.</p></li>
<li><p>Find the probability that a response takes between 220 and 280 ms.</p></li>
<li><p>The service level agreement (SLA) specifies that responses exceeding 320 ms are unacceptable. What proportion of responses violate the SLA?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X\)</span> = response time (ms), where <span class="math notranslate nohighlight">\(X \sim N(\mu = 250, \sigma^2 = 1225)\)</span>.</p>
<p class="sd-card-text">First, extract the standard deviation: <span class="math notranslate nohighlight">\(\sigma = \sqrt{1225} = 35\)</span> ms.</p>
<p class="sd-card-text"><strong>Part (a): P(X &lt; 200)</strong></p>
<figure class="align-center" id="id19">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig3a_forward_less_than.png"><img alt="P(X &lt; 200) shaded region" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig3a_forward_less_than.png" style="width: 50%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.41 </span><span class="caption-text">Shaded region represents P(X &lt; 200).</span><a class="headerlink" href="#id19" title="Link to this image"></a></p>
</figcaption>
</figure>
<p class="sd-card-text"><strong>Step 1</strong>: Standardize.</p>
<div class="math notranslate nohighlight">
\[z = \frac{200 - 250}{35} = \frac{-50}{35} = -1.43\]</div>
<p class="sd-card-text"><strong>Step 2</strong>: Use Z-table.</p>
<div class="math notranslate nohighlight">
\[P(X &lt; 200) = P(Z &lt; -1.43) = \Phi(-1.43) = 0.0764\]</div>
<p class="sd-card-text"><strong>Part (b): P(X &gt; 300)</strong></p>
<p class="sd-card-text"><strong>Step 1</strong>: Standardize.</p>
<div class="math notranslate nohighlight">
\[z = \frac{300 - 250}{35} = \frac{50}{35} = 1.43\]</div>
<p class="sd-card-text"><strong>Step 2</strong>: Use complement rule.</p>
<div class="math notranslate nohighlight">
\[P(X &gt; 300) = P(Z &gt; 1.43) = 1 - \Phi(1.43) = 1 - 0.9236 = 0.0764\]</div>
<p class="sd-card-text">Note: By symmetry, P(X &lt; 200) = P(X &gt; 300) since both are 1.43 standard deviations from the mean.</p>
<p class="sd-card-text"><strong>Part (c): P(220 &lt; X &lt; 280)</strong></p>
<figure class="align-center" id="id20">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig3b_forward_between.png"><img alt="P(220 &lt; X &lt; 280) shaded region" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig3b_forward_between.png" style="width: 50%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.42 </span><span class="caption-text">Shaded region represents P(220 &lt; X &lt; 280).</span><a class="headerlink" href="#id20" title="Link to this image"></a></p>
</figcaption>
</figure>
<p class="sd-card-text"><strong>Step 1</strong>: Standardize both bounds.</p>
<div class="math notranslate nohighlight">
\[z_1 = \frac{220 - 250}{35} = -0.86 \quad \text{and} \quad z_2 = \frac{280 - 250}{35} = 0.86\]</div>
<p class="sd-card-text"><strong>Step 2</strong>: Use interval formula.</p>
<div class="math notranslate nohighlight">
\[P(220 &lt; X &lt; 280) = \Phi(0.86) - \Phi(-0.86)\]</div>
<p class="sd-card-text"><strong>Step 3</strong>: Apply symmetry: <span class="math notranslate nohighlight">\(\Phi(-0.86) = 1 - \Phi(0.86)\)</span>.</p>
<div class="math notranslate nohighlight">
\[P(220 &lt; X &lt; 280) = \Phi(0.86) - (1 - \Phi(0.86)) = 2\Phi(0.86) - 1\]</div>
<p class="sd-card-text"><strong>Step 4</strong>: Look up and compute.</p>
<div class="math notranslate nohighlight">
\[P(220 &lt; X &lt; 280) = 2(0.8051) - 1 = 0.6102\]</div>
<p class="sd-card-text"><strong>Part (d): P(X &gt; 320)</strong></p>
<p class="sd-card-text"><strong>Step 1</strong>: Standardize.</p>
<div class="math notranslate nohighlight">
\[z = \frac{320 - 250}{35} = 2.0\]</div>
<p class="sd-card-text"><strong>Step 2</strong>: Compute.</p>
<div class="math notranslate nohighlight">
\[P(X &gt; 320) = 1 - \Phi(2.0) = 1 - 0.9772 = 0.0228\]</div>
<p class="sd-card-text">Approximately <strong>2.28%</strong> of responses violate the SLA.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 4: Backward Problem — Finding Percentiles</p>
<p>The fuel efficiency of a hybrid vehicle model follows a normal distribution with mean <span class="math notranslate nohighlight">\(\mu = 52\)</span> mpg and variance <span class="math notranslate nohighlight">\(\sigma^2 = 16\)</span> mpg².</p>
<ol class="loweralpha simple">
<li><p>Find the 90th percentile of fuel efficiency.</p></li>
<li><p>Find the fuel efficiency value such that only 5% of vehicles perform worse (lower mpg).</p></li>
<li><p>Find the cutoffs for the middle 80% of fuel efficiency values.</p></li>
<li><p>A vehicle is classified as “high efficiency” if it ranks in the top 10%. What is the minimum fuel efficiency for this classification?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X\)</span> = fuel efficiency (mpg), where <span class="math notranslate nohighlight">\(X \sim N(\mu = 52, \sigma^2 = 16)\)</span>.</p>
<p class="sd-card-text">First, extract the standard deviation: <span class="math notranslate nohighlight">\(\sigma = \sqrt{16} = 4\)</span> mpg.</p>
<p class="sd-card-text"><strong>Part (a): 90th percentile</strong></p>
<p class="sd-card-text">We seek <span class="math notranslate nohighlight">\(x_{0.90}\)</span> such that <span class="math notranslate nohighlight">\(P(X \leq x_{0.90}) = 0.90\)</span>.</p>
<p class="sd-card-text"><strong>Step 1</strong>: Find <span class="math notranslate nohighlight">\(z_{0.90}\)</span> from Z-table by locating 0.90 in the body.</p>
<p class="sd-card-text">From the table: <span class="math notranslate nohighlight">\(\Phi(1.28) = 0.8997\)</span> and <span class="math notranslate nohighlight">\(\Phi(1.29) = 0.9015\)</span>.</p>
<p class="sd-card-text">Since <span class="math notranslate nohighlight">\(|0.90 - 0.8997| = 0.0003 &lt; |0.90 - 0.9015| = 0.0015\)</span>, we use <span class="math notranslate nohighlight">\(z_{0.90} = 1.28\)</span>.</p>
<p class="sd-card-text"><strong>Step 2</strong>: Convert to original scale.</p>
<div class="math notranslate nohighlight">
\[x_{0.90} = \mu + z_{0.90} \cdot \sigma = 52 + 1.28(4) = 52 + 5.12 = 57.12 \text{ mpg}\]</div>
<figure class="align-center" id="id21">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig4_percentile.png"><img alt="90th percentile visualization" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig4_percentile.png" style="width: 60%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.43 </span><span class="caption-text">The 90th percentile: 90% of vehicles have fuel efficiency at or below 57.12 mpg.</span><a class="headerlink" href="#id21" title="Link to this image"></a></p>
</figcaption>
</figure>
<p class="sd-card-text"><strong>Part (b): 5th percentile</strong></p>
<p class="sd-card-text">We seek <span class="math notranslate nohighlight">\(x_{0.05}\)</span> such that <span class="math notranslate nohighlight">\(P(X \leq x_{0.05}) = 0.05\)</span>.</p>
<p class="sd-card-text"><strong>Step 1</strong>: Find <span class="math notranslate nohighlight">\(z_{0.05}\)</span> from the Z-table.</p>
<p class="sd-card-text">From the table: <span class="math notranslate nohighlight">\(\Phi(-1.64) = 0.0505\)</span> and <span class="math notranslate nohighlight">\(\Phi(-1.65) = 0.0495\)</span>.</p>
<p class="sd-card-text">Since 0.05 is exactly halfway between 0.0495 and 0.0505, we average the z-values:</p>
<div class="math notranslate nohighlight">
\[z_{0.05} = \frac{-1.64 + (-1.65)}{2} = -1.645\]</div>
<p class="sd-card-text"><strong>Step 2</strong>: Convert.</p>
<div class="math notranslate nohighlight">
\[x_{0.05} = 52 + (-1.645)(4) = 52 - 6.58 = 45.42 \text{ mpg}\]</div>
<p class="sd-card-text">Only 5% of vehicles have fuel efficiency below <strong>45.42 mpg</strong>.</p>
<p class="sd-card-text"><strong>Part (c): Middle 80% cutoffs</strong></p>
<p class="sd-card-text">The middle 80% leaves 10% in each tail, so we need <span class="math notranslate nohighlight">\(x_{0.10}\)</span> and <span class="math notranslate nohighlight">\(x_{0.90}\)</span>.</p>
<p class="sd-card-text"><em>For the 10th percentile</em>:</p>
<p class="sd-card-text">From the table: <span class="math notranslate nohighlight">\(\Phi(-1.28) = 0.1003 \approx 0.10\)</span>, so <span class="math notranslate nohighlight">\(z_{0.10} = -1.28\)</span>.</p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(x_{0.10} = 52 + (-1.28)(4) = 46.88\)</span> mpg</p>
<p class="sd-card-text"><em>For the 90th percentile</em>: <span class="math notranslate nohighlight">\(z_{0.90} = 1.28\)</span> (from part a).</p>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(x_{0.90} = 57.12\)</span> mpg</p>
<p class="sd-card-text">The middle 80% falls between <strong>46.88 and 57.12 mpg</strong>.</p>
<p class="sd-card-text"><strong>Part (d): Top 10% cutoff</strong></p>
<p class="sd-card-text">“Top 10%” means <span class="math notranslate nohighlight">\(P(X &gt; x) = 0.10\)</span>, which is equivalent to <span class="math notranslate nohighlight">\(P(X \leq x) = 0.90\)</span>.</p>
<p class="sd-card-text">This is the 90th percentile: <strong>57.12 mpg</strong> (same as part a).</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 5: Combined Forward and Backward Problems</p>
<p>Battery life for a laptop model follows a normal distribution with mean <span class="math notranslate nohighlight">\(\mu = 8.5\)</span> hours and variance <span class="math notranslate nohighlight">\(\sigma^2 = 1.44\)</span> hours².</p>
<ol class="loweralpha simple">
<li><p>What proportion of laptops have battery life between 7 and 10 hours?</p></li>
<li><p>The manufacturer wants to advertise a “minimum guaranteed battery life” that 95% of laptops will meet or exceed. What value should they advertise?</p></li>
<li><p>If 1000 laptops are sold, approximately how many will have battery life exceeding 11 hours?</p></li>
<li><p>A laptop’s battery life is at the 70th percentile. How many hours does it last?</p></li>
<li><p>Two laptops have battery lives of 6.5 hours and 10.5 hours. Which is more unusual relative to the distribution?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">Let <span class="math notranslate nohighlight">\(X\)</span> = battery life (hours), where <span class="math notranslate nohighlight">\(X \sim N(\mu = 8.5, \sigma^2 = 1.44)\)</span>.</p>
<p class="sd-card-text">First, extract the standard deviation: <span class="math notranslate nohighlight">\(\sigma = \sqrt{1.44} = 1.2\)</span> hours.</p>
<p class="sd-card-text"><strong>Part (a): P(7 &lt; X &lt; 10)</strong> — Forward problem</p>
<p class="sd-card-text">Standardize: <span class="math notranslate nohighlight">\(z_1 = \frac{7 - 8.5}{1.2} = -1.25\)</span> and <span class="math notranslate nohighlight">\(z_2 = \frac{10 - 8.5}{1.2} = 1.25\)</span>.</p>
<p class="sd-card-text">From the Z-table: <span class="math notranslate nohighlight">\(\Phi(1.25) = 0.8944\)</span> and <span class="math notranslate nohighlight">\(\Phi(-1.25) = 0.1056\)</span>.</p>
<div class="math notranslate nohighlight">
\[P(7 &lt; X &lt; 10) = \Phi(1.25) - \Phi(-1.25) = 0.8944 - 0.1056 = 0.7888\]</div>
<p class="sd-card-text">Approximately <strong>78.88%</strong> of laptops have battery life between 7 and 10 hours.</p>
<p class="sd-card-text"><strong>Part (b): 5th percentile</strong> — Backward problem</p>
<p class="sd-card-text">We need <span class="math notranslate nohighlight">\(x_{0.05}\)</span> such that 95% exceed this value (i.e., 5% fall below).</p>
<p class="sd-card-text">From the Z-table: <span class="math notranslate nohighlight">\(\Phi(-1.64) = 0.0505\)</span> and <span class="math notranslate nohighlight">\(\Phi(-1.65) = 0.0495\)</span>.</p>
<p class="sd-card-text">Since 0.05 is exactly halfway, we average: <span class="math notranslate nohighlight">\(z_{0.05} = \frac{-1.64 + (-1.65)}{2} = -1.645\)</span>.</p>
<div class="math notranslate nohighlight">
\[x_{0.05} = 8.5 + (-1.645)(1.2) = 8.5 - 1.974 = 6.526 \text{ hours}\]</div>
<p class="sd-card-text">Under the model, exactly 95% of laptops exceed 6.53 hours. For a conservative marketing claim, the manufacturer should advertise <strong>6.5 hours</strong> (rounded down to ensure the guarantee is met).</p>
<p class="sd-card-text"><strong>Part (c): Number exceeding 11 hours</strong> — Forward problem with application</p>
<p class="sd-card-text">Standardize: <span class="math notranslate nohighlight">\(z = \frac{11 - 8.5}{1.2} = 2.08\)</span>.</p>
<div class="math notranslate nohighlight">
\[P(X &gt; 11) = 1 - \Phi(2.08) = 1 - 0.9812 = 0.0188\]</div>
<p class="sd-card-text">Expected number: <span class="math notranslate nohighlight">\(1000 \times 0.0188 \approx 19\)</span> laptops.</p>
<p class="sd-card-text"><strong>Part (d): 70th percentile</strong> — Backward problem</p>
<p class="sd-card-text">From the Z-table, we locate 0.70 in the body: <span class="math notranslate nohighlight">\(\Phi(0.52) = 0.6985\)</span> and <span class="math notranslate nohighlight">\(\Phi(0.53) = 0.7019\)</span>.</p>
<p class="sd-card-text">Since <span class="math notranslate nohighlight">\(|0.70 - 0.6985| = 0.0015 &lt; |0.70 - 0.7019| = 0.0019\)</span>, we use <span class="math notranslate nohighlight">\(z_{0.70} = 0.52\)</span>.</p>
<div class="math notranslate nohighlight">
\[x_{0.70} = 8.5 + 0.52(1.2) = 8.5 + 0.624 = 9.12 \text{ hours}\]</div>
<p class="sd-card-text"><strong>Part (e): Compare unusualness</strong></p>
<p class="sd-card-text">For <span class="math notranslate nohighlight">\(x = 6.5\)</span>: <span class="math notranslate nohighlight">\(z = \frac{6.5 - 8.5}{1.2} = -1.67\)</span></p>
<p class="sd-card-text">For <span class="math notranslate nohighlight">\(x = 10.5\)</span>: <span class="math notranslate nohighlight">\(z = \frac{10.5 - 8.5}{1.2} = 1.67\)</span></p>
<p class="sd-card-text">Both have <span class="math notranslate nohighlight">\(|z| = 1.67\)</span>, so they are <strong>equally unusual</strong>.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 6: Parameter Identification</p>
<p>A normal distribution has specific characteristics. Use these to find the parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<ol class="loweralpha simple">
<li><p>The inflection points of the PDF occur at <span class="math notranslate nohighlight">\(x = 42\)</span> and <span class="math notranslate nohighlight">\(x = 58\)</span>. Find <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>.</p></li>
<li><p>The 16th percentile is 28 and the 84th percentile is 52. Find <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>.</p></li>
<li><p>The distribution has <span class="math notranslate nohighlight">\(P(X &lt; 70) = 0.90\)</span> and <span class="math notranslate nohighlight">\(P(X &lt; 40) = 0.20\)</span>. Find <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>.</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Using inflection points</strong></p>
<p class="sd-card-text">The inflection points of a normal PDF occur at <span class="math notranslate nohighlight">\(\mu - \sigma\)</span> and <span class="math notranslate nohighlight">\(\mu + \sigma\)</span>.</p>
<div class="math notranslate nohighlight">
\[\mu - \sigma = 42 \quad \text{and} \quad \mu + \sigma = 58\]</div>
<p class="sd-card-text">Adding: <span class="math notranslate nohighlight">\(2\mu = 100 \implies \mu = 50\)</span></p>
<p class="sd-card-text">Subtracting: <span class="math notranslate nohighlight">\(2\sigma = 16 \implies \sigma = 8\)</span></p>
<p class="sd-card-text"><strong>Answer</strong>: <span class="math notranslate nohighlight">\(\mu = 50\)</span>, <span class="math notranslate nohighlight">\(\sigma = 8\)</span>.</p>
<figure class="align-center" id="id22">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig6_inflection_points.png"><img alt="Normal distribution with inflection points marked" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig6_inflection_points.png" style="width: 60%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.44 </span><span class="caption-text">Inflection points occur exactly at μ ± σ.</span><a class="headerlink" href="#id22" title="Link to this image"></a></p>
</figcaption>
</figure>
<p class="sd-card-text"><strong>Part (b): Using symmetric percentiles</strong></p>
<p class="sd-card-text">Note that the 16th and 84th percentiles are symmetric about the mean.</p>
<p class="sd-card-text">From the Z-table: <span class="math notranslate nohighlight">\(\Phi(-0.99) = 0.1611\)</span> and <span class="math notranslate nohighlight">\(\Phi(-1.00) = 0.1587\)</span>.</p>
<p class="sd-card-text">Since <span class="math notranslate nohighlight">\(|0.16 - 0.1611| = 0.0011 &lt; |0.16 - 0.1587| = 0.0013\)</span>, we use <span class="math notranslate nohighlight">\(z_{0.16} = -0.99\)</span>.</p>
<p class="sd-card-text">By symmetry, <span class="math notranslate nohighlight">\(z_{0.84} = 0.99\)</span>.</p>
<p class="sd-card-text">This gives us:</p>
<div class="math notranslate nohighlight">
\[\mu - 0.99\sigma = 28 \quad \text{and} \quad \mu + 0.99\sigma = 52\]</div>
<p class="sd-card-text">Adding: <span class="math notranslate nohighlight">\(2\mu = 80 \implies \mu = 40\)</span></p>
<p class="sd-card-text">Subtracting: <span class="math notranslate nohighlight">\(1.98\sigma = 24 \implies \sigma = 12.12\)</span></p>
<p class="sd-card-text"><strong>Answer</strong>: <span class="math notranslate nohighlight">\(\mu = 40\)</span>, <span class="math notranslate nohighlight">\(\sigma \approx 12.1\)</span> (or <span class="math notranslate nohighlight">\(\sigma^2 \approx 147\)</span>).</p>
<p class="sd-card-text"><strong>Part (c): Using two probability statements</strong></p>
<p class="sd-card-text">From <span class="math notranslate nohighlight">\(P(X &lt; 70) = 0.90\)</span>: Looking up 0.90 in the Z-table, <span class="math notranslate nohighlight">\(\Phi(1.28) = 0.8997 \approx 0.90\)</span>, so <span class="math notranslate nohighlight">\(z = 1.28\)</span>.</p>
<p class="sd-card-text">From <span class="math notranslate nohighlight">\(P(X &lt; 40) = 0.20\)</span>: Looking up 0.20, <span class="math notranslate nohighlight">\(\Phi(-0.84) = 0.2005 \approx 0.20\)</span>, so <span class="math notranslate nohighlight">\(z = -0.84\)</span>.</p>
<p class="sd-card-text">Setting up equations:</p>
<div class="math notranslate nohighlight">
\[\frac{70 - \mu}{\sigma} = 1.28 \implies 70 - \mu = 1.28\sigma\]</div>
<div class="math notranslate nohighlight">
\[\frac{40 - \mu}{\sigma} = -0.84 \implies 40 - \mu = -0.84\sigma\]</div>
<p class="sd-card-text">Subtracting the second from the first:</p>
<div class="math notranslate nohighlight">
\[30 = 1.28\sigma + 0.84\sigma = 2.12\sigma \implies \sigma = \frac{30}{2.12} = 14.15\]</div>
<p class="sd-card-text">Substituting back: <span class="math notranslate nohighlight">\(\mu = 70 - 1.28(14.15) = 70 - 18.11 = 51.89\)</span></p>
<p class="sd-card-text"><strong>Answer</strong>: <span class="math notranslate nohighlight">\(\mu \approx 51.9\)</span>, <span class="math notranslate nohighlight">\(\sigma \approx 14.2\)</span> (or <span class="math notranslate nohighlight">\(\sigma^2 \approx 200\)</span>).</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 7: Assessing Normality — Visual Methods</p>
<p>A materials engineer collects 50 measurements of yield strength (MPa) for aluminum alloy specimens. The sample statistics are <span class="math notranslate nohighlight">\(\bar{x} = 275.3\)</span> MPa and <span class="math notranslate nohighlight">\(s = 12.8\)</span> MPa.</p>
<p>The histogram and QQ-plot are shown below.</p>
<figure class="align-center" id="id23">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig7_normality_assessment.png"><img alt="Histogram and QQ-plot for yield strength data" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig7_normality_assessment.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.45 </span><span class="caption-text">Left: Histogram with kernel density (red) and normal curve (blue). Right: Normal QQ-plot.</span><a class="headerlink" href="#id23" title="Link to this image"></a></p>
</figcaption>
</figure>
<ol class="loweralpha simple">
<li><p>Based on the histogram, does the data appear approximately normal? Comment on the alignment of the kernel density curve and the fitted normal curve.</p></li>
<li><p>Interpret the QQ-plot. Do the points follow the reference line reasonably well?</p></li>
<li><p>Identify any specific departures from normality visible in either plot.</p></li>
<li><p>Overall, would you conclude the normality assumption is reasonable for this data?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Histogram interpretation</strong></p>
<p class="sd-card-text">The histogram shows a roughly symmetric, unimodal distribution. The kernel density curve (red) and fitted normal curve (blue) align reasonably well, with both showing a bell-shaped pattern centered near 275 MPa. There is some minor roughness in the kernel density due to sampling variation with n=50, but no obvious skewness (neither tail appears systematically longer than the other).</p>
<p class="sd-card-text"><strong>Part (b): QQ-plot interpretation</strong></p>
<p class="sd-card-text">The QQ-plot shows points that generally follow the reference line from the lower-left to upper-right. Most points fall close to or on the line, suggesting the data quantiles match the theoretical normal quantiles well. There is no systematic curvature (which would indicate skewness) or S-shape (which would indicate heavy/light tails).</p>
<p class="sd-card-text"><strong>Part (c): Specific departures</strong></p>
<p class="sd-card-text">Examining the plots for specific features:</p>
<ul class="simple">
<li><p class="sd-card-text"><strong>Skewness</strong>: No evidence—both tails appear similar in length.</p></li>
<li><p class="sd-card-text"><strong>Outliers</strong>: No points in the QQ-plot are dramatically far from the line.</p></li>
<li><p class="sd-card-text"><strong>Tail behavior</strong>: The extreme points in the QQ-plot do not show systematic curvature at either end.</p></li>
</ul>
<p class="sd-card-text">Minor deviations are expected with n=50 due to sampling variability.</p>
<p class="sd-card-text"><strong>Part (d): Conclusion</strong></p>
<p class="sd-card-text">Based on both visual assessments, the normality assumption appears <strong>reasonable</strong> for this data. The histogram is approximately symmetric and bell-shaped, and the QQ-plot shows points close to the reference line with no systematic patterns of departure.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 8: Assessing Normality — Numerical Methods</p>
<p>For the aluminum alloy data from Exercise 7 (<span class="math notranslate nohighlight">\(n = 50\)</span>, <span class="math notranslate nohighlight">\(\bar{x} = 275.3\)</span> MPa, <span class="math notranslate nohighlight">\(s = 12.8\)</span> MPa), additional sample statistics are provided:</p>
<ul class="simple">
<li><p>Sample IQR: 17.1 MPa</p></li>
<li><p>Observations within <span class="math notranslate nohighlight">\(\bar{x} \pm s\)</span>: 34 out of 50</p></li>
<li><p>Observations within <span class="math notranslate nohighlight">\(\bar{x} \pm 2s\)</span>: 48 out of 50</p></li>
<li><p>Observations within <span class="math notranslate nohighlight">\(\bar{x} \pm 3s\)</span>: 50 out of 50</p></li>
</ul>
<ol class="loweralpha simple">
<li><p>Apply the empirical rule check. Compare the observed proportions to the expected 68-95-99.7 values.</p></li>
<li><p>Compute the IQR-to-standard deviation ratio. Compare to the theoretical value for normal distributions.</p></li>
<li><p>Based on these numerical checks, does the data appear consistent with a normal distribution?</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Part (a): Empirical rule check</strong></p>
<table class="docutils align-center">
<thead>
<tr class="row-odd"><th class="head"><p class="sd-card-text">Interval</p></th>
<th class="head"><p class="sd-card-text">Observed Count</p></th>
<th class="head"><p class="sd-card-text">Observed %</p></th>
<th class="head"><p class="sd-card-text">Expected %</p></th>
<th class="head"><p class="sd-card-text">Difference</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p class="sd-card-text"><span class="math notranslate nohighlight">\(\bar{x} \pm 1s\)</span></p></td>
<td><p class="sd-card-text">34/50</p></td>
<td><p class="sd-card-text">68%</p></td>
<td><p class="sd-card-text">68%</p></td>
<td><p class="sd-card-text">0%</p></td>
</tr>
<tr class="row-odd"><td><p class="sd-card-text"><span class="math notranslate nohighlight">\(\bar{x} \pm 2s\)</span></p></td>
<td><p class="sd-card-text">48/50</p></td>
<td><p class="sd-card-text">96%</p></td>
<td><p class="sd-card-text">95%</p></td>
<td><p class="sd-card-text">+1%</p></td>
</tr>
<tr class="row-even"><td><p class="sd-card-text"><span class="math notranslate nohighlight">\(\bar{x} \pm 3s\)</span></p></td>
<td><p class="sd-card-text">50/50</p></td>
<td><p class="sd-card-text">100%</p></td>
<td><p class="sd-card-text">99.7%</p></td>
<td><p class="sd-card-text">+0.3%</p></td>
</tr>
</tbody>
</table>
<p class="sd-card-text">The observed proportions are remarkably close to the expected values.</p>
<p class="sd-card-text"><strong>Note on sampling variability</strong>: With n=50 observations from a true normal distribution, the count within <span class="math notranslate nohighlight">\(\pm 2\sigma\)</span> follows approximately a Binomial(50, 0.95) distribution. The standard deviation of this count is <span class="math notranslate nohighlight">\(\sqrt{50 \times 0.95 \times 0.05} \approx 1.5\)</span>, so observing 48 instead of the expected 47.5 is well within normal sampling variation.</p>
<p class="sd-card-text"><strong>Part (b): IQR-to-SD ratio</strong></p>
<div class="math notranslate nohighlight">
\[\frac{\text{IQR}}{s} = \frac{17.1}{12.8} = 1.336\]</div>
<p class="sd-card-text">For a normal distribution, the theoretical ratio is approximately <strong>1.35</strong>.</p>
<p class="sd-card-text">The observed ratio (1.336) is very close to the expected value, indicating consistency with normality.</p>
<p class="sd-card-text"><strong>Part (c): Conclusion</strong></p>
<p class="sd-card-text">Yes, the numerical checks strongly support normality:</p>
<ul class="simple">
<li><p class="sd-card-text">Empirical rule proportions match almost exactly (68%, 96%, 100% vs. 68%, 95%, 99.7%)</p></li>
<li><p class="sd-card-text">IQR/SD ratio (1.336) is very close to the theoretical 1.35</p></li>
</ul>
<p class="sd-card-text">Combined with the visual assessments from Exercise 7, we have <strong>strong evidence</strong> that the normality assumption is appropriate.</p>
</div>
</details></div>
<hr class="docutils" />
<div class="note admonition">
<p class="admonition-title">Exercise 9: Identifying Non-Normal Distributions</p>
<p>Four datasets have been analyzed with QQ-plots shown below. Match each QQ-plot pattern to the appropriate description of the underlying distribution.</p>
<figure class="align-center" id="id24">
<a class="reference internal image-reference" href="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig9_qq_patterns.png"><img alt="Four QQ-plots showing different departures from normality" src="https://yjjpfnblgtrogqvcjaon.supabase.co/storage/v1/object/public/stat-350-assets/Exercises/ch6-4/fig9_qq_patterns.png" style="width: 90%;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 6.46 </span><span class="caption-text">Four QQ-plots: (A) upper-left, (B) upper-right, (C) lower-left, (D) lower-right.</span><a class="headerlink" href="#id24" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Match each plot (A, B, C, D) with one of these descriptions:</p>
<ol class="arabic simple">
<li><p>Right-skewed distribution (long right tail)</p></li>
<li><p>Left-skewed distribution (long left tail)</p></li>
<li><p>Heavy-tailed distribution (more extreme values than normal)</p></li>
<li><p>Approximately normal distribution</p></li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Solution</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>Plot A: Approximately normal distribution (Description 4)</strong></p>
<p class="sd-card-text">The points fall close to the reference line throughout, indicating the sample quantiles match the theoretical normal quantiles well.</p>
<p class="sd-card-text"><strong>Plot B: Right-skewed distribution (Description 1)</strong></p>
<p class="sd-card-text">The points curve upward (concave up) away from the reference line. This indicates:</p>
<ul class="simple">
<li><p class="sd-card-text">Lower quantiles match well</p></li>
<li><p class="sd-card-text">Upper quantiles are larger than expected for a normal</p></li>
<li><p class="sd-card-text">The right tail is stretched out (right/positive skew)</p></li>
</ul>
<p class="sd-card-text"><strong>Plot C: Left-skewed distribution (Description 2)</strong></p>
<p class="sd-card-text">The points curve downward (concave down) away from the reference line. This indicates:</p>
<ul class="simple">
<li><p class="sd-card-text">Lower quantiles are smaller than expected</p></li>
<li><p class="sd-card-text">Upper quantiles match reasonably</p></li>
<li><p class="sd-card-text">The left tail is stretched out (left/negative skew)</p></li>
</ul>
<p class="sd-card-text"><strong>Plot D: Heavy-tailed distribution (Description 3)</strong></p>
<p class="sd-card-text">The points form an S-shape:</p>
<ul class="simple">
<li><p class="sd-card-text">Lower quantiles fall below the line (more extreme negative values than normal)</p></li>
<li><p class="sd-card-text">Upper quantiles rise above the line (more extreme positive values than normal)</p></li>
<li><p class="sd-card-text">Both tails are heavier than a normal distribution</p></li>
</ul>
<p class="sd-card-text"><strong>Summary Table:</strong></p>
<table class="docutils align-center">
<thead>
<tr class="row-odd"><th class="head"><p class="sd-card-text">Plot</p></th>
<th class="head"><p class="sd-card-text">Pattern</p></th>
<th class="head"><p class="sd-card-text">Distribution Type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p class="sd-card-text">A</p></td>
<td><p class="sd-card-text">Points on line</p></td>
<td><p class="sd-card-text">Normal</p></td>
</tr>
<tr class="row-odd"><td><p class="sd-card-text">B</p></td>
<td><p class="sd-card-text">Concave up (curved up)</p></td>
<td><p class="sd-card-text">Right-skewed</p></td>
</tr>
<tr class="row-even"><td><p class="sd-card-text">C</p></td>
<td><p class="sd-card-text">Concave down (curved down)</p></td>
<td><p class="sd-card-text">Left-skewed</p></td>
</tr>
<tr class="row-odd"><td><p class="sd-card-text">D</p></td>
<td><p class="sd-card-text">S-shaped</p></td>
<td><p class="sd-card-text">Heavy-tailed</p></td>
</tr>
</tbody>
</table>
</div>
</details></div>
</section>
<hr class="docutils" />
<section id="additional-practice-problems">
<h2><span class="section-number">6.4.14. </span>Additional Practice Problems<a class="headerlink" href="#additional-practice-problems" title="Link to this heading"></a></h2>
<p><strong>True/False Questions</strong> (1 point each)</p>
<ol class="arabic">
<li><p>For any normal distribution, the mean equals the median.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>If <span class="math notranslate nohighlight">\(X \sim N(100, 25)\)</span>, then the standard deviation is 5.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>A z-score of -1.5 indicates a value 1.5 standard deviations below the mean.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>For a standard normal distribution, <span class="math notranslate nohighlight">\(P(Z &gt; 0) = 0.5\)</span>.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>The inflection points of a normal PDF occur at <span class="math notranslate nohighlight">\(\mu \pm 2\sigma\)</span>.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>If <span class="math notranslate nohighlight">\(X \sim N(\mu, \sigma^2)\)</span>, then <span class="math notranslate nohighlight">\(P(X &lt; \mu) = 0.5\)</span>.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>A QQ-plot that curves upward indicates left-skewed data.</p>
<p>Ⓣ or Ⓕ</p>
</li>
<li><p>For normal distributions, the IQR is approximately 1.35 times the standard deviation.</p>
<p>Ⓣ or Ⓕ</p>
</li>
</ol>
<p><strong>Multiple Choice Questions</strong> (2 points each)</p>
<ol class="arabic" start="9">
<li><p>For <span class="math notranslate nohighlight">\(X \sim N(50, 100)\)</span>, what is <span class="math notranslate nohighlight">\(P(X &lt; 60)\)</span>?</p>
<p>Ⓐ 0.6915</p>
<p>Ⓑ 0.8413</p>
<p>Ⓒ 0.9332</p>
<p>Ⓓ 0.9772</p>
</li>
<li><p>If <span class="math notranslate nohighlight">\(Z \sim N(0, 1)\)</span> and <span class="math notranslate nohighlight">\(P(Z &lt; z) = 0.75\)</span>, what is <span class="math notranslate nohighlight">\(z\)</span>?</p>
<p>Ⓐ 0.25</p>
<p>Ⓑ 0.67</p>
<p>Ⓒ 0.75</p>
<p>Ⓓ 1.15</p>
</li>
<li><p>A normal distribution has <span class="math notranslate nohighlight">\(\mu = 80\)</span> and <span class="math notranslate nohighlight">\(\sigma = 10\)</span>. What value has a z-score of -2?</p>
<p>Ⓐ 60</p>
<p>Ⓑ 70</p>
<p>Ⓒ 78</p>
<p>Ⓓ 100</p>
</li>
<li><p>According to the empirical rule, approximately what percentage of values fall more than 2 standard deviations from the mean?</p>
<p>Ⓐ 2.5%</p>
<p>Ⓑ 5%</p>
<p>Ⓒ 32%</p>
<p>Ⓓ 95%</p>
</li>
<li><p>For <span class="math notranslate nohighlight">\(X \sim N(200, 400)\)</span>, what is the 95th percentile?</p>
<p>Ⓐ 212.8</p>
<p>Ⓑ 225.8</p>
<p>Ⓒ 232.9</p>
<p>Ⓓ 265.8</p>
</li>
<li><p>Which QQ-plot pattern indicates heavy tails?</p>
<p>Ⓐ Points curve upward (concave up)</p>
<p>Ⓑ Points curve downward (concave down)</p>
<p>Ⓒ S-shaped pattern (low points below line, high points above)</p>
<p>Ⓓ Points fall exactly on the reference line</p>
</li>
</ol>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3 sd-border-success">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">Answers to Practice Problems</span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text"><strong>True/False Answers:</strong></p>
<ol class="arabic simple">
<li><p class="sd-card-text"><strong>True</strong> — Normal distributions are perfectly symmetric, so mean = median.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — In the notation <span class="math notranslate nohighlight">\(N(\mu, \sigma^2)\)</span>, the second parameter is variance. Since <span class="math notranslate nohighlight">\(\sigma^2 = 25\)</span>, we have <span class="math notranslate nohighlight">\(\sigma = \sqrt{25} = 5\)</span>.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — A z-score represents the number of standard deviations from the mean. Negative z-scores are below the mean.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — By symmetry around 0, exactly half the probability is above 0 and half below.</p></li>
<li><p class="sd-card-text"><strong>False</strong> — Inflection points occur at <span class="math notranslate nohighlight">\(\mu \pm \sigma\)</span> (one standard deviation), not two.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — By symmetry, exactly 50% of the distribution falls below the mean.</p></li>
<li><p class="sd-card-text"><strong>False</strong> — A QQ-plot that curves upward (concave up) indicates <strong>right-skewed</strong> data. Left-skewed data produces a concave-down pattern.</p></li>
<li><p class="sd-card-text"><strong>True</strong> — For normal distributions, IQR ≈ 1.35σ (specifically, 1.348σ).</p></li>
</ol>
<p class="sd-card-text"><strong>Multiple Choice Answers:</strong></p>
<ol class="arabic simple" start="9">
<li><p class="sd-card-text"><strong>Ⓑ</strong> — <span class="math notranslate nohighlight">\(\sigma = \sqrt{100} = 10\)</span>, so <span class="math notranslate nohighlight">\(z = \frac{60-50}{10} = 1.0\)</span>. From the table: <span class="math notranslate nohighlight">\(\Phi(1.00) = 0.8413\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — Looking up 0.75 in the Z-table body: <span class="math notranslate nohighlight">\(\Phi(0.67) = 0.7486\)</span> and <span class="math notranslate nohighlight">\(\Phi(0.68) = 0.7517\)</span>. Since 0.7486 is closer to 0.75, <span class="math notranslate nohighlight">\(z \approx 0.67\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓐ</strong> — <span class="math notranslate nohighlight">\(x = \mu + z\sigma = 80 + (-2)(10) = 60\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓑ</strong> — 95% fall within ±2σ, so 5% fall outside (more than 2 SD from mean).</p></li>
<li><p class="sd-card-text"><strong>Ⓒ</strong> — <span class="math notranslate nohighlight">\(\sigma = \sqrt{400} = 20\)</span>. For <span class="math notranslate nohighlight">\(z_{0.95}\)</span>: <span class="math notranslate nohighlight">\(\Phi(1.64) = 0.9495\)</span> and <span class="math notranslate nohighlight">\(\Phi(1.65) = 0.9505\)</span>. Since 0.95 is exactly halfway, <span class="math notranslate nohighlight">\(z_{0.95} = 1.645\)</span>. Thus <span class="math notranslate nohighlight">\(x_{0.95} = 200 + 1.645(20) = 232.9\)</span>.</p></li>
<li><p class="sd-card-text"><strong>Ⓒ</strong> — Heavy tails produce an S-shaped pattern where both extremes deviate from the line in opposite directions.</p></li>
</ol>
</div>
</details></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="6-3-cdfs.html" class="btn btn-neutral float-left" title="6.3. Cumulative Distribution Functions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="6-5-uniform-distribution.html" class="btn btn-neutral float-right" title="6.5. Uniform Distribution" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
  <p class="footer-credits-inline">
    <strong>Website Credits:</strong>
    Website development by Dr. Timothy Reese and Halin Shin.
    Generative AI tools were used to draft and refine some prose, code, and documentation; all content was reviewed by the instructors.
    Models: OpenAI o3 (2025-04-16 release) and Anthropic Claude Opus 4.1 (2025-08-05).
  </p>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 

<!-- Floating Chat Button -->
<button id="chatbot-toggle" class="chatbot-fab" aria-label="Open AI Course Assistant" aria-expanded="false">
  <span class="chatbot-fab-badge">BETA</span>
  <svg class="chatbot-fab-icon chatbot-icon-open" fill="none" stroke="currentColor" viewBox="0 0 24 24">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
          d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"/>
  </svg>
  <svg class="chatbot-fab-icon chatbot-icon-close" fill="none" stroke="currentColor" viewBox="0 0 24 24" style="display:none;">
    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
  </svg>
  <span class="chatbot-fab-text">Ask AI Assistant</span>
</button>

<!-- Chat Panel - Fullscreen -->
<div id="chatbot-panel" class="chatbot-panel" aria-hidden="true">
  <div class="chatbot-panel-topbar">
    <button id="chatbot-close" class="chatbot-panel-close-minimal" aria-label="Close chat">
      <svg width="24" height="24" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/>
      </svg>
    </button>
    <a href="https://advert-cingular-employer-humor.trycloudflare.com/" 
       target="_blank" 
       rel="noopener noreferrer" 
       class="chatbot-newtab">
      <svg width="16" height="16" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" 
              d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"/>
      </svg>
      Open in new tab
    </a>
  </div>
  <iframe id="chatbot-iframe" class="chatbot-iframe" title="STAT 350 AI Course Assistant"></iframe>
</div>

<script>
(function() {
  const CHATBOT_BASE_URL = 'https://advert-cingular-employer-humor.trycloudflare.com/';
  
  const toggle = document.getElementById('chatbot-toggle');
  const panel = document.getElementById('chatbot-panel');
  const closeBtn = document.getElementById('chatbot-close');
  const iframe = document.getElementById('chatbot-iframe');
  const iconOpen = toggle.querySelector('.chatbot-icon-open');
  const iconClose = toggle.querySelector('.chatbot-icon-close');
  
  let isOpen = false;
  let iframeLoaded = false;
  
  function getPageContext() {
    const pageTitle = document.title || '';
    const pageUrl = window.location.href;
    const pagePath = window.location.pathname;
    
    const h1 = document.querySelector('.rst-content h1, h1');
    const heading = h1 ? h1.textContent.replace(/[¶#]/g, '').trim() : '';
    
    const breadcrumbs = document.querySelectorAll('.wy-breadcrumbs li a');
    const breadcrumbPath = Array.from(breadcrumbs).map(a => a.textContent.trim()).join(' > ');
    
    const chapterMatch = pagePath.match(/chapter(\d+)/i);
    const chapter = chapterMatch ? 'Chapter ' + chapterMatch[1] : '';
    
    return {
      title: heading || pageTitle,
      url: pageUrl,
      path: pagePath,
      breadcrumbs: breadcrumbPath,
      chapter: chapter
    };
  }
  
  function buildChatbotUrl(context) {
    const params = new URLSearchParams();
    if (context.title) params.set('page_title', context.title);
    if (context.url) params.set('page_url', context.url);
    if (context.chapter) params.set('chapter', context.chapter);
    if (context.breadcrumbs) params.set('breadcrumbs', context.breadcrumbs);
    
    const queryString = params.toString();
    return queryString ? CHATBOT_BASE_URL + '?' + queryString : CHATBOT_BASE_URL;
  }
  
  function openChat() {
    const context = getPageContext();
    
    const newUrl = buildChatbotUrl(context);
    if (!iframeLoaded || iframe.dataset.lastUrl !== context.url) {
      iframe.src = newUrl;
      iframe.dataset.lastUrl = context.url;
      iframeLoaded = true;
    }
    
    panel.classList.add('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'false');
    toggle.setAttribute('aria-expanded', 'true');
    iconOpen.style.display = 'none';
    iconClose.style.display = 'block';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Close';
    isOpen = true;
    
    toggle.classList.add('chatbot-fab-opened');
    
    // Prevent body scroll when panel is open
    document.body.style.overflow = 'hidden';
  }
  
  function closeChat() {
    panel.classList.remove('chatbot-panel-open');
    panel.setAttribute('aria-hidden', 'true');
    toggle.setAttribute('aria-expanded', 'false');
    iconOpen.style.display = 'block';
    iconClose.style.display = 'none';
    toggle.querySelector('.chatbot-fab-text').textContent = 'Ask AI Assistant';
    isOpen = false;
    
    // Restore body scroll
    document.body.style.overflow = '';
  }
  
  function toggleChat() {
    if (isOpen) {
      closeChat();
    } else {
      openChat();
    }
  }
  
  toggle.addEventListener('click', toggleChat);
  closeBtn.addEventListener('click', closeChat);
  
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape' && isOpen) {
      closeChat();
    }
  });
})();
</script>


</body>
</html>