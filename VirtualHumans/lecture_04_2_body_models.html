

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Lecture 04.2 - Body Models: Vertex-Based Models and SMPL &mdash; Fitting SMPL to IMU Optimization</title>
      <link rel="stylesheet" type="text/css" href="/VirtualHumans/_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="/VirtualHumans/_static/css/theme.css?v=e59714d7" />

  
    <link rel="canonical" href="https://treese41528.github.io/VirtualHumans/lecture_04_2_body_models.html" />
      <script src="/VirtualHumans/_static/jquery.js?v=5d32c60e"></script>
      <script src="/VirtualHumans/_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="/VirtualHumans/_static/documentation_options.js?v=f2a433a1"></script>
      <script src="/VirtualHumans/_static/doctools.js?v=9bcbadda"></script>
      <script src="/VirtualHumans/_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="/VirtualHumans/_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Lecture 5.1 - Training a Body Model and Fitting SMPL to Scans" href="lecture_05_1_body_model_training.html" />
    <link rel="prev" title="Lecture 4.1: Iterative Closest Point" href="lecture_04_1_icp.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Virtual Humans Lecture
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="lecture_01_1_historical_body_models.html">Lecture 01.1 – Historical Body Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#early-origins-simplified-primitives-and-kinematic-skeletons-1970s1980s">Early Origins: Simplified Primitives and Kinematic Skeletons (1970s–1980s)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#advances-in-the-1990s-superquadrics-differentiable-fitting-and-physical-models">Advances in the 1990s: Superquadrics, Differentiable Fitting, and Physical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#the-impact-of-3d-scanning-and-data-from-anthropometry-to-statistical-models-1990s2000s">The Impact of 3D Scanning and Data: From Anthropometry to Statistical Models (1990s–2000s)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#scape-and-the-emergence-of-pose-aware-models-mid-2000s">SCAPE and the Emergence of Pose-Aware Models (Mid-2000s)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#consolidation-in-the-2010s-smpl-and-integration-with-learning-based-methods">Consolidation in the 2010s: SMPL and Integration with Learning-Based Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#deep-learning-and-neural-implicit-models-late-2010spresent">Deep Learning and Neural Implicit Models (Late 2010s–Present)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#timeline-summary-of-milestones">Timeline Summary of Milestones</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html">Lecture 01.2 – Introduction to Human Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#historical-context-of-human-body-modeling">1. Historical Context of Human Body Modeling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#early-developments">Early Developments</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#mid-20th-century-approaches">Mid-20th Century Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#data-driven-revolution-1990s-2000s">Data-Driven Revolution (1990s-2000s)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#mathematical-foundations-of-human-body-models">2. Mathematical Foundations of Human Body Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#the-smpl-model">The SMPL Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#pca-based-statistical-shape-modeling">PCA-Based Statistical Shape Modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#kinematic-modeling">Kinematic Modeling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#applications-of-human-body-models">3. Applications of Human Body Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#computer-animation-and-visual-effects">Computer Animation and Visual Effects</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#virtual-humans-and-avatars">Virtual Humans and Avatars</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#biomechanics-and-ergonomics">Biomechanics and Ergonomics</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#human-computer-interaction-hci">Human-Computer Interaction (HCI)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#computer-vision-and-ai">Computer Vision and AI</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#education-and-training">Education and Training</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#challenges-and-future-directions">4. Challenges and Future Directions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#computational-efficiency">Computational Efficiency</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#accuracy-and-detail">Accuracy and Detail</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#generalization">Generalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#clothing-and-accessories">Clothing and Accessories</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#emerging-approaches">Emerging Approaches</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html">Lecture 01.3 – Introduction to Human Models (Overview)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#historical-context">1. Historical Context</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#early-scientific-studies">Early Scientific Studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#mid-20th-century-to-digital-era">Mid-20th Century to Digital Era</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#st-century-advances">21st Century Advances</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#mathematical-foundations">2. Mathematical Foundations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#parametric-body-models">Parametric Body Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#implicit-surface-representations">Implicit Surface Representations</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#kinematic-modeling">Kinematic Modeling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#image-formation-and-rendering">3. Image Formation and Rendering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#camera-models">Camera Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#shading-and-visibility">Shading and Visibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#differentiable-rendering">Differentiable Rendering</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#surface-representation-methods">4. Surface Representation Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#explicit-mesh-models">Explicit Mesh Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#implicit-function-models">Implicit Function Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#motion-capture-and-behavior-synthesis">5. Motion Capture and Behavior Synthesis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#capturing-human-motion">Capturing Human Motion</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#behavior-synthesis">Behavior Synthesis</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#clothing-modeling">6. Clothing Modeling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#physically-based-simulation">Physically-Based Simulation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#data-driven-approaches">Data-Driven Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#implicit-clothing-models">Implicit Clothing Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#human-object-interaction">7. Human-Object Interaction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#physics-based-methods">Physics-Based Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#learning-based-approaches">Learning-Based Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#hybrid-systems">Hybrid Systems</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#applications">8. Applications</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#entertainment-and-media">Entertainment and Media</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#healthcare-and-biomechanics">Healthcare and Biomechanics</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#engineering-and-design">Engineering and Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#human-computer-interaction">Human-Computer Interaction</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#scientific-research">Scientific Research</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#challenges-and-future-directions">9. Challenges and Future Directions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#scalability-and-generalization">Scalability and Generalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#higher-fidelity-dynamics">Higher-Fidelity Dynamics</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#data-and-labeling-constraints">Data and Labeling Constraints</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#physics-and-learning-integration">Physics and Learning Integration</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#semantic-and-cognitive-aspects">Semantic and Cognitive Aspects</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_3_introduction_to_human_models_continued.html#realism-vs-controllability">Realism vs. Controllability</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_02_1_image_formation.html">Lecture 02.1 – Image Formation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#historical-developments-in-image-formation">1. Historical Developments in Image Formation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#ancient-and-medieval-optics-camera-obscura">Ancient and Medieval Optics – Camera Obscura</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#renaissance-perspective-and-geometry">Renaissance Perspective and Geometry</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#early-cameras-and-photographic-imaging">Early Cameras and Photographic Imaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#modern-developments">Modern Developments</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#the-pinhole-camera-model">2. The Pinhole Camera Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#coordinate-setup">Coordinate Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#proof-by-similar-triangles">Proof by Similar Triangles</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#numerical-example">Numerical Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#inadequacy-of-a-simple-pinhole">Inadequacy of a Simple Pinhole</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#camera-intrinsics-and-the-projection-matrix">3. Camera Intrinsics and the Projection Matrix</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#extrinsic-parameters">Extrinsic Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#full-projection-example">Full Projection Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#image-distortions-correction">4. Image Distortions &amp; Correction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#properties-of-perspective-projection">5. Properties of Perspective Projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#advanced-theoretical-extensions">6. Advanced Theoretical Extensions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#light-field-imaging-and-plenoptic-cameras">Light Field Imaging and Plenoptic Cameras</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#non-conventional-imaging-techniques">Non-Conventional Imaging Techniques</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#applications-in-modern-vision-and-graphics">7. Applications in Modern Vision and Graphics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#computer-vision-and-3d-reconstruction">Computer Vision and 3D Reconstruction</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#medical-imaging">Medical Imaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#photorealistic-rendering-in-computer-graphics">Photorealistic Rendering in Computer Graphics</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#python-example-simulating-image-formation">8. Python Example: Simulating Image Formation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html">Lecture 02.2 – Rotations and Kinematic Chains</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#representations-of-3d-rotations">1. Representations of 3D Rotations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#a-rotation-matrices">A) Rotation Matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#b-euler-angles">B) Euler Angles</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#c-quaternions">C) Quaternions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#lie-algebra-so-3-and-exponential-map">2. Lie Algebra <span class="math notranslate nohighlight">\(so(3)\)</span> and Exponential Map</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#rodrigues-rotation-formula">3. Rodrigues’ Rotation Formula</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#kinematic-chains-forward-inverse-kinematics">4. Kinematic Chains: Forward &amp; Inverse Kinematics</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#comparison-of-rotation-representations">Comparison of Rotation Representations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_03_1_surface_representations.html">Lecture 03.1 – Surface Representations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#mathematical-foundations-of-surface-representations">1. Mathematical Foundations of Surface Representations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-parametric-surfaces">A) Parametric Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-implicit-surfaces">B) Implicit Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-explicit-surfaces">C) Explicit Surfaces</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#surface-differential-properties">2. Surface Differential Properties</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-surface-normals">A) Surface Normals</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-fundamental-forms-and-curvature">B) Fundamental Forms and Curvature</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-geodesics">C) Geodesics</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#discrete-surface-representations">3. Discrete Surface Representations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-polygon-meshes">A) Polygon Meshes</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-point-clouds">B) Point Clouds</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-signed-distance-fields-sdf">C) Signed Distance Fields (SDF)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#advanced-surface-representations">4. Advanced Surface Representations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-bezier-curves-and-surfaces">A) Bézier Curves and Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-b-splines-and-nurbs">B) B-Splines and NURBS</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-subdivision-surfaces">C) Subdivision Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#d-level-sets">D) Level Sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#e-neural-implicit-representations">E) Neural Implicit Representations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#comparative-analysis-and-applications">5. Comparative Analysis and Applications</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-computational-efficiency-and-storage">A) Computational Efficiency and Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-practical-applications">B) Practical Applications</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-operations-complexity">C) Operations Complexity</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#implementation-examples">6. Implementation Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-basic-mesh-processing-python">A) Basic Mesh Processing (Python)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-implicit-surface-utilities">B) Implicit Surface Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-bezier-curve-implementation">C) Bézier Curve Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#d-curvature-estimation-on-meshes">D) Curvature Estimation on Meshes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#advanced-topics-and-future-directions">7. Advanced Topics and Future Directions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-multi-resolution-representations">A) Multi-Resolution Representations</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-machine-learning-for-geometry">B) Machine Learning for Geometry</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-dynamic-surfaces">C) Dynamic Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#d-non-manifold-geometries">D) Non-Manifold Geometries</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html">Lecture 03.2 – Procrustes Alignment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#goal-learning-a-model-of-pose-and-shape">Goal: Learning a Model of Pose and Shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#the-challenge-of-registration">The Challenge of Registration</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#surface-representation-mesh">Surface Representation: Mesh</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#the-procrustes-alignment-problem-mathematical-formulation">The Procrustes Alignment Problem: Mathematical Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#rigid-transformations">Rigid Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#procrustes-alignment-solution">Procrustes Alignment Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#decoupling-translation-by-centroid-alignment">Decoupling Translation by Centroid Alignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#optimal-rotation-via-svd">Optimal Rotation via SVD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#reflection-adjustment">Reflection Adjustment</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#optimal-scale-optional">Optimal Scale (Optional)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#complete-mathematical-derivation">Complete Mathematical Derivation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#translation-derivation">Translation Derivation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#rotation-derivation">Rotation Derivation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#scale-derivation">Scale Derivation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#summary-of-procrustes-alignment-algorithm">Summary of Procrustes Alignment Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#python-implementation-example">Python Implementation Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#practical-applications">Practical Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#interactive-visualization-ideas">Interactive Visualization Ideas</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_04_1_icp.html">Lecture 4.1: Iterative Closest Point</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#introduction-to-shape-alignment-and-registration">Introduction to Shape Alignment and Registration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#the-registration-problem">The Registration Problem</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#review-procrustes-analysis">Review: Procrustes Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#problem-unknown-correspondences">Problem: Unknown Correspondences</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#the-iterative-closest-point-icp-algorithm">The Iterative Closest Point (ICP) Algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#basic-icp-algorithm">Basic ICP Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#computational-considerations">Computational Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="lecture_04_1_icp.html#closest-point-computation">Closest Point Computation</a></li>
<li class="toctree-l4"><a class="reference internal" href="lecture_04_1_icp.html#convergence-and-local-minima">Convergence and Local Minima</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#point-to-point-vs-point-to-plane-icp">Point-to-Point vs. Point-to-Plane ICP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#point-to-point-icp">Point-to-Point ICP</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#point-to-plane-icp">Point-to-Plane ICP</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#gradient-based-icp-for-non-rigid-registration">Gradient-based ICP for Non-Rigid Registration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#gradient-based-icp-algorithm">Gradient-based ICP Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#advantages-of-gradient-based-icp">Advantages of Gradient-based ICP</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#computing-gradients">Computing Gradients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#improving-icp-s-robustness">Improving ICP’s Robustness</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#data-association-direction">Data Association Direction</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#robust-cost-functions">Robust Cost Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#trimmed-icp">Trimmed ICP</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#ransac-based-approaches">RANSAC-based Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#additional-information">Additional Information</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#point-to-surface-distance">Point-to-Surface Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#icp-variants-and-extensions">ICP Variants and Extensions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#generalized-icp-gicp">Generalized ICP (GICP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#em-icp-and-probabilistic-approaches">EM-ICP and Probabilistic Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#coherent-point-drift-cpd">Coherent Point Drift (CPD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#multi-scale-approaches">Multi-Scale Approaches</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#applications-of-icp">Applications of ICP</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#implementing-icp">Implementing ICP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#efficient-python-implementation">Efficient Python Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#practical-tips">Practical Tips</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Lecture 04.2 - Body Models: Vertex-Based Models and SMPL</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#body-models-as-parameterized-functions">1. Body Models as Parameterized Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rotations-articulation-and-pose-representation">2. Rotations, Articulation, and Pose Representation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#rotation-representation">2.1 Rotation Representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kinematic-chain">2.2 Kinematic Chain</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#linear-blend-skinning-and-its-limitations">3. Linear Blend Skinning and its Limitations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#linear-blend-skinning">3.1 Linear Blend Skinning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#problems-with-standard-lbs">3.2 Problems with Standard LBS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#blend-shapes-for-correcting-lbs-artifacts">3.3 Blend Shapes for Correcting LBS Artifacts</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#the-smpl-body-model">4. The SMPL Body Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#smpl-philosophy">4.1 SMPL Philosophy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#smpl-model-architecture">4.2 SMPL Model Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="#shape-blend-shapes">4.2.1 Shape Blend Shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pose-blend-shapes">4.2.2 Pose Blend Shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#joint-regression">4.2.3 Joint Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-training">4.3 Model Training</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#comparison-with-scape">5. Comparison with SCAPE</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-scape-model">5.1 The SCAPE Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#different-approaches-to-deformation">5.2 Different Approaches to Deformation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-comparison">5.3 Performance Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other-advantages">5.4 Other Advantages</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#alignment-techniques-procrustes-analysis-and-icp">6. Alignment Techniques: Procrustes Analysis and ICP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#procrustes-analysis">6.1 Procrustes Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="#iterative-closest-point-icp">6.2 Iterative Closest Point (ICP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fitting-smpl-to-scans">6.3 Fitting SMPL to Scans</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#image-formation-and-the-pinhole-camera-model">7. Image Formation and the Pinhole Camera Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-pinhole-camera-model">7.1 The Pinhole Camera Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lens-distortion">7.2 Lens Distortion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#extensions-and-advanced-applications">8. Extensions and Advanced Applications</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dynamic-soft-tissue-modeling">8.1 Dynamic Soft Tissue Modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#specialized-extensions">8.2 Specialized Extensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deep-learning-for-model-fitting">8.3 Deep Learning for Model Fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="#probabilistic-approaches">8.4 Probabilistic Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hybrid-models">8.5 Hybrid Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_05_1_body_model_training.html">Lecture 5.1 - Training a Body Model and Fitting SMPL to Scans</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#body-models-based-on-triangle-deformations">Body Models Based on Triangle Deformations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#scape-and-blendscape-models">SCAPE and BlendSCAPE Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#triangle-deformation-process">Triangle Deformation Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#comparison-smpl-vs-scape-blendscape">Comparison: SMPL vs. SCAPE/BlendSCAPE</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#training-a-body-model-from-registrations">Training a Body Model from Registrations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#the-challenge-of-raw-scan-data">The Challenge of Raw Scan Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#training-from-registrations">Training from Registrations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#obtaining-registrations-fitting-smpl-to-scans">Obtaining Registrations: Fitting SMPL to Scans</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#non-rigid-registration-process">Non-Rigid Registration Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#iterative-closest-point-icp-review">Iterative Closest Point (ICP) Review</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#registration-objective-formulation">Registration Objective Formulation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#point-to-surface-distance">Point-to-Surface Distance</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#multi-stage-optimization-strategy">Multi-Stage Optimization Strategy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#joint-registration-and-model-training">Joint Registration and Model Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#co-registration-approach">Co-Registration Approach</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_05_2_3d_registration.html">Lecture 05.2 - 3D Registration: From Classical ICP to Modern Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_2_3d_registration.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_2_3d_registration.html#rigid-registration-and-the-icp-algorithm">1. Rigid Registration and the ICP Algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#the-iterative-closest-point-icp-algorithm">The Iterative Closest Point (ICP) Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#convergence-analysis-and-failure-modes">Convergence Analysis and Failure Modes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_2_3d_registration.html#classical-non-rigid-registration">2. Classical Non-Rigid Registration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#thin-plate-spline-robust-point-matching-tps-rpm">Thin Plate Spline Robust Point Matching (TPS-RPM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#coherent-point-drift-cpd">Coherent Point Drift (CPD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#other-non-rigid-methods">Other Non-Rigid Methods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_2_3d_registration.html#parametric-models-and-the-smpl-body-model">3. Parametric Models and the SMPL Body Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#model-structure">Model Structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#shape-blend-shapes-identity-variation">Shape Blend Shapes (Identity Variation)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#pose-blend-shapes-pose-dependent-deformation">Pose Blend Shapes (Pose-Dependent Deformation)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#linear-blend-skinning-lbs-for-articulation">Linear Blend Skinning (LBS) for Articulation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#learning-smpl">Learning SMPL</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#using-smpl-for-registration">Using SMPL for Registration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_2_3d_registration.html#modeling-clothing-and-fine-details-smpl-d">4. Modeling Clothing and Fine Details: SMPL+D</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#why-smpl-d">Why SMPL+D?</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#how-displacements-are-applied">How Displacements Are Applied</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#limitations">Limitations</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#applications">Applications</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_2_3d_registration.html#survey-of-3d-registration-methods-from-icp-to-deep-learning">5. Survey of 3D Registration Methods: From ICP to Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#early-pioneering-works-1990s-foundational-rigid-registration">5.1 Early Pioneering Works (1990s) – Foundational Rigid Registration</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#the-2000s-robust-and-non-rigid-registration-emerges">5.2 The 2000s – Robust and Non-Rigid Registration Emerges</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#s-template-based-and-parametric-model-registration">5.3 2010s – Template-based and Parametric Model Registration</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_2_3d_registration.html#s-learning-based-parametric-registration-and-hybrid-approaches">5.4 2020s – Learning-Based Parametric Registration and Hybrid Approaches</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_2_3d_registration.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html">Lecture 06.1 - Fitting the SMPL Model to Images via Optimization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#mathematical-background-pinhole-camera-and-projections">Mathematical Background: Pinhole Camera and Projections</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#perspective-projection">Perspective Projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#weak-perspective-projection">Weak-Perspective Projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#camera-extrinsics-vs-model-pose">Camera Extrinsics vs. Model Pose</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#d-keypoints-and-projection">2D Keypoints and Projection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#the-smpl-model-as-a-differentiable-function-of-shape-and-pose">The SMPL Model as a Differentiable Function of Shape and Pose</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#shape-blend-shapes">Shape Blend Shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#pose-blend-shapes">Pose Blend Shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#joint-positions">Joint Positions</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#linear-blend-skinning">Linear Blend Skinning</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#differentiability-of-smpl">Differentiability of SMPL</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#fitting-smpl-to-images-via-optimization-smplify">Fitting SMPL to Images via Optimization (SMPLify)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#objective-function">Objective Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#combined-objective">Combined Objective</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#optimization-strategy">Optimization Strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#optimization-algorithms">Optimization Algorithms</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#automatic-differentiation-and-jacobians">Automatic Differentiation and Jacobians</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#result-of-smplify">Result of SMPLify</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#historical-progression-and-method-comparisons">Historical Progression and Method Comparisons</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#smplify-bogo-et-al-2016">SMPLify (Bogo et al. 2016)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_1_SMPL_optimization.html#smplify-x-2019">SMPLify-X (2019)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html">Lecture 06.2 - Learning-Based Fitting of the SMPL Model to Images</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#foundations-of-learning-based-smpl-estimation">Foundations of Learning-Based SMPL Estimation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#integrating-smpl-into-neural-networks">Integrating SMPL into Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#projection-functions">Projection Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#loss-functions">Loss Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#statistical-priors-and-adversarial-losses">Statistical Priors and Adversarial Losses</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#early-regression-approaches-hmr-and-nbf">Early Regression Approaches: HMR and NBF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#human-mesh-recovery-hmr">Human Mesh Recovery (HMR)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#neural-body-fitting-nbf">Neural Body Fitting (NBF)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#evolving-architectures-hybrid-and-improved-regression-methods">Evolving Architectures: Hybrid and Improved Regression Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#spin-optimization-in-the-training-loop">SPIN: Optimization in the Training Loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#pymaf-pyramidal-mesh-alignment-feedback">PyMAF: Pyramidal Mesh Alignment Feedback</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#cliff-using-full-frame-context-for-camera-orientation">CLIFF: Using Full-Frame Context for Camera Orientation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#pixie-whole-body-regression-with-part-experts">PIXIE: Whole-Body Regression with Part Experts</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#temporal-methods-from-single-images-to-video-sequences">Temporal Methods: From Single Images to Video Sequences</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#vibe-adversarial-motion-prior-with-grus">VIBE: Adversarial Motion Prior with GRUs</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#tcmr-temporally-consistent-mesh-recovery">TCMR: Temporally Consistent Mesh Recovery</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#motionbert-transformer-based-motion-representations">MotionBERT: Transformer-Based Motion Representations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#comparison-of-learning-based-methods">Comparison of Learning-Based Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#supervision-and-data">Supervision and Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#network-architecture">Network Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#objective-functions">Objective Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#pose-and-shape-priors">Pose and Shape Priors</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#performance">Performance</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#runtime">Runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#strengths-and-weaknesses">Strengths and Weaknesses</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_06_2SMPL_model_fitting.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html">Lecture 07.1: Fitting SMPL to IMU Data Using Optimization-Based Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#classical-imu-based-pose-estimation-a-historical-perspective">Classical IMU-Based Pose Estimation: A Historical Perspective</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#attitude-and-heading-reference-systems">Attitude and Heading Reference Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#kalman-filter-approaches">Kalman Filter Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#early-sparse-sensor-approaches">Early Sparse-Sensor Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#model-based-optimization-methods">Model-Based Optimization Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#learning-based-methods">Learning-Based Methods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#inertial-sensor-fundamentals-and-orientation-representations">Inertial Sensor Fundamentals and Orientation Representations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#gravity-alignment-and-drift-correction">Gravity Alignment and Drift Correction</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#orientation-representations">Orientation Representations</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#sensor-calibration">Sensor Calibration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#optimization-based-smpl-fitting-with-imu-data">Optimization-Based SMPL Fitting with IMU Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#kinematic-model-and-sensor-prediction">Kinematic Model and Sensor Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#regularization-and-prior-terms">Regularization and Prior Terms</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#gradient-and-jacobian-computation">Gradient and Jacobian Computation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#pseudocode-smpl-pose-estimation-from-imu-sequence">Pseudocode: SMPL Pose Estimation from IMU Sequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#imu-based-human-pose-datasets-and-resources">IMU-Based Human Pose Datasets and Resources</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#dip-imu-dataset-2018">DIP-IMU Dataset (2018)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#totalcapture-2017">TotalCapture (2017)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#amass-2019">AMASS (2019)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_1_fitting_SMPL_to_IMU_optimization.html#other-datasets-and-resources">Other Datasets and Resources</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html">Lecture 07.2: Fitting SMPL to IMU Data Using Learning-Based Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#optimization-based-vs-learning-based-approaches">Optimization-Based vs. Learning-Based Approaches</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#learning-based-imu-to-pose-estimation-historical-overview-of-key-models">Learning-Based IMU-to-Pose Estimation: Historical Overview of Key Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#deep-inertial-poser-dip-2018">Deep Inertial Poser (DIP, 2018)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#transpose-2021">TransPose (2021)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#transformer-inertial-poser-tip-2022">Transformer Inertial Poser (TIP, 2022)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#physics-physical-inertial-poser-pip-2022">Physics/Physical Inertial Poser (PIP, 2022)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#other-notable-models-and-developments">Other Notable Models and Developments</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#problem-formulation-and-learning-task-definition">Problem Formulation and Learning Task Definition</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#input-and-output-representations">Input and Output Representations</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#learning-objective-and-loss-functions">Learning Objective and Loss Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#temporal-modeling-approaches">Temporal Modeling Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#supervised-vs-semi-supervised-training-synthetic-data">Supervised vs. Semi-Supervised Training; Synthetic Data</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#model-architectures-and-design-considerations">Model Architectures and Design Considerations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#encoding-imu-measurements">Encoding IMU Measurements</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#network-structures">Network Structures</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#training-pipeline-and-pseudocode">Training Pipeline and Pseudocode</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#datasets-benchmarks-and-resources">Datasets, Benchmarks, and Resources</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#dip-imu-dataset-2018">DIP-IMU Dataset (2018)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#totalcapture-2017">TotalCapture (2017)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#amass-2019">AMASS (2019)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#other-datasets-and-resources">Other Datasets and Resources</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#challenges-and-outlook">Challenges and Outlook</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_07_2_fitting_SMPL_to_IMU_learning.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extended_materials_neural_radiance_fields.html">Neural Radiance Fields: A Historical and Theoretical Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#foundations-3d-scene-representation-and-reconstruction-techniques">Foundations: 3D Scene Representation and Reconstruction Techniques</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#voxel-grids">Voxel Grids</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#point-clouds">Point Clouds</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#mesh-based-surfaces">Mesh-Based Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#light-fields-and-volumetric-rendering">Light Fields and Volumetric Rendering</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#emergence-of-neural-radiance-fields-nerf">Emergence of Neural Radiance Fields (NeRF)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#core-idea">Core Idea</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#training-procedure">Training Procedure</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#nerf-architecture">NeRF Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#hierarchical-sampling">Hierarchical Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#original-results">Original Results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#theoretical-and-mathematical-analysis-of-nerf">Theoretical and Mathematical Analysis of NeRF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#volume-rendering-formulation-in-nerf">Volume Rendering Formulation in NeRF</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#positional-encoding-and-neural-network-architecture">Positional Encoding and Neural Network Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#loss-function-and-optimization">Loss Function and Optimization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#major-advancements-and-extensions-of-nerf">Major Advancements and Extensions of NeRF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#anti-aliasing-and-unbounded-scenes-mip-nerf-and-nerf">Anti-Aliasing and Unbounded Scenes: mip-NeRF and NeRF++</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#efficiency-improvements-instant-nerf-and-plenoctrees">Efficiency Improvements: Instant NeRF and PlenOctrees</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#dynamic-and-deformable-nerfs-d-nerf-nerfies-nsff-etc">Dynamic and Deformable NeRFs (D-NeRF, Nerfies, NSFF, etc.)</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#neural-radiance-fields-for-human-modeling-with-smpl-and-body-models">Neural Radiance Fields for Human Modeling (with SMPL and Body Models)</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#other-notable-extensions">Other Notable Extensions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#comparison-with-other-3d-representations">Comparison with Other 3D Representations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#vs-polygonal-meshes">Vs. Polygonal Meshes</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#vs-point-clouds-3d-splatting">Vs. Point Clouds / 3D Splatting</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#vs-voxel-grids-and-volumetric-methods">Vs. Voxel Grids and Volumetric Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#vs-multi-plane-images-mpis-light-fields">Vs. Multi-Plane Images (MPIs) / Light Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#accuracy-and-fidelity">Accuracy and Fidelity</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#applicability">Applicability</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#datasets-for-nerf-training-and-evaluation">Datasets for NeRF Training and Evaluation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#blender-synthetic-nerf-dataset">Blender Synthetic NeRF Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#local-light-field-fusion-llff-real-forward-facing-dataset">Local Light Field Fusion (LLFF) Real Forward-Facing Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#tanks-and-temples">Tanks and Temples</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#dtu-dataset">DTU Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#human3-6m">Human3.6M</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#zju-mocap-dataset">ZJU-MoCap Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#people-snapshot">People-Snapshot</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#synthetic-dynamic-scenes">Synthetic dynamic scenes</a></li>
<li class="toctree-l3"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#other-datasets">Other datasets</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extended_materials_neural_radiance_fields.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html">3D Gaussian Splatting: A Basic Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#introduction">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#foundations">Foundations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#what-is-a-3d-scene">What is a 3D Scene?</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#d-scene-representation">3D Scene Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#computer-graphics-fundamentals">Computer Graphics Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#rasterization-and-ray-tracing">Rasterization and Ray Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#alpha-blending-and-compositing">Alpha Blending and Compositing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#the-evolution-of-novel-view-synthesis">The Evolution of Novel View Synthesis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#image-based-rendering">Image-Based Rendering</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#structure-from-motion-and-multi-view-stereo">Structure-from-Motion and Multi-View Stereo</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#point-based-rendering">Point-Based Rendering</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#neural-rendering">Neural Rendering</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#accelerated-neural-fields">Accelerated Neural Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#d-gaussian-splatting-a-convergence-of-approaches">3D Gaussian Splatting: A Convergence of Approaches</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#id1">Point-Based Rendering</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#point-clouds-and-their-challenges">Point Clouds and Their Challenges</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#the-concept-of-splatting">The Concept of Splatting</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#elliptical-weighted-average-ewa-filtering">Elliptical Weighted Average (EWA) Filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#differentiable-point-based-rendering">Differentiable Point-Based Rendering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#d-gaussian-splatting-core-principles">3D Gaussian Splatting: Core Principles</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#key-insight-unifying-points-and-volumes">Key Insight: Unifying Points and Volumes</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#d-gaussians-as-scene-primitives">3D Gaussians as Scene Primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#the-volumetric-rendering-equation">The Volumetric Rendering Equation</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#alpha-compositing-with-gaussians">Alpha Compositing with Gaussians</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#mathematical-formulation-of-3d-gaussian-splatting">Mathematical Formulation of 3D Gaussian Splatting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#projecting-3d-gaussians-to-2d">Projecting 3D Gaussians to 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#parameterization-of-3d-gaussians">Parameterization of 3D Gaussians</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#view-dependent-appearance">View-Dependent Appearance</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#differentiable-rendering-equations">Differentiable Rendering Equations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#training-and-optimization">Training and Optimization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#photometric-loss">Photometric Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#initial-point-cloud">Initial Point Cloud</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#optimization-process">Optimization Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#differentiable-splatting-pipeline">Differentiable Splatting Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#adaptive-density-control">Adaptive Density Control</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#implementation-and-real-time-rendering">Implementation and Real-Time Rendering</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#tile-based-rendering">Tile-Based Rendering</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#fast-sorting-strategies">Fast Sorting Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#gpu-accelerated-rasterization">GPU-Accelerated Rasterization</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#memory-considerations">Memory Considerations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#comparison-with-other-methods">Comparison with Other Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#nerf-vs-3d-gaussian-splatting">NeRF vs. 3D Gaussian Splatting</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#voxel-based-representations-vs-gaussians">Voxel-Based Representations vs. Gaussians</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#traditional-point-based-rendering-vs-gaussian-splatting">Traditional Point-Based Rendering vs. Gaussian Splatting</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#applications-and-extensions">Applications and Extensions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#static-scene-reconstruction">Static Scene Reconstruction</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#dynamic-scene-capture">Dynamic Scene Capture</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#avatar-creation-and-animation">Avatar Creation and Animation</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#integration-with-neural-rendering">Integration with Neural Rendering</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#large-scale-scene-rendering">Large-Scale Scene Rendering</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#bezier-gaussian-triangles-bg-triangle-for-sharper-rendering">Bézier Gaussian Triangles (BG-Triangle) for Sharper Rendering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#representation">Representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#performance">Performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#human-reconstruction-with-gaussian-splatting-and-priors">Human Reconstruction with Gaussian Splatting and Priors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#eg-humannerf-efficient-generalizable-human-nerf">EG-HumanNeRF: Efficient Generalizable Human NeRF</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#gps-gaussian-pixel-wise-gaussian-splatting-for-humans">GPS-Gaussian: Pixel-Wise Gaussian Splatting for Humans</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#generalizable-human-gaussians-ghg-with-smpl">Generalizable Human Gaussians (GHG) with SMPL</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#dynamic-scene-reconstruction-with-4d-gaussian-splatting">Dynamic Scene Reconstruction with 4D Gaussian Splatting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#d-gaussian-splatting-4dgs">4D Gaussian Splatting (4DGS)</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#speed-and-memory-enhancements-4dgs-1k-and-mega">Speed and Memory Enhancements (4DGS-1K and MEGA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#applications-to-mocap-and-4d-human-rendering">Applications to MoCap and 4D Human Rendering</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#implementation-details-and-real-time-performance">Implementation Details and Real-Time Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#data-structures">Data Structures</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#rasterization-shaders">Rasterization &amp; Shaders</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#gpu-memory-and-throughput">GPU Memory and Throughput</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#differentiable-rendering-implementation">Differentiable Rendering Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#training-vs-inference-compute">Training vs. Inference Compute</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#accuracy-vs-speed-trade-offs">Accuracy vs. Speed trade-offs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#benchmarks-and-comparative-evaluation">Benchmarks and Comparative Evaluation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#static-scene-comparison">Static Scene Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#human-novel-view-comparison">Human Novel-View Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#dynamic-scene-comparison">Dynamic Scene Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#comparative-summary-table">Comparative Summary Table</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#comparative-summary">Comparative Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#datasets-and-resources">Datasets and Resources</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#key-datasets">Key Datasets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#datasets-and-benchmarks">Datasets and Benchmarks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#synthetic-nerf-dataset-blender-scenes">Synthetic NeRF Dataset (Blender Scenes)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#llff-local-light-field-fusion">LLFF (Local Light Field Fusion)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#tanks-and-temples">Tanks and Temples</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#multi-object-360-co3d-common-objects-in-3d">Multi-Object 360 (CO3D - Common Objects in 3D)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#amass-archive-of-motion-capture-as-surface-shapes">AMASS (Archive of Motion Capture as Surface Shapes)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#cape-clothed-auto-person-encoding">CAPE (Clothed Auto Person Encoding)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#thuman-thuman2-0">THuman / THuman2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#renderpeople">RenderPeople</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#open-source-implementations">Open-Source Implementations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#future-directions">Future Directions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#improved-compression-techniques-for-memory-efficiency">Improved Compression Techniques for Memory Efficiency</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#handling-dynamic-and-deformable-scenes">Handling Dynamic and Deformable Scenes</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#advanced-material-modeling-for-realistic-rendering">Advanced Material Modeling for Realistic Rendering</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#hybrid-approaches-integrating-neural-fields-and-explicit-representations">Hybrid Approaches Integrating Neural Fields and Explicit Representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#scalability-for-large-scale-scenes-city-level-and-beyond">Scalability for Large-Scale Scenes (City-Level and Beyond)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#real-time-applications-in-ar-vr-and-gaming">Real-Time Applications in AR/VR and Gaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#integration-with-existing-graphics-pipelines">Integration with Existing Graphics Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#learning-from-limited-data">Learning from Limited Data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#conclusion">Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="extendeed_materials_gaussian_splatting.html#glossary">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-01-1-historical-body-models">Lecture 01.1 (Historical Body Models)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-01-2-introduction-to-human-models">Lecture 01.2 (Introduction to Human Models)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-01-3-introduction-to-human-models-continued">Lecture 01.3 (Introduction to Human Models Continued)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-02-1-image-formation">Lecture 02.1 (Image Formation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-02-2-rotations-kinematic-chains">Lecture 02.2 (Rotations &amp; Kinematic Chains)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-03-1-surface-representations">Lecture 03.1 (Surface Representations)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-03-2-procrustes-alignment">Lecture 03.2 (Procrustes Alignment)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-04-1-iterative-closest-points">Lecture 04.1 (Iterative Closest Points)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-04-2-body-models">Lecture 04.2 (Body Models)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-05-1-body-model-training">Lecture 05.1 (Body Model Training)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-05-2-3d-registration">Lecture 05.2 (3D Registration)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-06-1-fitting-smpl-to-images">Lecture 06.1 (Fitting SMPL to Images)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-06-1-optimization-based-fitting-of-smpl-to-images">Lecture 06.1 (Optimization-Based Fitting of SMPL to Images)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-06-2-learning-based-fitting-of-smpl-to-images">Lecture 06.2 (Learning-Based Fitting of SMPL to Images)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-07-1-fitting-smpl-to-imu-optimization">Lecture 07.1 (Fitting SMPL to IMU Optimization)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-07-2-fitting-smpl-to-imu-learning">Lecture 07.2 (Fitting SMPL to IMU Learning)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="references.html#classic-and-optimization-based-methods">Classic and Optimization-Based Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="references.html#learning-based-methods">Learning-Based Methods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="references.html#datasets-and-resources">Datasets and Resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#relevant-software-and-libraries">Relevant Software and Libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#neural-radiance-fields-nerf">Neural Radiance Fields (NERF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#gaussian-splatting">Gaussian Splatting</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Virtual Humans Lecture</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Lecture 04.2 - Body Models: Vertex-Based Models and SMPL</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/lecture_04_2_body_models.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="lecture-04-2-body-models-vertex-based-models-and-smpl">
<span id="lecture-04-2-bodymodels"></span><h1>Lecture 04.2 - Body Models: Vertex-Based Models and SMPL<a class="headerlink" href="#lecture-04-2-body-models-vertex-based-models-and-smpl" title="Link to this heading"></a></h1>
<iframe width="600" height="400" src="https://www.youtube.com/embed/JYRC6hxoh5g"
title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p><a class="reference external" href="https://virtualhumans.mpi-inf.mpg.de/VH23/slides/pdf/Lecture_04_2_Vertex_Based%20Models.pdf">Lecture Slides: Body Models: Vertex-Based Models and SMPL</a></p>
<p>This chapter provides a comprehensive overview of vertex-based body models with a particular focus on the SMPL (Skinned Multi-Person Linear) model. We cover:</p>
<ul class="simple">
<li><p>The concept of body models as functions mapping shape and pose parameters to mesh vertices</p></li>
<li><p>The mathematical foundations of articulated body models</p></li>
<li><p>Linear Blend Skinning (LBS) and its limitations</p></li>
<li><p>The SMPL model architecture, training, and advantages</p></li>
<li><p>Comparison between SMPL and previous approaches like SCAPE</p></li>
<li><p>Alignment techniques including Procrustes analysis and Iterative Closest Point (ICP)</p></li>
<li><p>The challenges of training body models from 3D scans</p></li>
</ul>
<p>Throughout, we include mathematical formulations, equations, and contextual explanations to provide a thorough understanding of how these models work.</p>
<section id="body-models-as-parameterized-functions">
<h2>1. Body Models as Parameterized Functions<a class="headerlink" href="#body-models-as-parameterized-functions" title="Link to this heading"></a></h2>
<p>A body model can be defined as a function that maps input parameters to a 3D mesh representing a human body. Modern human body models aim to represent the immense variability of human shapes and poses with a small set of parameters. Typically, the variation is decomposed into two factors:</p>
<ul class="simple">
<li><p><strong>Shape (Identity):</strong> Parameters that control the body size, proportions, and general morphology</p></li>
<li><p><strong>Pose:</strong> Parameters that control the articulated body configuration (joint rotations)</p></li>
</ul>
<p>This separation allows for independent control of a person’s identity and their pose. For example, one can model the same person in different poses, or different people in the same pose.</p>
<p>Mathematically, we can represent this as:</p>
<div class="math notranslate nohighlight">
\[M(\vec{\theta}, \vec{\beta}) \mapsto \text{mesh vertices}\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(\vec{\theta}\)</span> represents the pose parameters
- <span class="math notranslate nohighlight">\(\vec{\beta}\)</span> represents the shape parameters
- <span class="math notranslate nohighlight">\(M\)</span> is the body model function that outputs 3D mesh vertices</p>
<p>This parameterization is intuitive and natural for modeling the human body, as it aligns with our understanding of how people vary in shape and how they move.</p>
</section>
<section id="rotations-articulation-and-pose-representation">
<h2>2. Rotations, Articulation, and Pose Representation<a class="headerlink" href="#rotations-articulation-and-pose-representation" title="Link to this heading"></a></h2>
<section id="rotation-representation">
<h3>2.1 Rotation Representation<a class="headerlink" href="#rotation-representation" title="Link to this heading"></a></h3>
<p>In SMPL, poses are represented using the axis-angle representation:</p>
<div class="math notranslate nohighlight">
\[\vec{\theta} = (\vec{\omega}_1, \ldots, \vec{\omega}_K)^T\]</div>
<p>Where each <span class="math notranslate nohighlight">\(\vec{\omega}_k\)</span> is a 3D axis-angle vector representing the rotation at joint <span class="math notranslate nohighlight">\(k\)</span>. In the axis-angle representation:</p>
<ul class="simple">
<li><p>The direction of the vector <span class="math notranslate nohighlight">\(\vec{\omega}_k\)</span> represents the axis of rotation</p></li>
<li><p>The magnitude <span class="math notranslate nohighlight">\(\|\vec{\omega}_k\|\)</span> represents the angle of rotation</p></li>
</ul>
<p>The corresponding rotation matrix can be computed using Rodrigues’ formula:</p>
<div class="math notranslate nohighlight">
\[R(\theta_j) = I + \frac{\sin\|\theta_j\|}{\|\theta_j\|} [\hat{n}]_\times + \frac{1-\cos\|\theta_j\|}{\|\theta_j\|^2} [\hat{n}]_\times^2,\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{n} = \frac{\theta_j}{\|\theta_j\|}\)</span>.</p>
<p>Other common rotation representations include:</p>
<ul class="simple">
<li><p><strong>Rotation Matrices:</strong> A <span class="math notranslate nohighlight">\(3 \times 3\)</span> matrix <span class="math notranslate nohighlight">\(R \in SO(3)\)</span> with 3 degrees of freedom.</p></li>
<li><p><strong>Euler Angles:</strong> Three angles (e.g., yaw, pitch, roll) that represent a sequence of rotations. They are intuitive but can suffer from gimbal lock.</p></li>
<li><p><strong>Quaternions:</strong> Four-dimensional vectors (with a unit norm) that allow smooth interpolation and avoid singularities.</p></li>
</ul>
</section>
<section id="kinematic-chain">
<h3>2.2 Kinematic Chain<a class="headerlink" href="#kinematic-chain" title="Link to this heading"></a></h3>
<p>The human body is modeled as a kinematic chain where each body part is connected to its parent. The global transformation of a point in the body frame <span class="math notranslate nohighlight">\(\vec{p}_b\)</span> to the spatial frame <span class="math notranslate nohighlight">\(\vec{p}_s\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\vec{p}_s = G(\vec{\omega}_1, \vec{\omega}_2, \vec{j}_1, \vec{j}_2) \cdot \vec{p}_b = G(\vec{\omega}_1, \vec{j}_1) \cdot G(\vec{\omega}_2, \vec{j}_2) \cdot \vec{p}_b\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(G(\vec{\omega}, \vec{j})\)</span> is the rigid body transformation associated with the rotation <span class="math notranslate nohighlight">\(\vec{\omega}\)</span> around joint <span class="math notranslate nohighlight">\(\vec{j}\)</span>.</p>
<p>For a joint <span class="math notranslate nohighlight">\(j\)</span> with parent <span class="math notranslate nohighlight">\(p(j)\)</span>, the global transformation is computed by:</p>
<div class="math notranslate nohighlight">
\[T_j^{global} = T_{p(j)}^{global} \; T_j^{local}(\theta_j).\]</div>
<p>Here, <span class="math notranslate nohighlight">\(T_j^{local}(\theta_j)\)</span> is a <span class="math notranslate nohighlight">\(4 \times 4\)</span> homogeneous transformation matrix that encodes the joint’s rotation (and translation).</p>
<p>The transformation matrix for a joint is given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}G(\vec{\omega}) = \begin{bmatrix}
[e^{\hat{\omega}}]_{3 \times 3} &amp; \vec{j} - \vec{j}_{\text{parent}} \\
\vec{0}_{1 \times 3} &amp; 1
\end{bmatrix}\end{split}\]</div>
<p>This ensures body parts remain connected as the pose changes.</p>
</section>
</section>
<section id="linear-blend-skinning-and-its-limitations">
<h2>3. Linear Blend Skinning and its Limitations<a class="headerlink" href="#linear-blend-skinning-and-its-limitations" title="Link to this heading"></a></h2>
<section id="linear-blend-skinning">
<h3>3.1 Linear Blend Skinning<a class="headerlink" href="#linear-blend-skinning" title="Link to this heading"></a></h3>
<p>Linear Blend Skinning (LBS) is a standard technique in computer graphics for animating articulated characters. In LBS, each vertex is transformed by a weighted combination of nearby joint transformations:</p>
<div class="math notranslate nohighlight">
\[\vec{t}'_i = \sum_{k=1}^{K} w_{k,i} G'_k(\vec{\theta}, J) \vec{t}_i\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(\vec{t}_i\)</span> is vertex <span class="math notranslate nohighlight">\(i\)</span> in the rest pose
- <span class="math notranslate nohighlight">\(\vec{t}'_i\)</span> is the transformed vertex in the posed configuration
- <span class="math notranslate nohighlight">\(w_{k,i}\)</span> is the blend weight that associates vertex <span class="math notranslate nohighlight">\(i\)</span> with joint <span class="math notranslate nohighlight">\(k\)</span>
- <span class="math notranslate nohighlight">\(G'_k\)</span> is the transformation matrix for joint <span class="math notranslate nohighlight">\(k\)</span></p>
<p>In SMPL, each vertex <span class="math notranslate nohighlight">\(v_i\)</span> is transformed as a weighted blend of the transformations from all joints:</p>
<div class="math notranslate nohighlight">
\[v_i(\beta, \theta) = \sum_{j=1}^{24} w_{ij} \; G_j(\theta, \beta) \; v_i^*(\beta, \theta),\]</div>
<p>where <span class="math notranslate nohighlight">\(G_j(\theta, \beta)\)</span> is the global transformation for joint <span class="math notranslate nohighlight">\(j\)</span> and <span class="math notranslate nohighlight">\(v_i^*(\beta, \theta)\)</span> is the vertex position in the canonical (rest) pose.</p>
</section>
<section id="problems-with-standard-lbs">
<h3>3.2 Problems with Standard LBS<a class="headerlink" href="#problems-with-standard-lbs" title="Link to this heading"></a></h3>
<p>Standard LBS has well-known artifacts:</p>
<ol class="arabic simple">
<li><p><strong>Volume collapse:</strong> Loss of volume around joints during bending (e.g., elbows, knees)</p></li>
<li><p><strong>Candy wrapper artifact:</strong> Unrealistic twisting when rotating limbs</p></li>
</ol>
<p>These issues occur because LBS linearly combines transformation matrices, which is not mathematically correct for the nonlinear space of rotations. Alternative approaches like Dual Quaternion Skinning address some of these issues but introduce new ones (e.g., joint bulging).</p>
</section>
<section id="blend-shapes-for-correcting-lbs-artifacts">
<h3>3.3 Blend Shapes for Correcting LBS Artifacts<a class="headerlink" href="#blend-shapes-for-correcting-lbs-artifacts" title="Link to this heading"></a></h3>
<p>To address these limitations, vertex-based models use corrective blend shapes. A blend shape is a set of vertex displacements applied in the rest pose to improve the realism of posed configurations.</p>
<p>In animation, these are often manually sculpted by artists. For each pose, an artist creates specific corrective displacements that are activated when that pose is applied. This is labor-intensive and does not scale well to model all possible poses.</p>
</section>
</section>
<section id="the-smpl-body-model">
<h2>4. The SMPL Body Model<a class="headerlink" href="#the-smpl-body-model" title="Link to this heading"></a></h2>
<section id="smpl-philosophy">
<h3>4.1 SMPL Philosophy<a class="headerlink" href="#smpl-philosophy" title="Link to this heading"></a></h3>
<p>SMPL (Skinned Multi-Person Linear model) aims to be the simplest possible body model while achieving state-of-the-art performance. Key goals include:</p>
<ul class="simple">
<li><p>Ease of training</p></li>
<li><p>Compatibility with standard animation software</p></li>
<li><p>High accuracy in representing real human bodies</p></li>
</ul>
</section>
<section id="smpl-model-architecture">
<h3>4.2 SMPL Model Architecture<a class="headerlink" href="#smpl-model-architecture" title="Link to this heading"></a></h3>
<p>SMPL builds on standard skinning but parameterizes each component with shape and pose:</p>
<div class="math notranslate nohighlight">
\[M(\vec{\theta}, \vec{\beta}) = W(T_P(\vec{\beta}, \vec{\theta}), J(\vec{\beta}), \mathcal{W}, \vec{\theta})\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(T_P(\vec{\beta}, \vec{\theta})\)</span> is the template mesh that depends on shape and pose
- <span class="math notranslate nohighlight">\(J(\vec{\beta})\)</span> are the joint positions that depend on shape
- <span class="math notranslate nohighlight">\(\mathcal{W}\)</span> are the blend weights
- <span class="math notranslate nohighlight">\(W\)</span> is the skinning function</p>
<p>The template mesh <span class="math notranslate nohighlight">\(T_P\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[T_P(\vec{\theta}, \vec{\beta}) = \bar{T} + B_S(\vec{\beta}) + B_P(\vec{\theta})\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(\bar{T}\)</span> is the mean template shape
- <span class="math notranslate nohighlight">\(B_S(\vec{\beta})\)</span> are shape blend shapes
- <span class="math notranslate nohighlight">\(B_P(\vec{\theta})\)</span> are pose blend shapes</p>
<p>This can be expressed equivalently as:</p>
<div class="math notranslate nohighlight">
\[V(\beta, \theta) = \text{LBS}\Bigl(T(\beta) + B_P(\theta),\, J(\beta),\, \theta,\, W\Bigr),\]</div>
</section>
<section id="shape-blend-shapes">
<h3>4.2.1 Shape Blend Shapes<a class="headerlink" href="#shape-blend-shapes" title="Link to this heading"></a></h3>
<p>Shape blend shapes model identity variations and are defined as a linear combination:</p>
<div class="math notranslate nohighlight">
\[B_S(\vec{\beta}) = \sum_{j=1}^{|\vec{\beta}|} \beta_j S_j\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(S_j\)</span> are the shape blend shapes (PCA components)
- <span class="math notranslate nohighlight">\(\beta_j\)</span> are the shape coefficients</p>
<p>In SMPL, shape variations are modeled using a low-dimensional vector <span class="math notranslate nohighlight">\(\beta \in \mathbb{R}^{10}\)</span> such that:</p>
<div class="math notranslate nohighlight">
\[T(\beta) = \bar{T} + \sum_{i=1}^{10} \beta_i \; S_i,\]</div>
</section>
<section id="pose-blend-shapes">
<h3>4.2.2 Pose Blend Shapes<a class="headerlink" href="#pose-blend-shapes" title="Link to this heading"></a></h3>
<p>Pose blend shapes correct LBS artifacts and add muscle deformations:</p>
<div class="math notranslate nohighlight">
\[B_P(\vec{\theta}) = \sum_{i=1}^{|f(\vec{\theta})|} f_i(\vec{\theta}) P_i\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(P_i\)</span> are the pose blend shapes
- <span class="math notranslate nohighlight">\(f_i(\vec{\theta})\)</span> are functions of the pose parameters</p>
<p>In SMPL, pose blend shapes are linear in the elements of the joint rotation matrices:</p>
<div class="math notranslate nohighlight">
\[f(\vec{\theta}) = [(e^{\hat{\omega}_1} - I), \ldots, (e^{\hat{\omega}_K} - I)]\]</div>
<p>These terms are vectorized, resulting in 9K pose blend shape coefficients (9 elements per rotation matrix × K joints).</p>
<p>The subtraction of the identity matrix I ensures that there are no pose blend shape effects in the zero pose.</p>
</section>
<section id="joint-regression">
<h3>4.2.3 Joint Regression<a class="headerlink" href="#joint-regression" title="Link to this heading"></a></h3>
<p>SMPL regresses joint locations linearly from the template mesh vertices:</p>
<div class="math notranslate nohighlight">
\[J = J(T; \mathcal{J}) = \mathcal{J} T\]</div>
<p>Where <span class="math notranslate nohighlight">\(\mathcal{J}\)</span> is the joint regressor matrix, a sparse matrix that maps vertices to joint locations.</p>
</section>
<section id="model-training">
<h3>4.3 Model Training<a class="headerlink" href="#model-training" title="Link to this heading"></a></h3>
<p>SMPL is trained on two datasets:</p>
<ol class="arabic simple">
<li><p><strong>Multipose dataset:</strong> ~1,800 scans of 44 subjects (20 males, 24 females) in various poses</p></li>
<li><p><strong>Multishape dataset:</strong> ~2,000 scans per gender in a standard pose</p></li>
</ol>
<p>The training objective is:</p>
<div class="math notranslate nohighlight">
\[\mathbf{w} = \arg\min_{\mathbf{w}} \sum_j \|M(\vec{\theta}_j, \vec{\beta}_j; \mathbf{w}) - \mathbf{V}_j\|^2\]</div>
<p>Where <span class="math notranslate nohighlight">\(\mathbf{V}_j\)</span> are the registered scans and <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> represents all model parameters.</p>
<p>This can be expanded to:</p>
<div class="math notranslate nohighlight">
\[\arg\min_{T, \mathcal{S}, \mathcal{P}, \mathcal{W}, \mathcal{J}} \sum_j \min_{\vec{\theta}_j, \vec{\beta}_j} \|M(\vec{\theta}_j, \vec{\beta}_j; T, \mathcal{S}, \mathcal{P}, \mathcal{W}, \mathcal{J}) - \mathbf{V}_j\|^2\]</div>
<p>Training details include:
- The pose blend shapes, blend weights, and joint regressor matrices are trained on the multipose dataset
- Pose blend shapes are regularized toward zero (ridge regression)
- Blend weights are regularized toward an initial configuration provided by an animator
- The joint regressor is forced to be sparse and to predict joints at body part boundaries
- The mean shape and shape blend shapes are learned from the multishape dataset</p>
<p>Training a model like SMPL involves two intertwined problems:</p>
<ol class="arabic simple">
<li><p><strong>Registration:</strong>
Each 3D scan must be aligned to the common template (using non-rigid ICP or similar methods) to establish
vertex correspondences across scans.</p></li>
<li><p><strong>Parameter Estimation:</strong>
Once registrations are available, PCA is applied to the vertex displacements to derive the shape blend shapes <span class="math notranslate nohighlight">\(S_i\)</span>, and pose blend shapes <span class="math notranslate nohighlight">\(B_P(\theta)\)</span> are estimated by analyzing how the mesh deforms across different poses. The joint regressor is learned from the registered data.</p></li>
</ol>
<p>Because registration and model training depend on each other, an alternating optimization or EM approach is used:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>Step 1:</strong> Initialize with a rough registration.</p></li>
<li><p><strong>Step 2:</strong> Train the model parameters (<span class="math notranslate nohighlight">\(\beta, \theta, B_P, W\)</span>, etc.).</p></li>
<li><p><strong>Step 3:</strong> Refine the registrations using the current model.</p></li>
<li><p><strong>Repeat</strong> until convergence.</p></li>
</ul>
</div></blockquote>
<p>In total, SMPL has about 6 million learned parameters for a 6,890-vertex model.</p>
</section>
</section>
<section id="comparison-with-scape">
<h2>5. Comparison with SCAPE<a class="headerlink" href="#comparison-with-scape" title="Link to this heading"></a></h2>
<p>SMPL is compared to earlier body models, particularly SCAPE (Shape Completion and Animation of People):</p>
<section id="the-scape-model">
<h3>5.1 The SCAPE Model<a class="headerlink" href="#the-scape-model" title="Link to this heading"></a></h3>
<p>SCAPE (Shape Completion and Animation of People) was one of the first models to separate identity from pose. Its key features include:</p>
<ul class="simple">
<li><p><strong>Triangle Deformations:</strong>
Rather than manipulating vertices directly, SCAPE applies local 3×3 transformation matrices to each triangle of the mesh. These matrices capture how local surface patches deform with changes in pose or shape.</p></li>
<li><p><strong>Separation of Pose and Shape:</strong>
SCAPE learns two distinct subspaces:</p>
<ul>
<li><p>The <strong>shape subspace</strong> is learned from scans of different individuals in a standard pose.</p></li>
<li><p>The <strong>pose subspace</strong> is learned from scans of one individual in various poses, capturing non-rigid deformations (e.g., muscle bulging).</p></li>
</ul>
</li>
<li><p><strong>Registration:</strong>
A common template mesh is registered to each scan using non-rigid ICP so that point-to-point correspondences are established. Principal Component Analysis (PCA) is then applied to the aligned vertex displacements to form the shape basis.</p></li>
</ul>
</section>
<section id="different-approaches-to-deformation">
<h3>5.2 Different Approaches to Deformation<a class="headerlink" href="#different-approaches-to-deformation" title="Link to this heading"></a></h3>
<p><strong>SCAPE:</strong>
- Uses local triangle deformations (3×3 transformations)
- Applied to two edges per triangle
- No explicit center of rotation</p>
<p><strong>SMPL:</strong>
- Uses global vertex deformations (3D displacements + rigid body motion)
- Applied directly to vertices
- Has explicit centers of rotation</p>
</section>
<section id="performance-comparison">
<h3>5.3 Performance Comparison<a class="headerlink" href="#performance-comparison" title="Link to this heading"></a></h3>
<p>Key advantages of SMPL over SCAPE include:</p>
<ol class="arabic simple">
<li><p><strong>Pose generalization:</strong> SMPL slightly outperforms SCAPE when generalizing to new poses</p></li>
<li><p><strong>Shape space efficiency:</strong> SMPL requires far fewer components to capture shape variance:
- With 10 components, SMPL captures &gt;90% of shape variance
- SCAPE needs ~300 components to reach the same level</p></li>
</ol>
</section>
<section id="other-advantages">
<h3>5.4 Other Advantages<a class="headerlink" href="#other-advantages" title="Link to this heading"></a></h3>
<p>SMPL offers:
- Faster runtime performance
- Superior compatibility with standard animation software
- A simpler mathematical formulation</p>
</section>
</section>
<section id="alignment-techniques-procrustes-analysis-and-icp">
<h2>6. Alignment Techniques: Procrustes Analysis and ICP<a class="headerlink" href="#alignment-techniques-procrustes-analysis-and-icp" title="Link to this heading"></a></h2>
<p>Aligning a model to data is a fundamental step for both model training and pose estimation.</p>
<section id="procrustes-analysis">
<h3>6.1 Procrustes Analysis<a class="headerlink" href="#procrustes-analysis" title="Link to this heading"></a></h3>
<p>Given two sets of corresponding 3D points <span class="math notranslate nohighlight">\(\{a_i\}\)</span> and <span class="math notranslate nohighlight">\(\{b_i\}\)</span>, the objective is to find the rotation <span class="math notranslate nohighlight">\(R\)</span> and translation <span class="math notranslate nohighlight">\(\mathbf{t}\)</span> minimizing</p>
<div class="math notranslate nohighlight">
\[E(R, \mathbf{t}) = \sum_{i=1}^{N} \|R\,a_i + \mathbf{t} - b_i\|^2.\]</div>
<p><strong>Derivation:</strong></p>
<ol class="arabic">
<li><p><strong>Centroid Alignment:</strong>
Compute the centroids:</p>
<div class="math notranslate nohighlight">
\[\bar{a} = \frac{1}{N}\sum_{i=1}^{N} a_i, \quad \bar{b} = \frac{1}{N}\sum_{i=1}^{N} b_i.\]</div>
<p>The optimal translation is:</p>
<div class="math notranslate nohighlight">
\[\mathbf{t}^* = \bar{b} - R\,\bar{a}.\]</div>
</li>
<li><p><strong>Optimal Rotation:</strong>
Center the points: <span class="math notranslate nohighlight">\(a'_i = a_i - \bar{a}\)</span>, <span class="math notranslate nohighlight">\(b'_i = b_i - \bar{b}\)</span>. Form the cross-covariance matrix:</p>
<div class="math notranslate nohighlight">
\[H = \sum_{i=1}^{N} b'_i {a'_i}^T.\]</div>
<p>Compute the SVD: <span class="math notranslate nohighlight">\(H = U \Sigma V^T\)</span>. Then, the optimal rotation is:</p>
<div class="math notranslate nohighlight">
\[R^* = V\,U^T.\]</div>
<p>If <span class="math notranslate nohighlight">\(\det(R^*) &lt; 0\)</span>, adjust by negating the last column of <span class="math notranslate nohighlight">\(V\)</span>.</p>
</li>
</ol>
</section>
<section id="iterative-closest-point-icp">
<h3>6.2 Iterative Closest Point (ICP)<a class="headerlink" href="#iterative-closest-point-icp" title="Link to this heading"></a></h3>
<p>ICP is used when correspondences are unknown. Its procedure is as follows:</p>
<ol class="arabic simple">
<li><p><strong>Initialization:</strong>
Start with an initial guess for the transformation.</p></li>
<li><p><strong>Correspondence Assignment:</strong>
For each point in the source set, find the closest point in the target.</p></li>
<li><p><strong>Transformation Update:</strong>
Solve for the optimal rigid transformation (using Procrustes analysis).</p></li>
<li><p><strong>Iteration:</strong>
Update the source points with the transformation and repeat until convergence.</p></li>
</ol>
<p><strong>Variants include:</strong></p>
<ul class="simple">
<li><p><strong>Point-to-Plane ICP:</strong> Utilizes surface normals to minimize the distance from a point to the tangent plane.</p></li>
<li><p><strong>Probabilistic ICP (e.g., CPD):</strong> Uses soft correspondences via a Gaussian mixture model.</p></li>
<li><p><strong>Robust ICP:</strong> Incorporates robust loss functions or outlier rejection strategies.</p></li>
</ul>
</section>
<section id="fitting-smpl-to-scans">
<h3>6.3 Fitting SMPL to Scans<a class="headerlink" href="#fitting-smpl-to-scans" title="Link to this heading"></a></h3>
<p>Fitting a body model such as SMPL to a 3D scan is a non-rigid registration problem. The goal is to find the parameters <span class="math notranslate nohighlight">\((\beta, \theta)\)</span> that minimize an error function:</p>
<div class="math notranslate nohighlight">
\[E(\beta, \theta) = \sum_{i=1}^{N} \rho\Bigl( \|v_i(\beta,\theta) - s_i\|^2 \Bigr) + \lambda\, R(\beta,\theta),\]</div>
<p>where:
- <span class="math notranslate nohighlight">\(v_i(\beta, \theta)\)</span> are the vertices of the SMPL model,
- <span class="math notranslate nohighlight">\(s_i\)</span> are the corresponding points on the scan,
- <span class="math notranslate nohighlight">\(\rho(\cdot)\)</span> is a robust loss function,
- <span class="math notranslate nohighlight">\(R(\beta,\theta)\)</span> are regularizers (such as pose and shape priors),
- <span class="math notranslate nohighlight">\(\lambda\)</span> is a balancing weight.</p>
<p>Since correspondences are unknown, an iterative process is used:</p>
<ul class="simple">
<li><p><strong>Step 1:</strong> Establish correspondences (e.g., using nearest neighbors).</p></li>
<li><p><strong>Step 2:</strong> Optimize <span class="math notranslate nohighlight">\((\beta, \theta)\)</span> using gradient-based methods.</p></li>
<li><p><strong>Step 3:</strong> Update correspondences and iterate until convergence.</p></li>
</ul>
<p>This process, an extension of ICP into the non-rigid domain, leverages the low-dimensional nature of SMPL to ensure plausible human shapes while fitting the scan data.</p>
</section>
</section>
<section id="image-formation-and-the-pinhole-camera-model">
<h2>7. Image Formation and the Pinhole Camera Model<a class="headerlink" href="#image-formation-and-the-pinhole-camera-model" title="Link to this heading"></a></h2>
<p>Understanding how 3D points are projected onto 2D images is essential for tasks such as fitting a model to image data.</p>
<section id="the-pinhole-camera-model">
<h3>7.1 The Pinhole Camera Model<a class="headerlink" href="#the-pinhole-camera-model" title="Link to this heading"></a></h3>
<p>For a 3D point <span class="math notranslate nohighlight">\(\mathbf{X} = (X, Y, Z)\)</span>, its projection onto the image plane is given by:</p>
<div class="math notranslate nohighlight">
\[x = f \frac{X}{Z}, \qquad y = f \frac{Y}{Z},\]</div>
<p>where <span class="math notranslate nohighlight">\(f\)</span> is the focal length.</p>
<p>In homogeneous coordinates, the projection can be written as:</p>
<div class="math notranslate nohighlight">
\[\tilde{\mathbf{x}} \sim P \; \tilde{\mathbf{X}},\]</div>
<p>with the projection matrix</p>
<div class="math notranslate nohighlight">
\[P = K \; [R \mid \mathbf{t}],\]</div>
<p>where:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(K\)</span> is the intrinsic matrix, for example:</p>
<div class="math notranslate nohighlight">
\[\begin{split}K = \begin{pmatrix} f_x &amp; 0 &amp; c_x \\ 0 &amp; f_y &amp; c_y \\ 0 &amp; 0 &amp; 1 \end{pmatrix},\end{split}\]</div>
</li>
<li><p><span class="math notranslate nohighlight">\([R \mid \mathbf{t}]\)</span> contains the extrinsic parameters.</p></li>
</ul>
<p>This formulation is used to reproject the 3D model into the 2D image space (e.g., for comparing with detected 2D keypoints).</p>
</section>
<section id="lens-distortion">
<h3>7.2 Lens Distortion<a class="headerlink" href="#lens-distortion" title="Link to this heading"></a></h3>
<p>Real cameras introduce lens distortions. Radial distortion, for instance, can be modeled by:</p>
<div class="math notranslate nohighlight">
\[x_{distorted} = x \; (1 + k_1 r^2 + k_2 r^4 + \dots), \qquad r = \sqrt{x^2 + y^2},\]</div>
<p>with analogous equations for <span class="math notranslate nohighlight">\(y\)</span>. These parameters are estimated during camera calibration and are applied to correct the projected image coordinates.</p>
</section>
</section>
<section id="extensions-and-advanced-applications">
<h2>8. Extensions and Advanced Applications<a class="headerlink" href="#extensions-and-advanced-applications" title="Link to this heading"></a></h2>
<section id="dynamic-soft-tissue-modeling">
<h3>8.1 Dynamic Soft Tissue Modeling<a class="headerlink" href="#dynamic-soft-tissue-modeling" title="Link to this heading"></a></h3>
<p>The SMPL framework can be extended to model soft tissue dynamics through additional blend shapes:</p>
<div class="math notranslate nohighlight">
\[B_D(\Phi, \vec{\beta})\]</div>
<p>Where <span class="math notranslate nohighlight">\(\Phi\)</span> represents dynamic parameters controlling soft tissue motion.</p>
<p>This approach has been used in the DYNA model to capture realistic jiggling and deformation of soft tissues during dynamic motion.</p>
</section>
<section id="specialized-extensions">
<h3>8.2 Specialized Extensions<a class="headerlink" href="#specialized-extensions" title="Link to this heading"></a></h3>
<p>SMPL has been extended to various specialized body modeling tasks:</p>
<ul class="simple">
<li><p><strong>MANO:</strong> Hand modeling based on the SMPL approach</p></li>
<li><p><strong>FLAME:</strong> Face modeling based on the SMPL approach</p></li>
<li><p><strong>SMPL-X:</strong> Integrated body, face, and hand modeling</p></li>
<li><p><strong>DMPL:</strong> Dynamic Multi-Person Linear model for soft tissue animation</p></li>
<li><p><strong>SMAL:</strong> Animal modeling based on the SMPL approach</p></li>
</ul>
</section>
<section id="deep-learning-for-model-fitting">
<h3>8.3 Deep Learning for Model Fitting<a class="headerlink" href="#deep-learning-for-model-fitting" title="Link to this heading"></a></h3>
<p>Methods such as HMR train convolutional neural networks to predict SMPL parameters from images. The SMPL layer is embedded as a differentiable component, and reprojection loss is used for supervision.</p>
</section>
<section id="probabilistic-approaches">
<h3>8.4 Probabilistic Approaches<a class="headerlink" href="#probabilistic-approaches" title="Link to this heading"></a></h3>
<p>Some frameworks treat the body model parameters as random variables with priors. These models use techniques like particle filtering or variational inference to estimate the posterior distribution over pose and shape.</p>
</section>
<section id="hybrid-models">
<h3>8.5 Hybrid Models<a class="headerlink" href="#hybrid-models" title="Link to this heading"></a></h3>
<p>Extensions like SMPL-X or neural implicit models combine parametric models with free-form deformations to capture details that the base SMPL model cannot, such as clothing and fine surface geometry.</p>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading"></a></h2>
<p>Vertex-based models, particularly SMPL, represent a significant advance in human body modeling. By parameterizing skinning with pose and shape, SMPL provides an efficient, accurate, and compatible framework for representing human bodies in computer graphics and vision applications.</p>
<p>Key contributions of the SMPL approach include:
- The insight that blend shapes should be linear in rotation matrix elements rather than axis angles
- The joint regressor that allows joint positions to vary with body shape
- The additive model that separates pose-dependent deformations from identity variation</p>
<p>Starting with the design of parametric models such as SCAPE and SMPL, we examined how shape and pose are mathematically represented and learned from data. We reviewed the principles of image formation via the pinhole camera model and the role of lens distortion in accurate 3D reconstruction. We also discussed the representation of rotations and the kinematic chains that form the basis of articulated models, as well as alignment techniques such as Procrustes analysis and ICP for fitting these models to scan data.</p>
<p>These innovations have made SMPL the de facto standard for human body modeling in many applications, from animation to computer vision and AR/VR. This rigorous foundation is essential for developing robust digital human representations for applications ranging from animation and augmented reality to robotics and beyond.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="lecture_04_1_icp.html" class="btn btn-neutral float-left" title="Lecture 4.1: Iterative Closest Point" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="lecture_05_1_body_model_training.html" class="btn btn-neutral float-right" title="Lecture 5.1 - Training a Body Model and Fitting SMPL to Scans" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>