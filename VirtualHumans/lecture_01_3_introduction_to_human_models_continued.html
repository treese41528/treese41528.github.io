

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Lecture 01.3 – Introduction to Human Models (Overview) &mdash; Fitting SMPL to IMU Optimization</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=f2a433a1"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Lecture 02.1 – Image Formation" href="lecture_02_1_image_formation.html" />
    <link rel="prev" title="Lecture 01.2 – Introduction to Human Models" href="lecture_01_2_introduction_to_human_models.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Virtual Humans Lecture
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="lecture_01_1_historical_body_models.html">Lecture 01.1 – Historical Body Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#early-origins-simplified-primitives-and-kinematic-skeletons-1970s1980s">Early Origins: Simplified Primitives and Kinematic Skeletons (1970s–1980s)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#advances-in-the-1990s-superquadrics-differentiable-fitting-and-physical-models">Advances in the 1990s: Superquadrics, Differentiable Fitting, and Physical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#the-impact-of-3d-scanning-and-data-from-anthropometry-to-statistical-models-1990s2000s">The Impact of 3D Scanning and Data: From Anthropometry to Statistical Models (1990s–2000s)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#scape-and-the-emergence-of-pose-aware-models-mid-2000s">SCAPE and the Emergence of Pose-Aware Models (Mid-2000s)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#consolidation-in-the-2010s-smpl-and-integration-with-learning-based-methods">Consolidation in the 2010s: SMPL and Integration with Learning-Based Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#deep-learning-and-neural-implicit-models-late-2010spresent">Deep Learning and Neural Implicit Models (Late 2010s–Present)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#timeline-summary-of-milestones">Timeline Summary of Milestones</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_historical_body_models.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html">Lecture 01.2 – Introduction to Human Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#historical-context-of-human-body-modeling">1. Historical Context of Human Body Modeling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#early-developments">Early Developments</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#mid-20th-century-approaches">Mid-20th Century Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#data-driven-revolution-1990s-2000s">Data-Driven Revolution (1990s-2000s)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#mathematical-foundations-of-human-body-models">2. Mathematical Foundations of Human Body Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#the-smpl-model">The SMPL Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#pca-based-statistical-shape-modeling">PCA-Based Statistical Shape Modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#kinematic-modeling">Kinematic Modeling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#applications-of-human-body-models">3. Applications of Human Body Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#computer-animation-and-visual-effects">Computer Animation and Visual Effects</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#virtual-humans-and-avatars">Virtual Humans and Avatars</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#biomechanics-and-ergonomics">Biomechanics and Ergonomics</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#human-computer-interaction-hci">Human-Computer Interaction (HCI)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#computer-vision-and-ai">Computer Vision and AI</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#education-and-training">Education and Training</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#challenges-and-future-directions">4. Challenges and Future Directions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#computational-efficiency">Computational Efficiency</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#accuracy-and-detail">Accuracy and Detail</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#generalization">Generalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#clothing-and-accessories">Clothing and Accessories</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#emerging-approaches">Emerging Approaches</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_introduction_to_human_models.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Lecture 01.3 – Introduction to Human Models (Overview)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#historical-context">1. Historical Context</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#early-scientific-studies">Early Scientific Studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mid-20th-century-to-digital-era">Mid-20th Century to Digital Era</a></li>
<li class="toctree-l3"><a class="reference internal" href="#st-century-advances">21st Century Advances</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#mathematical-foundations">2. Mathematical Foundations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#parametric-body-models">Parametric Body Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implicit-surface-representations">Implicit Surface Representations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kinematic-modeling">Kinematic Modeling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#image-formation-and-rendering">3. Image Formation and Rendering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#camera-models">Camera Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#shading-and-visibility">Shading and Visibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="#differentiable-rendering">Differentiable Rendering</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#surface-representation-methods">4. Surface Representation Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#explicit-mesh-models">Explicit Mesh Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implicit-function-models">Implicit Function Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#motion-capture-and-behavior-synthesis">5. Motion Capture and Behavior Synthesis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#capturing-human-motion">Capturing Human Motion</a></li>
<li class="toctree-l3"><a class="reference internal" href="#behavior-synthesis">Behavior Synthesis</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#clothing-modeling">6. Clothing Modeling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#physically-based-simulation">Physically-Based Simulation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-driven-approaches">Data-Driven Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implicit-clothing-models">Implicit Clothing Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#human-object-interaction">7. Human-Object Interaction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#physics-based-methods">Physics-Based Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="#learning-based-approaches">Learning-Based Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hybrid-systems">Hybrid Systems</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#applications">8. Applications</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#entertainment-and-media">Entertainment and Media</a></li>
<li class="toctree-l3"><a class="reference internal" href="#healthcare-and-biomechanics">Healthcare and Biomechanics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#engineering-and-design">Engineering and Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="#human-computer-interaction">Human-Computer Interaction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scientific-research">Scientific Research</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#challenges-and-future-directions">9. Challenges and Future Directions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#scalability-and-generalization">Scalability and Generalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#higher-fidelity-dynamics">Higher-Fidelity Dynamics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-and-labeling-constraints">Data and Labeling Constraints</a></li>
<li class="toctree-l3"><a class="reference internal" href="#physics-and-learning-integration">Physics and Learning Integration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#semantic-and-cognitive-aspects">Semantic and Cognitive Aspects</a></li>
<li class="toctree-l3"><a class="reference internal" href="#realism-vs-controllability">Realism vs. Controllability</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_02_1_image_formation.html">Lecture 02.1 – Image Formation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#historical-developments-in-image-formation">1. Historical Developments in Image Formation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#ancient-and-medieval-optics-camera-obscura">Ancient and Medieval Optics – Camera Obscura</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#renaissance-perspective-and-geometry">Renaissance Perspective and Geometry</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#early-cameras-and-photographic-imaging">Early Cameras and Photographic Imaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#modern-developments">Modern Developments</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#the-pinhole-camera-model">2. The Pinhole Camera Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#coordinate-setup">Coordinate Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#proof-by-similar-triangles">Proof by Similar Triangles</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#numerical-example">Numerical Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#inadequacy-of-a-simple-pinhole">Inadequacy of a Simple Pinhole</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#camera-intrinsics-and-the-projection-matrix">3. Camera Intrinsics and the Projection Matrix</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#extrinsic-parameters">Extrinsic Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#full-projection-example">Full Projection Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#image-distortions-correction">4. Image Distortions &amp; Correction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#properties-of-perspective-projection">5. Properties of Perspective Projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#advanced-theoretical-extensions">6. Advanced Theoretical Extensions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#light-field-imaging-and-plenoptic-cameras">Light Field Imaging and Plenoptic Cameras</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#non-conventional-imaging-techniques">Non-Conventional Imaging Techniques</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#applications-in-modern-vision-and-graphics">7. Applications in Modern Vision and Graphics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#computer-vision-and-3d-reconstruction">Computer Vision and 3D Reconstruction</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#medical-imaging">Medical Imaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_1_image_formation.html#photorealistic-rendering-in-computer-graphics">Photorealistic Rendering in Computer Graphics</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_image_formation.html#python-example-simulating-image-formation">8. Python Example: Simulating Image Formation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html">Lecture 02.2 – Rotations and Kinematic Chains</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#representations-of-3d-rotations">1. Representations of 3D Rotations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#a-rotation-matrices">A) Rotation Matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#b-euler-angles">B) Euler Angles</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#c-quaternions">C) Quaternions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#lie-algebra-so-3-and-exponential-map">2. Lie Algebra <span class="math notranslate nohighlight">\(so(3)\)</span> and Exponential Map</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#rodrigues-rotation-formula">3. Rodrigues’ Rotation Formula</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#kinematic-chains-forward-inverse-kinematics">4. Kinematic Chains: Forward &amp; Inverse Kinematics</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_2_rotations_kinematic_chains.html#comparison-of-rotation-representations">Comparison of Rotation Representations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_03_1_surface_representations.html">Lecture 03.1 – Surface Representations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#mathematical-foundations-of-surface-representations">1. Mathematical Foundations of Surface Representations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-parametric-surfaces">A) Parametric Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-implicit-surfaces">B) Implicit Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-explicit-surfaces">C) Explicit Surfaces</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#surface-differential-properties">2. Surface Differential Properties</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-surface-normals">A) Surface Normals</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-fundamental-forms-and-curvature">B) Fundamental Forms and Curvature</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-geodesics">C) Geodesics</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#discrete-surface-representations">3. Discrete Surface Representations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-polygon-meshes">A) Polygon Meshes</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-point-clouds">B) Point Clouds</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-signed-distance-fields-sdf">C) Signed Distance Fields (SDF)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#advanced-surface-representations">4. Advanced Surface Representations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-bezier-curves-and-surfaces">A) Bézier Curves and Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-b-splines-and-nurbs">B) B-Splines and NURBS</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-subdivision-surfaces">C) Subdivision Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#d-level-sets">D) Level Sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#e-neural-implicit-representations">E) Neural Implicit Representations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#comparative-analysis-and-applications">5. Comparative Analysis and Applications</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-computational-efficiency-and-storage">A) Computational Efficiency and Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-practical-applications">B) Practical Applications</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-operations-complexity">C) Operations Complexity</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#implementation-examples">6. Implementation Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-basic-mesh-processing-python">A) Basic Mesh Processing (Python)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-implicit-surface-utilities">B) Implicit Surface Utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-bezier-curve-implementation">C) Bézier Curve Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#d-curvature-estimation-on-meshes">D) Curvature Estimation on Meshes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_1_surface_representations.html#advanced-topics-and-future-directions">7. Advanced Topics and Future Directions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#a-multi-resolution-representations">A) Multi-Resolution Representations</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#b-machine-learning-for-geometry">B) Machine Learning for Geometry</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#c-dynamic-surfaces">C) Dynamic Surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_1_surface_representations.html#d-non-manifold-geometries">D) Non-Manifold Geometries</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html">Lecture 03.2 – Procrustes Alignment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#goal-learning-a-model-of-pose-and-shape">Goal: Learning a Model of Pose and Shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#the-challenge-of-registration">The Challenge of Registration</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#surface-representation-mesh">Surface Representation: Mesh</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#the-procrustes-alignment-problem-mathematical-formulation">The Procrustes Alignment Problem: Mathematical Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#rigid-transformations">Rigid Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#procrustes-alignment-solution">Procrustes Alignment Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#decoupling-translation-by-centroid-alignment">Decoupling Translation by Centroid Alignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#optimal-rotation-via-svd">Optimal Rotation via SVD</a><ul>
<li class="toctree-l4"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#reflection-adjustment">Reflection Adjustment</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#optimal-scale-optional">Optimal Scale (Optional)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#complete-mathematical-derivation">Complete Mathematical Derivation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#translation-derivation">Translation Derivation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#rotation-derivation">Rotation Derivation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#scale-derivation">Scale Derivation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#summary-of-procrustes-alignment-algorithm">Summary of Procrustes Alignment Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#python-implementation-example">Python Implementation Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#practical-applications">Practical Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_03_2_procrustes_alignment.html#interactive-visualization-ideas">Interactive Visualization Ideas</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_04_1_icp.html">Lecture 4.1: Iterative Closest Point</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#introduction-to-shape-alignment-and-registration">Introduction to Shape Alignment and Registration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#the-registration-problem">The Registration Problem</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#review-procrustes-analysis">Review: Procrustes Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#problem-unknown-correspondences">Problem: Unknown Correspondences</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#the-iterative-closest-point-icp-algorithm">The Iterative Closest Point (ICP) Algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#basic-icp-algorithm">Basic ICP Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#computational-considerations">Computational Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="lecture_04_1_icp.html#closest-point-computation">Closest Point Computation</a></li>
<li class="toctree-l4"><a class="reference internal" href="lecture_04_1_icp.html#convergence-and-local-minima">Convergence and Local Minima</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#point-to-point-vs-point-to-plane-icp">Point-to-Point vs. Point-to-Plane ICP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#point-to-point-icp">Point-to-Point ICP</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#point-to-plane-icp">Point-to-Plane ICP</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#gradient-based-icp-for-non-rigid-registration">Gradient-based ICP for Non-Rigid Registration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#gradient-based-icp-algorithm">Gradient-based ICP Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#advantages-of-gradient-based-icp">Advantages of Gradient-based ICP</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#computing-gradients">Computing Gradients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#improving-icp-s-robustness">Improving ICP’s Robustness</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#data-association-direction">Data Association Direction</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#robust-cost-functions">Robust Cost Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#trimmed-icp">Trimmed ICP</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#ransac-based-approaches">RANSAC-based Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#additional-information">Additional Information</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#point-to-surface-distance">Point-to-Surface Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#icp-variants-and-extensions">ICP Variants and Extensions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#generalized-icp-gicp">Generalized ICP (GICP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#em-icp-and-probabilistic-approaches">EM-ICP and Probabilistic Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#coherent-point-drift-cpd">Coherent Point Drift (CPD)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#multi-scale-approaches">Multi-Scale Approaches</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#applications-of-icp">Applications of ICP</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#implementing-icp">Implementing ICP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#efficient-python-implementation">Efficient Python Implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_1_icp.html#practical-tips">Practical Tips</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_1_icp.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_04_2_body_models.html">Lecture 04.2 - Body Models: Vertex-Based Models and SMPL</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_2_body_models.html#body-models-as-parameterized-functions">1. Body Models as Parameterized Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_2_body_models.html#rotations-articulation-and-pose-representation">2. Rotations, Articulation, and Pose Representation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#rotation-representation">2.1 Rotation Representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#kinematic-chain">2.2 Kinematic Chain</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_2_body_models.html#linear-blend-skinning-and-its-limitations">3. Linear Blend Skinning and its Limitations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#linear-blend-skinning">3.1 Linear Blend Skinning</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#problems-with-standard-lbs">3.2 Problems with Standard LBS</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#blend-shapes-for-correcting-lbs-artifacts">3.3 Blend Shapes for Correcting LBS Artifacts</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_2_body_models.html#the-smpl-body-model">4. The SMPL Body Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#smpl-philosophy">4.1 SMPL Philosophy</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#smpl-model-architecture">4.2 SMPL Model Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#shape-blend-shapes">4.2.1 Shape Blend Shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#pose-blend-shapes">4.2.2 Pose Blend Shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#joint-regression">4.2.3 Joint Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#model-training">4.3 Model Training</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_2_body_models.html#comparison-with-scape">5. Comparison with SCAPE</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#the-scape-model">5.1 The SCAPE Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#different-approaches-to-deformation">5.2 Different Approaches to Deformation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#performance-comparison">5.3 Performance Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#other-advantages">5.4 Other Advantages</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_2_body_models.html#alignment-techniques-procrustes-analysis-and-icp">6. Alignment Techniques: Procrustes Analysis and ICP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#procrustes-analysis">6.1 Procrustes Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#iterative-closest-point-icp">6.2 Iterative Closest Point (ICP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#fitting-smpl-to-scans">6.3 Fitting SMPL to Scans</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_2_body_models.html#image-formation-and-the-pinhole-camera-model">7. Image Formation and the Pinhole Camera Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#the-pinhole-camera-model">7.1 The Pinhole Camera Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#lens-distortion">7.2 Lens Distortion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_2_body_models.html#extensions-and-advanced-applications">8. Extensions and Advanced Applications</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#dynamic-soft-tissue-modeling">8.1 Dynamic Soft Tissue Modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#specialized-extensions">8.2 Specialized Extensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#deep-learning-for-model-fitting">8.3 Deep Learning for Model Fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#probabilistic-approaches">8.4 Probabilistic Approaches</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_04_2_body_models.html#hybrid-models">8.5 Hybrid Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_04_2_body_models.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_05_1_body_model_training.html">Lecture 5.1 - Training a Body Model and Fitting SMPL to Scans</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#body-models-based-on-triangle-deformations">Body Models Based on Triangle Deformations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#scape-and-blendscape-models">SCAPE and BlendSCAPE Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#triangle-deformation-process">Triangle Deformation Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#comparison-smpl-vs-scape-blendscape">Comparison: SMPL vs. SCAPE/BlendSCAPE</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#training-a-body-model-from-registrations">Training a Body Model from Registrations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#the-challenge-of-raw-scan-data">The Challenge of Raw Scan Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#training-from-registrations">Training from Registrations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#obtaining-registrations-fitting-smpl-to-scans">Obtaining Registrations: Fitting SMPL to Scans</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#non-rigid-registration-process">Non-Rigid Registration Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#iterative-closest-point-icp-review">Iterative Closest Point (ICP) Review</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#registration-objective-formulation">Registration Objective Formulation</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#point-to-surface-distance">Point-to-Surface Distance</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#multi-stage-optimization-strategy">Multi-Stage Optimization Strategy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#joint-registration-and-model-training">Joint Registration and Model Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_05_1_body_model_training.html#co-registration-approach">Co-Registration Approach</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_05_1_body_model_training.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a><ul>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-01-1-historical-body-models">Lecture 01.1 (Historical Body Models)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-01-2-introduction-to-human-models">Lecture 01.2 (Introduction to Human Models)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-01-3-introduction-to-human-models-continued">Lecture 01.3 (Introduction to Human Models Continued)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-02-1-image-formation">Lecture 02.1 (Image Formation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-02-2-rotations-kinematic-chains">Lecture 02.2 (Rotations &amp; Kinematic Chains)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-03-1-surface-representations">Lecture 03.1 (Surface Representations)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-03-2-procrustes-alignment">Lecture 03.2 (Procrustes Alignment)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-04-1-iterative-closest-points">Lecture 04.1 (Iterative Closest Points)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-04-2-body-models">Lecture 04.2 (Body Models)</a></li>
<li class="toctree-l2"><a class="reference internal" href="references.html#lecture-05-1-body-model-training">Lecture 05.1 (Body Model Training)</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Virtual Humans Lecture</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Lecture 01.3 – Introduction to Human Models (Overview)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/lecture_01_3_introduction_to_human_models_continued.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="lecture-01-3-introduction-to-human-models-overview">
<span id="lecture-01-3-intro-human-models-overview"></span><h1>Lecture 01.3 – Introduction to Human Models (Overview)<a class="headerlink" href="#lecture-01-3-introduction-to-human-models-overview" title="Link to this heading"></a></h1>
<iframe width="600" height="400" src="https://www.youtube.com/embed/q32aoImkiIo"
title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p><a class="reference external" href="https://virtualhumans.mpi-inf.mpg.de/VH23/slides/pdf/Lecture_01_3_Introduction_Body_Models_Overview.pdf">Lecture Slides: Introduction to Human Models</a></p>
<p>This lecture presents a comprehensive overview of human body modeling, from historical roots to
state-of-the-art techniques. We explore how knowledge from anatomy, computer vision, computer graphics,
and biomechanics converges to create digital representations of human shape, motion, and behavior.</p>
<section id="historical-context">
<h2>1. Historical Context<a class="headerlink" href="#historical-context" title="Link to this heading"></a></h2>
<p>Human body modeling has evolved through centuries of scientific investigation:</p>
<section id="early-scientific-studies">
<h3>Early Scientific Studies<a class="headerlink" href="#early-scientific-studies" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Weber Brothers (1836)</strong>: Conducted one of the first quantitative gait analyses, measuring
timing and distances in human walking.</p></li>
<li><p><strong>Marey and Muybridge (1870s-1880s)</strong>: Pioneered sequential photography (chronophotography)
to capture and analyze human motion.</p></li>
<li><p><strong>Braune and Fischer (1890s)</strong>: Applied Newtonian mechanics to study body-segment motion,
calculating joint forces and energy expenditure during locomotion.</p></li>
</ul>
</section>
<section id="mid-20th-century-to-digital-era">
<h3>Mid-20th Century to Digital Era<a class="headerlink" href="#mid-20th-century-to-digital-era" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Biomechanical Research</strong>: Rehabilitation needs for World War II veterans spurred comprehensive
gait studies at the University of California in the 1950s.</p></li>
<li><p><strong>Computer Graphics (1970s-1980s)</strong>:
- Phong’s illumination model (1975) improved rendering of 3D surfaces
- Fred Parke (1972) created the first 3D facial models</p></li>
<li><p><strong>Motion Capture Development</strong>:
- Tom Calvert’s goniometer suit (1983) for medical motion capture
- Marker-based optical systems emerged in the late 1980s
- Vicon systems with reflective markers became standard in the 1990s</p></li>
</ul>
</section>
<section id="st-century-advances">
<h3>21st Century Advances<a class="headerlink" href="#st-century-advances" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Markerless Motion Capture</strong>:
- Hogg’s work (1983) demonstrated tracking walking figures from video
- Multi-camera systems in the 2000s enabled visual hull reconstruction
- Depth sensors (Microsoft Kinect, 2010) accelerated markerless capture</p></li>
<li><p><strong>Deep Learning Revolution</strong>:
- Convolutional networks for 2D and 3D pose estimation (OpenPose, DeepPose)
- Parametric body models like SMPL enabled single-image 3D reconstruction</p></li>
<li><p><strong>Behavior Synthesis</strong>:
- From keyframe animation and physical simulations (1980s-1990s)
- To motion graphs for recombining captured clips (2000s)
- Modern deep learning approaches for generating realistic movements</p></li>
</ul>
<p>Today’s human body models combine anatomical insight, physics, and data-driven learning
to achieve unprecedented realism and functionality.</p>
</section>
</section>
<section id="mathematical-foundations">
<h2>2. Mathematical Foundations<a class="headerlink" href="#mathematical-foundations" title="Link to this heading"></a></h2>
<section id="parametric-body-models">
<h3>Parametric Body Models<a class="headerlink" href="#parametric-body-models" title="Link to this heading"></a></h3>
<p>The Skinned Multi-Person Linear (SMPL) model exemplifies modern parametric approaches:</p>
<div class="math notranslate nohighlight">
\[M(\boldsymbol{\theta}, \boldsymbol{\beta}) : \mathbb{R}^{|\theta| + |\beta|} \rightarrow \mathbb{R}^{3N}\]</div>
<p>where:
- <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> represents pose parameters (joint angles, typically 72 parameters for 24 joints)
- <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> represents shape parameters (typically 10 principal components)
- <span class="math notranslate nohighlight">\(N\)</span> is the number of mesh vertices (6890 in SMPL)</p>
<p>SMPL can be factored into:
1. <strong>Base mesh</strong> (mean shape)
2. <strong>Shape blend shapes</strong> (scaled by <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span>)
3. <strong>Pose blend shapes</strong> (dependent on <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>)
4. <strong>Skeleton-driven deformation</strong> via linear blend skinning</p>
<p>This creates a differentiable, low-dimensional representation that can be efficiently optimized.</p>
</section>
<section id="implicit-surface-representations">
<h3>Implicit Surface Representations<a class="headerlink" href="#implicit-surface-representations" title="Link to this heading"></a></h3>
<p>Alternative to meshes, implicit functions define the body as a level set:</p>
<div class="math notranslate nohighlight">
\[\text{Surface} = \{\mathbf{x} \in \mathbb{R}^3 : f(\mathbf{x}) = 0\}\]</div>
<p>Common implicit representations include:
- <strong>Signed Distance Functions (SDFs)</strong>: <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span> gives distance to surface (positive outside, negative inside)
- <strong>Occupancy Functions</strong>: Binary inside/outside classification</p>
<p>Neural networks can approximate these functions:
- <strong>DeepSDF</strong>: MLPs outputting distance values for query points
- <strong>Neural Articulated Shape Approximation (NASA)</strong>: Implicit functions conditioned on pose</p>
</section>
<section id="kinematic-modeling">
<h3>Kinematic Modeling<a class="headerlink" href="#kinematic-modeling" title="Link to this heading"></a></h3>
<p>Human movement is modeled as an articulated figure:</p>
<ul class="simple">
<li><p><strong>Forward Kinematics (FK)</strong>: Computing limb positions from joint angles
- Global transform of joint <span class="math notranslate nohighlight">\(j\)</span>: <span class="math notranslate nohighlight">\(G_j = G_{\text{parent}(j)} \cdot \text{Trans}(L_{\text{parent}(j)}) \cdot R_j(\theta_j)\)</span></p></li>
<li><p><strong>Inverse Kinematics (IK)</strong>: Solving for joint angles given desired end-effector positions
- Often uses Jacobian <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta}) = \frac{\partial \mathbf{p}}{\partial \boldsymbol{\theta}}\)</span> relating joint angle changes to end-effector position changes</p></li>
<li><p><strong>Skinning</strong>: Vertex position <span class="math notranslate nohighlight">\(v_i'\)</span> is computed as
<span class="math notranslate nohighlight">\(v_i' = \sum_j w_{ij} (\mathbf{T}_j(\theta) \cdot v_i)\)</span> where <span class="math notranslate nohighlight">\(w_{ij}\)</span> are skinning weights</p></li>
</ul>
<p>For pose and shape estimation, optimization seeks parameters that minimize the distance between
model and observations, often using iterative methods or learning-based approaches.</p>
</section>
</section>
<section id="image-formation-and-rendering">
<h2>3. Image Formation and Rendering<a class="headerlink" href="#image-formation-and-rendering" title="Link to this heading"></a></h2>
<p>Projecting 3D humans to 2D images involves several processes:</p>
<section id="camera-models">
<h3>Camera Models<a class="headerlink" href="#camera-models" title="Link to this heading"></a></h3>
<p>The pinhole camera model provides the foundation:</p>
<div class="math notranslate nohighlight">
\[(u, v) = \left(f \frac{X}{Z} + c_x, f \frac{Y}{Z} + c_y\right)\]</div>
<p>where:
- <span class="math notranslate nohighlight">\((X, Y, Z)\)</span> are 3D coordinates in camera space
- <span class="math notranslate nohighlight">\(f\)</span> is focal length
- <span class="math notranslate nohighlight">\((c_x, c_y)\)</span> is the principal point</p>
<p>Camera extrinsic parameters (rotation <span class="math notranslate nohighlight">\(R\)</span>, translation <span class="math notranslate nohighlight">\(t\)</span>) transform
world coordinates to camera coordinates before projection.</p>
</section>
<section id="shading-and-visibility">
<h3>Shading and Visibility<a class="headerlink" href="#shading-and-visibility" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Lambertian shading</strong>: Surface brightness proportional to <span class="math notranslate nohighlight">\(I = \rho \, (\mathbf{n} \cdot \mathbf{l})\)</span>
where <span class="math notranslate nohighlight">\(\mathbf{n}\)</span> is surface normal and <span class="math notranslate nohighlight">\(\mathbf{l}\)</span> is light direction</p></li>
<li><p><strong>Phong model</strong>: Adds specular highlights for more realistic rendering</p></li>
<li><p><strong>Z-buffer</strong>: Resolves visibility by keeping only the nearest surface at each pixel</p></li>
<li><p><strong>Silhouettes</strong>: In multi-view setups, combining silhouettes creates visual hulls approximating
the 3D volume of a person</p></li>
</ul>
</section>
<section id="differentiable-rendering">
<h3>Differentiable Rendering<a class="headerlink" href="#differentiable-rendering" title="Link to this heading"></a></h3>
<p>Recent advances make the rendering process differentiable, enabling gradient-based optimization:</p>
<ul class="simple">
<li><p><strong>Softened rasterization</strong>: Allows gradients to flow even through discrete operations</p></li>
<li><p><strong>End-to-end optimization</strong>: Neural networks can be trained to predict body parameters by
comparing rendered projections with input images</p></li>
<li><p><strong>Self-supervised learning</strong>: Using image synthesis error as a loss when 3D ground truth is unavailable</p></li>
</ul>
<p>This capability allows fitting 3D human models to 2D observations by iteratively refining the model
to align with the input image.</p>
</section>
</section>
<section id="surface-representation-methods">
<h2>4. Surface Representation Methods<a class="headerlink" href="#surface-representation-methods" title="Link to this heading"></a></h2>
<p>Two dominant approaches represent human body geometry:</p>
<section id="explicit-mesh-models">
<h3>Explicit Mesh Models<a class="headerlink" href="#explicit-mesh-models" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Fixed topology</strong>: Surface represented by vertices connected in a consistent mesh structure
(e.g., SMPL with 6890 vertices and ~13,776 triangular faces)</p></li>
<li><p><strong>Blendshapes</strong>: Shape variations expressed as vertex displacements from a template mesh
- SMPL uses linear combinations of learned shape basis vectors</p></li>
<li><p><strong>Advantages</strong>:
- Efficient rendering on graphics hardware
- Direct semantic correspondence across shapes
- Simple animation via skinning
- Easy texture mapping and collision detection</p></li>
<li><p><strong>Limitations</strong>:
- Cannot handle topology changes
- Fixed resolution (more details require more vertices)</p></li>
</ul>
</section>
<section id="implicit-function-models">
<h3>Implicit Function Models<a class="headerlink" href="#implicit-function-models" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Continuous field</strong>: Body defined as level set of a function in 3D space
- Neural networks can approximate these fields (e.g., DeepSDF, NASA)</p></li>
<li><p><strong>Advantages</strong>:
- Topological flexibility (can represent open jackets, loose clothing)
- Arbitrary resolution (can be sampled at any density)
- Natural handling of complex geometry
- Continuous surfaces and gradients</p></li>
<li><p><strong>Limitations</strong>:
- Computationally expensive to render
- Harder to animate in real-time
- Less direct control for artists</p></li>
</ul>
<p>Hybrid approaches combine explicit models for coarse structure with implicit functions
for high-resolution details.</p>
</section>
</section>
<section id="motion-capture-and-behavior-synthesis">
<h2>5. Motion Capture and Behavior Synthesis<a class="headerlink" href="#motion-capture-and-behavior-synthesis" title="Link to this heading"></a></h2>
<section id="capturing-human-motion">
<h3>Capturing Human Motion<a class="headerlink" href="#capturing-human-motion" title="Link to this heading"></a></h3>
<p><strong>Marker-Based Systems</strong>:
- <strong>Optical motion capture</strong>: Reflective markers tracked by infrared cameras
- <strong>Inertial systems</strong>: IMUs measuring orientation and acceleration on each limb
- <strong>Advantages</strong>: High accuracy, temporal resolution
- <strong>Limitations</strong>: Requires specialized equipment, markers can interfere with natural movement</p>
<p><strong>Markerless Approaches</strong>:
- <strong>Multi-camera systems</strong>: Reconstruct visual hulls from silhouettes
- <strong>Deep learning</strong>: Models like OpenPose detect 2D keypoints from regular video
- <strong>Model-fitting</strong>: SMPLify optimizes 3D body model to match 2D detections
- <strong>End-to-end networks</strong>: HMR, VIBE directly regress SMPL parameters from images/video</p>
<p><strong>Sparse Sensing</strong>:
- Recent work shows as few as 5 IMUs can reconstruct full body pose
- Learning fills gaps in sparse observations using motion priors</p>
</section>
<section id="behavior-synthesis">
<h3>Behavior Synthesis<a class="headerlink" href="#behavior-synthesis" title="Link to this heading"></a></h3>
<p><strong>Motion Graphs and Clip-Based Methods</strong>:
- Stitch existing motion clips at compatible transitions
- Introduced by Kovar et al. (2002)
- Good for interactive control with available motion data</p>
<p><strong>Physics-Based Simulation</strong>:
- Model body as articulated rigid bodies with physics
- Apply joint torques to generate movement
- Examples include Hodgins et al. (1995) simulating athletic movements</p>
<p><strong>Deep Learning Approaches</strong>:
- <strong>Generative models</strong>: VAEs, GANs, diffusion models learn motion distributions
- Can be conditioned on music, action labels, or other high-level inputs
- Example: DeepMimic (Peng et al. 2018) uses reinforcement learning to imitate mocap clips</p>
<p><strong>Hybrid Methods</strong>:
- Combine data-driven motion with physics constraints
- Xie et al. (2021) incorporate physics into training from video data
- Ensure plausible dynamics while leveraging large datasets</p>
</section>
</section>
<section id="clothing-modeling">
<h2>6. Clothing Modeling<a class="headerlink" href="#clothing-modeling" title="Link to this heading"></a></h2>
<p>Realistic virtual humans require clothing that moves naturally:</p>
<section id="physically-based-simulation">
<h3>Physically-Based Simulation<a class="headerlink" href="#physically-based-simulation" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Mass-spring systems</strong>: Cloth as mesh with physical forces</p></li>
<li><p><strong>Finite element methods</strong>: More accurate but computationally expensive</p></li>
<li><p><strong>Baraff &amp; Witkin (1998)</strong>: Pioneered efficient implicit integration for cloth</p></li>
</ul>
<div class="math notranslate nohighlight">
\[E = \text{Elastic forces} + \text{Gravity} + \text{Collision response}\]</div>
<ul class="simple">
<li><p><strong>Advantages</strong>: Realistic dynamics for any movement</p></li>
<li><p><strong>Limitations</strong>: Computationally intensive, requires accurate material parameters</p></li>
</ul>
</section>
<section id="data-driven-approaches">
<h3>Data-Driven Approaches<a class="headerlink" href="#data-driven-approaches" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Garment shape spaces</strong>: Learn how clothing deforms with different poses</p></li>
<li><p><strong>TailorNet</strong>: Neural network predicting clothing deformation from body pose and shape</p></li>
<li><p><strong>Displacement models</strong>: Map offsets from body surface to clothing</p></li>
<li><p><strong>Advantages</strong>: Fast runtime performance after training</p></li>
<li><p><strong>Limitations</strong>: Limited to training distribution of poses/shapes</p></li>
</ul>
</section>
<section id="implicit-clothing-models">
<h3>Implicit Clothing Models<a class="headerlink" href="#implicit-clothing-models" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Neural implicit functions</strong>: Represent clothing as level sets</p></li>
<li><p><strong>BCNet</strong>: Two-layer model with body and cloth as separate implicit surfaces</p></li>
<li><p><strong>Advantages</strong>: Handle topology changes (open jackets, loose garments)</p></li>
<li><p><strong>Limitations</strong>: More complex to train and render</p></li>
</ul>
<p>Layered approaches combine body models with separate clothing models, enabling
transfer between different bodies while maintaining natural movement.</p>
</section>
</section>
<section id="human-object-interaction">
<h2>7. Human-Object Interaction<a class="headerlink" href="#human-object-interaction" title="Link to this heading"></a></h2>
<p>Modeling interactions between humans and their environment:</p>
<section id="physics-based-methods">
<h3>Physics-Based Methods<a class="headerlink" href="#physics-based-methods" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Contact constraints</strong>: Ensure no penetration, appropriate reaction forces</p></li>
<li><p><strong>Motion planning</strong>: Find trajectories that accomplish tasks while obeying physics</p></li>
<li><p><strong>Contact-Invariant Optimization</strong>: Mordatch et al. (2012) optimized motion with contact variables</p></li>
<li><p><strong>Applications</strong>: Sitting, climbing, manipulating objects with proper physics</p></li>
</ul>
</section>
<section id="learning-based-approaches">
<h3>Learning-Based Approaches<a class="headerlink" href="#learning-based-approaches" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Affordances</strong>: Learn which objects allow which actions (chairs afford sitting)</p></li>
<li><p><strong>PROX</strong>: Hassan et al. (2019) captured realistic human-scene interactions</p></li>
<li><p><strong>Pose prediction</strong>: Generate appropriate human poses near specific objects</p></li>
<li><p><strong>Applications</strong>: Scene population, interaction prediction, ergonomic assessment</p></li>
</ul>
</section>
<section id="hybrid-systems">
<h3>Hybrid Systems<a class="headerlink" href="#hybrid-systems" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Reinforce learning for tasks</strong>: Learn to sit (ICLR 2020) used neural policies for chair interactions</p></li>
<li><p><strong>COUCH (2021)</strong>: Combined data-driven pose synthesis with controllable contact points</p></li>
<li><p><strong>Applications</strong>: Interactive virtual humans that respond naturally to environments</p></li>
</ul>
<p>Human-object interaction modeling is crucial for virtual reality, robotics, and
digital human simulations that involve realistic environmental interaction.</p>
</section>
</section>
<section id="applications">
<h2>8. Applications<a class="headerlink" href="#applications" title="Link to this heading"></a></h2>
<p>Virtual human models power applications across numerous domains:</p>
<section id="entertainment-and-media">
<h3>Entertainment and Media<a class="headerlink" href="#entertainment-and-media" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Film and Animation</strong>: Digital characters and crowds in movies</p></li>
<li><p><strong>Video Games</strong>: Real-time character control and procedural animation</p></li>
<li><p><strong>Virtual Reality</strong>: Avatars representing users in immersive environments</p></li>
</ul>
</section>
<section id="healthcare-and-biomechanics">
<h3>Healthcare and Biomechanics<a class="headerlink" href="#healthcare-and-biomechanics" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Gait Analysis</strong>: Quantify walking patterns for diagnosis and treatment</p></li>
<li><p><strong>Rehabilitation</strong>: Track and assess patient movements during therapy</p></li>
<li><p><strong>Surgical Planning</strong>: Patient-specific anatomical models</p></li>
<li><p><strong>Sports Performance</strong>: Technique analysis and injury prevention</p></li>
</ul>
</section>
<section id="engineering-and-design">
<h3>Engineering and Design<a class="headerlink" href="#engineering-and-design" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Ergonomics</strong>: Design workspaces and products for human comfort</p></li>
<li><p><strong>Robotics</strong>: Human-robot interaction and collaborative environments</p></li>
<li><p><strong>Autonomous Systems</strong>: Pedestrian tracking and behavior prediction</p></li>
</ul>
</section>
<section id="human-computer-interaction">
<h3>Human-Computer Interaction<a class="headerlink" href="#human-computer-interaction" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Gesture Recognition</strong>: Body-based input for interfaces</p></li>
<li><p><strong>Virtual Try-On</strong>: Visualize clothing on personalized avatars</p></li>
<li><p><strong>Accessibility</strong>: Design interfaces for diverse body types and abilities</p></li>
</ul>
</section>
<section id="scientific-research">
<h3>Scientific Research<a class="headerlink" href="#scientific-research" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Psychology</strong>: Study body language and non-verbal communication</p></li>
<li><p><strong>Anthropology</strong>: Analyze human movement across cultures</p></li>
<li><p><strong>Forensics</strong>: Reconstruct accidents or crime scenes</p></li>
</ul>
</section>
</section>
<section id="challenges-and-future-directions">
<h2>9. Challenges and Future Directions<a class="headerlink" href="#challenges-and-future-directions" title="Link to this heading"></a></h2>
<p>Despite significant progress, several challenges remain:</p>
<section id="scalability-and-generalization">
<h3>Scalability and Generalization<a class="headerlink" href="#scalability-and-generalization" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Population Diversity</strong>: Current models often lack coverage of children, elderly, or unusual body types</p></li>
<li><p><strong>Motion Diversity</strong>: Rare or extreme actions may fall outside training distributions</p></li>
<li><p><strong>Computational Efficiency</strong>: High-fidelity models require significant resources</p></li>
</ul>
</section>
<section id="higher-fidelity-dynamics">
<h3>Higher-Fidelity Dynamics<a class="headerlink" href="#higher-fidelity-dynamics" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Soft Tissue</strong>: Modeling fat and muscle jiggling during movement</p></li>
<li><p><strong>Fine Details</strong>: Realistic facial expressions and hand articulation</p></li>
<li><p><strong>Secondary Motion</strong>: Cloth, hair, and accessories with physical accuracy</p></li>
</ul>
</section>
<section id="data-and-labeling-constraints">
<h3>Data and Labeling Constraints<a class="headerlink" href="#data-and-labeling-constraints" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Ground Truth</strong>: Difficult to obtain accurate 3D pose for in-the-wild data</p></li>
<li><p><strong>Contact Information</strong>: Precisely capturing where and how bodies interact with objects</p></li>
<li><p><strong>Privacy Concerns</strong>: Ethical use of motion data that may be identifying</p></li>
</ul>
</section>
<section id="physics-and-learning-integration">
<h3>Physics and Learning Integration<a class="headerlink" href="#physics-and-learning-integration" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Physical Plausibility</strong>: Learned models can produce physically impossible results</p></li>
<li><p><strong>Differentiable Physics</strong>: Backpropagating through simulations for training</p></li>
<li><p><strong>Simulation-to-Real Gap</strong>: Ensuring models transfer from simulation to real data</p></li>
</ul>
</section>
<section id="semantic-and-cognitive-aspects">
<h3>Semantic and Cognitive Aspects<a class="headerlink" href="#semantic-and-cognitive-aspects" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Action Planning</strong>: High-level decision making for autonomous virtual humans</p></li>
<li><p><strong>Social Behavior</strong>: Modeling gestures, personal space, and interaction norms</p></li>
<li><p><strong>Context Awareness</strong>: Understanding environmental constraints and affordances</p></li>
</ul>
</section>
<section id="realism-vs-controllability">
<h3>Realism vs. Controllability<a class="headerlink" href="#realism-vs-controllability" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Multi-Level Control</strong>: Balancing high-level commands with low-level physics</p></li>
<li><p><strong>Real-Time Performance</strong>: Maintaining realism under interactive constraints</p></li>
<li><p><strong>Artist Tools</strong>: Providing intuitive interfaces for animation and control</p></li>
</ul>
<p>The future likely holds unified models combining shape, motion, clothing, and intention
in a single framework, enabling applications from immersive telepresence to autonomous
digital humans that interact naturally with users.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="lecture_01_2_introduction_to_human_models.html" class="btn btn-neutral float-left" title="Lecture 01.2 – Introduction to Human Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="lecture_02_1_image_formation.html" class="btn btn-neutral float-right" title="Lecture 02.1 – Image Formation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>