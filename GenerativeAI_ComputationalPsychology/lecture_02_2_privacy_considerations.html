

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Lecture 02.2 – Privacy Considerations &mdash; Generative AI for Computational Psychology</title>
      <link rel="stylesheet" type="text/css" href="/GenerativeAI_ComputationalPsychology/_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="/GenerativeAI_ComputationalPsychology/_static/css/theme.css?v=e59714d7" />

  
    <link rel="canonical" href="https://treese41528.github.io/GenerativeAI_ComputationalPsychology/lecture_02_2_privacy_considerations.html" />
      <script src="/GenerativeAI_ComputationalPsychology/_static/jquery.js?v=5d32c60e"></script>
      <script src="/GenerativeAI_ComputationalPsychology/_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="/GenerativeAI_ComputationalPsychology/_static/documentation_options.js?v=f2a433a1"></script>
      <script src="/GenerativeAI_ComputationalPsychology/_static/doctools.js?v=9bcbadda"></script>
      <script src="/GenerativeAI_ComputationalPsychology/_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="/GenerativeAI_ComputationalPsychology/_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Lecture 02.4 - Conversational AI Survey (BFITraitTalk_AI Tutorial)" href="lecture_02_3_bfitraittalk_ai_tutorial.html" />
    <link rel="prev" title="Lecture 02.1 – Interactive AI Surveys" href="lecture_02_1_interactive_ai_surveys.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Generative AI in Psychological Research
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="lecture_overview.html">Generative AI in Psychological Research: Course Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_overview.html#module-1-foundations-of-ai-in-psychology">Module 1: Foundations of AI in Psychology</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_overview.html#module-2-ai-driven-data-collection">Module 2: AI-Driven Data Collection</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_01_1_intro_to_genai_psychology.html">Lecture 01.1 – Introduction to Generative AI in Psychology</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_intro_to_genai_psychology.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_intro_to_genai_psychology.html#capabilities-of-modern-generative-ai">Capabilities of Modern Generative AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_intro_to_genai_psychology.html#the-evolution-from-traditional-to-ai-augmented-research">The Evolution from Traditional to AI-Augmented Research</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_intro_to_genai_psychology.html#the-spectrum-of-llm-applications-in-psychology">The Spectrum of LLM Applications in Psychology</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_intro_to_genai_psychology.html#key-ethical-and-methodological-considerations">Key Ethical and Methodological Considerations</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_intro_to_genai_psychology.html#case-study-the-emergence-of-silicon-samples">Case Study: The Emergence of “Silicon Samples”</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_1_intro_to_genai_psychology.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html">Lecture 01.2 – Survey Design with Large Language Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html#traditional-challenges-in-survey-design">Traditional Challenges in Survey Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html#how-llms-can-enhance-survey-design">How LLMs Can Enhance Survey Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html#case-study-ai-generated-vs-human-generated-questionnaires">Case Study: AI-Generated vs. Human-Generated Questionnaires</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html#practical-implementation-human-ai-collaboration-in-survey-design">Practical Implementation: Human-AI Collaboration in Survey Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html#optimizing-llm-prompts-for-survey-design">Optimizing LLM Prompts for Survey Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html#limitations-and-best-practices">Limitations and Best Practices</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html#case-example-developing-a-likert-scale-measure-of-climate-anxiety">Case Example: Developing a Likert-Scale Measure of Climate Anxiety</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_01_3_synthetic_respondents.html">Lecture 01.3 – Synthetic Respondents: Simulation and Supplementation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_synthetic_respondents.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_synthetic_respondents.html#the-promise-of-synthetic-respondents">The Promise of Synthetic Respondents</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_synthetic_respondents.html#the-scientific-reality-empirical-findings-on-synthetic-respondent-fidelity">The Scientific Reality: Empirical Findings on Synthetic Respondent Fidelity</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_synthetic_respondents.html#proper-use-cases-and-limitations">Proper Use Cases and Limitations</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_synthetic_respondents.html#case-study-depression-prediction-from-synthetic-clinical-interviews">Case Study: Depression Prediction from Synthetic Clinical Interviews</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_synthetic_respondents.html#best-practices-for-working-with-synthetic-respondents">Best Practices for Working With Synthetic Respondents</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_01_3_synthetic_respondents.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html">Lecture 02.1 – Interactive AI Surveys</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html#the-promise-of-conversational-ai-surveys">The Promise of Conversational AI Surveys</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html#empirical-evidence-do-ai-interviews-work">Empirical Evidence: Do AI Interviews Work?</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html#implementing-ai-conversational-surveys">Implementing AI Conversational Surveys</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html#case-study-an-ai-driven-mental-health-assessment">Case Study: An AI-Driven Mental Health Assessment</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html#ethical-considerations">Ethical Considerations</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html#best-practices-for-ai-driven-surveys">Best Practices for AI-Driven Surveys</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html#future-directions">Future Directions</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Lecture 02.2 – Privacy Considerations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#understanding-the-privacy-landscape">Understanding the Privacy Landscape</a></li>
<li class="toctree-l2"><a class="reference internal" href="#closed-api-llms-vs-open-source-models-a-privacy-comparison">Closed API LLMs vs. Open-Source Models: A Privacy Comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="#practical-privacy-preservation-strategies">Practical Privacy Preservation Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hybrid-approaches-balancing-privacy-and-capability">Hybrid Approaches: Balancing Privacy and Capability</a></li>
<li class="toctree-l2"><a class="reference internal" href="#responsible-documentation-and-transparency">Responsible Documentation and Transparency</a></li>
<li class="toctree-l2"><a class="reference internal" href="#case-study-privacy-preserving-clinical-assessment">Case Study: Privacy-Preserving Clinical Assessment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#future-directions-in-privacy-preserving-ai">Future Directions in Privacy-Preserving AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html">Lecture 02.4 - Conversational AI Survey (BFITraitTalk_AI Tutorial)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#setup">Setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#installation-steps">Installation Steps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#codebase-walkthrough">Codebase Walkthrough</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#frontend-design-user-interface">Frontend Design (User Interface)</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#survey-logic-and-adaptive-interview-flow">Survey Logic and Adaptive Interview Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#backend-structure-and-data-flow">Backend Structure and Data Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#psychological-design-considerations">Psychological Design Considerations</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#ethical-and-methodological-considerations">Ethical and Methodological Considerations</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#customization-and-extension-ideas">Customization and Extension Ideas</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Generative AI in Psychological Research</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Lecture 02.2 – Privacy Considerations</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/lecture_02_2_privacy_considerations.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="lecture-02-2-privacy-considerations">
<h1>Lecture 02.2 – Privacy Considerations<a class="headerlink" href="#lecture-02-2-privacy-considerations" title="Link to this heading"></a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading"></a></h2>
<p>The integration of large language models (LLMs) into psychological research introduces significant privacy and security considerations that researchers must carefully navigate. When we use AI systems to design surveys, generate synthetic data, or interact with participants, we create new data flows that may expose sensitive personal information to novel risks. This lecture examines the privacy implications of using generative AI in psychological research, with special attention to the trade-offs between closed API models and open-source alternatives.</p>
<p>Our focus will be on helping researchers make informed decisions about which AI approaches best protect participant confidentiality while still enabling innovative research. We will also discuss compliance with relevant regulations, institutional review board (IRB) considerations, and emerging best practices in this rapidly evolving landscape.</p>
</section>
<section id="understanding-the-privacy-landscape">
<h2>Understanding the Privacy Landscape<a class="headerlink" href="#understanding-the-privacy-landscape" title="Link to this heading"></a></h2>
<p>Before diving into specific AI models, it’s important to understand the broader privacy context in which psychological research operates:</p>
<p><strong>1. Regulatory Requirements</strong></p>
<p>Psychological research is subject to various regulations that protect participant privacy:</p>
<ul class="simple">
<li><p><strong>General Data Protection Regulation (GDPR)</strong> in the EU imposes strict requirements on the processing of personal data, with special protections for sensitive categories including health and psychological information (European Parliament, 2016).</p></li>
<li><p><strong>Health Insurance Portability and Accountability Act (HIPAA)</strong> in the US regulates protected health information, which may include psychological data in clinical contexts.</p></li>
<li><p><strong>Institutional Review Board (IRB) Requirements</strong> at most research institutions mandate specific privacy protections for human subjects data.</p></li>
</ul>
<p><strong>2. Psychological Data Sensitivity</strong></p>
<p>Data collected in psychological research is often inherently sensitive:</p>
<ul class="simple">
<li><p>Mental health assessments may reveal psychiatric conditions</p></li>
<li><p>Personal narratives often contain identifying details</p></li>
<li><p>Behavioral measures can reveal patterns unique to individuals</p></li>
<li><p>Longitudinal studies track changes in individuals over time</p></li>
</ul>
<p><strong>3. Participant Expectations</strong></p>
<p>Research participants typically expect that their data will be:</p>
<ul class="simple">
<li><p>Used only for the purposes they consented to</p></li>
<li><p>Kept confidential and secure</p></li>
<li><p>Not shared with commercial entities without explicit permission</p></li>
<li><p>Protected from re-identification</p></li>
</ul>
<p>These expectations create ethical obligations beyond regulatory compliance, particularly when introducing new technologies into the research process.</p>
</section>
<section id="closed-api-llms-vs-open-source-models-a-privacy-comparison">
<h2>Closed API LLMs vs. Open-Source Models: A Privacy Comparison<a class="headerlink" href="#closed-api-llms-vs-open-source-models-a-privacy-comparison" title="Link to this heading"></a></h2>
<p>When integrating LLMs into research, one of the most consequential decisions is whether to use closed API models (like OpenAI’s GPT-4 or Anthropic’s Claude) or open-source models that can be run locally (such as models from the LLaMA, Mistral, or BLOOM families).</p>
<p><strong>Closed API LLMs: Privacy Considerations</strong></p>
<p>When using closed API models, researchers send data to external servers owned by the model provider:</p>
<ul class="simple">
<li><p><strong>Data Transmission</strong>: Participant data (or data about participants) leaves your secure research environment and travels over the internet to the provider’s servers.</p></li>
<li><p><strong>Data Retention</strong>: Many providers retain query data for some period. For example, OpenAI previously retained API queries for 30 days by default for service improvement, though policies can change and opt-out options may be available (OpenAI, 2023).</p></li>
<li><p><strong>Terms of Service</strong>: API providers typically have terms that specify how they can use data sent through their services. These terms may change over time and should be carefully reviewed.</p></li>
<li><p><strong>Third-Party Access</strong>: Commercial API providers may be subject to legal demands for data from governments or other entities, potentially exposing research data to access beyond what researchers intend.</p></li>
<li><p><strong>Model Training</strong>: Some providers may use queries to improve their models unless researchers explicitly opt out. This could theoretically incorporate participant data into future model versions.</p></li>
</ul>
<p>For example, if a researcher uses ChatGPT to analyze open-ended survey responses about mental health experiences, those sensitive testimonials are transmitted to OpenAI’s servers, where they may be stored according to the company’s data retention policies. Researchers must consider whether this aligns with the confidentiality promised to participants.</p>
<p><strong>Open-Source Models: Privacy Advantages</strong></p>
<p>Open-source models that can be run locally or on secured cloud infrastructure offer several privacy advantages:</p>
<ul class="simple">
<li><p><strong>Data Containment</strong>: Participant data never leaves the researcher’s controlled environment, significantly reducing transmission risks.</p></li>
<li><p><strong>No Third-Party Exposure</strong>: The data is not exposed to commercial entities or their changing terms of service.</p></li>
<li><p><strong>Complete Control</strong>: Researchers determine their own data retention and security policies without depending on external providers.</p></li>
<li><p><strong>Audit Transparency</strong>: The model’s code is available for inspection, allowing for verification of how data is processed.</p></li>
<li><p><strong>Compliance Simplification</strong>: It’s often easier to satisfy IRB requirements and regulatory compliance when data stays within established secure research environments.</p></li>
</ul>
<p>These advantages make open-source models particularly attractive for highly sensitive research contexts. For instance, when analyzing therapy session transcripts or clinical interview data, keeping all processing in-house provides stronger privacy protections (Abdurahman et al., 2024).</p>
<p><strong>Performance vs. Privacy Trade-offs</strong></p>
<p>While open-source models offer privacy advantages, there are trade-offs to consider:</p>
<ul class="simple">
<li><p><strong>Computational Requirements</strong>: Running state-of-the-art open models locally requires significant computational resources (GPUs, memory, etc.).</p></li>
<li><p><strong>Technical Expertise</strong>: Local deployment requires more technical knowledge than using APIs.</p></li>
<li><p><strong>Performance Gap</strong>: Though rapidly closing, some open-source models may not yet match the capabilities of leading closed API models.</p></li>
<li><p><strong>Maintenance Burden</strong>: Locally deployed models require maintenance and updates, creating additional work for research teams.</p></li>
</ul>
<p>Recent research has shown that for specific research tasks, smaller open models (e.g., 7B parameter models) can perform competitively with much larger closed models (175B+ parameters) when properly fine-tuned (Abdurahman et al., 2024). This suggests that the privacy-performance trade-off is becoming less stark as open models improve.</p>
</section>
<section id="practical-privacy-preservation-strategies">
<h2>Practical Privacy Preservation Strategies<a class="headerlink" href="#practical-privacy-preservation-strategies" title="Link to this heading"></a></h2>
<p>Beyond the fundamental choice of model type, researchers can implement various strategies to enhance privacy protection:</p>
<p><strong>1. Data Minimization</strong></p>
<ul class="simple">
<li><p>Only send the specific data needed for the task when using APIs</p></li>
<li><p>Remove personally identifiable information (PII) before processing with any AI system</p></li>
<li><p>Use pseudonyms or ID codes instead of real names</p></li>
<li><p>Consider aggregating data when individual-level processing isn’t necessary</p></li>
</ul>
<p><strong>2. Local Preprocessing and Postprocessing</strong></p>
<ul class="simple">
<li><p>Perform anonymization locally before sending data to API models</p></li>
<li><p>Use local tools to filter out potentially identifying details</p></li>
<li><p>Process raw data locally and only send derived features to external APIs when necessary</p></li>
</ul>
<p><strong>3. Secure Model Deployment</strong></p>
<ul class="simple">
<li><p>When using open-source models, deploy them on secure infrastructure</p></li>
<li><p>Implement proper authentication and access controls</p></li>
<li><p>Ensure data-at-rest encryption for stored queries and responses</p></li>
<li><p>Consider air-gapped systems for particularly sensitive data</p></li>
</ul>
<p><strong>4. Consent and Transparency</strong></p>
<ul class="simple">
<li><p>Explicitly inform participants if their data will be processed by AI systems</p></li>
<li><p>Explain in clear language how the data will flow and what privacy measures are in place</p></li>
<li><p>Consider offering opt-out options for AI processing</p></li>
<li><p>Document all AI processing in your research protocol for IRB review</p></li>
</ul>
<p><strong>5. Synthetic Data Approaches</strong></p>
<ul class="simple">
<li><p>Use generative AI to create synthetic datasets that preserve statistical properties without exposing real participant data</p></li>
<li><p>Train models on synthetic data for preliminary analyses</p></li>
<li><p>Share synthetic rather than real data with collaborators when possible</p></li>
</ul>
<p>Kang et al. (2024) demonstrated an effective approach using synthetic data generation for depression prediction. By generating artificial clinical interview snippets that maintained the statistical properties of real interviews without exposing actual patient data, they were able to train improved prediction models while preserving privacy.</p>
</section>
<section id="hybrid-approaches-balancing-privacy-and-capability">
<h2>Hybrid Approaches: Balancing Privacy and Capability<a class="headerlink" href="#hybrid-approaches-balancing-privacy-and-capability" title="Link to this heading"></a></h2>
<p>Rather than viewing the choice as binary, many researchers are adopting hybrid approaches that leverage different models for different tasks based on sensitivity:</p>
<p><strong>1. Sensitivity-Based Model Selection</strong></p>
<p>Match the model deployment type to the sensitivity of the data being processed:</p>
<ul class="simple">
<li><p><strong>Low Sensitivity</strong>: General survey design, literature summarization, or code generation → API models may be appropriate</p></li>
<li><p><strong>Moderate Sensitivity</strong>: De-identified response analysis or aggregate data processing → Fine-tuned open models or API models with strong controls</p></li>
<li><p><strong>High Sensitivity</strong>: Individual-level clinical data, therapy transcripts, or identifiable information → Locally deployed open-source models only</p></li>
</ul>
<p><strong>2. Task Segregation</strong></p>
<p>Divide research workflows to keep sensitive data local:</p>
<ul class="simple">
<li><p>Use API models for generating survey questions, but open models for analyzing responses</p></li>
<li><p>Generate synthetic respondents via API, but process real participant data locally</p></li>
<li><p>Develop analysis code using APIs, but run the analysis on sensitive data using local deployment</p></li>
</ul>
<p><strong>3. Emerging Middle-Ground Solutions</strong></p>
<p>The landscape is evolving with new options that aim to provide both performance and privacy:</p>
<ul class="simple">
<li><p><strong>On-premises API deployments</strong>: Some providers now offer options to deploy their models within a customer’s infrastructure</p></li>
<li><p><strong>API providers with specialized privacy tiers</strong>: Enterprise offerings with enhanced privacy guarantees</p></li>
<li><p><strong>Fine-tuned smaller models</strong>: Specialized open models tuned for specific psychological applications</p></li>
</ul>
</section>
<section id="responsible-documentation-and-transparency">
<h2>Responsible Documentation and Transparency<a class="headerlink" href="#responsible-documentation-and-transparency" title="Link to this heading"></a></h2>
<p>Regardless of the approach chosen, thorough documentation is essential for responsible research:</p>
<p><strong>1. Method Transparency in Publications</strong></p>
<p>When reporting research using LLMs, always document:</p>
<ul class="simple">
<li><p>Which specific models were used (including versions)</p></li>
<li><p>How data was processed and what privacy measures were implemented</p></li>
<li><p>Any limitations or potential risks of the approach</p></li>
<li><p>Validation procedures used to ensure quality</p></li>
</ul>
<p><strong>2. IRB Protocol Specificity</strong></p>
<p>When submitting research protocols to IRBs, provide detailed information about:</p>
<ul class="simple">
<li><p>Data flows between systems</p></li>
<li><p>Privacy safeguards</p></li>
<li><p>Model provider terms of service (if using APIs)</p></li>
<li><p>Participant consent language regarding AI processing</p></li>
</ul>
<p><strong>3. Reproducibility Considerations</strong></p>
<p>The model choice also affects research reproducibility:</p>
<ul class="simple">
<li><p>Closed API models may change over time, potentially affecting results</p></li>
<li><p>Open-source models can be archived with specific weights to ensure computational reproducibility</p></li>
<li><p>Document random seeds and any sampling parameters used to enhance reproducibility</p></li>
</ul>
<p>Abdurahman et al. (2024) emphasize that using open models can enhance scientific reproducibility by allowing researchers to specify and share the exact model version used, avoiding the “moving target” problem that can occur with regularly updated API models.</p>
</section>
<section id="case-study-privacy-preserving-clinical-assessment">
<h2>Case Study: Privacy-Preserving Clinical Assessment<a class="headerlink" href="#case-study-privacy-preserving-clinical-assessment" title="Link to this heading"></a></h2>
<p>To illustrate these principles in practice, consider a hypothetical research project developing an AI-assisted clinical assessment tool for anxiety disorders:</p>
<p><strong>Initial Approach (Privacy Concerns)</strong>:
* Researchers planned to use a commercial API to analyze transcript data from clinical interviews
* Raw interview transcripts would be sent to the API for sentiment analysis and symptom detection
* Privacy review identified serious concerns with sending identifiable clinical data to external servers</p>
<p><strong>Revised Approach (Privacy-Preserving)</strong>:
* Team deployed an open-source 7B parameter model on a secure university server
* Model was fine-tuned on synthetic clinical data to improve performance on anxiety assessment
* All processing occurred within the university’s HIPAA-compliant infrastructure
* Only aggregated, de-identified results were reported externally</p>
<p><strong>Result</strong>: The research proceeded with stronger privacy protections, and while the analysis required more technical setup, the team avoided exposing sensitive clinical information to third parties. Performance was comparable to the API-based approach for this specific clinical assessment task.</p>
</section>
<section id="future-directions-in-privacy-preserving-ai">
<h2>Future Directions in Privacy-Preserving AI<a class="headerlink" href="#future-directions-in-privacy-preserving-ai" title="Link to this heading"></a></h2>
<p>The landscape of privacy-preserving AI is rapidly evolving. Several promising approaches may further improve the balance between capability and privacy:</p>
<p><strong>1. Federated Learning</strong></p>
<p>Federated learning allows models to be trained across multiple institutions without sharing raw data. Only model updates are shared, not the underlying data itself. This approach could enable collaborative model improvement while keeping sensitive psychological data within each institution’s secure environment.</p>
<p><strong>2. Differential Privacy</strong></p>
<p>Differential privacy techniques add noise to data or model outputs to mathematically guarantee privacy while preserving overall statistical properties. As these techniques mature, they may offer new ways to balance privacy and utility in psychological AI applications.</p>
<p><strong>3. Homomorphic Encryption</strong></p>
<p>This advanced encryption approach allows computations to be performed on encrypted data without decrypting it first. While still computationally intensive, future developments could enable secure processing of encrypted psychological data even in cloud environments.</p>
<p><strong>4. Dedicated Research Models</strong></p>
<p>There is growing momentum toward developing LLMs specifically designed for scientific research, with appropriate privacy guarantees and governance models aligned with research ethics rather than commercial priorities.</p>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading"></a></h2>
<p>Privacy considerations are fundamental, not peripheral, to the responsible use of generative AI in psychological research. By thoughtfully evaluating the privacy implications of different approaches, researchers can harness the power of these new tools while upholding their ethical obligations to participants.</p>
<p>The choice between closed API models and open-source alternatives represents one of the most consequential decisions affecting data privacy. While closed models may offer convenience and cutting-edge performance, open-source models deployed locally provide stronger privacy guarantees that align well with the sensitive nature of much psychological data (Abdurahman et al., 2024).</p>
<p>As this field continues to evolve, staying informed about emerging best practices, regularly reassessing privacy approaches, and maintaining transparency with participants and IRBs will be essential to conducting both innovative and ethical AI-augmented psychological research.</p>
<p>In the next lecture, we will turn our attention to the practical analysis of Likert-scale data, examining how traditional statistical approaches can be complemented by new AI-enabled techniques.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="lecture_02_1_interactive_ai_surveys.html" class="btn btn-neutral float-left" title="Lecture 02.1 – Interactive AI Surveys" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="lecture_02_3_bfitraittalk_ai_tutorial.html" class="btn btn-neutral float-right" title="Lecture 02.4 - Conversational AI Survey (BFITraitTalk_AI Tutorial)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>