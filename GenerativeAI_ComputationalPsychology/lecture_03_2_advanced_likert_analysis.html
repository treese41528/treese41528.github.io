

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Lecture 03.2 – Advanced Likert Analysis &mdash; Generative AI in Psychological Research 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/documentation_options.js?v=f2a433a1"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Generative AI in Psychological Research
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="lecture_overview.html">Generative AI in Psychological Research: Course Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Module 1: Foundations</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="lecture_01_1_intro_to_genai_psychology.html">Lecture 01.1 – Introduction to Generative AI in Psychology</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture_01_2_survey_design_with_llms.html">Lecture 01.2 – Survey Design with Large Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture_01_3_synthetic_respondents.html">Lecture 01.3 – Synthetic Respondents: Simulation and Supplementation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Module 2: Data Collection</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="lecture_02_1_interactive_ai_surveys.html">Lecture 02.1 – Interactive AI Surveys</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture_02_2_privacy_considerations.html">Lecture 02.2 – Privacy Considerations</a></li>
<li class="toctree-l1"><a class="reference internal" href="lecture_02_3_bfitraittalk_ai_tutorial.html">Lecture 02.4 - Conversational AI Survey (BFITraitTalk_AI Tutorial)</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Generative AI in Psychological Research</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Lecture 03.2 – Advanced Likert Analysis</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/lecture_03_2_advanced_likert_analysis.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="lecture-03-2-advanced-likert-analysis">
<h1>Lecture 03.2 – Advanced Likert Analysis<a class="headerlink" href="#lecture-03-2-advanced-likert-analysis" title="Link to this heading">¶</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">¶</a></h2>
<p>Building on our previous lecture’s introduction to basic Likert-scale analysis, we now turn to more advanced analytical techniques. While fundamental approaches like reliability analysis and descriptive statistics form the foundation of Likert data analysis, more sophisticated methods are often necessary to fully leverage the rich information contained in psychometric scales.</p>
<p>This lecture explores advanced statistical techniques for analyzing Likert-scale data, including factor analysis, structural equation modeling, and specialized regression approaches (Fabrigar et al., 1999). We’ll also examine how generative AI can enhance these complex analyses while discussing their limitations and appropriate applications. Our goal is to equip researchers with a comprehensive analytical toolkit that balances statistical sophistication with practical implementation.</p>
<p>Throughout the lecture, we’ll provide concrete examples using R and Python to demonstrate these techniques, making advanced methods more accessible to computational psychology researchers.</p>
</section>
<section id="factor-analysis-for-likert-scales">
<h2>Factor Analysis for Likert Scales<a class="headerlink" href="#factor-analysis-for-likert-scales" title="Link to this heading">¶</a></h2>
<p>Factor analysis is a powerful technique for uncovering the underlying structure of Likert-scale data. It helps researchers identify latent constructs that explain patterns of correlations among observed variables.</p>
<p><strong>1. Exploratory Factor Analysis (EFA)</strong></p>
<p>EFA is used when researchers are uncertain about the underlying structure of their data:</p>
<ul class="simple">
<li><p><strong>Purpose</strong>: To discover the number of factors (latent constructs) and how observed variables (items) relate to them.</p></li>
<li><p><strong>When to Use</strong>: During scale development, when validating new measures, or when exploring the structure of existing scales in new populations.</p></li>
<li><p><strong>Key Decisions</strong>:</p>
<ul>
<li><p><strong>Extraction Method</strong>: Principal Axis Factoring is often preferred for psychological constructs as it focuses on shared variance (Fabrigar et al., 1999).</p></li>
<li><p><strong>Rotation Method</strong>: Varimax (orthogonal) assumes factors are uncorrelated; Oblimin or Promax (oblique) allow factors to correlate—often more realistic for psychological constructs.</p></li>
<li><p><strong>Number of Factors</strong>: Determined using multiple criteria, including eigenvalues &gt;1 (Kaiser criterion), scree plot examination, parallel analysis, and theoretical interpretability (Costello &amp; Osborne, 2005).</p></li>
</ul>
</li>
<li><p><strong>Interpretation</strong>:</p>
<ul>
<li><p>Factor loadings represent correlations between items and factors</p></li>
<li><p>Loadings ≥ 0.40 are typically considered meaningful</p></li>
<li><p>Items that load strongly on one factor and weakly on others show good “simple structure”</p></li>
</ul>
</li>
</ul>
<p><strong>2. Confirmatory Factor Analysis (CFA)</strong></p>
<p>CFA tests how well a pre-specified factor structure fits the data:</p>
<ul class="simple">
<li><p><strong>Purpose</strong>: To verify hypothesized relationships between observed variables and latent constructs.</p></li>
<li><p><strong>When to Use</strong>: When testing theory-driven models, validating established scales, or confirming structures identified in EFA.</p></li>
<li><p><strong>Model Specification</strong>: Researchers must specify which items load on which factors, whether factors correlate, and any error covariances.</p></li>
<li><p><strong>Fit Indices</strong>: Multiple indices assess how well the model fits the data:</p>
<ul>
<li><p><strong>Comparative Fit Index (CFI)</strong> and <strong>Tucker-Lewis Index (TLI)</strong>: Values &gt;0.90 indicate acceptable fit, &gt;0.95 good fit</p></li>
<li><p><strong>Root Mean Square Error of Approximation (RMSEA)</strong>: Values &lt;0.08 suggest acceptable fit, &lt;0.05 good fit</p></li>
<li><p><strong>Standardized Root Mean Square Residual (SRMR)</strong>: Values &lt;0.08 indicate good fit</p></li>
</ul>
</li>
<li><p><strong>Modification</strong>: If fit is poor, modification indices may suggest improvements, though changes should be theoretically justified.</p></li>
</ul>
<p><strong>3. Ordinal Factor Analysis</strong></p>
<p>Standard factor analysis assumes continuous variables, but Likert items are ordinal. Specialized approaches include:</p>
<ul class="simple">
<li><p><strong>Polychoric Correlations</strong>: These estimate the correlations between the continuous latent variables presumed to underlie ordinal responses.</p></li>
<li><p><strong>Diagonally Weighted Least Squares (DWLS)</strong>: An estimation method better suited for ordinal data than maximum likelihood.</p></li>
<li><p><strong>Item Response Theory (IRT)</strong>: A more complex approach that models the probability of specific responses as a function of the latent trait being measured.</p></li>
</ul>
<p>These approaches are particularly important when working with Likert scales that have few response options (e.g., 3 or 5 points) or highly skewed distributions.</p>
<p><strong>R Implementation Example (EFA)</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">psych</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">GPArotation</span><span class="p">)</span>

<span class="c1"># Assuming &#39;likert_data&#39; contains your Likert items</span>

<span class="c1"># Compute polychoric correlation matrix for ordinal data</span>
<span class="n">poly_cor</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">polychoric</span><span class="p">(</span><span class="n">likert_data</span><span class="p">)</span>

<span class="c1"># Determine number of factors using parallel analysis</span>
<span class="nf">fa.parallel</span><span class="p">(</span><span class="n">poly_cor</span><span class="o">$</span><span class="n">rho</span><span class="p">,</span><span class="w"> </span><span class="n">n.obs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">nrow</span><span class="p">(</span><span class="n">likert_data</span><span class="p">),</span><span class="w"> </span><span class="n">fa</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;fa&quot;</span><span class="p">)</span>

<span class="c1"># Perform EFA with oblique rotation (allowing factors to correlate)</span>
<span class="n">efa_result</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">fa</span><span class="p">(</span><span class="n">poly_cor</span><span class="o">$</span><span class="n">rho</span><span class="p">,</span><span class="w"> </span><span class="n">nfactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">rotate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;oblimin&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">fm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;pa&quot;</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">efa_result</span><span class="o">$</span><span class="n">loadings</span><span class="p">,</span><span class="w"> </span><span class="n">cutoff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">)</span>

<span class="c1"># Visualize the factor structure</span>
<span class="nf">fa.diagram</span><span class="p">(</span><span class="n">efa_result</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Python Implementation Example (CFA)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">factor_analyzer</span><span class="w"> </span><span class="kn">import</span> <span class="n">FactorAnalyzer</span><span class="p">,</span> <span class="n">calculate_bartlett_sphericity</span><span class="p">,</span> <span class="n">calculate_kmo</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">lavaan</span>

<span class="c1"># Check if data is suitable for factor analysis</span>
<span class="n">chi_square_value</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">calculate_bartlett_sphericity</span><span class="p">(</span><span class="n">likert_data</span><span class="p">)</span>
<span class="n">kmo_all</span><span class="p">,</span> <span class="n">kmo_model</span> <span class="o">=</span> <span class="n">calculate_kmo</span><span class="p">(</span><span class="n">likert_data</span><span class="p">)</span>

<span class="c1"># Confirmatory Factor Analysis using lavaan via rpy2 (Python interface to R)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">rpy2.robjects</span><span class="w"> </span><span class="kn">import</span> <span class="n">pandas2ri</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">rpy2.robjects.packages</span><span class="w"> </span><span class="kn">import</span> <span class="n">importr</span>

<span class="n">pandas2ri</span><span class="o">.</span><span class="n">activate</span><span class="p">()</span>
<span class="n">lavaan</span> <span class="o">=</span> <span class="n">importr</span><span class="p">(</span><span class="s1">&#39;lavaan&#39;</span><span class="p">)</span>

<span class="c1"># Define CFA model (example with two factors)</span>
<span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="s1"># Measurement model</span>
<span class="s1">Factor1 =~ item1 + item2 + item3 + item4</span>
<span class="s1">Factor2 =~ item5 + item6 + item7 + item8</span>
<span class="s1">&#39;&#39;&#39;</span>

<span class="c1"># Fit model</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">lavaan</span><span class="o">.</span><span class="n">cfa</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">likert_data</span><span class="p">,</span> <span class="n">ordered</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Get summary</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">lavaan</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">fit</span><span class="o">.</span><span class="n">measures</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">standardized</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="structural-equation-modeling-for-likert-data">
<h2>Structural Equation Modeling for Likert Data<a class="headerlink" href="#structural-equation-modeling-for-likert-data" title="Link to this heading">¶</a></h2>
<p>Structural equation modeling (SEM) extends factor analysis to examine relationships between latent variables, not just their measurement structure.</p>
<p><strong>1. Basic SEM Concepts</strong></p>
<p>SEM combines measurement models (similar to CFA) with structural models (paths between latent variables):</p>
<ul class="simple">
<li><p><strong>Measurement Model</strong>: Specifies how latent constructs are measured by observed variables (Likert items)</p></li>
<li><p><strong>Structural Model</strong>: Defines hypothesized relationships between latent constructs (e.g., whether anxiety predicts depression)</p></li>
<li><p><strong>Complete SEM</strong>: Integrates both components to test complex psychological theories</p></li>
</ul>
<p><strong>2. SEM Applications with Likert Data</strong></p>
<p>SEM offers several powerful applications for psychological research using Likert scales:</p>
<ul class="simple">
<li><p><strong>Mediation Analysis</strong>: Testing whether the effect of one variable on another operates through a third variable</p></li>
<li><p><strong>Multi-group Analysis</strong>: Examining whether the same measurement or structural model holds across different groups (e.g., gender, culture)</p></li>
<li><p><strong>Longitudinal Analysis</strong>: Modeling change over time in latent constructs measured by Likert scales</p></li>
<li><p><strong>Method Effects</strong>: Accounting for systematic variance due to measurement artifacts, such as negatively-worded items</p></li>
</ul>
<p><strong>3. Handling Ordinal Data in SEM</strong></p>
<p>Like factor analysis, SEM traditionally assumes continuous variables. For Likert data:</p>
<ul class="simple">
<li><p><strong>Robust Maximum Likelihood (MLR)</strong>: Works reasonably well with 5+ response categories and approximately normal distributions</p></li>
<li><p><strong>Weighted Least Squares (WLS)</strong> or <strong>DWLS</strong>: More appropriate for clearly ordinal data (few response options or skewed distributions)</p></li>
<li><p><strong>Ordinal Variable Specification</strong>: In software like lavaan, items can be declared as ordinal, automatically triggering appropriate estimation methods</p></li>
</ul>
<p><strong>R Implementation Example (Mediation SEM)</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">lavaan</span><span class="p">)</span>

<span class="c1"># Define a mediation model</span>
<span class="n">med_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="s">&#39;</span>
<span class="s">  # Measurement models</span>
<span class="s">  Stress =~ stress1 + stress2 + stress3 + stress4</span>
<span class="s">  SocialSupport =~ support1 + support2 + support3</span>
<span class="s">  MentalHealth =~ mhealth1 + mhealth2 + mhealth3 + mhealth4</span>

<span class="s">  # Structural model</span>
<span class="s">  MentalHealth ~ c*Stress + b*SocialSupport</span>
<span class="s">  SocialSupport ~ a*Stress</span>

<span class="s">  # Indirect effect (a*b)</span>
<span class="s">  indirect := a*b</span>
<span class="s">  total := c + (a*b)</span>
<span class="s">&#39;</span>

<span class="c1"># Fit the model, specifying ordinal variables</span>
<span class="n">fit</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sem</span><span class="p">(</span><span class="n">med_model</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">likert_data</span><span class="p">,</span>
<span class="w">          </span><span class="n">ordered</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;stress1&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;stress2&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;stress3&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;stress4&quot;</span><span class="p">,</span>
<span class="w">                      </span><span class="s">&quot;support1&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;support2&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;support3&quot;</span><span class="p">,</span>
<span class="w">                      </span><span class="s">&quot;mhealth1&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;mhealth2&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;mhealth3&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;mhealth4&quot;</span><span class="p">))</span>

<span class="c1"># Summarize results</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">standardized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">fit.measures</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>

<span class="c1"># Test indirect effect</span>
<span class="nf">parameterEstimates</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">boot.ci.type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;bca.simple&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">standardized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="specialized-regression-approaches-for-likert-data">
<h2>Specialized Regression Approaches for Likert Data<a class="headerlink" href="#specialized-regression-approaches-for-likert-data" title="Link to this heading">¶</a></h2>
<p>When Likert scales serve as dependent variables or individual Likert items are analyzed, specialized regression approaches may be appropriate.</p>
<p><strong>1. Ordinal Logistic Regression</strong></p>
<p>This approach respects the ordinal nature of Likert items:</p>
<ul class="simple">
<li><p><strong>Purpose</strong>: To predict responses on an ordinal scale (e.g., a single Likert item)</p></li>
<li><p><strong>Assumptions</strong>: Proportional odds (the effect of predictors is consistent across response thresholds)</p></li>
<li><p><strong>Interpretation</strong>: Coefficients represent log-odds of higher versus lower responses; exponentiated coefficients are odds ratios</p></li>
<li><p><strong>Advantage</strong>: Properly accounts for the ordinal nature of the data, unlike linear regression</p></li>
</ul>
<p><strong>2. Mixed-Effects Models</strong></p>
<p>These models are valuable when analyzing nested data structures:</p>
<ul class="simple">
<li><p><strong>Purpose</strong>: To account for dependencies in data (e.g., multiple Likert responses from the same participants, or participants nested within groups)</p></li>
<li><p><strong>Components</strong>: Fixed effects (regular predictors) and random effects (accounting for clustering)</p></li>
<li><p><strong>Applications</strong>: Repeated measures designs, longitudinal studies, or multilevel sampling</p></li>
<li><p><strong>Implementation</strong>: Can be combined with ordinal regression for ordinal outcomes or use linear mixed models for scale scores</p></li>
</ul>
<p><strong>3. Bayesian Approaches</strong></p>
<p>Bayesian methods offer advantages for complex models with Likert data:</p>
<ul class="simple">
<li><p><strong>Flexibility</strong>: Can handle ordinal data naturally through appropriate model specification</p></li>
<li><p><strong>Small Samples</strong>: Often more stable than frequentist approaches with smaller sample sizes</p></li>
<li><p><strong>Prior Information</strong>: Can incorporate existing knowledge about parameters</p></li>
<li><p><strong>Full Distributions</strong>: Provides complete posterior distributions rather than just point estimates</p></li>
</ul>
<p><strong>R Implementation Example (Ordinal Regression)</strong></p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">effects</span><span class="p">)</span>

<span class="c1"># Assuming &#39;likert_item&#39; is a single 5-point Likert item</span>
<span class="c1"># and we have predictors &#39;age&#39;, &#39;gender&#39;, and &#39;education&#39;</span>

<span class="c1"># Convert to ordered factor if not already</span>
<span class="n">likert_data</span><span class="o">$</span><span class="n">likert_item</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">factor</span><span class="p">(</span><span class="n">likert_data</span><span class="o">$</span><span class="n">likert_item</span><span class="p">,</span>
<span class="w">                                   </span><span class="n">levels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">,</span>
<span class="w">                                   </span><span class="n">ordered</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>

<span class="c1"># Fit ordinal logistic regression model</span>
<span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">polr</span><span class="p">(</span><span class="n">likert_item</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">age</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gender</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">education</span><span class="p">,</span>
<span class="w">              </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">likert_data</span><span class="p">,</span>
<span class="w">              </span><span class="n">Hess</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span>

<span class="c1"># Summary of model</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Convert coefficients to odds ratios</span>
<span class="nf">exp</span><span class="p">(</span><span class="nf">coef</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>

<span class="c1"># Calculate confidence intervals</span>
<span class="nf">confint.default</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Plot effects</span>
<span class="nf">plot</span><span class="p">(</span><span class="nf">allEffects</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
</pre></div>
</div>
<p><strong>Python Implementation Example (Mixed-Effects Model)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.formula.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">smf</span>

<span class="c1"># For a scale score as outcome with repeated measures</span>
<span class="c1"># Assuming &#39;subject_id&#39; identifies participants with multiple observations</span>

<span class="c1"># Linear mixed model</span>
<span class="n">mixed_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">mixedlm</span><span class="p">(</span><span class="s2">&quot;likert_scale ~ time + condition&quot;</span><span class="p">,</span>
                         <span class="n">data</span><span class="o">=</span><span class="n">long_format_data</span><span class="p">,</span>
                         <span class="n">groups</span><span class="o">=</span><span class="n">long_format_data</span><span class="p">[</span><span class="s2">&quot;subject_id&quot;</span><span class="p">])</span>

<span class="n">mixed_result</span> <span class="o">=</span> <span class="n">mixed_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mixed_result</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="c1"># For ordinal outcomes, we would use mord package or R via rpy2</span>
</pre></div>
</div>
</section>
<section id="how-llms-can-enhance-advanced-likert-analysis">
<h2>How LLMs Can Enhance Advanced Likert Analysis<a class="headerlink" href="#how-llms-can-enhance-advanced-likert-analysis" title="Link to this heading">¶</a></h2>
<p>Large Language Models offer several capabilities that can assist with advanced Likert-scale analysis:</p>
<p><strong>1. Code Generation and Debugging</strong></p>
<p>Advanced analysis often requires complex code that can be challenging to write and debug:</p>
<ul class="simple">
<li><p>LLMs can generate syntactically correct code for sophisticated analyses like CFA, SEM, or mixed models</p></li>
<li><p>They can help troubleshoot error messages and suggest fixes</p></li>
<li><p>They can translate analysis code between languages (e.g., from R to Python or vice versa)</p></li>
</ul>
<p><strong>2. Model Specification Assistance</strong></p>
<p>SEM and factor analysis require careful model specification:</p>
<ul class="simple">
<li><p>LLMs can help translate conceptual models into proper syntax</p></li>
<li><p>They can suggest appropriate estimators for ordinal data</p></li>
<li><p>They can recommend fit indices and cutoff criteria based on current best practices</p></li>
</ul>
<p><strong>3. Interpretation Support</strong></p>
<p>Advanced analyses produce complex output that requires careful interpretation:</p>
<ul class="simple">
<li><p>LLMs can explain the meaning of various statistical parameters</p></li>
<li><p>They can help draft results sections following reporting standards</p></li>
<li><p>They can suggest visualizations that effectively communicate key findings</p></li>
</ul>
<p><strong>4. Literature-Informed Recommendations</strong></p>
<p>LLMs have been trained on vast research literature:</p>
<ul class="simple">
<li><p>They can suggest analysis approaches based on similar published studies</p></li>
<li><p>They can reference methodological papers relevant to specific analytical challenges</p></li>
<li><p>They can help identify potential limitations of various approaches</p></li>
</ul>
</section>
<section id="case-study-using-ai-to-enhance-multi-group-sem-analysis">
<h2>Case Study: Using AI to Enhance Multi-Group SEM Analysis<a class="headerlink" href="#case-study-using-ai-to-enhance-multi-group-sem-analysis" title="Link to this heading">¶</a></h2>
<p>To illustrate how AI can assist with advanced analysis, consider a hypothetical case study:</p>
<p>A researcher is examining whether a psychological resilience model works similarly across different cultural contexts. The model includes three latent factors (Personal Competence, Social Resources, and Coping Strategies), each measured by multiple Likert items, with hypothesized relationships between these factors. The researcher wants to test whether the measurement and structural components are invariant across American and Japanese samples.</p>
<p><strong>Traditional Approach</strong>:
* The researcher might struggle with complex multi-group SEM syntax
* Testing for different levels of invariance (configural, metric, scalar) requires multiple models
* Interpretation of modification indices to identify non-invariant items is complex</p>
<p><strong>AI-Enhanced Approach</strong>:
* The researcher describes the conceptual model to an LLM
* The LLM generates appropriate lavaan syntax for a multi-group SEM with measurement invariance testing
* When initial results show poor fit, the LLM suggests potential modifications based on modification indices while considering theoretical justifications
* The LLM helps interpret complex output tables and writes clear descriptions of findings for the paper
* The LLM generates publication-quality visualizations of the final model</p>
<p>This AI assistance allows the researcher to conduct a sophisticated analysis that might otherwise be daunting, while ensuring that the results are properly interpreted and communicated.</p>
</section>
<section id="limitations-and-considerations">
<h2>Limitations and Considerations<a class="headerlink" href="#limitations-and-considerations" title="Link to this heading">¶</a></h2>
<p>While advanced techniques and AI assistance offer powerful tools for Likert analysis, several limitations and considerations deserve attention:</p>
<p><strong>1. Statistical vs. Practical Significance</strong></p>
<p>Advanced methods can detect statistically significant effects that have limited practical importance:</p>
<ul class="simple">
<li><p>Large samples may yield significant but trivial effects</p></li>
<li><p>Complex models may fit statistically but lack theoretical coherence</p></li>
<li><p>Always consider effect sizes and practical implications alongside statistical significance</p></li>
</ul>
<p><strong>2. Sample Size Requirements</strong></p>
<p>Advanced techniques often require substantial sample sizes:</p>
<ul class="simple">
<li><p>Factor analysis typically needs 5-10 participants per variable (Costello &amp; Osborne, 2005)</p></li>
<li><p>SEM generally requires 100+ participants at minimum, with 200+ preferred (Kline, 2015)</p></li>
<li><p>Complex models with many parameters demand even larger samples</p></li>
<li><p>Bayesian approaches may help mitigate some sample size concerns</p></li>
</ul>
<p><strong>3. Ordinal vs. Continuous Treatment</strong></p>
<p>The debate about treating Likert data as ordinal versus continuous remains relevant:</p>
<ul class="simple">
<li><p>Methods that treat data as continuous (using means, Pearson correlations) are common and often robust</p></li>
<li><p>Methods that respect the ordinal nature of the data (using polychoric correlations, ordinal regression) are technically more appropriate</p></li>
<li><p>The practical difference diminishes with more response categories and more normal distributions</p></li>
<li><p>Researchers should consider both substantive questions and data characteristics</p></li>
</ul>
<p><strong>4. AI Limitations</strong></p>
<p>LLMs have limitations when assisting with advanced analyses:</p>
<ul class="simple">
<li><p>They may suggest code that appears correct but contains subtle statistical misunderstandings</p></li>
<li><p>They lack the ability to directly examine the researcher’s actual data</p></li>
<li><p>They may not always incorporate the very latest methodological developments</p></li>
<li><p>Human expertise remains essential for validating AI-suggested approaches</p></li>
</ul>
</section>
<section id="best-practices-for-ai-assisted-advanced-likert-analysis">
<h2>Best Practices for AI-Assisted Advanced Likert Analysis<a class="headerlink" href="#best-practices-for-ai-assisted-advanced-likert-analysis" title="Link to this heading">¶</a></h2>
<p>To maximize the benefits while mitigating the limitations of AI assistance, we recommend these best practices:</p>
<p><strong>1. Verify All AI-Generated Code</strong></p>
<ul class="simple">
<li><p>Manually review code for logical errors or inappropriate approaches</p></li>
<li><p>Run simplified test cases where you know the expected output</p></li>
<li><p>Compare results across different analytical approaches when possible</p></li>
<li><p>Consult with human statistical experts when introducing new methods</p></li>
</ul>
<p><strong>2. Maintain Theoretical Grounding</strong></p>
<ul class="simple">
<li><p>Start with theory-driven models rather than purely data-driven exploration</p></li>
<li><p>Ensure model modifications suggested by AI align with theoretical understanding</p></li>
<li><p>Question AI-suggested approaches that seem statistically elegant but theoretically dubious</p></li>
<li><p>Remember that AI lacks domain expertise in your specific research area</p></li>
</ul>
<p><strong>3. Document AI Assistance Transparently</strong></p>
<ul class="simple">
<li><p>Record which parts of analysis were AI-assisted</p></li>
<li><p>Note any modifications made to AI-suggested code or interpretations</p></li>
<li><p>Consider methodological transparency statements in publications</p></li>
<li><p>Share both AI-suggested and human-revised analysis scripts when possible</p></li>
</ul>
<p><strong>4. Use Multiple AI Queries for Critical Decisions</strong></p>
<ul class="simple">
<li><p>Ask the same analytical question in different ways to see if responses converge</p></li>
<li><p>Explicitly request AI to critique its own suggestions</p></li>
<li><p>Ask for explanations of the reasoning behind suggested approaches</p></li>
<li><p>Compare suggestions from different AI systems when possible</p></li>
</ul>
<p><strong>5. Invest in Your Statistical Understanding</strong></p>
<ul class="simple">
<li><p>Use AI as a learning tool, not just a solution provider</p></li>
<li><p>Ask AI to explain statistical concepts you don’t fully understand</p></li>
<li><p>Verify key information through traditional sources (textbooks, peer-reviewed papers)</p></li>
<li><p>Gradually build expertise rather than remaining dependent on AI assistance</p></li>
</ul>
</section>
<section id="future-directions">
<h2>Future Directions<a class="headerlink" href="#future-directions" title="Link to this heading">¶</a></h2>
<p>The landscape of Likert-scale analysis continues to evolve, with several promising developments on the horizon:</p>
<p><strong>1. Advanced Measurement Models</strong></p>
<ul class="simple">
<li><p>Network psychometrics views psychological constructs as complex systems of interacting components rather than reflections of latent variables (Borsboom, 2017)</p></li>
<li><p>Dynamic measurement models incorporate temporal dependencies in psychological processes</p></li>
<li><p>These approaches may provide more nuanced perspectives than traditional factor-analytic models</p></li>
</ul>
<p><strong>2. Integration of Qualitative and Quantitative Data</strong></p>
<ul class="simple">
<li><p>Mixed-methods approaches that combine Likert scales with open-ended responses are becoming more sophisticated</p></li>
<li><p>AI text analysis can help bridge qualitative and quantitative traditions by identifying themes in open text that complement Likert responses</p></li>
<li><p>Multimodal measurement that integrates self-report with behavioral or physiological data</p></li>
</ul>
<p><strong>3. Personalized Measurement</strong></p>
<ul class="simple">
<li><p>Adaptive testing approaches that customize item presentation based on previous responses</p></li>
<li><p>Person-specific models that acknowledge the unique structure of psychological constructs within individuals</p></li>
<li><p>AI-enhanced systems that can identify idiosyncratic response patterns</p></li>
</ul>
<p><strong>4. Enhanced Visualization and Communication</strong></p>
<ul class="simple">
<li><p>Interactive data visualization techniques that allow exploration of complex patterns in Likert data</p></li>
<li><p>Automated explanation generation that helps researchers and audiences understand complex statistical results</p></li>
<li><p>Translation of technical findings into accessible language for various stakeholders</p></li>
</ul>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">¶</a></h2>
<p>Advanced Likert-scale analysis offers powerful tools for extracting rich insights from psychological measurement data. Factor analysis, structural equation modeling, and specialized regression approaches can reveal complex patterns and relationships that basic analyses might miss. These methods, when properly applied, enhance our ability to test sophisticated psychological theories and develop more refined measurement instruments.</p>
<p>The integration of generative AI into these advanced analytical workflows represents an exciting frontier in computational psychology. LLMs can reduce technical barriers, suggest innovative approaches, and help communicate complex findings—if used thoughtfully with appropriate human oversight. By combining advanced statistical techniques with AI assistance while maintaining rigorous scientific standards, researchers can push the boundaries of what’s possible with Likert-scale measurement.</p>
<p>As we conclude this lecture series on generative AI in psychological research, remember that these tools—both statistical and computational—are means to an end: better understanding of human psychology. The most sophisticated analysis is valuable only insofar as it advances our theoretical understanding and, ultimately, our ability to address real-world psychological challenges.</p>
<p>In your own research, we encourage you to explore these advanced techniques and AI enhancements while maintaining a critical perspective and strong methodological rigor. The future of psychological measurement lies not in choosing between human expertise and artificial intelligence, but in their thoughtful integration.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h2>
<p>Borsboom, D. (2017). A network theory of mental disorders. <em>World Psychiatry, 16</em>(1), 5-13. <a class="reference external" href="https://doi.org/10.1002/wps.20375">https://doi.org/10.1002/wps.20375</a></p>
<p>Costello, A. B., &amp; Osborne, J. W. (2005). Best practices in exploratory factor analysis: Four recommendations for getting the most from your analysis. <em>Practical Assessment, Research &amp; Evaluation, 10</em>(7), 1-9. <a class="reference external" href="https://doi.org/10.7275/jyj1-4868">https://doi.org/10.7275/jyj1-4868</a></p>
<p>DeVellis, R. F. (2016). <em>Scale development: Theory and applications</em> (4th ed.). SAGE Publications.</p>
<p>Fabrigar, L. R., Wegener, D. T., MacCallum, R. C., &amp; Strahan, E. J. (1999). Evaluating the use of exploratory factor analysis in psychological research. <em>Psychological Methods, 4</em>(3), 272-299. <a class="reference external" href="https://doi.org/10.1037/1082-989X.4.3.272">https://doi.org/10.1037/1082-989X.4.3.272</a></p>
<p>Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., … &amp; Oliphant, T. E. (2020). Array programming with NumPy. <em>Nature, 585</em>(7825), 357-362. <a class="reference external" href="https://doi.org/10.1038/s41586-020-2649-2">https://doi.org/10.1038/s41586-020-2649-2</a></p>
<p>Kline, R. B. (2015). <em>Principles and practice of structural equation modeling</em> (4th ed.). Guilford Press.</p>
<p>Revelle, W. (2023). <em>psych: Procedures for personality and psychological research</em> (Version 2.3.6) [R package]. Northwestern University. <a class="reference external" href="https://CRAN.R-project.org/package=psych">https://CRAN.R-project.org/package=psych</a></p>
<p>Rosseel, Y. (2012). lavaan: An R package for structural equation modeling. <em>Journal of Statistical Software, 48</em>(2), 1-36. <a class="reference external" href="https://doi.org/10.18637/jss.v048.i02">https://doi.org/10.18637/jss.v048.i02</a></p>
<p>Waskom, M. L. (2021). seaborn: Statistical data visualization. <em>Journal of Open Source Software, 6</em>(60), 3021. <a class="reference external" href="https://doi.org/10.21105/joss.03021">https://doi.org/10.21105/joss.03021</a></p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Reese.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>